{
  "feed": {
    "title": "NVIDIA Blog",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "https://blogs.nvidia.com/feed/",
      "value": "NVIDIA Blog"
    },
    "links": [
      {
        "href": "https://blogs.nvidia.com/feed/",
        "rel": "self",
        "type": "application/rss+xml"
      },
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://blogs.nvidia.com/"
      }
    ],
    "link": "https://blogs.nvidia.com/",
    "subtitle": "",
    "subtitle_detail": {
      "type": "text/html",
      "language": null,
      "base": "https://blogs.nvidia.com/feed/",
      "value": ""
    },
    "updated": "Tue, 26 Aug 2025 23:46:28 +0000",
    "updated_parsed": [
      2025,
      8,
      26,
      23,
      46,
      28,
      1,
      238,
      0
    ],
    "language": "en-US",
    "sy_updateperiod": "hourly",
    "sy_updatefrequency": "1",
    "generator_detail": {
      "name": "https://wordpress.org/?v=6.8.2"
    },
    "generator": "https://wordpress.org/?v=6.8.2"
  },
  "entries": [
    {
      "title": "Take It for a Spin: NVIDIA Rolls Out DRIVE AGX Thor Developer Kit to World’s Automotive Developers",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Take It for a Spin: NVIDIA Rolls Out DRIVE AGX Thor Developer Kit to World’s Automotive Developers"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/drive-agx-developer-kit-general-availability/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/drive-agx-developer-kit-general-availability/",
      "authors": [
        {
          "name": "Ali Kani"
        }
      ],
      "author": "Ali Kani",
      "author_detail": {
        "name": "Ali Kani"
      },
      "published": "Mon, 25 Aug 2025 15:00:51 +0000",
      "published_parsed": [
        2025,
        8,
        25,
        15,
        0,
        51,
        0,
        237,
        0
      ],
      "tags": [
        {
          "term": "Driving",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA DRIVE",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=84236",
      "guidislink": false,
      "summary": "As autonomous vehicle systems rapidly grow in complexity, equipped with reasoning vision language action models, generative AI and advanced sensor technologies, developers need tools that are powerful, efficient and built to meet automotive-grade safety requirements. The NVIDIA DRIVE AGX Thor developer kit — now available for preorder today, with delivery in September — provides developers\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/drive-agx-developer-kit-general-availability/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>As <a href=\"https://www.nvidia.com/en-us/glossary/autonomous-vehicles/\" target=\"_blank\">autonomous vehicle</a> systems rapidly grow in complexity, equipped with reasoning vision language action models, generative AI and advanced sensor technologies, developers need tools that are powerful, efficient and built to meet automotive-grade safety requirements.</p>\n<p>The NVIDIA DRIVE AGX Thor developer kit — now available for <a href=\"https://developer.nvidia.com/drive/agx#section-where-to-buy\" target=\"_blank\">preorder</a> today, with delivery in September — provides developers and researchers worldwide an advanced platform to accelerate the design, testing and deployment of AVs and intelligent mobility solutions.</p>\n<p>The developer kit is built on the <a href=\"https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/\" target=\"_blank\">NVIDIA Blackwell architecture</a>, next-generation <a href=\"https://newsroom.arm.com/blog/nvidia-drive-agx-jetson-thor-arm-neoverse\" target=\"_blank\">Arm Neoverse V3AE CPUs</a> and the <a href=\"https://developer.nvidia.com/drive/os\" target=\"_blank\">NVIDIA DriveOS</a> 7 software stack. It’s purpose-built for reasoning vision language action models and ideal for automotive development, with sufficient I/O to support surround cameras, radars and lidars, as well as common vehicle interfaces including GbE/10GbE and PCI-Express. DRIVE AGX Thor also meets the automotive industry’s stringent functional safety (ISO 26262) and cybersecurity requirements (ISO 21434).</p>\n<h2><b>The Growing DRIVE AGX Thor Ecosystem</b></h2>\n<p>The world’s leading automotive companies are building on NVIDIA DRIVE AGX Thor, including <a href=\"https://www.nvidia.com/en-us/solutions/autonomous-vehicles/partners/byd/\" target=\"_blank\">BYD</a>, GAC, IM Motors, <a href=\"https://www.nvidia.com/en-us/solutions/autonomous-vehicles/partners/li-auto/\" target=\"_blank\">Li Auto</a>, <a href=\"https://blogs.nvidia.com/blog/volvo-cars-accelerated-computing-ai/\">Volvo Cars</a>, Xiaomi and Zeekr. Autonomous trucking companies building on NVIDIA DRIVE AGX Thor include <a href=\"https://ir.aurora.tech/news-events/press-releases/detail/112/aurora-continental-and-nvidia-partner-to-deploy-driverless-trucks-at-scale\" target=\"_blank\">Aurora</a>, <a href=\"https://gatik.ai/news/press-releases/gatik-collaboration-with-nvidia/\" target=\"_blank\">Gatik,</a> <a href=\"https://plus.ai/news-and-insights/plus-advances-the-development-of-next-generation-vision-models-built-on-nvidia-drive-for-ai-processing-in-its-self-driving-software\" target=\"_blank\">PlusAI</a> and <a href=\"https://waabi.ai/nvidia-drivethor/\" target=\"_blank\">Waabi</a>.</p>\n<p>NVIDIA AV partners <a href=\"https://www.deeproute.ai/en/news-detail/711176034676805\" target=\"_blank\">DeepRoute.ai</a>, <a href=\"https://www.nvidia.com/en-us/solutions/autonomous-vehicles/partners/nuro/\" target=\"_blank\">Nuro</a>, <a href=\"https://www.prnewswire.com/news-releases/lenovo-vehicle-computing-and-weride-forge-a-strategic-partnership-using-nvidia-drive-thor-platform-to-accelerate-autonomous-driving-302092408.html\" target=\"_blank\">WeRide</a> and ZYT are using DRIVE AGX Thor for their AV software platforms. DRIVE AGX Thor production systems are available from Tier 1 suppliers <a href=\"https://www.continental.com/en-us/press/press-releases/aurora-continental-and-nvidia-partner-to-deploy-driverless-trucks-at-scale/\" target=\"_blank\">Continental Automotive</a>, <a href=\"https://www.prnewswire.com/apac/news-releases/desay-sv-unveils-cutting-edge-automotive-technologies-at-izb-2024-302291223.html\" target=\"_blank\">Desay SV</a>, <a href=\"https://www.prnewswire.com/news-releases/lenovo-vehicle-computing-and-weride-forge-a-strategic-partnership-using-nvidia-drive-thor-platform-to-accelerate-autonomous-driving-302092408.html\" target=\"_blank\">Lenovo</a>, <a href=\"https://www.magna.com/stories/news-press-release/2025/magna-and-nvidia-team-up-to-advance-next-gen-automotive-technologies\" target=\"_blank\">Magna</a> and <a href=\"https://go.qct.io/nvidia/qct-servers-powered-by-nvidia-gpus/\" target=\"_blank\">Quanta</a>.</p>\n<p>DRIVE AGX Thor is supported by a growing number of sensor and embedded technology pioneers, including <a href=\"https://www.adacore.com/nvidia\" target=\"_blank\">AdaCore</a>, <a href=\"https://www.lauterbach.com/company/partner-ecosystem/nvidia\" target=\"_blank\">Lauterbach</a>, <a href=\"https://www.ovt.com/partners/nvidia/\" target=\"_blank\">OMNIVISION</a>, <a href=\"https://www.blackberry.com/us/en/company/newsroom/press-releases/2023/blackberry-qnx-releases-ultra-scalable-high-performance-compute-ready-operating-system-to-advance-software-development-efforts-for-next-generation-vehicles-and-iot-systems\" target=\"_blank\">QNX</a> and <a href=\"https://www.vector.com/int/en/news/news/on-the-fast-track-innovators-race-to-redefine-autonomous-mobility-with-safer-and-smarter-solutions/\" target=\"_blank\">Vector</a>.</p>\n<h2><b>AV Safety From Cloud to Car</b></h2>\n<p>Designed for automotive-grade safety and security, DRIVE AGX Thor and DriveOS are key elements of <a href=\"https://blogs.nvidia.com/blog/halos-safety-system-autonomous-vehicles/\">NVIDIA Halos</a>, a comprehensive safety system that brings together NVIDIA’s automotive hardware and software safety technologies with cutting-edge AI research in AV safety.</p>\n<p>Halos offers a holistic approach to automotive safety:</p>\n<ul>\n<li>At the technology level, it spans platform, algorithmic and ecosystem safety.</li>\n<li>At the development level, it includes design-, deployment- and validation-time guardrails.</li>\n<li>At the computational level, it spans AI training to deployment, using three powerful computers — <a href=\"https://www.nvidia.com/en-us/data-center/dgx-platform/\" target=\"_blank\">NVIDIA DGX</a> for AI training, <a href=\"https://www.nvidia.com/en-us/omniverse/\" target=\"_blank\">NVIDIA Omniverse</a> and <a href=\"https://www.nvidia.com/en-us/ai/cosmos/\" target=\"_blank\">NVIDIA Cosmos</a> running on <a href=\"https://www.nvidia.com/en-us/data-center/products/ovx/\" target=\"_blank\">NVIDIA OVX</a> for simulation, and <a href=\"https://developer.nvidia.com/drive/agx\" target=\"_blank\">NVIDIA DRIVE AGX</a> for deployment.</li>\n</ul>\n<h2><b>Get Started</b></h2>\n<p>Watch the <a href=\"https://www.youtube.com/watch?v=FnBbQfXdd3o\" target=\"_blank\">NVIDIA DRIVE AGX Thor unboxing video</a> and join the <a href=\"https://developer.nvidia.com/drive/agx-sdk-program\" target=\"_blank\">NVIDIA DRIVE AGX SDK Developer Program.</a></p>\n<p>Plus, learn more about <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-thor/\" target=\"_blank\">NVIDIA Jetson AGX Thor developer kit</a> and <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-thor/\" target=\"_blank\">NVIDIA Jetson T5000 modules</a> — available today — empowering robotics developers everywhere to build the future of <a href=\"https://www.nvidia.com/en-us/glossary/generative-physical-ai/\" target=\"_blank\">physical AI</a>.</p>\n<p><i>See </i><a href=\"https://www.nvidia.com/en-eu/about-nvidia/terms-of-service/\" target=\"_blank\"><i>notice</i></a><i> regarding software product information.</i></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/automotive-comms-drive-agx-thor-1280x680-1.png",
          "type": "image/png",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/automotive-comms-drive-agx-thor-1280x680-1-842x450.png",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "NVIDIA Jetson Thor Unlocks Real-Time Reasoning for General Robotics and Physical AI",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "NVIDIA Jetson Thor Unlocks Real-Time Reasoning for General Robotics and Physical AI"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/jetson-thor-physical-ai-edge/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/jetson-thor-physical-ai-edge/",
      "authors": [
        {
          "name": "Chen Su"
        }
      ],
      "author": "Chen Su",
      "author_detail": {
        "name": "Chen Su"
      },
      "published": "Mon, 25 Aug 2025 15:00:31 +0000",
      "published_parsed": [
        2025,
        8,
        25,
        15,
        0,
        31,
        0,
        237,
        0
      ],
      "tags": [
        {
          "term": "Generative AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Robotics",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Computer Vision",
          "scheme": null,
          "label": null
        },
        {
          "term": "Digital Twin",
          "scheme": null,
          "label": null
        },
        {
          "term": "Embedded Computing",
          "scheme": null,
          "label": null
        },
        {
          "term": "Isaac",
          "scheme": null,
          "label": null
        },
        {
          "term": "Jetson",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA Isaac Sim",
          "scheme": null,
          "label": null
        },
        {
          "term": "Omniverse",
          "scheme": null,
          "label": null
        },
        {
          "term": "Physical AI",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=84194",
      "guidislink": false,
      "summary": "Robots around the world are about to get a lot smarter as physical AI developers plug in NVIDIA Jetson Thor modules — new robotics computers that can serve as the brains for robotic systems across research and industry. Robots demand rich sensor data and low-latency AI processing. Running real-time robotic applications requires significant AI compute\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/jetson-thor-physical-ai-edge/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>Robots around the world are about to get a lot smarter as physical AI developers plug in <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-thor/\" target=\"_blank\">NVIDIA Jetson Thor</a> modules — new robotics computers that can serve as the brains for robotic systems across research and industry.</p>\n<p>Robots demand rich sensor data and low-latency AI processing. Running real-time robotic applications requires significant AI compute and memory to handle concurrent data streams from multiple sensors. Jetson Thor, now in general availability, delivers 7.5x more AI compute, 3.1x more CPU performance and 2x more memory than its predecessor, the <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/\" target=\"_blank\">NVIDIA Jetson Orin</a>, to make this possible on device.</p>\n<p>This performance leap will enable roboticists to process high-speed sensor data and perform visual reasoning at the edge — workflows that were previously too slow to run in dynamic real-world environments. This opens new possibilities for multimodal AI applications such as <a href=\"https://www.nvidia.com/en-us/glossary/humanoid-robot/\" target=\"_blank\">humanoid robotics</a>.</p>\n<p></p>\n<p><a href=\"https://www.agilityrobotics.com/content/agility-robotics-powering-the-future-of-robotics-with-nvidia-jetson-thor\" target=\"_blank\">Agility Robotics</a>, a leader in humanoid robotics, has integrated NVIDIA Jetson into the fifth generation of its robot, Digit — and plans to adopt Jetson Thor as the onboard compute platform for the sixth generation of Digit. This transition will enhance Digit’s real-time perception and decision-making capabilities, supporting increasingly complex AI skills and behaviors. Digit is commercially deployed and performs logistics tasks such as stacking, loading and palletizing in warehouse and manufacturing environments.</p>\n<p>“The powerful edge processing offered by Jetson Thor will take Digit to the next level — enhancing its real-time responsiveness and expanding its abilities to a broader, more complex set of skills,” said Peggy Johnson, CEO of Agility Robotics. “With Jetson Thor, we can deliver the latest physical AI advancements to optimize operations across our customers’ warehouses and factories.”</p>\n<p>Boston Dynamics — which has been building some of the industry’s most advanced robots for over 30 years — is integrating Jetson Thor into its humanoid robot Atlas, enabling Atlas to harness formerly server-level compute, AI workload acceleration, high-bandwidth data processing and significant memory on device.</p>\n<p>Beyond humanoids, Jetson Thor will accelerate various robotic applications — such as surgical assistants, smart tractors, delivery robots, industrial manipulators and <a href=\"https://www.nvidia.com/en-us/use-cases/video-analytics-ai-agents/\" target=\"_blank\">visual AI agents</a> — with real-time inference on device for larger, more complex AI models.</p>\n<h2><b>A Giant Leap for Real-Time Robot Reasoning</b></h2>\n<p>Jetson Thor is built for generative reasoning models. It enables the next generation of <a href=\"https://www.nvidia.com/en-us/glossary/generative-physical-ai/\" target=\"_blank\">physical AI</a> agents — powered by large <a href=\"https://blogs.nvidia.com/blog/what-is-a-transformer-model/\">transformer models</a>, <a href=\"https://www.nvidia.com/en-us/glossary/vision-language-models/\" target=\"_blank\">vision language models</a> and vision language action models — to run in real time at the edge while minimizing cloud dependency.</p>\n<p>Optimized with the Jetson software stack to enable the low latency and high performance required in real-world applications, Jetson Thor supports all popular generative AI frameworks and AI reasoning models with unmatched real-time performance. These include <a href=\"https://research.nvidia.com/labs/dir/cosmos-reason1/\" target=\"_blank\">Cosmos Reason</a>, DeepSeek, Llama, Gemini and Qwen models, as well as domain-specific models for robotics like <a href=\"https://developer.nvidia.com/isaac/gr00t\" target=\"_blank\">Isaac GR00T</a> N1.5, enabling any developer to easily experiment and run inference locally.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_84198\" style=\"width: 1680px;\"><img alt=\"\" class=\"size-large wp-image-84198\" height=\"945\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/Slide1-1680x945.jpeg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-84198\">NVIDIA Jetson Thor opens new capabilities for real-time reasoning with multi-sensor input. Further performance improvement is expected with FP4 and speculative decoding optimization.</figcaption></figure>\n<p>With <a href=\"https://developer.nvidia.com/cuda-toolkit\" target=\"_blank\">NVIDIA CUDA</a> ecosystem support through its lifecycle, Jetson Thor is expected to deliver even better throughput and faster responses with future software releases.</p>\n<p>Jetson Thor modules also run the full NVIDIA AI software stack to accelerate virtually every physical AI workflow with platforms including <a href=\"https://developer.nvidia.com/isaac\" target=\"_blank\">NVIDIA Isaac</a> for robotics, <a href=\"https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/\" target=\"_blank\">NVIDIA Metropolis</a> for video analytics AI agents and <a href=\"https://developer.nvidia.com/holoscan-sdk\" target=\"_blank\">NVIDIA Holoscan</a> for sensor processing.</p>\n<p>With these software tools, developers can easily build and deploy applications, such as visual AI agents that can analyze live camera streams to monitor worker safety, humanoid robots capable of manipulation tasks in unstructured environments and smart operating rooms that guide surgeons based on data from multi-camera streams.</p>\n<h2><b>Jetson Thor Set to Advance Research Innovation </b></h2>\n<p>Research labs at Stanford University, Carnegie Mellon University and the University of Zurich are tapping Jetson Thor to push the boundaries of perception, planning and navigation models for a host of potential applications.</p>\n<p>At Carnegie Mellon’s Robotics Institute, a research team uses NVIDIA Jetson to power autonomous robots that can navigate complex, unstructured environments to conduct medical triage as well as search and rescue.</p>\n<p>“We can only do as much as the compute available allows,” said Sebastian Scherer, an associate research professor at the university and head of the <a href=\"https://theairlab.org/\" target=\"_blank\">AirLab</a>. “Years ago, there was a big disconnect between computer vision and robotics because computer vision workloads were too slow for real-time decision-making — but now, models and computing have gotten fast enough so robots can handle much more nuanced tasks.”</p>\n<p>Scherer anticipates that by upgrading from his team’s existing NVIDIA Jetson AGX Orin systems to Jetson AGX Thor developer kit, they’ll improve the performance of AI models including their award-winning <a href=\"https://github.com/MAC-VO/MAC-VO\" target=\"_blank\">MAC-VO</a> model for robot perception at the edge, boost their sensor-fusion capabilities and be able to experiment with robot fleets.</p>\n<h2><b>Wield the Strength of Jetson Thor</b></h2>\n<p>The Jetson Thor family includes a developer kit and production modules. The developer kit includes a Jetson T5000 module, a reference carrier board with abundant connectivity, an active heatsink with a fan and a power supply.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_84201\" style=\"width: 1680px;\"><img alt=\"\" class=\"wp-image-84201 size-large\" height=\"945\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/Slide2-1680x945.jpeg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-84201\">NVIDIA Jetson AGX Thor Developer Kit</figcaption></figure>\n<p>The <a href=\"https://developer.nvidia.com/embedded/ecosystem\" target=\"_blank\">Jetson ecosystem</a> supports a variety of application requirements, high-speed industrial automation protocols and sensor interfaces, accelerating time to market for enterprise developers. Hardware partners including <a href=\"https://www.advantech.com/en-us/resources/news/advantech-announces-next-gen-robotics-development-kit-with-nvidia-jetson-thor-with-holoscan-built-in\" target=\"_blank\">Advantech</a>, <a href=\"https://www.aetina.com/about-news-detail.php?i=1204\" target=\"_blank\">Aetina</a>, <a href=\"https://connecttech.com/early-success-gauntlet-integrated-solutions-nvidia-new-jetson-thor-redefining-real-time-reasoning-robotics/\" target=\"_blank\">ConnectTech</a>, <a href=\"https://www.miivii.com/index.php?s=index/show/index&amp;id=557)\" target=\"_blank\">MiiVii</a> and <a href=\"https://www.tztek.com/overview/news/robot/51\" target=\"_blank\">TZTEK</a> are building production-ready Jetson Thor systems with flexible I/O and custom configurations in various form factors.</p>\n<p>Sensor and Actuator companies including <a href=\"https://www.analog.com/en/newsroom/press-releases/2025/8-25-2025-adi-adopts-jetson-thor.html\" target=\"_blank\">Analog Devices, Inc. (ADI</a>), <a href=\"https://www.e-consystems.com/pr/ai-powered-vision-and-compute-solutions-accelerated-by-nvidia-jetson-thor.asp\" target=\"_blank\">e-con Systems</a>,  <a href=\"https://www.infineon.com/press-release/2025/INFXX202508-134\" target=\"_blank\">Infineon</a>, <a href=\"https://leopardimaging.com/leopard-imaging-launches-full-vision-solution-suite-for-nvidia-jetson-thor-powering-the-next-generation-of-physical-ai/\" target=\"_blank\">Leopard Imaging</a>, <a href=\"https://realsenseai.com/news-insights/news/RealSense-and-NVIDIA-Collaborate-to-Usher-in-the-Age-of-Physical-AI\" target=\"_blank\">RealSense</a> and <a href=\"https://www.sensing-world.com/JetsonThor/\" target=\"_blank\">Sensing</a> are using <a href=\"https://www.nvidia.com/en-us/technologies/holoscan-sensor-bridge/\" target=\"_blank\">NVIDIA Holoscan Sensor Bridge</a> — a platform that simplifies sensor fusion and data streaming — to connect sensor data from cameras, radar, lidar and more directly to GPU memory on Jetson Thor with ultralow latency.</p>\n<p>Thousands of software companies can now elevate their traditional vision AI and robotics applications with multi-AI agent workflows running on Jetson Thor. Leading adopters include <a href=\"https://openzeka.com/en/openzeka-adopts-nvidia-jetson-thor-to-power-real-time-visual-ai-agents/\" target=\"_blank\">Openzeka</a>, <a href=\"https://rebotnix.com/thor_pr25082025/\" target=\"_blank\">Rebotnix</a>, <a href=\"https://www.solomon-3d.com/news-events/press-releases/solomon-humanoid-robot-nvidia-jetson-thor-automation-taipei-2025/\" target=\"_blank\">Solomon</a> and <a href=\"https://www.vaidio.ai/blog/vaidio-with-nvidia-jetson-thor-the-next-frontier-in-vision-ai\" target=\"_blank\">Vaidio</a>.</p>\n<p>More than 2 million developers use NVIDIA technologies to accelerate robotics workflows. Get started with Jetson Thor by <a href=\"https://developer.nvidia.com/blog/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai/\" target=\"_blank\">reading the NVIDIA Technical Blog</a> and watching the developer kit walkthrough.</p>\n<p></p>\n<p>To get hands-on experience with Jetson Thor, <a href=\"https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.seeedstudio.com%2Fembodied-ai-worldwide-hackathon-home-robot.html&amp;data=05%7C02%7Ckahuynh%40nvidia.com%7Cac69585890ce4fb566aa08dde19312c7%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638914744011425383%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&amp;sdata=p2mnwVdjF%2F%2FKccs78jWNTj%2BizG8g6I3J1uJpixQls8k%3D&amp;reserved=0\" target=\"_blank\">sign up</a> to participate in upcoming hackathons with <a href=\"https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.seeedstudio.com%2Ftag%2Fnvidia.html&amp;data=05%7C02%7Ckahuynh%40nvidia.com%7C8bb7886cc7e041796a9208dde193ccbb%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638914747152417179%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&amp;sdata=2w2Ag16XhQh6TJAFyf8%2BbHHw7y4RxfABDueIk1%2F9l5o%3D&amp;reserved=0\" target=\"_blank\">Seeed Studio</a> and <a href=\"https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fhuggingface.co%2Flerobot&amp;data=05%7C02%7Ckahuynh%40nvidia.com%7C702a85d371e4438613b108dde16c9897%7C43083d15727340c1b7db39efd9ccc17a%7C0%7C0%7C638914578751950342%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&amp;sdata=Uztcbhb5Y9vYejZYxqDl9pu7CZPHMTEz9S2PRDc17gg%3D&amp;reserved=0\" target=\"_blank\">LeRobot</a> by Hugging Face.</p>\n<p>The NVIDIA Jetson AGX Thor developer kit is available now starting at $3,499. NVIDIA Jetson T5000 modules are available starting at $2,999 for 1,000 units. <a href=\"https://store.nvidia.com/jetson/store/\" target=\"_blank\">Buy now</a> from authorized NVIDIA partners.</p>\n<p>NVIDIA today also announced that the <a href=\"https://developer.nvidia.com/drive/agx\" target=\"_blank\">NVIDIA DRIVE AGX Thor</a> developer kit, which provides a platform for developing <a href=\"https://www.nvidia.com/en-us/glossary/autonomous-vehicles/\" target=\"_blank\">autonomous vehicles</a> and mobility solutions, is available for <a href=\"https://developer.nvidia.com/drive/agx#section-where-to-buy\" target=\"_blank\">preorder</a>. Deliveries are slated to start in September.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/robotics-corp-blog-jetson-thor-1080x1920-1.jpg",
          "type": "image/jpeg",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/robotics-corp-blog-jetson-thor-1080x1920-1-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "Hot Topics at Hot Chips: Inference, Networking, AI Innovation at Every Scale — All Built on NVIDIA",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Hot Topics at Hot Chips: Inference, Networking, AI Innovation at Every Scale — All Built on NVIDIA"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/hot-chips-inference-networking/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/hot-chips-inference-networking/",
      "authors": [
        {
          "name": "Dave Salvator"
        }
      ],
      "author": "Dave Salvator",
      "author_detail": {
        "name": "Dave Salvator"
      },
      "published": "Fri, 22 Aug 2025 15:00:29 +0000",
      "published_parsed": [
        2025,
        8,
        22,
        15,
        0,
        29,
        4,
        234,
        0
      ],
      "tags": [
        {
          "term": "Corporate",
          "scheme": null,
          "label": null
        },
        {
          "term": "Data Center",
          "scheme": null,
          "label": null
        },
        {
          "term": "Generative AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Networking",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "CUDA",
          "scheme": null,
          "label": null
        },
        {
          "term": "Events",
          "scheme": null,
          "label": null
        },
        {
          "term": "GeForce RTX",
          "scheme": null,
          "label": null
        },
        {
          "term": "GPU",
          "scheme": null,
          "label": null
        },
        {
          "term": "Hardware",
          "scheme": null,
          "label": null
        },
        {
          "term": "High-Performance Computing",
          "scheme": null,
          "label": null
        },
        {
          "term": "Inference",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA NIM",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA RTX",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVLink",
          "scheme": null,
          "label": null
        },
        {
          "term": "Open Source",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=84133",
      "guidislink": false,
      "summary": "AI reasoning, inference and networking will be top of mind for attendees of next week’s Hot Chips conference. A key forum for processor and system architects from industry and academia, Hot Chips — running Aug. 24-26 at Stanford University — showcases the latest innovations poised to advance AI factories and drive revenue for the trillion-dollar\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/hot-chips-inference-networking/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>AI reasoning, inference and networking will be top of mind for attendees of next week’s Hot Chips conference.</p>\n<p>A key forum for processor and system architects from industry and academia, Hot Chips — running Aug. 24-26 at Stanford University — showcases the latest innovations poised to advance <a href=\"https://www.nvidia.com/en-us/glossary/ai-factory/\" target=\"_blank\">AI factories</a> and drive revenue for the trillion-dollar data center computing market.</p>\n<p>At the conference, NVIDIA will join industry leaders including Google and Microsoft in a “tutorial” session — taking place on Sunday, Aug. 24 — that discusses designing rack-scale architecture for data centers.</p>\n<p>In addition, NVIDIA experts will present at four sessions and one tutorial detailing how:</p>\n<ul>\n<li>NVIDIA networking, including the <a href=\"https://www.nvidia.com/en-us/networking/products/ethernet/supernic/\" target=\"_blank\">NVIDIA ConnectX-8 SuperNIC</a>, delivers AI reasoning at rack- and data-center scale. <em>(Featuring Idan Burstein, principal architect of network adapters and systems-on-a-chip at NVIDIA)</em></li>\n<li>Neural rendering advancements and massive leaps in inference — powered by the NVIDIA Blackwell architecture, including the <a href=\"https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/rtx-5090/\" target=\"_blank\">NVIDIA GeForce RTX 5090 GPU</a> — provide next-level graphics and simulation capabilities. <em>(Featuring Marc Blackstein, senior director of architecture at NVIDIA)</em></li>\n<li><a href=\"https://www.nvidia.com/en-us/networking/products/silicon-photonics/\" target=\"_blank\">Co-packaged optics (CPO) switches</a> with integrated silicon photonics — built with light-speed fiber rather than copper wiring to send information quicker and using less power — enable efficient, high-performance, gigawatt-scale AI factories. The talk will also highlight <a href=\"https://nvidianews.nvidia.com/news/nvidia-introduces-spectrum-xgs-ethernet-to-connect-distributed-data-centers-into-giga-scale-ai-super-factories\" target=\"_blank\">NVIDIA </a><a href=\"https://nvidianews.nvidia.com/news/nvidia-introduces-spectrum-xgs-ethernet-to-connect-distributed-data-centers-into-giga-scale-ai-super-factories\" target=\"_blank\">Spectrum-XGS</a><a href=\"https://nvidianews.nvidia.com/news/nvidia-introduces-spectrum-xgs-ethernet-to-connect-distributed-data-centers-into-giga-scale-ai-super-factories\" target=\"_blank\"> Ethernet</a>, a new scale-across technology for unifying distributed data centers into AI super-factories. <em>(Featuring Gilad Shainer, senior vice president of networking at NVIDIA)</em></li>\n<li>The NVIDIA GB10 Superchip serves as the engine within the <a href=\"https://www.nvidia.com/en-us/products/workstations/dgx-spark/\" target=\"_blank\">NVIDIA DGX Spark</a> desktop supercomputer. <em>(Featuring Andi Skende, senior distinguished engineer at NVIDIA)</em></li>\n</ul>\n<p>It’s all part of how NVIDIA’s latest technologies are accelerating inference to drive AI innovation everywhere, at every scale.</p>\n<h2>NVIDIA Networking Fosters AI Innovation at Scale</h2>\n<p><a href=\"https://www.nvidia.com/en-us/glossary/ai-reasoning/\" target=\"_blank\">AI reasoning</a> — when artificial intelligence systems can analyze and solve complex problems through multiple AI inference passes — requires rack-scale performance to deliver optimal user experiences efficiently.</p>\n<p>In data centers powering today’s AI workloads, networking acts as the central nervous system, connecting all the components — servers, storage devices and other hardware — into a single, cohesive, powerful computing unit.</p>\n<figure class=\"wp-caption alignleft\" id=\"attachment_84155\" style=\"width: 303px;\"><img alt=\"\" class=\"wp-image-84155 size-full\" height=\"171\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/two-nvidia-connectx08-supernic.png\" width=\"303\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-84155\">NVIDIA ConnectX-8 SuperNIC</figcaption></figure>\n<p>Burstein’s Hot Chips session will dive into how NVIDIA networking technologies — particularly NVIDIA ConnectX-8 SuperNICs — enable high-speed, low-latency, multi-GPU communication to deliver market-leading AI reasoning performance at scale.</p>\n<p>As part of the NVIDIA networking platform, NVIDIA NVLink, NVLink Switch and NVLink Fusion deliver scale-up connectivity — linking GPUs and compute elements within and across servers for ultra low-latency, high-bandwidth data exchange.</p>\n<p><a href=\"https://www.nvidia.com/en-us/networking/spectrumx/\" target=\"_blank\">NVIDIA Spectrum-X Ethernet</a> provides the scale-out fabric to connect entire clusters, rapidly streaming massive datasets into AI models and orchestrating GPU-to-GPU communication across the data center. <a href=\"https://nvidianews.nvidia.com/news/nvidia-introduces-spectrum-xgs-ethernet-to-connect-distributed-data-centers-into-giga-scale-ai-super-factories\" target=\"_blank\">Spectrum-XGS</a> <a href=\"https://nvidianews.nvidia.com/news/nvidia-introduces-spectrum-xgs-ethernet-to-connect-distributed-data-centers-into-giga-scale-ai-super-factories\" target=\"_blank\">Ethernet</a> scale-across technology extends the extreme performance and scale of Spectrum-X Ethernet to interconnect multiple, distributed data centers to form AI super-factories capable of giga-scale intelligence.</p>\n<figure class=\"wp-caption alignright\" id=\"attachment_84152\" style=\"width: 423px;\"><img alt=\"\" class=\"wp-image-84152 size-full\" height=\"235\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/three-distributed-ai-data-centers.png\" width=\"423\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-84152\">Connecting distributed AI data centers with NVIDIA Spectrum-XGS Ethernet.</figcaption></figure>\n<p>At the heart of Spectrum-X Ethernet, CPO switches push the limits of performance and efficiency for AI infrastructure at scale, and will be covered in detail by Shainer in his talk.</p>\n<p><a href=\"https://www.nvidia.com/en-us/data-center/gb200-nvl72/\" target=\"_blank\">NVIDIA GB200 NVL72</a> — an exascale computer in a single rack — features 36 NVIDIA GB200 Superchips, each containing two NVIDIA B200 GPUs and an NVIDIA Grace CPU, interconnected by the largest NVLink domain ever offered, with NVLink Switch providing 130 terabytes per second of low-latency GPU communications for AI and high-performance computing workloads.</p>\n<figure class=\"wp-caption alignleft\" id=\"attachment_84143\" style=\"width: 282px;\"><img alt=\"\" class=\"wp-image-84143 size-full\" height=\"159\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/four-rack-scale-system.png\" width=\"282\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-84143\">An NVIDIA rack-scale system.</figcaption></figure>\n<p>Built with the NVIDIA Blackwell architecture, GB200 NVL72 systems deliver massive leaps in reasoning inference performance.</p>\n<h2>NVIDIA Blackwell and CUDA Bring AI to Millions of Developers</h2>\n<p>The NVIDIA GeForce RTX 5090 GPU — also powered by Blackwell and to be covered in Blackstein’s talk — doubles performance in today’s games with <a href=\"https://www.nvidia.com/en-us/geforce/technologies/dlss/\" target=\"_blank\">NVIDIA DLSS 4</a> technology.</p>\n<figure class=\"wp-caption alignright\" id=\"attachment_84140\" style=\"width: 256px;\"><img alt=\"\" class=\"wp-image-84140 size-full\" height=\"144\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/five-geforce.jpg\" width=\"256\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-84140\">NVIDIA GeForce RTX 5090 GPU</figcaption></figure>\n<p>It can also add neural rendering features for games to deliver up to 10x performance, 10x footprint amplification and a 10x reduction in design cycles,  helping enhance realism in computer graphics and simulation. This offers smooth, responsive visual experiences at low energy consumption and improves the lifelike simulation of characters and effects.</p>\n<p><a href=\"https://developer.nvidia.com/cuda-toolkit\" target=\"_blank\">NVIDIA CUDA</a>, the world’s most widely available computing infrastructure, lets users deploy and run AI models using NVIDIA Blackwell anywhere.</p>\n<p>Hundreds of millions of GPUs run CUDA across the globe, from NVIDIA GB200 NVL72 rack-scale systems to <a href=\"https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/\" target=\"_blank\">GeForce RTX</a>&#8211; and <a href=\"https://www.nvidia.com/en-us/products/workstations/\" target=\"_blank\">NVIDIA RTX PRO</a>-powered PCs and workstations, with <a href=\"https://www.nvidia.com/en-us/products/workstations/dgx-spark/\" target=\"_blank\">NVIDIA DGX Spark</a> powered by NVIDIA GB10 — discussed in Skende’s session — coming soon.</p>\n<h2>From Algorithms to AI Supercomputers — Optimized for LLMs</h2>\n<figure class=\"wp-caption alignleft\" id=\"attachment_84149\" style=\"width: 292px;\"><img alt=\"\" class=\"wp-image-84149 size-full\" height=\"164\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/six-dgx-spark.png\" width=\"292\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-84149\">NVIDIA DGX Spark</figcaption></figure>\n<p>Delivering powerful performance and capabilities in a compact package, DGX Spark lets developers, researchers, data scientists and students push the boundaries of <a href=\"https://www.nvidia.com/en-us/glossary/generative-ai/\" target=\"_blank\">generative AI</a> right at their desktops, and accelerate workloads across industries.</p>\n<p>As part of the NVIDIA Blackwell platform, DGX Spark brings support for NVFP4, a low-precision numerical format to enable efficient <a href=\"https://blogs.nvidia.com/blog/what-is-agentic-ai/\">agentic AI</a> inference, particularly of large language models (<a href=\"https://www.nvidia.com/en-us/glossary/large-language-models/\" target=\"_blank\">LLMs</a>). Learn more about NVFP4 in this NVIDIA Technical Blog.</p>\n<h2>Open-Source Collaborations Propel Inference Innovation</h2>\n<p>NVIDIA accelerates several open-source libraries and frameworks to accelerate and optimize AI workloads for LLMs and distributed inference. These include <a href=\"https://docs.nvidia.com/tensorrt-llm/index.html\" target=\"_blank\">NVIDIA TensorRT-LLM</a>, <a href=\"https://www.nvidia.com/en-us/ai/dynamo/\" target=\"_blank\">NVIDIA Dynamo</a>, TileIR, Cutlass, the <a href=\"https://developer.nvidia.com/nccl\" target=\"_blank\">NVIDIA Collective Communication Library</a> and NIX — which are integrated into millions of workflows.</p>\n<p>Allowing developers to build with their framework of choice, NVIDIA has collaborated with top open framework providers to offer model optimizations for FlashInfer, PyTorch, SGLang, vLLM and others.</p>\n<p>Plus, <a href=\"https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/\" target=\"_blank\">NVIDIA NIM microservices</a> are available for popular open models like OpenAI’s gpt-oss and Llama 4,  making it easy for developers to operate managed application programming interfaces with the flexibility and security of self-hosting models on their preferred infrastructure.</p>\n<p><em>Learn more about the latest advancements in inference and accelerated computing by joining </em><a href=\"https://hotchips.org/\" target=\"_blank\"><em>NVIDIA at Hot Chips</em></a><em>. </em></p>\n<p>&nbsp;</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/adj-blackwell-corp-blog-family-render-1600x900-1.jpg",
          "type": "image/jpeg",
          "width": "1200",
          "height": "675"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/adj-blackwell-corp-blog-family-render-1600x900-1-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "RIKEN, Japan’s Leading Science Institute, Taps Fujitsu and NVIDIA for Next Flagship Supercomputer",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "RIKEN, Japan’s Leading Science Institute, Taps Fujitsu and NVIDIA for Next Flagship Supercomputer"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/fugakunext/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/fugakunext/",
      "authors": [
        {
          "name": "Dion Harris"
        }
      ],
      "author": "Dion Harris",
      "author_detail": {
        "name": "Dion Harris"
      },
      "published": "Fri, 22 Aug 2025 03:00:56 +0000",
      "published_parsed": [
        2025,
        8,
        22,
        3,
        0,
        56,
        4,
        234,
        0
      ],
      "tags": [
        {
          "term": "Corporate",
          "scheme": null,
          "label": null
        },
        {
          "term": "Supercomputing",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=84109",
      "guidislink": false,
      "summary": "Japan is once again building a landmark high-performance computing system — not simply by chasing speed, but by rethinking how technology can best serve the nation’s most urgent scientific needs. At the FugakuNEXT International Initiative Launch Ceremony held in Tokyo on Aug. 22, leaders from RIKEN, Japan’s top research institute, announced the start of an\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/fugakunext/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>Japan is once again building a landmark high-performance computing system — not simply by chasing speed, but by rethinking how technology can best serve the nation’s most urgent scientific needs.</p>\n<p>At the FugakuNEXT International Initiative Launch Ceremony held in Tokyo on Aug. 22, leaders from RIKEN, Japan’s top research institute, announced the start of an international collaboration with Fujitsu and NVIDIA to co-design FugakuNEXT, the successor to the world-renowned supercomputer, Fugaku.</p>\n<p>Awarded early in the process, the contract enables the partners to work side by side in shaping the system’s architecture to address Japan’s most critical research priorities — from earth systems modeling and disaster resilience to drug discovery and advanced manufacturing.</p>\n<p>More than an upgrade, the effort will highlight Japan’s embrace of modern AI and showcase Japanese innovations that can be harnessed by researchers and enterprises across the globe.</p>\n<p>The ceremony featured remarks from the initiative’s leaders, RIKEN President Makoto Gonokami and Satoshi Matsuoka, director of the RIKEN Center for Computational Science and one of Japan’s most respected high-performance computing architects.</p>\n<p>Fujitsu Chief Technology Officer Vivek Mahajan attended, emphasizing the company’s role in advancing Japan’s computing capabilities.</p>\n<p>Ian Buck, vice president of hyperscale and high-performance computing at NVIDIA, attended in person as well to discuss the collaborative design approach and how the resulting platform will serve as a foundation for innovation well into the next decade.</p>\n<p>Momentum has been building. <a href=\"https://blogs.nvidia.com/blog/ai-summit-japan-huang-son/\">When NVIDIA founder and CEO Jensen Huang touched down in Tokyo last year</a>, he called on Japan to seize the moment — to put NVIDIA’s latest technologies to work building its own AI, on its own soil, with its own infrastructure.</p>\n<p>FugakuNEXT answers that call, drawing on NVIDIA’s whole software stack —  from <a href=\"https://www.nvidia.com/en-us/technologies/cuda-x/\" target=\"_blank\">NVIDIA CUDA-X</a> libraries such as <a href=\"https://developer.nvidia.com/cuquantum-sdk\" target=\"_blank\">NVIDIA cuQuantum</a> for quantum simulation, RAPIDS for data science, NVIDIA TensorRT for high-performance inference and NVIDIA NeMo for large language model development, to other domain-specific software development kits tailored for science and industry.</p>\n<p>Innovations pioneered on FugakuNEXT could become blueprints for the world. <b></b></p>\n<h2>What’s Inside</h2>\n<p>FugakuNEXT will be a hybrid AI-HPC system, combining simulation and AI workloads.</p>\n<p>It will feature FUJITSU-MONAKA-X CPUs, which can be paired with NVIDIA technologies using <a href=\"https://nvidianews.nvidia.com/news/nvidia-nvlink-fusion-semi-custom-ai-infrastructure-partner-ecosystem\" target=\"_blank\">NVLink Fusion</a>, new silicon enabling high-bandwidth connections between Fujitsu’s CPUs and NVIDIA’s architecture.</p>\n<p>The system will be built for speed, scale and efficiency.</p>\n<h2>What It Will Do</h2>\n<p>FugakuNEXT will support a wide range of applications — such as automating hypothesis generation, code creation and experiment simulation.</p>\n<ul>\n<li style=\"font-weight: 400;\"><b>Scientific research: </b>Accelerating simulations with surrogate models and physics-informed neural networks.</li>\n<li style=\"font-weight: 400;\"><b>Manufacturing:</b> Using AI to learn from simulations to generate efficient and aesthetically pleasing designs faster than ever before.</li>\n<li style=\"font-weight: 400;\"><b>Earth systems modeling: </b>aiding disaster preparedness and prediction for earthquakes and severe weather, and more.</li>\n</ul>\n<p>RIKEN, Fujitsu and NVIDIA will collaborate on software developments, including tools for mixed-precision computing, continuous benchmarking, and performance optimization.</p>\n<p>FugakuNEXT isn’t just a technical upgrade — it’s a strategic investment in Japan’s future.</p>\n<p>Backed by Japan’s MEXT (Ministry of Education, Culture, Sports, Science and Technology), it will serve universities, government agencies, and industry partners nationwide.</p>\n<p>It marks the start of a new era in Japanese supercomputing — one built on sovereign infrastructure, global collaboration, and a commitment to scientific leadership.</p>\n<p><i>Image courtesy of RIKEN</i></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/hpc-corp-blog-fugaku-1280x680-1.png",
          "type": "image/png",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/hpc-corp-blog-fugaku-1280x680-1-842x450.png",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "Gearing Up for the Gigawatt Data Center Age",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Gearing Up for the Gigawatt Data Center Age"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/networking-matters-more-than-ever/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/networking-matters-more-than-ever/",
      "authors": [
        {
          "name": "Gilad Shainer"
        }
      ],
      "author": "Gilad Shainer",
      "author_detail": {
        "name": "Gilad Shainer"
      },
      "published": "Thu, 21 Aug 2025 15:00:53 +0000",
      "published_parsed": [
        2025,
        8,
        21,
        15,
        0,
        53,
        3,
        233,
        0
      ],
      "tags": [
        {
          "term": "Corporate",
          "scheme": null,
          "label": null
        },
        {
          "term": "Data Center",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=84045",
      "guidislink": false,
      "summary": "Across the globe, AI factories are rising — massive new data centers built not to serve up web pages or email, but to train and deploy intelligence itself. Internet giants have invested billions in cloud-scale AI infrastructure for their customers. Companies are racing to build AI foundries that will spawn the next generation of products\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/networking-matters-more-than-ever/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>Across the globe, AI factories are rising — massive new data centers built not to serve up web pages or email, but to train and deploy intelligence itself. Internet giants have invested billions in cloud-scale AI infrastructure for their customers. Companies are racing to build AI foundries that will spawn the next generation of products and services. Governments are investing too, eager to harness AI for personalized medicine and language services tailored to national populations.</p>\n<p>Welcome to the age of AI factories — where the rules are being rewritten and the wiring doesn’t look anything like the old internet. These aren’t typical hyperscale data centers. They’re something else entirely. Think of them as high-performance engines stitched together from tens to hundreds of thousands of GPUs — not just built, but orchestrated, operated and activated as a single unit. And that orchestration? It’s the whole game.</p>\n<p>This giant data center has become the new unit of computing, and the way these GPUs are connected defines what this unit of computing can do. One network architecture won’t cut it. What’s needed is a layered design with bleeding-edge technologies — like co-packaged optics that once seemed like science fiction.</p>\n<p>The complexity isn’t a bug; it’s the defining feature. AI infrastructure is diverging fast from everything that came before it, and if there isn’t rethinking on how the pipes connect, scale breaks down. Get the network layers wrong, and the whole machine grinds to a halt. Get it right, and gain extraordinary performance.</p>\n<p><img alt=\"\" class=\" wp-image-84050 alignleft\" height=\"374\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/newsletter-inception-nvidia-gb200-nvl72-600x600-1.jpg\" width=\"374\" />With that shift comes weight — literally. A decade ago, chips were built to be sleek and lightweight. Now, the cutting edge looks like the multi‑hundred‑pound copper spine of a server rack. Liquid-cooled manifolds. Custom busbars. Copper spines. AI now demands massive, industrial-scale hardware. And the deeper the models go, the more these machines scale up, and out.</p>\n<p>The NVIDIA NVLink spine, for example, is built from over 5,000 coaxial cables — tightly wound and precisely routed. It almost as much data per second as the entire internet. That’s 130 TB/s of GPU-to-GPU bandwidth, fully meshed.</p>\n<p>This isn’t just fast. It’s foundational. The AI super-highway now lives inside the rack.</p>\n<h2>The Data Center Is the Computer</h2>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-84064\" height=\"680\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-corp-blog-ai-factories-cpo-blog-1280x680-1.jpg\" width=\"1280\" /></p>\n<p>Training the modern large language models (<a href=\"https://www.google.com/search?q=llms+nvidia&amp;oq=llms+nvidia+&amp;gs_lcrp=EgZjaHJvbWUyCggAEEUYFhgeGDkyCAgBEAAYFhgeMggIAhAAGBYYHjIICAMQABgWGB4yCAgEEAAYFhgeMgYIBRBFGEAyBggGEEUYQDIGCAcQRRhA0gEINzA1N2owajeoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8\" target=\"_blank\">LLMs</a>) behind AI isn’t about burning cycles on a single machine. It’s about orchestrating the work of tens or even hundreds of thousands of GPUs that are the heavy lifters of AI computation.</p>\n<p>These systems rely on distributed computing, splitting massive calculations across nodes (individual servers), where each node handles a slice of the workload. In training, those slices — typically massive matrices of numbers — need to be regularly merged and updated. That merging occurs through collective operations, such as “all-reduce” (which combines data from all nodes and redistributes the result) and “all-to-all” (where each node exchanges data with every other node).</p>\n<p>These processes are susceptible to the speed and responsiveness of the network — what engineers call latency (delay) and bandwidth (data capacity) — causing stalls in training.</p>\n<p>For inference — the process of running trained models to generate answers or predictions — the challenges flip. <a href=\"https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/\">Retrieval-augmented generation</a> systems, which combine LLMs with search, demand real-time lookups and responses. And in cloud environments, multi-tenant inference means keeping workloads from different customers running smoothly, without interference. That requires lightning-fast, high-throughput networking that can handle massive demand with strict isolation between users.</p>\n<p>Traditional Ethernet was designed for single-server workloads — not for the demands of distributed AI. Tolerating jitter and inconsistent delivery were once acceptable. Now, it’s a bottleneck. Traditional Ethernet switch architectures were never designed for consistent, predictable performance — and that legacy still shapes their latest generations.</p>\n<p>Distributed computing requires a scale-out infrastructure built for zero-jitter operation — one that can handle bursts of extreme throughput, deliver low latency, maintain predictable and consistent RDMA performance, and isolate network noise. This is why InfiniBand networking is the gold standard for high-performance computing supercomputers and AI factories.</p>\n<p>With NVIDIA Quantum InfiniBand, collective operations run inside the network itself using <a href=\"https://network.nvidia.com/pdf/solutions/hpc/paperieee_copyright.pdf\" target=\"_blank\">Scalable Hierarchical Aggregation and Reduction Protocol</a> technology, doubling data bandwidth for reductions. It uses adaptive routing and telemetry-based congestion control to spread flows across paths, guarantee deterministic bandwidth and isolate noise. These optimizations let InfiniBand scale AI communication with precision. It’s why NVIDIA Quantum infrastructure connects the majority of the systems on the TOP500 list of the world’s most powerful supercomputers, demonstrating 35% growth in just two years.</p>\n<p>For clusters spanning dozens of racks, <a href=\"https://www.nvidia.com/en-us/networking/products/infiniband/quantum-x800/\" target=\"_blank\">NVIDIA Quantum‑X800</a> Infiniband switches push InfiniBand to new heights. Each switch provides 144 ports of 800 Gbps connectivity, featuring hardware-based SHARPv4, adaptive routing and telemetry-based congestion control. The platform integrates <a href=\"https://www.nvidia.com/en-us/networking/products/silicon-photonics/\" target=\"_blank\">co‑packaged silicon photonics</a> to minimize the distance between electronics and optics, reducing power consumption and latency. Paired with NVIDIA ConnectX-8 SuperNICs delivering 800 Gb/s per GPU, this fabric links trillion-parameter models and drives in-network compute.</p>\n<p>But hyperscalers and enterprises have invested billions in their Ethernet software infrastructure. They need a quick path forward that uses the existing ecosystem for AI workloads. Enter <a href=\"https://www.nvidia.com/en-us/networking/spectrumx/\" target=\"_blank\">NVIDIA Spectrum‑X</a>: a new kind of Ethernet purpose-built for distributed AI.</p>\n<h2>Spectrum‑X Ethernet: Bringing AI to the Enterprise</h2>\n<p><img alt=\"\" class=\"aligncenter wp-image-84069\" height=\"720\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-render-spectrum-x-sn5610-cx8-exploded-4050050-1680x945.jpg\" width=\"1280\" /></p>\n<p>Spectrum‑X reimagines Ethernet for AI. Launched in 2023 <a href=\"https://developer.nvidia.com/blog/optimize-large-scale-ai-workloads-with-nvidia-spectrum-x/#:~:text=Here%E2%80%99s%20what%20we%20did%20differently%3A\" target=\"_blank\">Spectrum‑X delivers lossless networking, adaptive routing and performance isolation</a>. The SN5610 switch, based on the Spectrum‑4 ASIC, <a href=\"https://nvidianews.nvidia.com/news/spectrum-x-ethernet-networking-xai-colossus#:~:text=switch%20www,%C2%AE%20SuperNICs%20for%20unprecedented%20performance\" target=\"_blank\">supports port speeds up to 800 Gb/s and uses NVIDIA’s congestion control to maintain 95% data throughput at scale</a>.</p>\n<p>Spectrum‑X is fully standards‑based Ethernet. In addition to supporting Cumulus Linux, it supports the open‑source <a href=\"https://www.nvidia.com/en-us/networking/spectrumx/#:~:text=Powered%20by%20NVIDIA%20networking%20innovations%2C,SONiC%29%20at%20cloud%20scale\" target=\"_blank\">SONiC network operating system</a> — giving customers flexibility. A key ingredient is NVIDIA SuperNICs — based on NVIDIA BlueField-3 or ConnectX-8 — <a href=\"https://www.nvidia.com/en-us/networking/spectrumx/#:~:text=NVIDIA%20BlueField\" target=\"_blank\">which provide up to 800 Gb/s RoCE connectivity</a> and offload packet reordering and congestion management.</p>\n<p>Spectrum-X brings InfiniBand’s best innovations — like telemetry-driven congestion control, adaptive load balancing and direct data placement — to Ethernet, enabling enterprises to scale to hundreds of thousands of GPUs. Large-scale systems with Spectrum‑X, including the <a href=\"https://nvidianews.nvidia.com/news/spectrum-x-ethernet-networking-xai-colossus\" target=\"_blank\">world’s most colossal AI supercomputer</a>, have <a href=\"https://nvidianews.nvidia.com/news/spectrum-x-ethernet-networking-xai-colossus#:~:text=NVIDIA%20today%20announced%20that%20xAI%E2%80%99s,RDMA%29%20network\" target=\"_blank\">achieved 95% data throughput with zero application latency degradation</a>. Standard Ethernet fabrics would deliver only <a href=\"https://nvidianews.nvidia.com/news/spectrum-x-ethernet-networking-xai-colossus#:~:text=This%20level%20of%20performance%20cannot,data%20throughput\" target=\"_blank\">~60% throughput due to flow collisions</a>.</p>\n<h2>A Portfolio for Scale‑Up and Scale‑Out</h2>\n<p>No single network can serve every layer of an AI factory. NVIDIA’s approach is to match the right fabric to the right tier, then tie everything together with software and silicon.</p>\n<h2>NVLink: Scale Up Inside the Rack</h2>\n<p>Inside a server rack, GPUs need to talk to each other as if they were different cores on the same chip. NVIDIA NVLink and NVLink Switch extend GPU memory and bandwidth across nodes. In an NVIDIA GB300 NVL72 system, 36 NVIDIA Grace CPUs and 72 NVIDIA Blackwell Ultra GPUs are <a href=\"https://developer.nvidia.com/blog/nvidia-blackwell-ultra-for-the-era-of-ai-reasoning/#:~:text=Blackwell%20Ultra%20will%20be%20at,NVLink%20bandwidth%20of%20130%20TB%2Fs\" target=\"_blank\">connected in a single NVLink domain, with an aggregate bandwidth of 130 TB/s</a>. NVLink Switch technology further extends this fabric: a single GB300 NVL72 system can offer 130 TB/s of GPU bandwidth, <a href=\"https://www.nvidia.com/en-us/data-center/nvlink/\" target=\"_blank\">enabling clusters to support 9x the GPU count of a single 8‑GPU server</a>. With NVLink, the entire rack becomes one large GPU.</p>\n<h2>Photonics: The Next Leap</h2>\n<p><img alt=\"\" class=\"aligncenter wp-image-84073\" height=\"718\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-tech-blog-cpo-blog-2-1480x830-1.png\" width=\"1280\" /></p>\n<p>To reach million‑GPU AI factories, the network must break the power and density limits of pluggable optics. NVIDIA Quantum-X and Spectrum-X Photonics switches integrate silicon photonics directly into the switch package, <a href=\"https://nvidianews.nvidia.com/news/nvidia-spectrum-x-co-packaged-optics-networking-switches-ai-factories#:~:text=NVIDIA%20Spectrum,a%20total%20throughput%20of%20400Tb%2Fs\" target=\"_blank\">delivering 128 to 512 ports of 800 Gb/s with total bandwidths ranging from 100 Tb/s to 400 Tb/s</a>. These switches offer <a href=\"https://nvidianews.nvidia.com/news/nvidia-spectrum-x-co-packaged-optics-networking-switches-ai-factories#:~:text=,Optics%20Process%20and%20Supply%20Chain\" target=\"_blank\">3.5x more power efficiency and 10x better resiliency compared with traditional optics</a>, paving the way for gigawatt‑scale AI factories.</p>\n<p><br />\n<!-- The surrounding HTML, head, and body tags were removed because WordPress already provides them. --></p>\n<p><!-- This div acts as the \"grey box\" container for all the content. --></p>\n<div>\n<p><!-- The headline, as requested, uses the h2 tag. --></p>\n<h2 style=\"margin-top: 0; color: #ffffff;\">Delivering on the Promise of Open Standards</h2>\n<p><!-- The first paragraph. The first sentence is wrapped in <strong> for bolding. --></p>\n<p style=\"line-height: 1.6; color: #ffffff;\"><strong>Spectrum‑X and NVIDIA Quantum InfiniBand are built on open standards.</strong> Spectrum‑X is fully standards‑based Ethernet with support for open Ethernet stacks like SONiC, while NVIDIA Quantum InfiniBand and Spectrum-X conform to the InfiniBand Trade Association’s InfiniBand and RDMA over Converged Ethernet (RoCE) specifications. Key elements of NVIDIA’s software stack — including NCCL and DOCA libraries — run on a variety of hardware, and partners such as Cisco, Dell Technologies, HPE and Supermicro integrate Spectrum-X into their systems.</p>\n<p><!-- The second paragraph. The first sentence is also bolded. --></p>\n<p style=\"line-height: 1.6; color: #ffffff;\"><strong>Open standards create the foundation for interoperability, but real-world AI clusters require tight optimization across the entire stack — GPUs, NICs, switches, cables and software.</strong> Vendors that invest in end‑to‑end integration deliver better latency and throughput. SONiC, the open‑source network operating system hardened in hyperscale data centers, eliminates licensing and vendor lock‑in and allows intense customization, but operators still choose purpose‑built hardware and software bundles to meet AI’s performance needs. In practice, open standards alone don’t deliver deterministic performance; they need innovation layered on top.</p>\n</div>\n<h2>Toward Million‑GPU AI Factories</h2>\n<p>AI factories are scaling fast. Governments in Europe are building seven national AI factories, while <a href=\"https://blogs.nvidia.com/blog/ai-factory/#:~:text=Reshaping%20Industries%20and%20Economies%20With,Tokens\">cloud providers and enterprises across Japan, India and Norway are rolling out NVIDIA‑powered AI infrastructure</a>. The next horizon is gigawatt‑class facilities with a million GPUs. To get there, the network must evolve from an afterthought to a pillar of AI infrastructure.</p>\n<p>The lesson from the gigawatt data center age is simple: the data center is now the computer. NVLink stitches together GPUs inside the rack. NVIDIA Quantum InfiniBand scales them across it. Spectrum-X brings that performance to broader markets. Silicon photonics makes it sustainable. Everything is open where it matters, optimized where it counts.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<div class=\"text-container\">\n<p>&nbsp;</p>\n</div>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/dgx-spod-gb200_2-gtc24-social-li-1200x628-1.png",
          "type": "image/png",
          "width": "1200",
          "height": "628"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/dgx-spod-gb200_2-gtc24-social-li-1200x628-1-842x450.png",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "Think SMART: How to Optimize AI Factory Inference Performance",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Think SMART: How to Optimize AI Factory Inference Performance"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/think-smart-optimize-ai-factory-inference-performance/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/think-smart-optimize-ai-factory-inference-performance/",
      "authors": [
        {
          "name": "Dion Harris"
        }
      ],
      "author": "Dion Harris",
      "author_detail": {
        "name": "Dion Harris"
      },
      "published": "Thu, 21 Aug 2025 15:00:15 +0000",
      "published_parsed": [
        2025,
        8,
        21,
        15,
        0,
        15,
        3,
        233,
        0
      ],
      "tags": [
        {
          "term": "Data Center",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Factory",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "dynamo",
          "scheme": null,
          "label": null
        },
        {
          "term": "Inference",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=84021",
      "guidislink": false,
      "summary": "From AI assistants doing deep research to autonomous vehicles making split-second navigation decisions, AI adoption is exploding across industries. Behind every one of those interactions is inference — the stage after training where an AI model processes inputs and produces outputs in real time. Today’s most advanced AI reasoning models — capable of multistep logic\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/think-smart-optimize-ai-factory-inference-performance/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>From <a href=\"https://www.nvidia.com/en-us/use-cases/ai-assistants/\" target=\"_blank\">AI assistants</a> doing deep research to autonomous vehicles making split-second navigation decisions, AI adoption is exploding across industries.</p>\n<p>Behind every one of those interactions is <a href=\"https://www.nvidia.com/en-us/glossary/ai-inference/\" target=\"_blank\">inference</a> — the stage after training where an AI model processes inputs and produces outputs in real time.</p>\n<p>Today’s most advanced <a href=\"https://www.nvidia.com/en-us/glossary/ai-reasoning/\" target=\"_blank\">AI reasoning models</a> — capable of multistep logic and complex decision-making — generate far <a href=\"https://blogs.nvidia.com/blog/ai-scaling-laws/\">more tokens per interaction</a> than older models, driving a surge in <a href=\"https://blogs.nvidia.com/blog/ai-tokens-explained/\">token</a> usage and the need for infrastructure that can manufacture intelligence at scale.</p>\n<p><a href=\"https://www.nvidia.com/en-us/glossary/ai-factory/\" target=\"_blank\">AI factories</a> are one way of meeting these growing needs.</p>\n<p>But running inference at such a large scale isn’t just about throwing more compute at the problem.</p>\n<p>To deploy AI with maximum efficiency, inference must be evaluated based on the <b>Think SMART framework:</b></p>\n<ul>\n<li><b>S</b>cale and complexity</li>\n<li><b>M</b>ultidimensional performance</li>\n<li><b>A</b>rchitecture and software</li>\n<li><b>R</b>eturn on investment driven by performance</li>\n<li><b>T</b>echnology ecosystem and install base</li>\n</ul>\n<h2><strong>Scale and Complexity</strong></h2>\n<p>As models evolve from compact applications to massive, multi-expert systems, inference must keep pace with increasingly diverse workloads — from answering quick, single-shot queries to <a href=\"https://blogs.nvidia.com/blog/ai-scaling-laws/\">multistep reasoning involving millions of tokens</a>.</p>\n<p></p>\n<p>The expanding size and intricacy of AI models introduce major implications for inference, such as resource intensity, latency and throughput, energy and costs, as well as diversity of use cases.</p>\n<p>To meet this complexity, AI service providers and enterprises are scaling up their infrastructure, with new AI factories coming online from partners like <a href=\"https://www.coreweave.com/blog/coreweave-leads-the-way-with-first-nvidia-gb300-nvl72-deployment?linkId=100000372104110\" target=\"_blank\">CoreWeave</a>, <a href=\"https://blogs.nvidia.com/blog/dell-technologies-ai-factories-blackwell/\">Dell Technologies</a>, <a href=\"https://blogs.nvidia.com/blog/nvidia-google-blackwell-gemini/\">Google Cloud</a> and <a href=\"https://group.nebius.com/newsroom/nebius-delivers-first-nvidia-blackwell-general-availability-in-europe-brings-nvidia-ai-enterprise-to-nebius-ai-cloud\" target=\"_blank\">Nebius</a>.</p>\n<h2><strong>Multidimensional Performance</strong></h2>\n<p>Scaling complex AI deployments means AI factories need the flexibility to serve tokens across a wide spectrum of use cases while <a href=\"https://www.nvidia.com/en-us/solutions/ai/inference/balancing-cost-latency-and-performance-ebook/\" target=\"_blank\">balancing accuracy, latency and costs</a>.</p>\n<p>Some workloads, such as real-time speech-to-text translation, demand <a href=\"https://developer.nvidia.com/blog/introducing-nvidia-dynamo-a-low-latency-distributed-inference-framework-for-scaling-reasoning-ai-models/\" target=\"_blank\">ultralow latency</a> and a large number of tokens per user, straining computational resources for maximum responsiveness. Others are latency-insensitive and geared for sheer throughput, <a href=\"https://developer.nvidia.com/blog/asking-an-encyclopedia-sized-question-how-to-make-the-world-smarter-with-multi-million-token-real-time-inference/\" target=\"_blank\">such as generating answers to dozens of complex questions simultaneously</a>.</p>\n<p>But most popular <a href=\"https://resources.nvidia.com/en-us-financial-services-industry/nasdaq\" target=\"_blank\">real-time scenarios</a> operate somewhere in the middle: requiring quick responses to keep users happy and high throughput to simultaneously serve up to millions of users — all while minimizing cost per token.</p>\n<p>For example, the <a href=\"https://www.nvidia.com/en-us/solutions/ai/inference/\" target=\"_blank\">NVIDIA inference platform</a> is built to balance both latency and throughput, powering inference benchmarks on models like <a href=\"https://developer.nvidia.com/blog/delivering-1-5-m-tps-inference-on-nvidia-gb200-nvl72-nvidia-accelerates-openai-gpt-oss-models-from-cloud-to-edge/\" target=\"_blank\">gpt-oss</a>, <a href=\"https://developer.nvidia.com/deep-learning-performance-training-inference/ai-inference\" target=\"_blank\">DeepSeek-R1</a> and <a href=\"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-massive-performance-leaps-in-mlperf-inference-v5-0/\" target=\"_blank\">Llama 3.1</a>.</p>\n<h3><b>What to Assess to Achieve Optimal Multidimensional Performance</b></h3>\n<ul>\n<li><b>Throughput:</b> How many tokens can the system process per second? The more, the better for scaling workloads and revenue.</li>\n<li><b>Latency:</b> How quickly does the system respond to each individual prompt? Lower latency means a better experience for users — crucial for interactive applications.</li>\n<li><b>Scalability:</b> Can the system setup quickly adapt as demand increases, going from one to thousands of GPUs without complex restructuring or wasted resources?</li>\n<li><b>Cost Efficiency:</b> Is performance per dollar high, and are those gains sustainable as system demands grow?</li>\n</ul>\n<h2><strong>Architecture and Software</strong></h2>\n<p>AI inference performance needs to be engineered from the ground up. It comes from hardware and software working in sync — GPUs, networking and code tuned to avoid bottlenecks and make the most of every cycle.</p>\n<p>Powerful architecture without smart orchestration wastes potential; great software without fast, low-latency hardware means sluggish performance. The key is architecting a system so that it can quickly, efficiently and flexibly turn prompts into useful answers.</p>\n<p>Enterprises can use NVIDIA infrastructure to build a system that delivers optimal performance.</p>\n<h3><strong>Architecture Optimized for Inference at AI Factory Scale</strong></h3>\n<p>The <a href=\"https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/\" target=\"_blank\">NVIDIA Blackwell platform</a> unlocks a 50x boost in AI factory productivity for inference — <a href=\"https://blogs.nvidia.com/blog/ai-factory-inference-optimization/\">meaning enterprises can optimize throughput and interactive responsiveness</a>, even when running the most complex models.</p>\n<p>The NVIDIA GB200 NVL72 rack-scale system connects 36 NVIDIA Grace CPUs and 72 Blackwell GPUs with NVIDIA NVLink interconnect, delivering 40x higher revenue potential, 30x higher throughput, 25x more <a href=\"https://www.nvidia.com/en-us/glossary/energy-efficiency/\" target=\"_blank\">energy efficiency</a> and <a href=\"https://blogs.nvidia.com/blog/blackwell-platform-water-efficiency-liquid-cooling-data-centers-ai-factories/\">300x more water efficiency</a> for demanding AI reasoning workloads.</p>\n<p>Further, <a href=\"https://developer.nvidia.com/blog/introducing-nvfp4-for-efficient-and-accurate-low-precision-inference/\" target=\"_blank\">NVFP4 is a low-precision format</a> that delivers peak performance on NVIDIA Blackwell and slashes energy, memory and bandwidth demands without skipping a beat on accuracy, so users can deliver more queries per watt and lower costs per token.</p>\n<h3><strong>Full-Stack Inference Platform Accelerated on Blackwell</strong></h3>\n<p>Enabling inference at AI factory scale requires more than accelerated architecture. It requires a full-stack platform with multiple layers of solutions and tools that can work in concert together.</p>\n<p>Modern AI deployments require dynamic autoscaling from one to thousands of GPUs. The <a href=\"https://www.nvidia.com/en-us/ai/dynamo/\" target=\"_blank\">NVIDIA Dynamo</a> platform steers distributed inference to dynamically assign GPUs and <a href=\"https://www.vastdata.com/blog/accelerating-inference\" target=\"_blank\">optimize data flows</a>, delivering up to <a href=\"https://developer.nvidia.com/blog/dynamo-0-4-delivers-4x-faster-performance-slo-based-autoscaling-and-real-time-observability/?linkId=100000378038765\" target=\"_blank\">4x more performance without cost increases</a>. <a href=\"https://developer.nvidia.com/blog/nvidia-dynamo-adds-support-for-aws-services-to-deliver-cost-efficient-inference-at-scale/\" target=\"_blank\">New cloud integrations</a> further improve scalability and ease of deployment.</p>\n<p>For inference workloads focused on getting optimal performance per GPU, such as speeding up large <a href=\"https://developer.nvidia.com/blog/applying-mixture-of-experts-in-llm-architectures/\" target=\"_blank\">mixture of expert</a> models, frameworks like <a href=\"https://docs.nvidia.com/tensorrt-llm/index.html\" target=\"_blank\">NVIDIA TensorRT-LLM</a> are helping developers achieve <a href=\"https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/tech_blog/blog8_Scaling_Expert_Parallelism_in_TensorRT-LLM_part2.md\" target=\"_blank\">breakthrough performance</a>.</p>\n<p>With its new PyTorch-centric workflow, TensorRT-LLM streamlines AI deployment by removing the need for manual engine management. These solutions aren’t just powerful on their own — they’re built to work in tandem. For example, using Dynamo and TensorRT-LLM, mission-critical inference providers like Baseten can immediately deliver <a href=\"https://www.baseten.co/blog/sota-performance-for-gpt-oss-120b-on-nvidia-gpus/\" target=\"_blank\">state-of-the-art</a> model performance even on new frontier models like gpt-oss.</p>\n<p>On the model side, families like <a href=\"https://www.nvidia.com/en-us/ai-data-science/foundation-models/nemotron/\" target=\"_blank\">NVIDIA Nemotron</a> are built with open training data for transparency, while still generating tokens quickly enough to handle advanced reasoning tasks with high accuracy — without increasing compute costs. And with <a href=\"https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/?ncid=so-link-771815\" target=\"_blank\">NVIDIA NIM</a>, those models can be packaged into ready-to-run microservices, making it easier for teams to roll them out and scale across environments while achieving the lowest total cost of ownership.</p>\n<p>Together, these layers — dynamic orchestration, optimized execution, well-designed models and simplified deployment — form the backbone of inference enablement for cloud providers and enterprises alike.</p>\n<h2><strong>Return on Investment Driven by Performance</strong></h2>\n<p>As AI adoption grows, organizations are increasingly looking to maximize the return on investment from each user query.</p>\n<p>Performance is the biggest driver of return on investment. A 4x increase in performance from the NVIDIA Hopper architecture to Blackwell yields up to 10x profit growth within a similar power budget.</p>\n<p></p>\n<p>In power-limited data centers and AI factories, generating more tokens per watt translates directly to higher revenue per rack. Managing token throughput efficiently — balancing latency, accuracy and user load — is crucial for keeping costs down.</p>\n<p>The industry is seeing rapid cost improvements, going as far as reducing<a href=\"https://community.openai.com/t/o3-is-80-cheaper-and-introducing-o3-pro/1284925/1\" target=\"_blank\"> costs-per-million-tokens by 80%</a> through stack-wide optimizations. The same gains are achievable running <a href=\"https://blogs.nvidia.com/blog/openai-gpt-oss/\">gpt-oss</a> and other open-source models from NVIDIA’s inference ecosystem, whether in hyperscale data centers or on <a href=\"https://blogs.nvidia.com/blog/rtx-ai-garage-openai-oss/\">local AI PCs</a>.</p>\n<h2><strong>Technology Ecosystem and Install Base</strong></h2>\n<p>As models advance — featuring longer context windows, more tokens and more sophisticated runtime behaviors — their inference performance scales.</p>\n<p><a href=\"https://developer.nvidia.com/ai-models\" target=\"_blank\">Open models</a> are a driving force in this momentum, <a href=\"https://www.bentoml.com/blog/2024-ai-infra-survey-highlights\" target=\"_blank\">accelerating over 70% of AI inference workloads today</a>. They enable startups and enterprises alike to <a href=\"https://www.youtube.com/watch?v=YsIv9Kr99C4\" target=\"_blank\">build custom</a> agents, copilots and applications across every sector.</p>\n<p>Open-source communities play a critical role in the generative AI ecosystem — fostering collaboration, accelerating innovation and democratizing access. NVIDIA has over 1,000 open-source projects on GitHub in addition to 450 models and more than 80 datasets on <a href=\"https://huggingface.co/nvidia\" target=\"_blank\">Hugging Face</a>. These help integrate popular frameworks like <a href=\"https://developer.nvidia.com/blog/optimizing-for-low-latency-communication-in-inference-workloads-with-jax-and-xla/\" target=\"_blank\">JAX</a>, <a href=\"https://developer.nvidia.com/blog/double-pytorch-inference-speed-for-diffusion-models-using-torch-tensorrt/\" target=\"_blank\">PyTorch</a>, <a href=\"https://blog.vllm.ai/2025/08/05/gpt-oss.html\" target=\"_blank\"><span>vLLM</span></a> and <a href=\"https://github.com/NVIDIA/TensorRT-LLM\" target=\"_blank\">TensorRT-LLM</a> into NVIDIA’s inference platform — ensuring maximum inference performance and flexibility across configurations.</p>\n<p>That’s why NVIDIA continues to contribute to open-source <a href=\"https://developer.nvidia.com/blog/nvidia-dynamo-accelerates-llm-d-community-initiatives-for-advancing-large-scale-distributed-inference/\" target=\"_blank\">projects like llm-d</a> and <a href=\"https://blogs.nvidia.com/blog/national-science-foundation-ai2-open-ai-models/\">collaborate with industry leaders</a> on open models, including <a href=\"https://developer.nvidia.com/blog/blackwell-breaks-the-1000-tps-user-barrier-with-metas-llama-4-maverick/?ncid=so-link-616639&amp;linkId=100000366267873\" target=\"_blank\">Llama</a>, <a href=\"https://blogs.nvidia.com/blog/nvidia-google-blackwell-gemini/\">Google Gemma</a>, <a href=\"https://www.nvidia.com/en-us/ai-data-science/foundation-models/nemotron/\" target=\"_blank\">NVIDIA Nemotron</a>, <a href=\"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/\" target=\"_blank\">DeepSeek</a> and <a href=\"https://blogs.nvidia.com/blog/openai-gpt-oss/\">gpt-oss</a> — helping bring AI applications from idea to production at unprecedented speed.</p>\n<p><img alt=\"\" class=\"alignnone size-full wp-image-84040\" height=\"512\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/think-smart-infrographic.png\" width=\"1280\" /></p>\n<h2><strong>The Bottom Line for Optimized Inference</strong></h2>\n<p>The NVIDIA inference platform, coupled with the Think SMART framework for deploying modern AI workloads, helps enterprises ensure their infrastructure can keep pace with the demands of rapidly advancing models — and that each token generated delivers <a href=\"https://blogs.nvidia.com/blog/ai-inference-economics/\">maximum value</a>.</p>\n<p>Learn more about how inference drives the <a href=\"https://blogs.nvidia.com/blog/revenue-potential-ai-factories/\">revenue generating potential of AI factories</a>.</p>\n<p>For <a href=\"https://info.nvidia.com/rs/156-OFN-742/images/Inference_Think_SMART_Newsletter_August_2025.html?version=0\" target=\"_blank\">monthly updates</a>, sign up for the <a href=\"https://www.nvidia.com/en-us/solutions/ai/inference/?modal=sign-up-form\" target=\"_blank\">NVIDIA Think SMART newsletter</a>.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/think-smart-inference-main-feature.jpg",
          "type": "image/jpeg",
          "width": "1920",
          "height": "1080"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/think-smart-inference-main-feature-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "GeForce NOW Brings RTX 5080 Power to the Ultimate Membership",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "GeForce NOW Brings RTX 5080 Power to the Ultimate Membership"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/geforce-now-thursday-gamescom-2025/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/geforce-now-thursday-gamescom-2025/",
      "authors": [
        {
          "name": "GeForce NOW Community"
        }
      ],
      "author": "GeForce NOW Community",
      "author_detail": {
        "name": "GeForce NOW Community"
      },
      "published": "Thu, 21 Aug 2025 13:00:58 +0000",
      "published_parsed": [
        2025,
        8,
        21,
        13,
        0,
        58,
        3,
        233,
        0
      ],
      "tags": [
        {
          "term": "Gaming",
          "scheme": null,
          "label": null
        },
        {
          "term": "Cloud Gaming",
          "scheme": null,
          "label": null
        },
        {
          "term": "GeForce NOW",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83933",
      "guidislink": false,
      "summary": "Get a glimpse into the future of gaming. The NVIDIA Blackwell RTX architecture is coming to GeForce NOW in September, marking the service’s biggest upgrade yet. Turn any device into a powerhouse gaming rig with GeForce RTX 5080-class performance, next-generation AI features and a major leap forward in stunning cinematic visuals — all without raising\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/geforce-now-thursday-gamescom-2025/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>Get a glimpse into the future of gaming.</p>\n<p>The NVIDIA Blackwell RTX architecture is coming to <a href=\"https://geforcenow.com\" target=\"_blank\">GeForce NOW</a> in September, marking the service’s biggest upgrade yet. Turn any device into a powerhouse gaming rig with GeForce RTX 5080-class performance, next-generation AI features and a major leap forward in stunning cinematic visuals — all without raising membership prices.</p>\n<p>With the upgrade to the Blackwell RTX architecture, all Premium members will get access to a new feature called Install-to-Play, which expands the GeForce NOW cloud game catalog to nearly 4,500 titles.</p>\n<p>And be on the lookout for an upcoming lineup of this year’s hottest new titles, optimized to take full advantage of the GeForce RTX 5080-gaming rig in the cloud. The list includes <i>ARC Raiders</i>,<i> Borderlands 4</i>, <i>Call of Duty: Black Ops 7</i>,<i> Cinder City</i>,<i> Dying Light: The Beast, Hell Is Us</i>, <i>The Outer Worlds 2</i>,<i> Vampire: The Masquerade – Bloodlines 2 </i>and more<i>. </i>Members will be able to play these blockbuster titles in the cloud when they launch, streaming instantly from their device of choice.</p>\n<p>NVIDIA will also be launching GeForce NOW in India this November. It follows Thailand as the latest region to gain access to GeForce NOW through GFNA partner Brothers Picture — enabling even more gamers around the world to experience the future of cloud gaming at the same great membership prices.</p>\n<p>Be among the first to tap into GeForce RTX 5080 power from the cloud by upgrading to an Ultimate membership today. Server space will be limited, so be sure to lock it in today.</p>\n<p>There’s even more fun to come — check out the list of 13 new games joining the GeForce NOW library this week.</p>\n<h2><b>Paint It Blackwell</b></h2>\n<p class=\"elementtoproof\" style=\"background: white; text-align: center;\"></p>\n<p>With the NVIDIA Blackwell RTX architecture, GeForce NOW is beaming GeForce RTX 5080-class power from the cloud straight to nearly any device.</p>\n<p>GeForce RTX 5080-class GPUs bring a staggering 62 teraflops of compute performance, a 48GB frame buffer, more than 3x the performance of current consoles and 2.8x faster frame rates than previous-generation servers. Advanced ray tracing, richer textures and AI-enhanced rendering with AMD “Zen 5” CPUs and NVIDIA ConnectX-7 networking deliver an experience that’s more responsive than ever.</p>\n<p>It isn’t just raw speed either. NVIDIA Blackwell RTX unlocks:</p>\n<ul>\n<li><b>The highest resolutions and frame rates in the cloud: </b>NVIDIA DLSS 4 with Multi Frame Generation unlocks up to 5K streaming at 120 frames per second (fps) — performance once reserved for the most elite PCs. <a href=\"https://www.nvidia.com/en-us/geforce/technologies/reflex/\" target=\"_blank\">NVIDIA Reflex</a> technology levels up the cloud for competitive gaming, delivering streams up to 360 fps at 1080p and network latency under 30 milliseconds.</li>\n<li><b>Vastly improved visual fidelity: </b>A new Cinematic Quality Streaming mode delivers richer colors, sharper text and crystal-clear scenes with 4:4:4 chroma sampling, AI sharpening and advanced AV1 encoding — even when network conditions change.</li>\n<li><b>GeForce NOW support on more devices: </b>Premium members will be able to stream at 90 fps on Steam Decks and 4k 120 fps on the Lenovo Legion Go S handheld. Supported LG monitors can stream at up to 5K 120Hz and supported LG TVs at 4K 120Hz — no extra hardware required. Mac users get the full NVIDIA Blackwell RTX upgrade, and there’s expanded support for peripherals like Logitech racing wheels.</li>\n</ul>\n<p>Plus, collaborations with Comcast, Deutsche Telekom AG and others bring enhanced broadband and 5G performance.</p>\n<p>Ultimate memberships remain at $19.99 a month and Performance memberships at $9.99 a month. With the launch of NVIDIA Blackwell RTX on GeForce NOW, upgraded Ultimate memberships will debut with an unchanged $19.99 a month or $199.99 for 12-month plans.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83973\" style=\"width: 1680px;\"><img alt=\"Blackwell product matrix on GeForce NOW\" class=\"size-large wp-image-83973\" height=\"1089\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Blackwell_Product_Matrix-1680x1089.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83973\"><em>Newly upgraded Ultimate, who dis?</em></figcaption></figure>\n<h2><b>Double the Games, Double the Fun</b><b><br />\n</b></h2>\n<p>The biggest expansion yet for the GeForce NOW game library arrives with the launch of Install-to-Play. This new feature harnesses high-performance cloud storage, powered by NVIDIA NVMesh technology, to allow game installations directly in the cloud.</p>\n<p>Members will be able to bring even more of their PC collections to the cloud to play instantly, mirroring the experience of a local PC. Install-to-Play instantly doubles the supported games on GeForce NOW with more than 2,200 Steam titles already opted in for cloud streaming, rocketing the total GeForce NOW library size to over 4,500 accessible games, with more to come.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83970\" style=\"width: 1680px;\"><img alt=\"Install-to-Play coming to GeForce NOW\" class=\"size-large wp-image-83970\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Install_to_Play-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83970\"><em>The game multiplier.</em></figcaption></figure>\n<p>Ultimate and Performance members will have 100GB of single-session storage included, with flexible add-ons for persistent storage — 200GB for $2.99 per month, 500GB for $4.99 per month and 1TB for $7.99 per month. Once a game is installed on persistent storage, it remains instantly ready for members to play.</p>\n<h2><b>The Ultimate Party</b></h2>\n<p>The upgrade to NVIDIA Blackwell RTX in the cloud arrives just in time for some of the year’s top-tier game launches. These highly anticipated titles will be among the first to take full advantage of the upgraded platform’s powerful performance — letting members experience cutting-edge gameplay, ultrahigh resolutions and instant day-one access in the cloud.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83967\" style=\"width: 1680px;\"><img alt=\"Borderlands 4 on GeForce NOW\" class=\"size-large wp-image-83967\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Borderlands_4-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83967\"><em>The cloud is the best way to play.</em></figcaption></figure>\n<p>Gear up for all out mayhem in <i>Borderlands 4</i>. Unleash chaos across the galaxy with outrageous weapons, irreverent humor and the signature co-op action that makes this iconic looter-shooter franchise a fan favorite.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83964\" style=\"width: 1680px;\"><img alt=\"Dying Light The Beast on GeForce NOW\" class=\"size-large wp-image-83964\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Dying_Light_The_Beast-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83964\"><em>Own the day, fear the night.</em></figcaption></figure>\n<p>Get ready for a unique blend of open-world and action-survival horror when <i>Dying Light: The Beast </i>launches in the cloud on Friday, Sept. 19. Play as Kyle Crane, a hero with the DNA of both man and beast. After escaping brutal experiments, players will feel the thirst for revenge — but soon learn there’s more at stake in the unforgiving wilds of Castor Woods.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83961\" style=\"width: 1680px;\"><img alt=\"Outer Worlds 2 on GeForce NOW\" class=\"size-large wp-image-83961\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_The_Outer_Worlds_2-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83961\"><em>The universe needs a hero, but you’ll have to do.</em></figcaption></figure>\n<p>Get ready to explore strange new colonies in <i>The Outer Worlds 2</i>. This highly anticipated sequel brings fresh characters, wild alien planets and Obsidian’s trademark wit — promising even bigger adventures and choices that shape the game’s story.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83955\" style=\"width: 1680px;\"><img alt=\"Arc Raiders on GeForce NOW\" class=\"size-large wp-image-83955\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/arc-raiders-tw-li-2048x1024-1-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83955\"><em>Prepare to claim what was lost.</em></figcaption></figure>\n<p>Action fans can look forward to heart-pounding, squad-based battles in <i>Arc Raiders</i>. This dynamic co-op shooter drops players into a war for survival against overwhelming mechanized threats, blending teamwork and tactical action in a richly detailed multiplayer world.</p>\n<p>For a dark, atmospheric role-playing game, look no further than <i>Vampire: The Masquerade – Bloodlines 2</i>, which will bring players back to Seattle’s supernatural underworld. Navigate dangerous alliances, political intrigue and vampire factions to carve a unique path through the city’s shadowy streets.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83952\" style=\"width: 1680px;\"><img alt=\"Hell is Us on GeForce NOW\" class=\"size-large wp-image-83952\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Hell_Is_Us-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83952\"><em>The cloud reveals all about the calamity.</em></figcaption></figure>\n<p>For those in search of mystery and action, look no further than <i>Hell Is Us</i>. Set in a land torn by conflict and haunted by otherworldly forces, this unique adventure blends fast-paced melee combat and a striking, atmospheric world, challenging gamers to discover what’s real amid human and supernatural threats.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83949\" style=\"width: 1680px;\"><img alt=\"COD Black Ops 7 on GeForce NOW\" class=\"size-large wp-image-83949\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_COD_Black_Ops_7-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83949\"><em>The mind games never stop.</em></figcaption></figure>\n<p>And the action of <i>Call of Duty: Black Ops 7</i> will bring the franchise’s intensity to GeForce NOW. Dive into a high-stakes co-op campaign packed with action, a signature multiplayer experience and the next twisted chapter of Round-Based Zombies.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83946\" style=\"width: 1680px;\"><img alt=\"Cinder City on GeForce NOW\" class=\"size-large wp-image-83946\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_CINDER_CITY-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83946\"><em>Every flame tells a story.</em></figcaption></figure>\n<p>In <i>CINDER CITY</i>, a tactical shooter developed in-house by Bigfire Games under NCSOFT, suit up as a futuristic knight and battle through post-apocalyptic Seoul. Players must face brutal choices as they search for their missing daughter — solo or with a squad.</p>\n<h2><b>A Special Squad-Up</b></h2>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83943\" style=\"width: 1200px;\"><img alt=\"Discord and GeForce NOW new integration\" class=\"size-full wp-image-83943\" height=\"627\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_NVIDIA_Discord.png\" width=\"1200\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83943\"><em>Better together.</em></figcaption></figure>\n<p>NVIDIA, Discord and Epic are teaming up to change how games are discovered and played together, making it easier than ever to stay connected to friends through gaming.</p>\n<p>Powered by GeForce NOW streaming, <a href=\"http://dis.gd/DiscordxNVIDIA\" target=\"_blank\">this new integrated experience</a> — demoed behind closed doors at Gamescom — will let players discover and try new games with friends directly on Discord. They can do so with no downloads or installs, and even without owning the game or a GeForce NOW membership. It’s fueled by a limited-time trial of the GeForce NOW Performance experience for streaming at up 1440p 60 fps — all without needing to leave Discord.</p>\n<p>The first game to take advantage of the integrated experience is <i>Fortnite. </i>Connecting an Epic account is all it takes to join the action. For Discord’s hundreds of millions of users, it’s a faster, simpler way to discover games and play together where gaming conversations are already happening.</p>\n<h2><b>Legendary New Games</b></h2>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83940\" style=\"width: 1680px;\"><img alt=\"Total War series on GeForce NOW\" class=\"size-large wp-image-83940\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/gfn-thursday-8-21-social-2048x1024-no-copy-logo-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83940\"><em>History isn’t written, it’s forged in the cloud.</em></figcaption></figure>\n<p>Command grand armies and shape history in Creative Assembly’s acclaimed <i>Total War</i> series, including:</p>\n<ul>\n<li><i>Total War: MEDIEVAL II – Definitive Edition</i></li>\n<li><i>Total War: ATTILA</i></li>\n<li><i>A Total War Saga: Troy</i></li>\n<li><i>Total War: NAPOLEON &#8211; Definitive Edition</i></li>\n<li><i>Total War: EMPIRE – Definitive Edition</i></li>\n</ul>\n<p>Rally knights in <i>MEDIEVAL II</i>, defy empires in <i>ATTILA</i>, lead legendary heroes in <i>Troy</i>, outmaneuver rivals in <i>NAPOLEON</i> and forge global dominance in <i>EMPIRE</i>. Epic strategy, monumental battles and world-shaking decisions await as the fate of civilizations is in players’ hands. Gamers can rewrite history — or be swept aside by it.</p>\n<p>Catch the full list of games coming to the cloud this week on GeForce NOW:</p>\n<ul>\n<li><i>Stick It to the Stickman</i> (New release on <a href=\"https://store.steampowered.com/app/2085540?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>, Aug. 18)</li>\n<li><i>Blacksmith Master </i>(New release on <a href=\"https://www.xbox.com/games/store/blacksmith-master-game-preview/9NMZH1KXLTSB?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Xbox</a>, available on PC Game Pass, Aug. 19)<i> </i></li>\n<li><i>VOID/BREAKER </i>(New release on <a href=\"https://store.steampowered.com/app/2615540?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a> and <a href=\"https://www.xbox.com/games/store/voidbreaker/9n9k5qp9g3gl?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Xbox</a> available on PC Game Pass, Aug. 19)</li>\n<li><i>The Rogue Prince of Persia </i>(New release on <a href=\"https://store.ubi.com/6635164075637a09298a6001.html?ucid=AFL-ID_152062&amp;maltcode=geforcenow_convst_AFL_geforcenow_vg__STORE____&amp;addinfo=\" target=\"_blank\">Ubisoft</a>, Aug. 20)</li>\n<li><i>Funko Fusion</i> (<a href=\"https://store.steampowered.com/app/1843310?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>Total War: MEDIEVAL II – Definitive Edition</i> (<a href=\"https://store.steampowered.com/app/4700?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>Total War: ATTILA </i>(<a href=\"https://store.steampowered.com/app/325610?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>A Total War Saga: Troy </i>(<a href=\"https://store.steampowered.com/app/1099410?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>Total War: NAPOLEON &#8211; Definitive Edition </i>(<a href=\"https://store.steampowered.com/app/34030?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>Total War: EMPIRE – Definitive Edition </i>(<a href=\"https://store.steampowered.com/app/10500?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>Total War: PHARAOH DYNASTIES </i>(<a href=\"https://store.steampowered.com/app/2951630?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>Total War: ROME REMASTERED </i>(<a href=\"https://store.steampowered.com/app/885970?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>Total War: SHOGUN 2 </i>(<a href=\"https://store.steampowered.com/app/201270?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n</ul>\n<p>Which Gamescom announcement has you most excited this week? Let us know on <a href=\"https://www.twitter.com/nvidiagfn\" target=\"_blank\">X</a> or in the comments below.</p>\n<p><i>See </i><a href=\"https://www.nvidia.com/en-eu/about-nvidia/terms-of-service/\" target=\"_blank\"><i>notice</i></a><i> regarding software product information.</i></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/gfn-thursday-8-21-nv-blog-1280x680-logo.jpg",
          "type": "image/jpeg",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/gfn-thursday-8-21-nv-blog-1280x680-logo-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "Into the Omniverse: How OpenUSD and Digital Twins Are Powering Industrial and Physical AI",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Into the Omniverse: How OpenUSD and Digital Twins Are Powering Industrial and Physical AI"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/openusd-digital-twins-industrial-physical-ai/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/openusd-digital-twins-industrial-physical-ai/",
      "authors": [
        {
          "name": "James McKenna"
        }
      ],
      "author": "James McKenna",
      "author_detail": {
        "name": "James McKenna"
      },
      "published": "Wed, 20 Aug 2025 13:00:08 +0000",
      "published_parsed": [
        2025,
        8,
        20,
        13,
        0,
        8,
        2,
        232,
        0
      ],
      "tags": [
        {
          "term": "Pro Graphics",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Digital Twin",
          "scheme": null,
          "label": null
        },
        {
          "term": "Industrial and Manufacturing",
          "scheme": null,
          "label": null
        },
        {
          "term": "Into the Omniverse",
          "scheme": null,
          "label": null
        },
        {
          "term": "Omniverse",
          "scheme": null,
          "label": null
        },
        {
          "term": "Physical AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Universal Scene Description",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83895",
      "guidislink": false,
      "summary": "Editor’s note: This blog is a part of Into the Omniverse, a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advances in OpenUSD and NVIDIA Omniverse. Investments in industrial AI and physical AI are driving increased demand for digital twins across industries. These physically accurate, virtual replicas\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/openusd-digital-twins-industrial-physical-ai/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p><i>Editor’s note: This blog is a part of </i><a href=\"https://www.nvidia.com/en-us/omniverse/news/\" target=\"_blank\"><i>Into the Omniverse</i></a><i>, a series focused on how developers, 3D practitioners and enterprises can transform their workflows using the latest advances in </i><a href=\"https://www.nvidia.com/en-us/omniverse/usd/\" target=\"_blank\"><i>OpenUSD</i></a><i> and </i><a href=\"https://www.nvidia.com/en-us/omniverse/\" target=\"_blank\"><i>NVIDIA Omniverse</i></a><i>.</i></p>\n<p>Investments in <a href=\"https://www.nvidia.com/en-us/glossary/industrial-ai/\" target=\"_blank\">industrial AI</a> and <a href=\"https://www.nvidia.com/en-us/glossary/generative-physical-ai/\" target=\"_blank\">physical AI</a> are driving increased demand for <a href=\"https://www.nvidia.com/en-us/use-cases/industrial-facility-digital-twins/\" target=\"_blank\">digital twins</a> across industries.</p>\n<p>These physically accurate, virtual replicas of real-world environments, facilities and processes aren’t just helping manufacturers streamline planning and optimize operations. They serve as the training ground for helping ensure vision AI agents, autonomous vehicles and robot fleets can operate safely, efficiently and reliably.</p>\n<p>Creating physically accurate simulation environments that enable physical AI to transition seamlessly to the real world typically involves substantial manual effort. However, with the latest advancements in OpenUSD — a powerful open standard for describing and connecting complex 3D worlds — alongside improvements in rendering, neural reconstruction and <a href=\"https://www.nvidia.com/en-us/glossary/world-models/\" target=\"_blank\">world foundation models (WFMs)</a>, developers can fast-track the construction of digital twins at scale.</p>\n<h2><b>Accelerating Digital Twin and Physical AI Development</b></h2>\n<p>To speed digital twin and physical AI development, NVIDIA announced at this year’s SIGGRAPH conference new research, NVIDIA Omniverse libraries, NVIDIA Cosmos WFMs and advanced AI infrastructure — including <a href=\"https://www.nvidia.com/en-us/data-center/rtx-pro-6000-blackwell-server-edition/\" target=\"_blank\">NVIDIA RTX PRO Servers</a> and <a href=\"https://www.nvidia.com/en-us/data-center/dgx-cloud/\" target=\"_blank\">NVIDIA DGX Cloud</a>.</p>\n<ul>\n<li>The <a href=\"https://developer.nvidia.com/blog/developers-build-fast-and-reliable-robot-simulations-with-nvidia-omniverse-libraries/\" target=\"_blank\">latest Omniverse software development kits</a> bridge MuJoCo and Universal Scene Description (OpenUSD), enabling over 250,000 MJCF <a href=\"https://www.nvidia.com/en-us/glossary/robot-learning/\" target=\"_blank\">robot learning </a>developers to simulate robots across platforms.</li>\n<li><a href=\"https://developer.nvidia.com/blog/how-to-instantly-render-real-world-scenes-in-interactive-simulation/\" target=\"_blank\">Omniverse NuRec</a> libraries and AI models enable Omniverse RTX ray-traced <a href=\"https://www.nvidia.com/en-us/glossary/3d-reconstruction/\" target=\"_blank\">3D Gaussian splatting</a>, allowing developers to capture, reconstruct and simulate the real world in 3D using sensor data.</li>\n<li><a href=\"https://github.com/isaac-sim\" target=\"_blank\">NVIDIA Isaac Sim 5.0</a> and <a href=\"https://github.com/isaac-sim/IsaacLab\" target=\"_blank\">Isaac Lab 2.2</a> open-source robot simulation and learning frameworks are now available on GitHub. <a href=\"https://developer.nvidia.com/isaac/sim\" target=\"_blank\">Isaac Sim</a> features NuRec neural rendering and new OpenUSD robot and sensor schemas to narrow the simulation-to-reality gap.</li>\n<li>Cosmos WFMs, including <a href=\"https://github.com/nvidia-cosmos/cosmos-transfer2\" target=\"_blank\">Cosmos Transfer-2</a> and <a href=\"https://build.nvidia.com/nvidia/cosmos-reason1-7b\" target=\"_blank\">NVIDIA Cosmos Reason</a>, deliver leaps in synthetic data generation and reasoning for physical AI development.</li>\n<li><a href=\"https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/\">NVIDIA research</a> advances in rendering and AI-assisted material generation help developers scale digital twin development.</li>\n</ul>\n<p></p>\n<h2><b>Growing OpenUSD Ecosystem</b></h2>\n<p>OpenUSD serves as a foundational ecosystem for digital twin and physical AI development, empowering developers to integrate industrial and 3D data to create physically accurate digital twins.</p>\n<p>The <a href=\"https://aousd.org/\" target=\"_blank\">Alliance for OpenUSD</a> (AOUSD) recently welcomed <a href=\"https://aousd.org/news/alliance-for-openusd-announces-new-members-inclusive-language-guide-and-core-specification-progress/\" target=\"_blank\">new general members</a>, including Accenture, Esri, HCLTech, PTC, Renault and Tech Soft 3D. These additions underscore the continued growth of the OpenUSD community and its commitment to unifying 3D workflows across industries.</p>\n<p>To address the growing demand for OpenUSD and digital twins expertise, NVIDIA launched a new industry-recognized <a href=\"https://www.nvidia.com/en-us/learn/certification/openusd-development-professional/\" target=\"_blank\">OpenUSD development certification</a> and a free <a href=\"https://www.nvidia.com/en-us/learn/learning-path/digital-twins/\" target=\"_blank\">digital twins learning path</a>.</p>\n<h2><b>Developers Building Digital Twins</b></h2>\n<p>Industry leaders including <a href=\"https://www.nvidia.com/en-us/customer-stories/siemens-accelerates-product-development-and-innovation-with-industrial-ai/\" target=\"_blank\">Siemens</a>, <a href=\"https://www.nvidia.com/en-us/customer-stories/sight-machine/\" target=\"_blank\">Sight Machine</a>, <a href=\"https://www.nvidia.com/en-us/customer-stories/rockwell-automation/\" target=\"_blank\">Rockwell Automation</a>, <a href=\"https://www.nvidia.com/en-us/customer-stories/edag/\" target=\"_blank\">EDAG</a>, <a href=\"https://blogs.nvidia.com/blog/amazon-zero-touch-manufacturing/\">Amazon Devices &amp; Services</a> and <a href=\"https://www.youtube.com/watch?v=y8ZW4GUvKmI&amp;t=1s\" target=\"_blank\">Vention</a> are building digital twin solutions with Omniverse libraries and OpenUSD to enable transformation with industrial and physical AI.</p>\n<p><a href=\"https://www.nvidia.com/en-us/customer-stories/siemens-accelerates-product-development-and-innovation-with-industrial-ai/\" target=\"_blank\">Siemens</a>’ Teamcenter Digital Reality Viewer enables engineers to visualize, interact with and collaborate on photorealistic digital twins at unprecedented scale. These efforts are enabling faster design reviews, minimizing the need for physical prototypes and accelerating time to market — all while reducing costs.</p>\n<p><img alt=\"\" class=\"alignnone size-full wp-image-83905\" height=\"450\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/ito-digital-twin-ship.gif\" width=\"800\" /></p>\n<p><a href=\"https://www.nvidia.com/en-us/customer-stories/sight-machine/\" target=\"_blank\">Sight Machine’s</a> Operator Agent platform combines live production data, agentic AI-powered recommendations and digital twins to provide real-time visibility into production and enable faster, more informed decisions for plant operations teams.</p>\n<p><img alt=\"\" class=\"alignnone size-full wp-image-83902\" height=\"450\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/rockwell-automation-ito-emulate3d.gif\" width=\"800\" /></p>\n<p><a href=\"https://www.nvidia.com/en-us/customer-stories/rockwell-automation/\" target=\"_blank\">Rockwell Automation’s</a> Emulate3D Factory Test platform enables manufacturers to build factory-scale, physics-based digital twins for simulating, validating and optimizing automation and autonomous systems at scale.</p>\n<p><img alt=\"\" class=\"alignnone size-full wp-image-83896\" height=\"450\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/ito-edag-digital-twin.gif\" width=\"800\" /></p>\n<p><a href=\"https://www.nvidia.com/en-us/customer-stories/edag/\" target=\"_blank\">EDAG’s</a> industrial digital twin platform helps manufacturers improve project management, optimize production layouts, train workers and perform data-driven quality assurance.</p>\n<p><a href=\"https://blogs.nvidia.com/blog/amazon-zero-touch-manufacturing/\">Amazon Devices &amp; Services</a> uses digital twins to train robotic arms to recognize, inspect and handle new devices. Robotic actions can be configured to manufacture products purely based on training performed in simulation — including for steps involved in assembly, testing, packaging and auditing.</p>\n<p></p>\n<p><a href=\"https://www.youtube.com/watch?v=y8ZW4GUvKmI&amp;t=1s\" target=\"_blank\">Vention</a> is using NVIDIA robotics, AI and simulation technologies — including Omniverse libraries, Isaac Sim and Jetson hardware — to deliver plug-and-play digital twin and automation solutions that simplify and accelerate the deployment of intelligent manufacturing systems.</p>\n<h2><b>Get Plugged Into the World of OpenUSD</b></h2>\n<p>To learn more about OpenUSD and how to develop digital twin applications with Omniverse libraries, take free courses as part of the new <a href=\"https://www.nvidia.com/en-us/learn/learning-path/digital-twins/\" target=\"_blank\">digital twin learning path</a>, and check out the <a href=\"https://docs.omniverse.nvidia.com/kit/docs/kit-app-template/latest/docs/intro.html\" target=\"_blank\">Omniverse Kit companion tutorial</a> and how-to guide for <a href=\"https://developer.nvidia.com/blog/deploying-your-omniverse-kit-apps-at-scale/\" target=\"_blank\">deploying Omniverse Kit-based applications at scale</a>.</p>\n<p>Watch a replay of NVIDIA’s SIGGRAPH <a href=\"https://www.youtube.com/watch?v=rFcmv2pXR0w\" target=\"_blank\">Research Special Address</a>. Plus, try out <a href=\"https://developer.nvidia.com/blog/how-to-instantly-render-real-world-scenes-in-interactive-simulation/\" target=\"_blank\">Omniverse NuRec on Isaac Sim and CARLA</a>, and learn more about <a href=\"https://developer.nvidia.com/isaac/sim\" target=\"_blank\">Isaac Sim</a><i>.</i></p>\n<p><i>Stay up to date by subscribing to</i> <a href=\"https://nvda.ws/3u5KPv1\" target=\"_blank\"><i>NVIDIA Omniverse news</i></a><i>, joining the Omniverse </i><a href=\"https://developer.nvidia.com/omniverse/community\" target=\"_blank\"><i>community</i></a><i> and following Omniverse </i><i>on</i> <a href=\"https://discord.com/channels/827959428476174346/828737081479004230\" target=\"_blank\"><i>Discord</i></a><i>,</i> <a href=\"https://www.instagram.com/nvidiaomniverse/\" target=\"_blank\"><i>Instagram</i></a><i>, </i><a href=\"https://www.linkedin.com/showcase/71986325/admin/dashboard/\" target=\"_blank\"><i>LinkedIn</i></a><i>, </i><a href=\"https://www.threads.com/@nvidiaomniverse\" target=\"_blank\"><i>Threads</i></a><a href=\"https://medium.com/@nvidiaomniverse\" target=\"_blank\"><i>,</i></a> <a href=\"https://twitter.com/nvidiaomniverse\" target=\"_blank\"><i>X</i></a><i>, </i><i>and</i> <a href=\"https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA\" target=\"_blank\"><i>YouTube</i></a><b><i>. </i></b></p>\n<p><i>Explore the </i><a href=\"https://forum.aousd.org/\" target=\"_blank\"><i>Alliance for OpenUSD forum</i></a><i> and the </i><a href=\"https://aousd.org/\" target=\"_blank\"><i>AOUSD website</i></a><i>.</i></p>\n<p><i>Featured image courtesy of Siemens, Sight Machine.</i></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/nv-ov-ito-august-1280x680-r4.png",
          "type": "image/png",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/nv-ov-ito-august-1280x680-r4-842x450.png",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "New Lightweight AI Model for Project G-Assist Brings Support for 6GB NVIDIA GeForce RTX and RTX PRO GPUs",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "New Lightweight AI Model for Project G-Assist Brings Support for 6GB NVIDIA GeForce RTX and RTX PRO GPUs"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/rtx-ai-garage-gamescom-g-assist-rtx-remix/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/rtx-ai-garage-gamescom-g-assist-rtx-remix/",
      "authors": [
        {
          "name": "Gerardo Delgado"
        }
      ],
      "author": "Gerardo Delgado",
      "author_detail": {
        "name": "Gerardo Delgado"
      },
      "published": "Mon, 18 Aug 2025 19:30:40 +0000",
      "published_parsed": [
        2025,
        8,
        18,
        19,
        30,
        40,
        0,
        230,
        0
      ],
      "tags": [
        {
          "term": "Generative AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Conversational AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "GeForce",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA RTX",
          "scheme": null,
          "label": null
        },
        {
          "term": "RTX AI Garage",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83848",
      "guidislink": false,
      "summary": "At Gamescom, NVIDIA is releasing its first major update to Project G‑Assist — an experimental on-device AI assistant that allows users to tune their NVIDIA RTX systems with voice and text commands. The update brings a new AI model that uses 40% less VRAM, improves tool-calling intelligence and extends G-Assist support to all RTX GPUs\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/rtx-ai-garage-gamescom-g-assist-rtx-remix/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>At <a href=\"https://www.gamescom.global/en\" target=\"_blank\">Gamescom</a>, NVIDIA is releasing its first major update to <a href=\"https://www.nvidia.com/en-us/software/nvidia-app/g-assist/\" target=\"_blank\">Project G‑Assist</a> — an experimental on-device AI assistant that allows users to tune their NVIDIA RTX systems with voice and text commands.</p>\n<p>The update brings a new AI model that uses 40% less VRAM, improves tool-calling intelligence and extends G-Assist support to all RTX GPUs with 6GB or more VRAM, including laptops. Plus, a new <a href=\"https://mod.io/g/g-assist\" target=\"_blank\">G-Assist Plug-In Hub</a> enables users to easily discover and download plug-ins to enable more G-Assist features.</p>\n<p>NVIDIA also announced a new path-traced particle system, coming in September to the NVIDIA RTX Remix modding platform, that brings fully simulated physics, dynamic shadows and realistic reflections to visual effects.</p>\n<p>In addition, NVIDIA named the winners of the <a href=\"https://www.nvidia.com/en-us/geforce/news/rtx-remix-mod-contest-winners\" target=\"_blank\">NVIDIA and ModDB RTX Remix Mod Contest</a>. Check out the winners and finalist RTX mods in the <a href=\"https://www.nvidia.com/en-us/geforce/news/rtx-remix-mod-contest-winners\" target=\"_blank\">RTX Remix GeForce article</a>.</p>\n<h2><b>G-Assist Gets Smarter, Expands to More RTX PCs</b></h2>\n<p>The modern PC is a powerhouse, but unlocking its full potential means navigating a complex maze of settings across system software, GPU and peripheral utilities, control panels and more.</p>\n<p>Project G-Assist is a free, on-device AI assistant built to cut through that complexity. It acts as a central command center, providing easy access to functions previously buried in menus through voice or text commands. Users can ask the assistant to:</p>\n<ul>\n<li>Run diagnostics to optimize game performance</li>\n<li>Display or chart frame rates, latency and GPU temperatures</li>\n<li>Adjust GPU or even peripheral settings, such as keyboard lighting</li>\n</ul>\n<p></p>\n<p>The G-Assist update also introduces a new, significantly more efficient AI model that’s faster and uses 40% less memory while maintaining response accuracy. The more efficient model means that G-Assist can now run on all RTX GPUs with 6GB or more VRAM, including laptops.</p>\n<p>Getting started is simple:</p>\n<ol>\n<li>Install the latest Game Ready Driver (580.97 and above) from the NVIDIA app.</li>\n<li>Open the NVIDIA app, go to Settings &gt; About and opt in to Beta and Experimental Features / Early Access. Then re-launch the app; it should be on version 11.0.5.</li>\n<li>On the NVIDIA app, go to Home, scroll down to Discover and download the G-Assist 0.1.17 update.</li>\n<li>Press Alt+G to activate.</li>\n</ol>\n<p>Another G-Assist update coming in September will introduce support for laptop-specific commands for features like <a href=\"https://www.nvidia.com/en-us/geforce/technologies/battery-boost/\" target=\"_blank\">NVIDIA BatteryBoost</a> and Battery OPS.</p>\n<h2><b>Introducing the G-Assist Plug-In Hub With Mod.io</b></h2>\n<p>NVIDIA is collaborating with <a href=\"https://mod.io/\" target=\"_blank\">mod.io</a> to launch the <a href=\"https://mod.io/g/g-assist\" target=\"_blank\">G-Assist Plug-In Hub</a>, which allows users to easily access <a href=\"https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-plugin-builder/\">G-Assist plug-ins</a>, as well as discover and download community-created ones.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83855\" style=\"width: 777px;\"><a href=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/mod.io-plug-in.jpg\"><img alt=\"\" class=\"size-full wp-image-83855\" height=\"611\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/mod.io-plug-in.jpg\" width=\"777\" /></a><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83855\">With the mod.io plug-in, users can ask G-Assist to discover and install new plug-ins.</figcaption></figure>\n<p>With the latest update, users can also directly ask G-Assist what new plug-ins are available in the hub and install them using natural language, thanks to a mod.io plug-in.</p>\n<p>The recent <a href=\"https://developer.nvidia.com/g-assist-hackathon\" target=\"_blank\">G-Assist Plug-In Hackathon</a> showcased the incredible creativity of the G-Assist community. Here’s a sneak peek of what they came up with:</p>\n<p></p>\n<p>Some finalists include:</p>\n<ul>\n<li><b>Omniplay</b> — allows gamers to use G-Assist to research lore from online wikis or take notes in real time while gaming</li>\n<li><b>Launchpad</b> — lets gamers set, launch and toggle custom app groups on the fly to boost productivity</li>\n<li><b>Flux NIM Microservice for G-Assist</b> — allows gamers to easily generate AI images from within G-Assist, using on-device NVIDIA NIM microservices</li>\n</ul>\n<p>The winners of the hackathon will be announced on Wednesday, Aug. 20.</p>\n<p>Building custom plug-ins is simple. They’re based on a foundation of JSON and Python scripts — and the Project G-Assist <a href=\"https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-plugin-builder/\">Plug-In Builder</a> helps further simplify development by enabling users to code plug-ins with natural language.</p>\n<h2><b>Mod It Like It’s Hot With RTX Remix </b></h2>\n<p>Classic PC games remain beloved for their unforgettable stories, characters and gameplay — but their dated graphics can be a barrier for new and longtime players.</p>\n<p><a href=\"https://www.nvidia.com/en-us/geforce/rtx-remix/\" target=\"_blank\">NVIDIA RTX Remix</a> enables modders to revitalize these timeless titles with the latest NVIDIA gaming technologies — bridging nostalgic gameplay with modern visuals.</p>\n<p>Since the platform’s release, the RTX Remix modding community has grown with over 350 active projects and over 100 mods released. The mods span a catalog of beloved games like <i>Half-Life 2</i>, <i>Need for Speed: Underground</i>, <i>Portal 2 </i>and <i>Deus Ex — </i>and have amassed over 2 million downloads.</p>\n<p></p>\n<p>In May, NVIDIA invited modders to participate in the <a href=\"https://www.nvidia.com/en-us/geforce/news/rtx-remix-mod-contest-portal-with-rtx-dlss-4-multi-frame-gen/\" target=\"_blank\">NVIDIA and ModDB RTX Remix Mod Contest</a> for a chance to win $50,000 in cash prizes. At Gamescom, NVIDIA announced the winners:</p>\n<ul>\n<li><b>Best Overall RTX Mod Winner: </b><a href=\"https://www.moddb.com/mods/painkiller-rtx-remix\" target=\"_blank\"><i>Painkiller</i> RTX Remix</a>, by Binq_Adams</li>\n<li><b>Best Use of RTX in a Mod Winner: </b><a href=\"https://www.moddb.com/mods/painkiller-rtx-remix\" target=\"_blank\"><i>Painkiller</i> RTX Remix</a>, by Binq_Adams\n<ul>\n<li><b>Runner-Up: </b><a href=\"https://www.moddb.com/mods/vampire-the-masquerade-bloodlines-rtx-remaster\" target=\"_blank\"><i>Vampire: The Masquerade – Bloodlines</i> &#8211; RTX Remaster</a>, by Safemilk</li>\n</ul>\n</li>\n<li><b>Most Complete RTX Mod Winner:</b> <a href=\"https://www.moddb.com/mods/painkiller-rtx-remix\" target=\"_blank\"><i>Painkiller</i> RTX Remix</a>, by Binq_Adams\n<ul>\n<li><b>Runner-Up:</b> <a href=\"https://www.moddb.com/mods/i-ninja-remixed/videos/i-ninja-remixed-trailer\" target=\"_blank\"><i>I-Ninja</i> Remixed</a>, by g.i.george333</li>\n</ul>\n</li>\n<li><b>Community Choice RTX Mod Winner: </b><a href=\"https://www.moddb.com/mods/call-of-duty-2-rtx-remix-of-carentan\" target=\"_blank\"><i>Call of Duty 2</i> RTX Remix of Carentan</a>, by tadpole3159</li>\n</ul>\n<p>These modders tapped RTX Remix and generative AI to bring their creations to life — from enhancing textures to quickly creating images and 3D assets.</p>\n<p>For example, the Merry Pencil Studios modder team used a workflow that seamlessly connected RTX Remix and ComfyUI, allowing them to simply select textures in the RTX Remix viewport and, with a single click in ComfyUI, restore them.</p>\n<p>The results are stunning, with each texture meticulously recreated with physically based materials layered with grime and rust. With a fully path-traced lighting system, the game’s gothic horror atmosphere has never felt more immersive to play through.</p>\n<p>All mods submitted to the RTX Remix Modding Contest, as well as 100 more Remix mods, are available to download from <a href=\"https://www.moddb.com/groups/rtx-remix-modding/competition\" target=\"_blank\">ModDB</a>. For a sneak peek at RTX Remix projects under active development, check out the <a href=\"https://discord.gg/j6sh7JD3v9\" target=\"_blank\">RTX Remix Showcase Discord server</a>.</p>\n<p>Another RTX Remix update coming in September will allow modders to create new particles that match the look of those found in modern titles. This opens the door for over 165 RTX Remix-compatible games to have particles for the first time.</p>\n<p>To get started creating RTX mods, download NVIDIA RTX Remix from the home screen of the <a href=\"https://www.nvidia.com/en-us/software/nvidia-app/\" target=\"_blank\">NVIDIA app</a>. Read the <a href=\"https://www.nvidia.com/en-us/geforce/news/rtx-remix-mod-contest-winners\" target=\"_blank\">RTX Remix article</a> to learn more about the contest and winners.</p>\n<p><i>Each week, the </i><a href=\"https://blogs.nvidia.com/blog/tag/rtx-ai-garage/\"><i>RTX AI Garage</i></a> <i>blog series features community-driven AI innovations and content for those looking to learn more about NVIDIA NIM microservices and AI Blueprints, as well as building </i><a href=\"https://www.nvidia.com/en-us/glossary/ai-agents/\" target=\"_blank\"><i>AI agents</i></a><i>, creative workflows, productivity apps and more on AI PCs and workstations. </i></p>\n<p><i>Plug in to NVIDIA AI PC on </i><a href=\"https://www.facebook.com/NVIDIA.AI.PC/\" target=\"_blank\"><i>Facebook</i></a><i>, </i><a href=\"https://www.instagram.com/nvidia.ai.pc/\" target=\"_blank\"><i>Instagram</i></a><i>, </i><a href=\"https://www.tiktok.com/@nvidia_ai_pc\" target=\"_blank\"><i>TikTok</i></a><i> and </i><a href=\"https://x.com/NVIDIA_AI_PC\" target=\"_blank\"><i>X</i></a><i> — and stay informed by subscribing to the </i><a href=\"https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai\" target=\"_blank\"><i>RTX AI PC newsletter</i></a><i>. Join NVIDIA’s </i><a href=\"https://discord.gg/taH4gkMt\" target=\"_blank\"><i>Discord server</i></a><i> to connect with community developers and AI enthusiasts for discussions on what’s possible with RTX AI.</i></p>\n<p><i>Follow NVIDIA Workstation on </i><a href=\"https://www.linkedin.com/showcase/3761136/\" target=\"_blank\"><i>LinkedIn</i></a><i> and </i><a href=\"https://x.com/NVIDIAworkstatn\" target=\"_blank\"><i>X</i></a><i>. </i></p>\n<p><i>See </i><a href=\"https://www.nvidia.com/en-eu/about-nvidia/terms-of-service/\" target=\"_blank\"><i>notice</i></a><i> regarding software product information.</i></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/gamescom-g-assist-nv-blog-1280x680-1.jpg",
          "type": "image/jpeg",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/gamescom-g-assist-nv-blog-1280x680-1-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "At Gamescom 2025, NVIDIA DLSS 4 and Ray Tracing Come to This Year’s Biggest Titles",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "At Gamescom 2025, NVIDIA DLSS 4 and Ray Tracing Come to This Year’s Biggest Titles"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/gamescom-2025-dlss-4-ray-tracing/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/gamescom-2025-dlss-4-ray-tracing/",
      "authors": [
        {
          "name": "Caiti Sullivan"
        }
      ],
      "author": "Caiti Sullivan",
      "author_detail": {
        "name": "Caiti Sullivan"
      },
      "published": "Mon, 18 Aug 2025 19:30:01 +0000",
      "published_parsed": [
        2025,
        8,
        18,
        19,
        30,
        1,
        0,
        230,
        0
      ],
      "tags": [
        {
          "term": "Gaming",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA DLSS",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA RTX",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83810",
      "guidislink": false,
      "summary": "With over 175 games now supporting NVIDIA DLSS 4 — a suite of advanced, AI-powered neural rendering technologies — gamers and tech enthusiasts everywhere can experience breakthrough performance in this year’s most anticipated titles, including Borderlands 4, Hell Is Us and Fate Trigger. Plus, path tracing is making its way to Resident Evil Requiem and\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/gamescom-2025-dlss-4-ray-tracing/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>With over 175 games now supporting <a href=\"https://www.nvidia.com/en-us/geforce/technologies/dlss/\" target=\"_blank\">NVIDIA DLSS 4</a> — a suite of advanced, AI-powered neural rendering technologies — gamers and tech enthusiasts everywhere can experience breakthrough performance in this year’s most anticipated titles, including <i>Borderlands 4</i>, <i>Hell Is Us</i> and <i>Fate Trigger</i>.</p>\n<p>Plus, path tracing is making its way to <i>Resident Evil Requiem</i> and <i>Directive 8020</i>, as well as ray tracing in upcoming releases like <i>Phantom Blade Zero</i>, <i>PRAGMATA</i> and <i>CINDER CITY</i> — enabling crystal-clear visuals for more immersive gameplay</p>\n<p>“DLSS 4 and path tracing are no longer cutting-edge graphical experiments — they’re the foundation of modern PC gaming titles,” said Matt Wuebbling, vice president of global GeForce marketing at NVIDIA. “Developers are embracing AI-powered rendering to unlock stunning visuals and massive performance gains, enabling gamers everywhere to experience the future of real-time graphics today.”</p>\n<p>These announcements come alongside a new NVIDIA GeForce RTX 50 Series bundle for <i>Borderlands 4</i> and updates to the <a href=\"https://www.nvidia.com/en-us/software/nvidia-app/\" target=\"_blank\">NVIDIA app</a> — a companion platform for content creators, gamers and AI enthusiasts using NVIDIA GeForce RTX GPUs.</p>\n<h2><b>DLSS 4 Now Accelerating Over 175 Games and Applications</b></h2>\n<p>Launched with the GeForce RTX 50 Series earlier this year, DLSS 4 with Multi Frame Generation uses AI to generate up to three frames for every traditionally rendered frame, delivering performance boosts of up to 8x over traditional rendering.</p>\n<p>In addition to Multi Frame Generation, DLSS 4 titles include support for DLSS Super Resolution, Ray Reconstruction and NVIDIA Reflex technology — unlocking incredible performance gains and responsive gameplay for every GeForce RTX 50 Series owner.</p>\n<p>New titles announced at Gamescom that will support the latest RTX technologies include:</p>\n<ul>\n<li><i>Directive 8020</i> and <i>Resident Evil Requiem</i>, which are launching with DLSS 4 and path tracing</li>\n<li><i>Black State</i>, <i>CINDER CITY</i> (formerly <i>Project LLL</i>), <i>Cronos: The New Dawn</i>, <i>Dying Light: The Beast</i>, <i>Honeycomb: The World Beyond</i>, <i>Lost Soul Aside</i>, <i>The Outer Worlds 2</i>, <i>Phantom Blade Zero</i> and <i>PRAGMATA</i>, which are launching with DLSS 4 and ray tracing</li>\n<li><i>Borderlands 4</i> and <i>Fate Trigger</i>, which are launching with DLSS 4 with Multi Frame Generation</li>\n<li><i>Indiana Jones and the Great Circle, </i>which in September will add support for RTX Hair, a technology that uses new hardware capabilities in RTX 50 Series GPUs to model hair with greater path-traced detail and realism</li>\n<li></li>\n</ul>\n<p>Many of these RTX titles will also launch on the <a href=\"https://www.nvidia.com/en-us/geforce-now/\" target=\"_blank\">GeForce NOW</a> cloud gaming platform, including<i> Borderlands 4, CINDER CITY </i>(formerly<i> Project LLL</i>)<i>, Hell Is Us </i>and <i>The Outer Worlds 2.</i></p>\n<h2><b>NVIDIA App Adds Global DLSS Overrides and Software Updates</b></h2>\n<p>The <a href=\"https://www.nvidia.com/en-us/software/nvidia-app/\" target=\"_blank\">NVIDIA app</a> is the essential companion for NVIDIA GeForce RTX GPU users, simplifying the process of keeping PCs updated with the latest GeForce Game Ready and NVIDIA Studio Drivers.</p>\n<p>New updates to the NVIDIA app include:</p>\n<ul>\n<li><b>Global DLSS Overrides:</b> Easily enable DLSS Multi-Frame Generation or DLSS Super Resolution profiles globally across hundreds of DLSS Override titles, instead of needing to configure per title.</li>\n<li><b>Project G-Assist Upgrades: </b>The latest update to Project G-Assist — an on-device AI assistant that lets users control and tune their RTX systems with voice and text commands — introduces a significantly more efficient AI model that uses 40% less memory. Despite its smaller footprint, it responds to queries faster and more accurately calls the right tools.</li>\n<li><b>Highly Requested Legacy 3D Settings:</b> Use easily configurable control panel settings — including anisotropic filtering, anti-aliasing and ambient occlusion — to enhance classic games.</li>\n</ul>\n<p>The NVIDIA app beta update launches Tuesday, Aug. 19, at 9 a.m. PT, with full availability coming the following week.</p>\n<h2><b>NVIDIA ACE Enhances Voice-Driven Gaming Experiences</b></h2>\n<p><a href=\"https://developer.nvidia.com/ace-for-games\" target=\"_blank\">NVIDIA ACE</a> — a suite of generative AI technologies that power lifelike non-playable character interactions in games like Krafton’s <i>inZOI</i> — now features in Iconic Interactive’s <i>The Oversight Bureau</i>, a darkly comic, voice-driven puzzle game.</p>\n<p>Using speech-to-text technology powered by ACE, players can interact naturally with in-game characters using speech, with Iconic’s Narrative Engine interpreting the input and determining and delivering the pre-recorded character dialogue that best fits the story and situation.</p>\n<p>This system keeps developers in creative control while offering players real agency in games — all running locally on RTX AI PCs with sub-second latency.</p>\n<p><i>The Oversight Bureau</i> launches later this year and will be playable at NVIDIA’s Gamescom B2B press suite.</p>\n<h2><b>NVIDIA RTX Remix Evolves With Community Expansions and New Particle System</b></h2>\n<p><a href=\"https://www.nvidia.com/en-us/geforce/rtx-remix/\" target=\"_blank\">NVIDIA RTX Remix</a>, an open-source modding platform for remastering classic games with path tracing and neural rendering, continues to grow thanks to its passionate community.</p>\n<p>Modders have been using large language models to extend RTX Remix’s capabilities. For example, one modder “vibe coded” a plug-in that connects RTX Remix to Adobe Substance 3D, the industry-standard tool for 3D texturing and materials. Another modder made it possible for RTX Remix to use classic game data to instantly make objects glow with emissive effects.</p>\n<p>RTX Remix’s open-source community has even expanded compatibility to allow many new titles to be remastered, including iconic games like <i>Call Of Duty 4: Modern Warfare</i>, <i>Knights Of The Old Republic</i>, <i>Doom 3</i>, <i>Half-Life: Black Mesa</i> and <i>Bioshock.</i></p>\n<p>Some of these games were featured in the RTX Remix’s $50K Mod Contest, which wrapped up at Gamescom. <i>Painkiller RTX</i> by Merry Pencil Studios won numerous awards, including “Best Overall RTX Remix Mod.” Explore all mod submissions on <a href=\"https://www.moddb.com/groups/rtx-remix-modding/competition\" target=\"_blank\">ModDB.com</a>.</p>\n<p>At Gamescom, NVIDIA also unveiled a new RTX Remix particle system that brings dynamic, realistically lit and physically accurate particles to 165 classic games — the majority of which have never had a particle editor.</p>\n<p>Modders can use the system to change the look, size, quantity, light emission, turbulence and even gravity of particles in games. The new particle system will be available in September.</p>\n<h2><b>‘Borderlands 4’ GeForce RTX 50 Series Bundle Available Now</b></h2>\n<p>To celebrate Gearbox’s <a href=\"https://borderlands.2k.com/\" target=\"_blank\"><i>Borderlands 4</i></a>, which will be enhanced by DLSS 4 with Multi Frame Generation and NVIDIA Reflex, NVIDIA is introducing a new GeForce RTX 50 Series bundle.</p>\n<p>Players who purchase a GeForce RTX 5090, 5080, 5070 Ti, or 5070 desktop system or graphics card — or laptops with a GeForce RTX<img alt=\"™\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2122.png\" style=\"height: 1em;\" /> 5090 Laptop GPU, RTX 5080 Laptop GPU, RTX 5070 Ti Laptop GPU or RTX 5070 Laptop GPU from participating retailers — will receive a copy of <i>Borderlands 4</i> and <i>The Gilded Glory Pack</i> DLC. The offer is available through Monday, Sept. 22.</p>\n<p><i>Learn more about GeForce announcements at </i><a href=\"https://www.nvidia.com/en-us/geforce/news/gamescom-2025-nvidia-geforce-rtx-announcements\" target=\"_blank\"><i>Gamescom</i></a><i>.</i></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/gamescom-2025-dlss.jpg",
          "type": "image/jpeg",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/gamescom-2025-dlss-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "Launching NVIDIA Jetson Thor for the Millions of Developers Embracing NVIDIA Robotics",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Launching NVIDIA Jetson Thor for the Millions of Developers Embracing NVIDIA Robotics"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/2-million-robotics-developers/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/2-million-robotics-developers/",
      "authors": [
        {
          "name": "NVIDIA Writers"
        }
      ],
      "author": "NVIDIA Writers",
      "author_detail": {
        "name": "NVIDIA Writers"
      },
      "published": "Mon, 18 Aug 2025 16:00:34 +0000",
      "published_parsed": [
        2025,
        8,
        18,
        16,
        0,
        34,
        0,
        230,
        0
      ],
      "tags": [
        {
          "term": "Robotics",
          "scheme": null,
          "label": null
        },
        {
          "term": "Developer Program",
          "scheme": null,
          "label": null
        },
        {
          "term": "Embedded Computing",
          "scheme": null,
          "label": null
        },
        {
          "term": "Inception",
          "scheme": null,
          "label": null
        },
        {
          "term": "Isaac",
          "scheme": null,
          "label": null
        },
        {
          "term": "Jetson",
          "scheme": null,
          "label": null
        },
        {
          "term": "Physical AI",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83816",
      "guidislink": false,
      "summary": "We’re celebrating the more than 2 million developers now using the NVIDIA robotics stack. These builders are reshaping industries across manufacturing, food delivery, agriculture, healthcare, facilities maintenance and much more.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/robotics-jetson-agx-thor-2million-devs-v011-scaled.png",
          "type": "image/png",
          "width": "2048",
          "height": "1152"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/robotics-jetson-agx-thor-2million-devs-v011-842x450.png",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "Now We’re Talking: NVIDIA Releases Open Dataset, Models for Multilingual Speech AI",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Now We’re Talking: NVIDIA Releases Open Dataset, Models for Multilingual Speech AI"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/speech-ai-dataset-models/"
        },
        {
          "length": "7817537",
          "type": "video/mp4",
          "href": "https://blogs.nvidia.com/wp-content/uploads/2025/08/Canary-demo.mp4",
          "rel": "enclosure"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/speech-ai-dataset-models/",
      "authors": [
        {
          "name": "Jonathan Cohen"
        }
      ],
      "author": "Jonathan Cohen",
      "author_detail": {
        "name": "Jonathan Cohen"
      },
      "published": "Fri, 15 Aug 2025 07:00:30 +0000",
      "published_parsed": [
        2025,
        8,
        15,
        7,
        0,
        30,
        4,
        227,
        0
      ],
      "tags": [
        {
          "term": "Generative AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA NeMo",
          "scheme": null,
          "label": null
        },
        {
          "term": "Open Source",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83769",
      "guidislink": false,
      "summary": "Of around 7,000 languages in the world, a tiny fraction are supported by AI language models. NVIDIA is tackling the problem with a new dataset and models that support the development of high-quality speech recognition and translation AI for 25 European languages — including languages with limited available data like Croatian, Estonian and Maltese. These\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/speech-ai-dataset-models/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>Of around 7,000 languages in the world, a tiny fraction are supported by AI language models. NVIDIA is tackling the problem with a new dataset and models that support the development of high-quality speech recognition and translation AI for 25 European languages — including languages with limited available data like Croatian, Estonian and Maltese.</p>\n<p>These tools will enable developers to more easily scale AI applications to support global users with fast, accurate speech technology for production-scale use cases such as multilingual chatbots, customer service voice agents and near-real-time translation services. They include:</p>\n<ul>\n<li><a href=\"https://huggingface.co/datasets/nvidia/granary\" target=\"_blank\">Granary</a>, a massive, open-source corpus of multilingual speech datasets that contains around a million hours of audio, including nearly 650,000 hours for speech recognition and over 350,000 hours for speech translation.</li>\n<li><a href=\"https://huggingface.co/nvidia/canary-1b-v2\" target=\"_blank\">NVIDIA Canary-1b-v2</a>, a billion-parameter model trained on Granary for high-quality transcription of European languages, plus translation between English and two dozen supported languages. <span>It </span><a href=\"https://huggingface.co/spaces/hf-audio/open_asr_leaderboard\" target=\"_blank\"><span>tops Hugging Face’s leaderboard</span></a><span> of open models for multilingual speech recognition accuracy.</span></li>\n<li><a href=\"https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3\" target=\"_blank\">NVIDIA Parakeet-tdt-0.6b-v3</a>, a streamlined, 600-million-parameter model designed for real-time or large-volume transcription of Granary’s supported languages. <span>It has the highest throughput of multilingual models </span><a href=\"https://huggingface.co/spaces/hf-audio/open_asr_leaderboard\" target=\"_blank\"><span>on the Hugging Face leaderboard</span></a><span>, measured as duration of audio transcribed divided by computation time.</span></li>\n</ul>\n<p>The <a href=\"https://arxiv.org/pdf/2505.13404\" target=\"_blank\">paper behind Granary</a> will be presented at Interspeech, a language processing conference taking place in the Netherlands, Aug. 17-21. The dataset, as well as the new Canary and Parakeet models, are now <a href=\"https://hf.co/datasets/nvidia/Granary\" target=\"_blank\">available on Hugging Face</a>.</p>\n<h2><b>How Granary Addresses Data Scarcity</b></h2>\n<p>To develop the Granary dataset, the NVIDIA speech AI team <a href=\"https://huggingface.co/datasets/nvidia/Granary#overview\" target=\"_blank\">collaborated with researchers</a> from Carnegie Mellon University and Fondazione Bruno Kessler. The team passed unlabeled audio through an innovative processing pipeline powered by <a href=\"https://github.com/NVIDIA/NeMo-speech-data-processor/tree/main/dataset_configs/multilingual/granary\" target=\"_blank\">NVIDIA NeMo Speech Data Processor</a> toolkit that turned it into structured, high-quality data.</p>\n<p>This pipeline allowed the researchers to enhance public speech data into a usable format for AI training, without the need for resource-intensive human annotation. It’s <a href=\"https://github.com/NVIDIA/NeMo-speech-data-processor/tree/main/dataset_configs/multilingual/granary\" target=\"_blank\">available in open source on GitHub</a>.</p>\n<p>With Granary’s clean, ready-to-use data, developers can get a head start building models that tackle transcription and translation tasks in nearly all of the European Union’s 24 official languages, plus Russian and Ukrainian.</p>\n<p>For European languages underrepresented in human-annotated datasets, Granary provides a critical resource to develop more inclusive speech technologies that better reflect the linguistic diversity of the continent — all while using less training data.</p>\n<p>The team demonstrated in their Interspeech paper that, compared to other popular datasets, it takes around half as much Granary training data to achieve a target accuracy level for automatic speech recognition (ASR) and automatic speech translation (AST).</p>\n<h2><b>Tapping NVIDIA NeMo to Turbocharge Transcription</b></h2>\n<p>The new Canary and Parakeet models offer examples of the kinds of models developers can build with Granary, customized to their target applications. Canary-1b-v2 is optimized for accuracy on complex tasks, while parakeet-tdt-0.6b-v3 is designed for high-speed, low-latency tasks.</p>\n<p>By sharing the methodology behind the Granary dataset and these two models, NVIDIA is enabling the global speech AI developer community to adapt this data processing workflow to other ASR or AST models or additional languages, accelerating speech AI innovation.</p>\n<p>Canary-1b-v2, available under a <a href=\"https://creativecommons.org/licenses/by/4.0/deed.en\" target=\"_blank\">permissive license</a>, expands the Canary family’s supported languages from four to 25. It offers transcription and translation quality comparable to models 3x larger while running inference up to 10x faster.</p>\n<div class=\"wp-video\" style=\"width: 1920px;\"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->\n<video class=\"wp-video-shortcode\" controls=\"controls\" height=\"1080\" id=\"video-83769-1\" poster=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/Screenshot-2025-08-14-at-5.07.10-PM.png\" preload=\"metadata\" width=\"1920\"><source src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/Canary-demo.mp4?_=1\" type=\"video/mp4\" /><a href=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/Canary-demo.mp4\">https://blogs.nvidia.com/wp-content/uploads/2025/08/Canary-demo.mp4</a></video></div>\n<p><a href=\"https://www.nvidia.com/en-us/ai-data-science/products/nemo/\" target=\"_blank\">NVIDIA NeMo</a>, a modular software suite for managing the AI agent lifecycle, accelerated speech AI model development. <a href=\"https://developer.nvidia.com/nemo-curator\" target=\"_blank\">NeMo Curator</a>, part of the software suite, enabled the team to filter out synthetic examples from the source data so that only high-quality samples were used for model training. The team also harnessed the NeMo Speech Data Processor toolkit for tasks like aligning transcripts with audio files and converting data into the required formats.</p>\n<p>Parakeet-tdt-0.6b-v3 prioritizes high throughput and is capable of transcribing 24-minute audio segments in a single inference pass. The model automatically detects the input audio language and transcribes without additional prompting steps.</p>\n<p>Both Canary and Parakeet models provide accurate punctuation, capitalization and word-level timestamps in their outputs.</p>\n<p><a href=\"https://nvidia-nemo.github.io/blog/2025/08/13/granary-data-for-fine-tune/\" target=\"_blank\">Read more on GitHub</a> and get started with <a href=\"https://huggingface.co/datasets/nvidia/Granary\" target=\"_blank\">Granary on Hugging Face</a>.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/speech-transcription.jpg",
          "type": "image/jpeg",
          "width": "1600",
          "height": "900"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/speech-transcription-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "‘Warhammer 40,000: Dawn of War – Definitive Edition’ Storms GeForce NOW at Launch",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "‘Warhammer 40,000: Dawn of War – Definitive Edition’ Storms GeForce NOW at Launch"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/geforce-now-thursday-warhammer-dawn-of-war-definitive-edition/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/geforce-now-thursday-warhammer-dawn-of-war-definitive-edition/",
      "authors": [
        {
          "name": "GeForce NOW Community"
        }
      ],
      "author": "GeForce NOW Community",
      "author_detail": {
        "name": "GeForce NOW Community"
      },
      "published": "Thu, 14 Aug 2025 13:00:46 +0000",
      "published_parsed": [
        2025,
        8,
        14,
        13,
        0,
        46,
        3,
        226,
        0
      ],
      "tags": [
        {
          "term": "Gaming",
          "scheme": null,
          "label": null
        },
        {
          "term": "Cloud Gaming",
          "scheme": null,
          "label": null
        },
        {
          "term": "GeForce NOW",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83745",
      "guidislink": false,
      "summary": "Warhammer 40,000: Dawn of War – Definitive Edition is marching onto GeForce NOW, expanding the cloud gaming platform’s library to over 2,300 supported titles. Battle is just a click away, as the iconic real-time strategy game joins seven new releases this week. Commanders can prepare their squads and steel their nerves on any device —\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/geforce-now-thursday-warhammer-dawn-of-war-definitive-edition/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p><i>Warhammer 40,000: Dawn of War – Definitive Edition</i> is marching onto <a href=\"https://www.nvidia.com/en-us/geforce-now/\" target=\"_blank\">GeForce NOW</a>, expanding the cloud gaming platform’s library to over 2,300 supported titles.</p>\n<p>Battle is just a click away, as the iconic real-time strategy game joins seven new releases this week. Commanders can prepare their squads and steel their nerves on any device — including laptops, Macs, Steam Decks and <a href=\"https://www.nvidia.com/en-us/shield/\" target=\"_blank\">NVIDIA SHIELD TVs</a>.</p>\n<p>Microsoft’s surprise announcement at Quakecon is now available in the cloud: legendary fantasy shooters <i>Heretic + Hexen</i> have been conjured out of the shadows and are streaming on GeForce NOW.</p>\n<p>And don’t miss out on in-game rewards for the popular, free-to-play, massively multiplayer online game <i>World of Tanks </i>as publisher Wargaming celebrates the title’s 15-year anniversary.</p>\n<p>GeForce NOW will be at Gamescom 2025 — the world’s largest gaming tradeshow — starting Wednesday, Aug. 20. Stay tuned to GFN Thursday for all the latest updates.</p>\n<h2><b>The Emperor’s Call </b></h2>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83759\" style=\"width: 1680px;\"><img alt=\"Warhammer 40k Dawn of War definitive edition on GeForce NOW\" class=\"size-large wp-image-83759\" height=\"945\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/Warhammer-screenshot-1680x945.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83759\"><em>Make your victories shine from the cloud.</em></figcaption></figure>\n<p>The grimdark future calls. <i>Warhammer 40,000: Dawn of War – Definitive Edition</i> storms onto the battlefield with ferocious, squad-based real-time strategy. Command the Space Marines, Orks, Chaos, Eldar and more across four legendary campaigns and nine playable armies. From bolter roars to Waaagh! cries, battles erupt with uncompromising brutality, tactical depth and a healthy dose of swagger.</p>\n<p>Fully remastered with enhanced 4K visuals, a refined camera, an improved user interface and more, <i>Dawn of War: Definitive Edition</i> preserves the iconic chaos of the original game while throwing open the gates for creative mayhem. Every charge, psychic blast and last-stand is rendered sharper than ever as cunning, courage and unrelenting war decide the fate of worlds.</p>\n<p>GeForce NOW delivers the firepower needed to join the frontlines without having to wait for downloads or lengthy installs. Gamers can leap straight into battle, resume campaigns and join multiplayer chaos with just a few clicks. No frames lost to underpowered hardware — every skirmish, every decisive strike is rendered in full glory in the cloud.</p>\n<h2><b>Time to Celebrate</b></h2>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83756\" style=\"width: 1680px;\"><img alt=\"World of Tanks 15 year celebration on GeForce NOW\" class=\"size-large wp-image-83756\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-World_of_Tanks_15yr_celebration-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83756\"><em>Make your victories shine from the cloud.</em></figcaption></figure>\n<p>Roll out the tanks for <i>World of Tanks</i>’s 15th-anniversary celebration. Join the party by logging into the game every day through Sunday, Aug. 31 for exclusive commemorative rewards.</p>\n<p>Here’s what’s on deck: daily in-game giveaways, deep discounts, a pulse-pounding limited-time game mode and a special Battle Pass chapter packed with surprises. Watch for Twitch drops, enjoy increased credit earnings when playing with veteran tankers and dive into a unique photo-album event where each day reveals a new chapter in the evolution of maps, vehicles and epic memories.</p>\n<p>Enjoy smooth, lightning-fast gameplay on GeForce NOW — even on modest hardware — and share every explosive moment with friends, fans and fellow commanders. No download hassles, just pure, seamless action.</p>\n<h2><b>Get Hexed</b></h2>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83753\" style=\"width: 1680px;\"><img alt=\"Heretic + Hexen on GeForce NOW\" class=\"size-large wp-image-83753\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-HereticHexen-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83753\"><em>Suit up, pick a class and let chaos reign.</em></figcaption></figure>\n<p>Step into the shadowy worlds that shaped fantasy shooters — fully restored by Nightdive Studios. <i>Heretic + Hexen</i>, the cult classics forged by Raven Software, are back with a vengeance, bringing their spell-slinging attitude and dark magic to a whole new generation.</p>\n<p>This definitive collection brings together <i>Heretic: Shadow of the Serpent Riders, Hexen: Beyond Heretic </i>and<i> Hexen: Deathkings of the Dark Citadel</i> — plus two brand-new episodes,<i> Heretic: Faith Renewed</i> and <i>Hexen: Vestiges of Grandeur,</i> crafted with id Software and Nightdive Studios.</p>\n<p>Dive into over 110 campaign maps, 120 deathmatch arenas, online and split-screen multiplayer modes, 4K 120 frames-per-second (fps) visuals, modern controls and more spell-slinging action than ever.</p>\n<p>Experience the arcane might of <i>Heretic + Hexen</i> with GeForce NOW, which offers instant gameplay on nearly any device, with cloud-powered graphics, ultrasmooth performance and zero downloads. <a href=\"https://www.nvidia.com/en-us/geforce-now/memberships/\" target=\"_blank\">Ultimate members</a> can crank up the magic and stream at up to 4K 120 fps — even without the latest hardware, so every exploding tome and fireball looks spellbindingly sharp.</p>\n<h2><b>All Aboard for New Games</b></h2>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83750\" style=\"width: 1680px;\"><img alt=\"Honkai Star Rail V3.5 on GeForce NOW\" class=\"size-large wp-image-83750\" height=\"840\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Honkai_Star_Rail_V3_5-1680x840.jpg\" width=\"1680\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83750\">Outwit the future.</figcaption></figure>\n<p>All aboard, Trailblazers. <i>Honkai Star Rail</i>’s new Version 3.5 “Before Their Deaths” is available to stream on GeForce NOW — no need to wait for patches or updates to downloads.</p>\n<p>The latest version brings two new playable characters, Hysilens and Imperator Cerydra, who bring fresh abilities and strategies to the game. Journey back a thousand years to ancient Okhema, face the ever-shifting menace Lygus and explore the dazzling streets of Styxia, the City of Infinite Revelry. Between epic battles, serve fairy patrons in the Chrysos Maze Grand Restaurant, mix drinks with old friends and uncover secrets that could change everything. Get ready — the next stop on the Astral Express is about to be unforgettable.</p>\n<p>In addition, members can look for the following:</p>\n<ul>\n<li><i>Echoes of the End </i>(New release on <a href=\"https://store.steampowered.com/app/2821610?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>, Aug. 12)</li>\n<li><i>9 Kings</i> (New release on Xbox, available on PC Game Pass, Aug. 14)</li>\n<li><i>Warhammer 40,000: Dawn of War &#8211; Definitive Edition </i>(New release on <a href=\"https://store.steampowered.com/app/3556750?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>, Aug. 14)</li>\n<li><i>Supraworld </i>(New release on <a href=\"https://store.steampowered.com/app/1869290?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>, Aug. 15)</li>\n<li><i>Crash Bandicoot 4: It’s About Time</i> (New release on <a href=\"https://store.steampowered.com/app/1378990?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a> and <a href=\"https://shop.battle.net/family/crash-bandicoot-4?utm_source=nvidia&amp;utm_medium=referral&amp;utm_campaign=geforce_now\" target=\"_blank\">Battle.net</a>)</li>\n<li><i>Guntouchables</i> (<a href=\"https://store.steampowered.com/app/2543510?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a>)</li>\n<li><i>Heretic + Hexen</i> (<a href=\"https://store.steampowered.com/app/3286930?utm_source=nvidia&amp;utm_campaign=geforce_now\" target=\"_blank\">Steam</a> and <a href=\"https://play.geforcenow.com/games?game-id=07439023-d0d4-475b-a638-a3032f598435&amp;utm_source=nvidia&amp;utm_campaign=obm&amp;utm_medium=email\" target=\"_blank\">Xbox</a>, available on PC Game Pass)</li>\n</ul>\n<p>What are you planning to play this weekend? Let us know on <a href=\"https://www.twitter.com/nvidiagfn\" target=\"_blank\">X</a> or in the comments below.</p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">What's a classic game that you still love to play? <img alt=\"⭐\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/2b50.png\" style=\"height: 1em;\" /></p>\n<p>&mdash; <img alt=\"🌩\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/16.0.1/72x72/1f329.png\" style=\"height: 1em;\" /> NVIDIA GeForce NOW (@NVIDIAGFN) <a href=\"https://twitter.com/NVIDIAGFN/status/1955660621292167249?ref_src=twsrc%5Etfw\" target=\"_blank\">August 13, 2025</a></p></blockquote>\n<p></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/gfn-thursday-wh-40k-dawn-of-war-de-nv-blog-1280x680-logo.jpg",
          "type": "image/jpeg",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/gfn-thursday-wh-40k-dawn-of-war-de-nv-blog-1280x680-logo-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "NVIDIA, National Science Foundation Support Ai2 Development of Open AI Models to Drive U.S. Scientific Leadership",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "NVIDIA, National Science Foundation Support Ai2 Development of Open AI Models to Drive U.S. Scientific Leadership"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/national-science-foundation-ai2-open-ai-models/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/national-science-foundation-ai2-open-ai-models/",
      "authors": [
        {
          "name": "Jack Wells"
        }
      ],
      "author": "Jack Wells",
      "author_detail": {
        "name": "Jack Wells"
      },
      "published": "Thu, 14 Aug 2025 12:00:44 +0000",
      "published_parsed": [
        2025,
        8,
        14,
        12,
        0,
        44,
        3,
        226,
        0
      ],
      "tags": [
        {
          "term": "Software",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA AI Enterprise",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA Blackwell Platform",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83688",
      "guidislink": false,
      "summary": "NVIDIA is partnering with the U.S. National Science Foundation (NSF) to create an AI system that supports the development of multimodal language models for advancing scientific research in the United States. The partnership supports the NSF Mid-Scale Research Infrastructure project, called Open Multimodal AI Infrastructure to Accelerate Science (OMAI). “Bringing AI into scientific research has\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/national-science-foundation-ai2-open-ai-models/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>NVIDIA is partnering with the U.S. National Science Foundation (NSF) to create an AI system that supports the development of multimodal language models for advancing scientific research in the United States.</p>\n<p>The <a href=\"https://www.nsf.gov/news/nsf-nvidia-partnership-enables-ai2-develop-fully-open-ai\" target=\"_blank\">partnership</a> supports the NSF Mid-Scale Research Infrastructure project, called Open Multimodal AI Infrastructure to Accelerate Science (OMAI).</p>\n<p>“Bringing AI into scientific research has been a game changer,” said Brian Stone, performing the duties of the NSF director. “NSF is proud to partner with NVIDIA to equip America’s scientists with the tools to accelerate breakthroughs. These investments are not just about enabling innovation; they are about securing U.S. global leadership in science and technology and tackling challenges once thought impossible.”</p>\n<p>OMAI, part of the work of the <a href=\"https://allenai.org/blog/nsf-nvidia\" target=\"_blank\">Allen Institute for AI, or Ai2</a>, aims to build a national fully open AI ecosystem to drive scientific discovery through AI, while also advancing the science of AI itself.</p>\n<p>NVIDIA’s support of OMAI includes providing <a href=\"https://www.nvidia.com/en-us/data-center/hgx/\" target=\"_blank\">NVIDIA HGX B300 systems</a> — state-of-the-art AI infrastructure built to accelerate model training and inference with exceptional efficiency — along with the <a href=\"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/get-started/\" target=\"_blank\">NVIDIA AI Enterprise software platform,</a> empowering OMAI to transform massive datasets into actionable intelligence and breakthrough innovations.</p>\n<p>NVIDIA HGX B300 systems are built with NVIDIA Blackwell Ultra GPUs and feature industry-leading high-bandwidth memory and interconnect technologies to deliver groundbreaking acceleration, scalability and efficiency to run the world’s largest models and most demanding workloads.</p>\n<p>“AI is the engine of modern science — and large, open models for America’s researchers will ignite the next industrial revolution,” said Jensen Huang, founder and CEO of NVIDIA. “In collaboration with NSF and Ai2, we’re accelerating innovation with state-of-the-art infrastructure that empowers U.S. scientists to generate limitless intelligence, making it America’s most powerful and renewable resource.”</p>\n<p>The contributions will support research teams from the University of Washington, the University of Hawaii at Hilo, the University of New Hampshire and the University of New Mexico. The public-private partnership investment in U.S. technology aligns with recent initiatives outlined by the White House AI Action Plan, which supports America’s global AI leadership.</p>\n<p>“The models are part of the national research infrastructure — but we can’t build the models without compute, and that’s why NVIDIA is so important to this project,” said Noah Smith, senior director of natural language processing research at Ai2.</p>\n<h2><b>Opening Language Models to Advance American Researchers </b></h2>\n<p>Driving some of the fastest-growing applications in history, today’s large language models (<a href=\"https://www.nvidia.com/en-us/glossary/large-language-models/\" target=\"_blank\">LLMs</a>) have many billions of parameters, or internal weights and biases learned in training. LLMs are trained on trillions of words, and multimodal LLMs can ingest images, graphs, tables and more.</p>\n<p>But the power of these so-called frontier models can sometimes be out of reach for scientific research when the parameters, training data, code and documentation are not openly available.</p>\n<p>“With the model training data in hand, you have the opportunity to trace back to particular training instances similar to a response, and also more systematically study how emerging behaviors relate to the training data,” said Smith.</p>\n<p>NVIDIA’s partnership with NSF to support Ai2’s OMAI initiative provides fully open model access to data, open-source data interrogation tools to help refine datasets, as well as documentation and training for early-career researchers — advancing U.S. global leadership in science and engineering. <span>Cirrascale Cloud Services will provide managed services for the new hardware infrastructure funded by the support, helping Ai2 push the boundaries of AI for science.</span></p>\n<p>The Ai2 project — supported by NVIDIA technologies — pledges to make the software and models available at low or zero cost to researchers, similar to open-source code repositories and science-oriented digital libraries. It’s in line with Ai2’s previous work in creating fully open language models and multimodal models, maximizing access.</p>\n<h2><b>Driving U.S. Global Leadership in Science and Engineering </b></h2>\n<p>“Winning the AI Race: America’s AI Action Plan” <a href=\"https://www.whitehouse.gov/articles/2025/07/white-house-unveils-americas-ai-action-plan/\" target=\"_blank\">was announced</a> in July by the White House, supported with executive orders to accelerate federal permitting of data center infrastructure and promote exportation of the American AI technology stack.</p>\n<p>The OMAI initiative aligns with White House AI Action Plan priorities, emphasizing the acceleration of AI-enabled science and supporting the creation of leading open models to enhance America’s global AI leadership in academic research and education.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/her-image-nvidia-nsf-ai2-logo-for-blog-4187350-1280x680-1-scaled.png",
          "type": "image/png",
          "width": "2048",
          "height": "1088"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/her-image-nvidia-nsf-ai2-logo-for-blog-4187350-1280x680-1-842x450.png",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "Applications Now Open for $60,000 NVIDIA Graduate Fellowship Awards",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Applications Now Open for $60,000 NVIDIA Graduate Fellowship Awards"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/applications-open-graduate-fellowship-awards-2025/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/applications-open-graduate-fellowship-awards-2025/",
      "authors": [
        {
          "name": "Sylvia Chanak"
        }
      ],
      "author": "Sylvia Chanak",
      "author_detail": {
        "name": "Sylvia Chanak"
      },
      "published": "Wed, 13 Aug 2025 15:00:02 +0000",
      "published_parsed": [
        2025,
        8,
        13,
        15,
        0,
        2,
        2,
        225,
        0
      ],
      "tags": [
        {
          "term": "Corporate",
          "scheme": null,
          "label": null
        },
        {
          "term": "Deep Learning",
          "scheme": null,
          "label": null
        },
        {
          "term": "Generative AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Research",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Education",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83693",
      "guidislink": false,
      "summary": "Bringing together the world’s brightest minds and the latest accelerated computing technology leads to powerful breakthroughs that help tackle some of the biggest research problems. To foster such innovation, the NVIDIA Graduate Fellowship Program provides grants, mentors and technical support to doctoral students doing outstanding research relevant to NVIDIA technologies. The program, in its 25th\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/applications-open-graduate-fellowship-awards-2025/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>Bringing together the world’s brightest minds and the latest accelerated computing technology leads to powerful breakthroughs that help tackle some of the biggest research problems.</p>\n<p>To foster such innovation, the <a href=\"https://www.nvidia.com/en-us/research/graduate-fellowships/\" target=\"_blank\">NVIDIA Graduate Fellowship Program</a> provides grants, mentors and technical support to doctoral students doing outstanding research relevant to NVIDIA technologies. The program, in its 25th year, is now accepting applications worldwide.</p>\n<p>It focuses on supporting students working in AI, machine learning, autonomous vehicles, computer graphics, robotics, healthcare, high-performance computing and related fields. Awards are up to $60,000 per student.</p>\n<p>Since its start in 2002, the Graduate Fellowship Program has awarded over 200 grants worth more than $7.3 million.</p>\n<p>Students must have completed at least their first year of Ph.D.-level studies at the time of application.</p>\n<p>The application deadline for the 2026-2027 academic year is Monday, Sept. 15, 2025. An in-person internship at an NVIDIA research office preceding the fellowship year is mandatory; eligible candidates must be available for the internship in summer 2026.</p>\n<p>For more on eligibility and how to apply, visit the <a href=\"https://www.nvidia.com/en-us/research/graduate-fellowships/\" target=\"_blank\">program website</a>.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2024/02/2023-nvidia-corporate-key-visual-wallpaper-1080p-cropped.jpg",
          "type": "image/jpeg",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2024/02/2023-nvidia-corporate-key-visual-wallpaper-1080p-cropped-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "FLUX.1 Kontext NVIDIA NIM Microservice Now Available for Download",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "FLUX.1 Kontext NVIDIA NIM Microservice Now Available for Download"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/rtx-ai-garage-flux-kontext-nim-microservice-siggraph/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/rtx-ai-garage-flux-kontext-nim-microservice-siggraph/",
      "authors": [
        {
          "name": "Michael Fukuyama"
        }
      ],
      "author": "Michael Fukuyama",
      "author_detail": {
        "name": "Michael Fukuyama"
      },
      "published": "Wed, 13 Aug 2025 13:00:00 +0000",
      "published_parsed": [
        2025,
        8,
        13,
        13,
        0,
        0,
        2,
        225,
        0
      ],
      "tags": [
        {
          "term": "Generative AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Art",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Creators",
          "scheme": null,
          "label": null
        },
        {
          "term": "GeForce",
          "scheme": null,
          "label": null
        },
        {
          "term": "In the NVIDIA Studio",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA RTX",
          "scheme": null,
          "label": null
        },
        {
          "term": "Rendering",
          "scheme": null,
          "label": null
        },
        {
          "term": "RTX AI Garage",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83705",
      "guidislink": false,
      "summary": "Black Forest Labs’ FLUX.1 Kontext [dev] image editing model is now available as an NVIDIA NIM microservice. FLUX.1 models allow users to edit existing images with simple language, without the need for fine-tuning or complex workflows. Deploying powerful AI requires curation of model variants, adaptation to manage all input and output data, and quantization to\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/rtx-ai-garage-flux-kontext-nim-microservice-siggraph/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p>Black Forest Labs’ <a href=\"https://blogs.nvidia.com/blog/rtx-ai-garage-flux-kontext-nim-tensorrt/\">FLUX.1 Kontext</a> [dev] image editing model is now available as an <a href=\"https://www.nvidia.com/en-us/ai-data-science/products/nim-microservices/\" target=\"_blank\">NVIDIA NIM microservice</a>.</p>\n<p>FLUX.1 models allow users to edit existing images with simple language, without the need for fine-tuning or complex workflows.</p>\n<p>Deploying powerful AI requires curation of model variants, adaptation to manage all input and output data, and quantization to reduce VRAM requirements. Models must be converted to work with optimized inference backend software and connected to new AI application programming interfaces.</p>\n<p>The FLUX.1 Kontext [dev] NIM microservice simplifies this process, unlocking faster generative AI workflows, and is optimized for RTX AI PCs.</p>\n<p></p>\n<h2><b>Generative AI in Kontext</b></h2>\n<p><a href=\"https://bfl.ai/announcements/flux-1-kontext-dev\" target=\"_blank\">FLUX.1 Kontext</a> [dev] is an open-weight generative model built for image editing. It features a guided, step-by-step generation process that makes it easier to control how an image evolves, whether refining small details or transforming an entire scene.</p>\n<p><figure class=\"wp-caption aligncenter\" id=\"attachment_83711\" style=\"width: 1680px;\"><a href=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-bird.png\"><img alt=\"\" class=\"size-large wp-image-83711\" height=\"934\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-bird-1680x934.png\" width=\"1680\" /></a><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83711\">Image generated by FLUX.1 Kontext [dev] with a simple text prompt.</figcaption></figure>Because the model accepts both text and image inputs, users can easily reference a visual concept and guide how it evolves in a natural and intuitive way. This enables coherent, high-quality image edits that stay true to the original concept.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83714\" style=\"width: 1205px;\"><a href=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-example.png\"><img alt=\"\" class=\"size-full wp-image-83714\" height=\"681\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-example.png\" width=\"1205\" /></a><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83714\">Guide edits with simple language, without the need for fine-tuning or complex workflows.</figcaption></figure>\n<p>The FLUX.1 Kontext [dev] NIM microservice provides prepackaged, optimized files that are ready for one-click download through <a href=\"https://github.com/Comfy-Org/NIMnodes\" target=\"_blank\">ComfyUI NIM nodes</a> — making them easily accessible to users.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83717\" style=\"width: 1301px;\"><a href=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-birds.png\"><img alt=\"\" class=\"size-full wp-image-83717\" height=\"716\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-birds.png\" width=\"1301\" /></a><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83717\">The original image is revised with six prompts to reach the desired result.</figcaption></figure>\n<p>NVIDIA and Black Forest Labs worked together to quantize FLUX.1 Kontext [dev], reducing the model size from 24GB to 12GB for FP8 (NVIDIA Ada Generation GPUs) and 7GB for FP4 (NVIDIA Blackwell architecture). The FP8 checkpoint is optimized for GeForce RTX 40 Series GPUs, which have FP8 accelerators in their Tensor Cores. The FP4 checkpoint is optimized for GeForce RTX 50 Series GPUs and uses a new method called SVDQuant, which preserves image quality while reducing model size.</p>\n<p><figure class=\"wp-caption aligncenter\" id=\"attachment_83720\" style=\"width: 1200px;\"><a href=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-chart.png\"><img alt=\"\" class=\"size-full wp-image-83720\" height=\"424\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-chart.png\" width=\"1200\" /></a><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83720\">Speedup compared with BF16 GPU (left, higher is better), and memory usage required to run FLUX.1 Kontext [dev] in different precisions (right, lower is better).</figcaption></figure>In addition, NVIDIA TensorRT — a framework to access the Tensor Cores in NVIDIA RTX GPUs for maximum performance — provides over 2x acceleration compared with running the original BF16 model with PyTorch.</p>\n<p>These dramatic performance gains were previously limited to AI specialists and developers with advanced AI infrastructure knowledge. With the FLUX.1 Kontext [dev] NIM microservice, even enthusiasts can achieve these time savings with greater performance.</p>\n<h2><b>Get NIMble</b></h2>\n<p>FLUX.1 Kontext [dev] is available on Hugging Face with TensorRT optimizations and ComfyUI.</p>\n<p>To get started, follow the directions on <a href=\"https://github.com/Comfy-Org/NIMnodes?tab=readme-ov-file\" target=\"_blank\">ComfyUI’s NIM nodes GitHub</a>:</p>\n<ol>\n<li>Install NVIDIA AI Workbench.</li>\n<li>Get ComfyUI.</li>\n<li>Install NIM nodes through the ComfyUI Manager within the app.</li>\n<li>Accept the model licenses on Black Forest Labs’ FLUX.1 Kontext’s [dev] Hugging Face.</li>\n<li>The node will prepare the desired workflow and help with downloading all necessary models after clicking “Run.”</li>\n</ol>\n<p>NIM microservices are optimized for performance on NVIDIA <a href=\"https://www.nvidia.com/en-us/geforce/rtx/\" target=\"_blank\">GeForce RTX</a> and <a href=\"https://www.nvidia.com/en-us/products/workstations/\" target=\"_blank\">RTX PRO</a> GPUs and include popular models from the AI community. Explore NIM microservices on <a href=\"https://github.com/Comfy-Org/NIMnodes\" target=\"_blank\">GitHub</a> and <a href=\"https://build.nvidia.com\" target=\"_blank\">build.nvidia.com</a>.</p>\n<p></p>\n<p><i>Each week, the </i><a href=\"https://blogs.nvidia.com/blog/tag/rtx-ai-garage/\"><i>RTX AI Garage</i></a> <i>blog series features community-driven AI innovations and content for those looking to learn more about NVIDIA NIM microservices and AI Blueprints, as well as building </i><a href=\"https://www.nvidia.com/en-us/glossary/ai-agents/\" target=\"_blank\"><i>AI agents</i></a><i>, creative workflows, productivity apps and more on AI PCs and workstations. </i></p>\n<p><i>Plug in to NVIDIA AI PC on </i><a href=\"https://www.facebook.com/NVIDIA.AI.PC/\" target=\"_blank\"><i>Facebook</i></a><i>, </i><a href=\"https://www.instagram.com/nvidia.ai.pc/\" target=\"_blank\"><i>Instagram</i></a><i>, </i><a href=\"https://www.tiktok.com/@nvidia_ai_pc\" target=\"_blank\"><i>TikTok</i></a><i> and </i><a href=\"https://x.com/NVIDIA_AI_PC\" target=\"_blank\"><i>X</i></a><i> — and stay informed by subscribing to the </i><a href=\"https://www.nvidia.com/en-us/ai-on-rtx/?modal=subscribe-ai\" target=\"_blank\"><i>RTX AI PC newsletter</i></a><i>. Join NVIDIA’s </i><a href=\"https://discord.gg/taH4gkMt\" target=\"_blank\"><i>Discord server</i></a><i> to connect with community developers and AI enthusiasts for discussions on what’s possible with RTX AI.</i></p>\n<p><i>Follow NVIDIA Workstation on </i><a href=\"https://www.linkedin.com/showcase/3761136/\" target=\"_blank\"><i>LinkedIn</i></a><i> and </i><a href=\"https://x.com/NVIDIAworkstatn\" target=\"_blank\"><i>X</i></a><i>. </i></p>\n<p><i>See </i><a href=\"https://www.nvidia.com/en-eu/about-nvidia/terms-of-service/\" target=\"_blank\"><i>notice</i></a><i> regarding software product information.</i></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-dev-nim-nv-blog-1280x680-1.jpg",
          "type": "image/jpeg",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/flux-dev-nim-nv-blog-1280x680-1-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "Making Safer Spaces: NVIDIA and Partners Bring Physical AI to Cities and Industrial Infrastructure",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "Making Safer Spaces: NVIDIA and Partners Bring Physical AI to Cities and Industrial Infrastructure"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/physical-ai-partners-metropolis-updates-siggraph/"
        },
        {
          "length": "25525088",
          "type": "video/mp4",
          "href": "https://blogs.nvidia.com/wp-content/uploads/2025/08/turbine-cosmos-reasoning.mp4",
          "rel": "enclosure"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/physical-ai-partners-metropolis-updates-siggraph/",
      "authors": [
        {
          "name": "Adam Scraba"
        }
      ],
      "author": "Adam Scraba",
      "author_detail": {
        "name": "Adam Scraba"
      },
      "published": "Mon, 11 Aug 2025 15:00:44 +0000",
      "published_parsed": [
        2025,
        8,
        11,
        15,
        0,
        44,
        0,
        223,
        0
      ],
      "tags": [
        {
          "term": "Data Center",
          "scheme": null,
          "label": null
        },
        {
          "term": "Robotics",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Computer Vision",
          "scheme": null,
          "label": null
        },
        {
          "term": "DeepStream",
          "scheme": null,
          "label": null
        },
        {
          "term": "Digital Twin",
          "scheme": null,
          "label": null
        },
        {
          "term": "Embedded Computing",
          "scheme": null,
          "label": null
        },
        {
          "term": "Inception",
          "scheme": null,
          "label": null
        },
        {
          "term": "Industrial and Manufacturing",
          "scheme": null,
          "label": null
        },
        {
          "term": "Isaac",
          "scheme": null,
          "label": null
        },
        {
          "term": "Jetson",
          "scheme": null,
          "label": null
        },
        {
          "term": "Metropolis",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA Blueprints",
          "scheme": null,
          "label": null
        },
        {
          "term": "Omniverse",
          "scheme": null,
          "label": null
        },
        {
          "term": "Physical AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "SIGGRAPH 2025",
          "scheme": null,
          "label": null
        },
        {
          "term": "Simulation and Design",
          "scheme": null,
          "label": null
        },
        {
          "term": "Smart Spaces",
          "scheme": null,
          "label": null
        },
        {
          "term": "Synthetic Data Generation",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83562",
      "guidislink": false,
      "summary": "Physical AI is becoming the foundation of smart cities, facilities and industrial processes across the globe. NVIDIA is working with companies including Accenture, Avathon, Belden, DeepHow, Milestone Systems and Telit Cinterion to enhance operations across the globe with physical AI-based perception and reasoning. The continuous loop of simulating, training and deploying physical AI offers sophisticated\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/physical-ai-partners-metropolis-updates-siggraph/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div><p><a href=\"https://www.nvidia.com/en-us/glossary/generative-physical-ai/\" target=\"_blank\">Physical AI</a> is becoming the foundation of smart cities, facilities and industrial processes across the globe.</p>\n<p>NVIDIA is working with companies including Accenture, Avathon, Belden, DeepHow, Milestone Systems and Telit Cinterion to enhance operations across the globe with physical AI-based perception and reasoning.</p>\n<p>The continuous loop of simulating, training and deploying physical AI offers sophisticated industrial automation capabilities, making cities and infrastructure safer, smarter and more efficient.</p>\n<p>For example, physical AI applications can automate potentially dangerous tasks for workers, such as working with heavy machinery. Physical AI can also improve transportation services and public safety, detect defective products in factories and more.</p>\n<p>The need for this is greater than ever. The numbers tell the story:</p>\n<p><img alt=\"Statistics in infographic: $7 Trillion lost annually due to poor quality and defects in manufacturing. ~2.8 Million workers die annually from occupational accidents and work-related diseases. 514,000 industrial robots installed worldwide in 2024. $300 billion spent per year on public order and safety in the EU. By 2030, projected global labor shortage of 50 million.\" class=\"aligncenter wp-image-83564 size-medium\" height=\"384\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/metropolis-siggraph-2025-infographic-960x384.jpg\" width=\"960\" /></p>\n<p>Infrastructure that can perceive, reason and act relies on video sensors and the latest vision AI capabilities. Using the <a href=\"https://www.nvidia.com/en-us/autonomous-machines/intelligent-video-analytics-platform/\" target=\"_blank\">NVIDIA Metropolis</a> platform — which simplifies the development, deployment and scaling of <a href=\"https://www.nvidia.com/en-us/use-cases/video-analytics-ai-agents/\" target=\"_blank\">video analytics AI agents</a> and services from the edge to the cloud — developers can build visual perception into their facilities faster to enhance productivity and improve safety across environments.</p>\n<p>Below are five leading companies advancing physical AI — and five key NVIDIA Metropolis updates, announced today at the <a href=\"https://www.nvidia.com/en-us/events/siggraph/\" target=\"_blank\">SIGGRAPH</a> computer graphics conference, making such advancements possible.</p>\n<h2><b>Five Companies Advancing Physical AI</b></h2>\n<p>Global professional services company <b>Accenture</b> is collaborating with Belden, a leading provider of complete connection solutions, to enhance worker safety by creating smart virtual fences that factories can place around large robots to prevent accidents with human operators.</p>\n<figure class=\"wp-caption aligncenter\" id=\"attachment_83569\" style=\"width: 960px;\"><img alt=\"Smart fence image.\" class=\"size-medium wp-image-83569\" height=\"639\" src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/accenture-960x639.png\" width=\"960\" /><figcaption class=\"wp-caption-text\" id=\"caption-attachment-83569\">Image courtesy of Accenture and Belden.</figcaption></figure>\n<p>The smart virtual fence is a physical AI safety system that uses an <a href=\"https://www.nvidia.com/en-us/omniverse/usd/\" target=\"_blank\">OpenUSD</a>-based <a href=\"https://www.nvidia.com/en-us/glossary/digital-twin/\" target=\"_blank\">digital twin</a> and physics-grounded simulation to model complex <a href=\"https://www.nvidia.com/en-us/use-cases/industrial-facility-digital-twins/\" target=\"_blank\">industrial environments</a>. Using computer vision-based mapping and 3D spatial intelligence, the system is adaptive to increased variability in the dynamic human-robot interactions that occur in a modern shopfloor environment.</p>\n<p>Accenture taps into the <a href=\"https://www.nvidia.com/en-us/omniverse/\" target=\"_blank\">NVIDIA Omniverse</a> platform and Metropolis to build and simulate these smart fences. With Omniverse, Accenture created a digital twin of a robot arm and workers moving in a space. And with Metropolis, the company trained its AI models and deployed them at the edge with video ingestion and the <a href=\"https://developer.nvidia.com/deepstream-sdk\" target=\"_blank\">NVIDIA DeepStream</a> software development kit (SDK)’s real-time inference capabilities.</p>\n<p><a href=\"https://avathon.com/blog/transforming-industrial-safety-and-efficiency-avathon-integrates-nvidia-metropolis-to-supercharge-ai-powered-video-intelligence/\" target=\"_blank\"><b>Avathon</b></a>, an industrial automation platform provider, uses the <a href=\"https://build.nvidia.com/nvidia/video-search-and-summarization\" target=\"_blank\">NVIDIA Blueprint for video search and summarization</a> (VSS), part of NVIDIA Metropolis, to provide manufacturing and energy facilities with real-time insights that improve operational efficiency and worker safety.</p>\n<p>Reliance British Petroleum Mobility Limited, a leader in India’s fuel and mobility sector, used the Avathon video intelligence product during the construction of its gas stations to achieve higher standards of safety compliance, a reduction in safety noncompliance incidents and higher productivity by saving thousands of work hours.</p>\n<p><b>DeepHow</b> has developed a “Smart Know-How Companion” for employees in manufacturing and other industries. The companion uses the Metropolis VSS blueprint to transform key workflows into bite-sized, multilingual videos and digital instructions, improving onboarding, safety and floor operator efficiency.</p>\n<p>Facing upskilling needs and retiring skilled workers, beverage company Anheuser-Busch InBev turned to the DeepHow platform to convert standard operating procedures into easy-to-understand visual guides. This has slashed onboarding time by 80%, boosted training consistency and improved long-term knowledge retention for employees.</p>\n<p><b>Milestone Systems</b>, which offers one of the world’s largest platforms for managing IP video sensor data in complex industrial and city deployments, is creating the world’s largest real-world computer vision data library through its platform, Project Hafnia. Among its capabilities, the platform provides physical AI developers with access to customized vision language models (VLMs).</p>\n<p>Tapping <a href=\"https://developer.nvidia.com/nemo-curator\" target=\"_blank\">NVIDIA NeMo Curator</a>, Milestone Systems built a VLM fine-tuned for intelligent transportation systems for use within the VSS blueprint to help develop AI agents that better manage city roadways. Milestone Systems is also looking to use the new open, customizable <a href=\"https://github.com/nvidia-cosmos/cosmos-reason1\" target=\"_blank\">NVIDIA Cosmos Reason</a> VLM for physical AI.</p>\n<p>Internet-of-things company <b>Telit Cinterion</b> has integrated <a href=\"https://github.com/NVIDIA/tao_tutorials\" target=\"_blank\">NVIDIA TAO Toolkit 6</a> into its AI-powered visual inspection platform, which uses vision foundation models like <a href=\"https://catalog.ngc.nvidia.com/orgs/nvidia/teams/isaac/models/foundationpose\" target=\"_blank\">FoundationPose</a>, alongside other NVIDIA models, to support multimodal AI and deliver high-performance inferencing. TAO brings low-code AI capabilities to the Telit platform, enabling manufacturers to quickly develop and deploy accurate, custom AI models for defect detection and quality control.</p>\n<h2><b>Five NVIDIA Metropolis Updates for Physical AI</b></h2>\n<p>Key updates to NVIDIA Metropolis are enhancing developers’ capabilities to build physical AI applications more quickly and easily:</p>\n<p><b>Cosmos Reason VLM</b></p>\n<div class=\"wp-video\" style=\"width: 1920px;\"><video class=\"wp-video-shortcode\" controls=\"controls\" height=\"1080\" id=\"video-83562-2\" preload=\"metadata\" width=\"1920\"><source src=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/turbine-cosmos-reasoning.mp4?_=2\" type=\"video/mp4\" /><a href=\"https://blogs.nvidia.com/wp-content/uploads/2025/08/turbine-cosmos-reasoning.mp4\">https://blogs.nvidia.com/wp-content/uploads/2025/08/turbine-cosmos-reasoning.mp4</a></video></div>\n<p>The latest version of <a href=\"https://build.nvidia.com/nvidia/cosmos-reason1-7b\" target=\"_blank\">Cosmos Reason</a> — NVIDIA’s advanced open, customizable, 7-billion-parameter reasoning VLM for physical AI — enables contextual video understanding, temporal event reasoning for Metropolis use cases. Its compact size makes it easy to deploy from edge to cloud and ideal for automating traffic monitoring, public safety, visual inspection and intelligent decision-making.</p>\n<p><b>VSS Blueprint 2.4</b></p>\n<p>VSS 2.4 makes it easy to quickly augment existing vision AI applications with Cosmos Reason and deliver powerful new features to smart infrastructure. An expanded set of application programming interfaces in the blueprint offers users direct more flexibility in choosing specific VSS components and capabilities to augment computer vision pipelines with generative AI.</p>\n<p><b>New Vision Foundation Models</b></p>\n<p>The <a href=\"https://developer.nvidia.com/tao-toolkit\" target=\"_blank\">NVIDIA TAO Toolkit</a> includes a new suite of vision foundation models, along with advanced fine-tuning methods, self-supervised learning and knowledge distillation capabilities, to optimize deployment of physical AI solutions across edge and cloud environments. The <a href=\"https://developer.nvidia.com/deepstream-sdk\" target=\"_blank\">NVIDIA DeepStream SDK</a> includes a new Inference Builder to enable seamless deployment of TAO 6 models.</p>\n<p>Companies around the world — including Advex AI, Instrumental AI and <a href=\"https://www.spingence.com/en/news-detail/NVIDIA-TAO-6/\" target=\"_blank\">Spingence</a> — are experimenting with these new models and NVIDIA TAO to build intelligent solutions that optimize industrial operations and drive efficiency.</p>\n<p><b>NVIDIA Isaac Sim Extensions</b></p>\n<p><a href=\"https://docs.isaacsim.omniverse.nvidia.com/latest/action_and_event_data_generation/index.html\" target=\"_blank\">New extensions</a> in the NVIDIA Isaac Sim reference application help solve common challenges in vision AI development — such as limited labeled data and rare edge-case scenarios. These tools simulate human and robot interactions, generate rich object-detection datasets, and create incident-based scenes and image-caption pairs to train VLMs, accelerating development and improving AI performance in real-world conditions.</p>\n<p><b>Expanded Hardware Support</b></p>\n<p>All of these Metropolis components can now run on <a href=\"https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/rtx-pro-6000-family/\" target=\"_blank\">NVIDIA RTX PRO 6000 Blackwell GPUs</a>, the <a href=\"https://www.nvidia.com/en-us/products/workstations/dgx-spark/\" target=\"_blank\">NVIDIA DGX Spark</a> desktop supercomputer and the <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-thor/\" target=\"_blank\">NVIDIA Jetson Thor</a> platform for physical AI and humanoid robotics — so users can develop and deploy from the edge to the cloud.</p>\n<p><a href=\"https://build.nvidia.com/nvidia/cosmos-reason1-7b\" target=\"_blank\">Cosmos Reason 1</a> and <a href=\"https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/containers/tao-toolkit\" target=\"_blank\">NVIDIA TAO 6.0</a> are now available for download. <a href=\"https://www.nvidia.com/en-us/metropolis/software-availability-notify-me/\" target=\"_blank\">Sign up</a> to be alerted when VSS 2.4, the Cosmos Reason VLM fine-tuning update and NVIDIA DeepStream 8.0 become available.</p>\n<p><i>Watch the </i><a href=\"https://www.youtube.com/watch?v=rFcmv2pXR0w\" target=\"_blank\"><i>NVIDIA Research special address at SIGGRAPH</i></a><i> and learn more about how graphics and simulation innovations come together to drive industrial digitalization by joining NVIDIA at the conference, running through Thursday, Aug. 14.</i></p>\n<p><i>See </i><a href=\"https://www.nvidia.com/en-eu/about-nvidia/terms-of-service/\" target=\"_blank\"><i>notice</i></a><i> regarding software product information.</i></p>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/sigg25-metropolis-corp-blog-1280x680-1.jpg",
          "type": "image/jpeg",
          "width": "1280",
          "height": "680"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/sigg25-metropolis-corp-blog-1280x680-1-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    },
    {
      "title": "NVIDIA Research Shapes Physical AI",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": "NVIDIA Research Shapes Physical AI"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/"
        }
      ],
      "link": "https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/",
      "authors": [
        {
          "name": "Isha Salian"
        }
      ],
      "author": "Isha Salian",
      "author_detail": {
        "name": "Isha Salian"
      },
      "published": "Mon, 11 Aug 2025 15:00:38 +0000",
      "published_parsed": [
        2025,
        8,
        11,
        15,
        0,
        38,
        0,
        223,
        0
      ],
      "tags": [
        {
          "term": "Deep Learning",
          "scheme": null,
          "label": null
        },
        {
          "term": "Generative AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Pro Graphics",
          "scheme": null,
          "label": null
        },
        {
          "term": "Research",
          "scheme": null,
          "label": null
        },
        {
          "term": "3D",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Cosmos",
          "scheme": null,
          "label": null
        },
        {
          "term": "Metropolis",
          "scheme": null,
          "label": null
        },
        {
          "term": "NVIDIA Research",
          "scheme": null,
          "label": null
        },
        {
          "term": "Physical AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Ray Tracing",
          "scheme": null,
          "label": null
        },
        {
          "term": "SIGGRAPH 2025",
          "scheme": null,
          "label": null
        },
        {
          "term": "Simulation and Design",
          "scheme": null,
          "label": null
        },
        {
          "term": "Synthetic Data Generation",
          "scheme": null,
          "label": null
        }
      ],
      "id": "https://blogs.nvidia.com/?p=83572",
      "guidislink": false,
      "summary": "AI and graphics research breakthroughs in neural rendering, 3D generation and world simulation power robotics, autonomous vehicles and content creation.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "https://blogs.nvidia.com/feed/",
        "value": ""
      },
      "content": [
        {
          "type": "text/html",
          "language": null,
          "base": "https://blogs.nvidia.com/feed/",
          "value": "<div id=\"bsf_rt_marker\"></div>"
        }
      ],
      "media_content": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/NV_SIGGRAPH-KV-video_Still001.jpg",
          "type": "image/jpeg",
          "width": "1920",
          "height": "1080"
        }
      ],
      "media_thumbnail": [
        {
          "url": "https://blogs.nvidia.com/wp-content/uploads/2025/08/NV_SIGGRAPH-KV-video_Still001-842x450.jpg",
          "width": "842",
          "height": "450"
        }
      ],
      "href": ""
    }
  ]
}