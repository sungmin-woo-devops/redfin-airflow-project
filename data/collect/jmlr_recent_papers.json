{
  "feed": {
    "links": [
      {
        "href": "http://jmlr.org/jmlr.xml",
        "rel": "self",
        "type": "application/rss+xml"
      },
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "http://www.jmlr.org"
      }
    ],
    "link": "http://www.jmlr.org",
    "title": "JMLR",
    "title_detail": {
      "type": "text/plain",
      "language": null,
      "base": "http://www.jmlr.org/jmlr.xml",
      "value": "JMLR"
    },
    "subtitle": "Journal of Machine Learning Research",
    "subtitle_detail": {
      "type": "text/html",
      "language": null,
      "base": "http://www.jmlr.org/jmlr.xml",
      "value": "Journal of Machine Learning Research"
    }
  },
  "entries": [
    {
      "title": "DRM Revisited: A Complete Error Analysis",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "DRM Revisited: A Complete Error Analysis"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1258.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1258.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1258/24-1258.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Yuling Jiao, Ruoxuan Li, Peiying Wu, Jerry Zhijian Yang, Pingwen Zhang"
        }
      ],
      "author": "Yuling Jiao, Ruoxuan Li, Peiying Wu, Jerry Zhijian Yang, Pingwen Zhang",
      "author_detail": {
        "name": "Yuling Jiao, Ruoxuan Li, Peiying Wu, Jerry Zhijian Yang, Pingwen Zhang"
      },
      "summary": "It is widely known that the error analysis for deep learning involves approximation, statistical, and optimization errors. However, it is challenging to combine them together due to overparameterization. In this paper, we address this gap by providing a comprehensive error analysis of the Deep Ritz Method (DRM). Specifically, we investigate a foundational question in the theoretical analysis of DRM under the overparameterized regime: given a target precision level, how can one determine the appropriate number of training samples, the key architectural parameters of the neural networks, the step size for the projected gradient descent optimization procedure, and the requisite number of iterations, such that the output of the gradient descent process closely approximates the true solution of the underlying partial differential equation to the specified precision?",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "It is widely known that the error analysis for deep learning involves approximation, statistical, and optimization errors. However, it is challenging to combine them together due to overparameterization. In this paper, we address this gap by providing a comprehensive error analysis of the Deep Ritz Method (DRM). Specifically, we investigate a foundational question in the theoretical analysis of DRM under the overparameterized regime: given a target precision level, how can one determine the appropriate number of training samples, the key architectural parameters of the neural networks, the step size for the projected gradient descent optimization procedure, and the requisite number of iterations, such that the output of the gradient descent process closely approximates the true solution of the underlying partial differential equation to the specified precision?"
      }
    },
    {
      "title": "Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0720.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0720.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0720/24-0720.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Han Shen, Zhuoran Yang, Tianyi Chen"
        }
      ],
      "author": "Han Shen, Zhuoran Yang, Tianyi Chen",
      "author_detail": {
        "name": "Han Shen, Zhuoran Yang, Tianyi Chen"
      },
      "summary": "Bilevel optimization has been recently applied to many machine learning tasks. However, their applications have been restricted to the supervised learning setting, where static objective functions with benign structures are considered. But bilevel problems such as incentive design, inverse reinforcement learning (RL), and RL from human feedback (RLHF) are often modeled as dynamic objective functions that go beyond the simple static objective structures, which pose significant challenges of using existing bilevel solutions. To tackle this new class of bilevel problems, we introduce the first principled algorithmic framework for solving bilevel RL problems through the lens of penalty formulation. We provide theoretical studies of the problem landscape and its penalty-based (policy) gradient algorithms. We demonstrate the effectiveness of our algorithms via simulations in the Stackelberg Markov game, RL from human feedback and incentive design.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bilevel optimization has been recently applied to many machine learning tasks. However, their applications have been restricted to the supervised learning setting, where static objective functions with benign structures are considered. But bilevel problems such as incentive design, inverse reinforcement learning (RL), and RL from human feedback (RLHF) are often modeled as dynamic objective functions that go beyond the simple static objective structures, which pose significant challenges of using existing bilevel solutions. To tackle this new class of bilevel problems, we introduce the first principled algorithmic framework for solving bilevel RL problems through the lens of penalty formulation. We provide theoretical studies of the problem landscape and its penalty-based (policy) gradient algorithms. We demonstrate the effectiveness of our algorithms via simulations in the Stackelberg Markov game, RL from human feedback and incentive design."
      }
    },
    {
      "title": "Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0454.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0454.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0454/24-0454.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Fan Yang, Hongyang R. Zhang, Sen Wu, Christopher Re, Weijie J. Su"
        }
      ],
      "author": "Fan Yang, Hongyang R. Zhang, Sen Wu, Christopher Re, Weijie J. Su",
      "author_detail": {
        "name": "Fan Yang, Hongyang R. Zhang, Sen Wu, Christopher Re, Weijie J. Su"
      },
      "summary": "The problem of learning one task using samples from another task is central to transfer learning. In this paper, we focus on answering the following question: when does combining the samples from two related tasks perform better than learning with one target task alone? This question is motivated by an empirical phenomenon known as negative transfer often observed in transfer learning practice. While the transfer effect from one task to another depends on factors such as their sample sizes and the spectrum of their covariance matrices, precisely quantifying this dependence has remained a challenging problem. In order to compare a transfer learning estimator to single-task learning, one needs to compare the risks between the two estimators precisely. Further, the comparison depends on the distribution shifts between the two tasks. This paper applies recent developments of random matrix theory to tackle this challenge in a high-dimensional linear regression setting with two tasks. We provide precise high-dimensional asymptotics for the bias and variance of a classical hard parameter sharing (HPS) estimator in the proportional limit, when the sample sizes of both tasks increase proportionally with dimension at fixed ratios. The precise asymptotics apply to various types of distribution shifts, including covariate shifts, model shifts, and combinations of both. We illustrate these results in a random-effects model to mathematically prove a phase transition from positive to negative transfer as the number of source task samples increases. One insight from the analysis is that a rebalanced HPS estimator, which downsizes the source task when the model shift is high, achieves the minimax optimal rate. The finding regarding phase transition also applies to multiple tasks when feature covariates are shared across all tasks. Simulations validate the accuracy of the high-dimensional asymptotics for finite dimensions.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The problem of learning one task using samples from another task is central to transfer learning. In this paper, we focus on answering the following question: when does combining the samples from two related tasks perform better than learning with one target task alone? This question is motivated by an empirical phenomenon known as negative transfer often observed in transfer learning practice. While the transfer effect from one task to another depends on factors such as their sample sizes and the spectrum of their covariance matrices, precisely quantifying this dependence has remained a challenging problem. In order to compare a transfer learning estimator to single-task learning, one needs to compare the risks between the two estimators precisely. Further, the comparison depends on the distribution shifts between the two tasks. This paper applies recent developments of random matrix theory to tackle this challenge in a high-dimensional linear regression setting with two tasks. We provide precise high-dimensional asymptotics for the bias and variance of a classical hard parameter sharing (HPS) estimator in the proportional limit, when the sample sizes of both tasks increase proportionally with dimension at fixed ratios. The precise asymptotics apply to various types of distribution shifts, including covariate shifts, model shifts, and combinations of both. We illustrate these results in a random-effects model to mathematically prove a phase transition from positive to negative transfer as the number of source task samples increases. One insight from the analysis is that a rebalanced HPS estimator, which downsizes the source task when the model shift is high, achieves the minimax optimal rate. The finding regarding phase transition also applies to multiple tasks when feature covariates are shared across all tasks. Simulations validate the accuracy of the high-dimensional asymptotics for finite dimensions."
      }
    },
    {
      "title": "Score-based Causal Representation Learning: Linear and General Transformations",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Score-based Causal Representation Learning: Linear and General Transformations"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0194.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0194.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0194/24-0194.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Burak Varici, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, Ali Tajer"
        }
      ],
      "author": "Burak Varici, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, Ali Tajer",
      "author_detail": {
        "name": "Burak Varici, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, Ali Tajer"
      },
      "summary": "This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure the recovery of the true latent causal variables and the underlying latent causal graph. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to mixing with parents for general causal models and perfect recovery of the latent graph for sufficiently nonlinear causal models. Secondly, it focuses on general transformations and demonstrates that two stochastic hard interventions per node are sufficient for identifiability. This is achieved by defining a differentiable loss function whose global optima ensure identifiability for general CRL. Notably, one does not need to know which pair of interventional environments has the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure the recovery of the true latent causal variables and the underlying latent causal graph. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to mixing with parents for general causal models and perfect recovery of the latent graph for sufficiently nonlinear causal models. Secondly, it focuses on general transformations and demonstrates that two stochastic hard interventions per node are sufficient for identifiability. This is achieved by defining a differentiable loss function whose global optima ensure identifiability for general CRL. Notably, one does not need to know which pair of interventional environments has the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data."
      }
    },
    {
      "title": "On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0054.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0054.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0054/24-0054.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Saptarshi Chakraborty, Peter L. Bartlett"
        }
      ],
      "author": "Saptarshi Chakraborty, Peter L. Bartlett",
      "author_detail": {
        "name": "Saptarshi Chakraborty, Peter L. Bartlett"
      },
      "summary": "Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\\left( n^{-1/d_\\mu } \\right)$  for GANs and $\\tilde{O}\\left( n^{-1/(d_\\mu+\\ell)} \\right)$  for BiGANs,  where $d_\\mu$ and $\\ell$ are the upper Wasserstein-1 dimension of the data-distribution and latent-space dimension, respectively. The theoretical analyses not only suggest that these methods successfully avoid the curse of dimensionality, in the sense that the exponent of $n$ in the error rates does not depend on the data dimension but also serve to bridge the gap between the theoretical analyses of GANs and the known sharp rates from optimal transport literature.  Additionally, we demonstrate that GANs can effectively achieve the minimax optimal rate even for non-smooth underlying distributions, with the use of interpolating generator networks.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\\left( n^{-1/d_\\mu } \\right)$  for GANs and $\\tilde{O}\\left( n^{-1/(d_\\mu+\\ell)} \\right)$  for BiGANs,  where $d_\\mu$ and $\\ell$ are the upper Wasserstein-1 dimension of the data-distribution and latent-space dimension, respectively. The theoretical analyses not only suggest that these methods successfully avoid the curse of dimensionality, in the sense that the exponent of $n$ in the error rates does not depend on the data dimension but also serve to bridge the gap between the theoretical analyses of GANs and the known sharp rates from optimal transport literature.  Additionally, we demonstrate that GANs can effectively achieve the minimax optimal rate even for non-smooth underlying distributions, with the use of interpolating generator networks."
      }
    },
    {
      "title": "Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Prominent Roles of Conditionally Invariant Components in Domain Adaptation: Theory and Algorithms"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1234.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1234.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1234/23-1234.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Keru Wu, Yuansi Chen, Wooseok Ha, Bin Yu"
        }
      ],
      "author": "Keru Wu, Yuansi Chen, Wooseok Ha, Bin Yu",
      "author_detail": {
        "name": "Keru Wu, Yuansi Chen, Wooseok Ha, Bin Yu"
      },
      "summary": "Domain adaptation (DA) is a statistical learning problem that arises when the distribution of the source data used to train a model differs from that of the target data used to evaluate the model. While many DA algorithms have demonstrated considerable empirical success, blindly applying these algorithms can often lead to worse performance on new datasets. To address this, it is crucial to clarify the assumptions under which a DA algorithm has good target performance. In this work, we focus on the assumption of the presence of conditionally invariant components (CICs), which are relevant for prediction and remain conditionally invariant across the source and target data. We demonstrate that CICs, which can be estimated through conditional invariant penalty (CIP), play three prominent roles in providing target risk guarantees in DA.  First, we propose a new algorithm based on CICs, importance-weighted conditional invariant penalty (IW-CIP), which has target risk guarantees beyond simple settings such as covariate shift and label shift. Second, we show that CICs help identify large discrepancies between source and target risks of other DA algorithms. Finally, we demonstrate that incorporating CICs into the domain invariant projection (DIP) algorithm can address its failure scenario caused by label-flipping features. We support our new algorithms and theoretical findings via numerical experiments on synthetic data, MNIST, CelebA, Camelyon17, and DomainNet datasets.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Domain adaptation (DA) is a statistical learning problem that arises when the distribution of the source data used to train a model differs from that of the target data used to evaluate the model. While many DA algorithms have demonstrated considerable empirical success, blindly applying these algorithms can often lead to worse performance on new datasets. To address this, it is crucial to clarify the assumptions under which a DA algorithm has good target performance. In this work, we focus on the assumption of the presence of conditionally invariant components (CICs), which are relevant for prediction and remain conditionally invariant across the source and target data. We demonstrate that CICs, which can be estimated through conditional invariant penalty (CIP), play three prominent roles in providing target risk guarantees in DA.  First, we propose a new algorithm based on CICs, importance-weighted conditional invariant penalty (IW-CIP), which has target risk guarantees beyond simple settings such as covariate shift and label shift. Second, we show that CICs help identify large discrepancies between source and target risks of other DA algorithms. Finally, we demonstrate that incorporating CICs into the domain invariant projection (DIP) algorithm can address its failure scenario caused by label-flipping features. We support our new algorithms and theoretical findings via numerical experiments on synthetic data, MNIST, CelebA, Camelyon17, and DomainNet datasets."
      }
    },
    {
      "title": "Near-Optimal Nonconvex-Strongly-Convex Bilevel Optimization with Fully First-Order Oracles",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Near-Optimal Nonconvex-Strongly-Convex Bilevel Optimization with Fully First-Order Oracles"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1104.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1104.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1104/23-1104.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Lesi Chen, Yaohua Ma, Jingzhao Zhang"
        }
      ],
      "author": "Lesi Chen, Yaohua Ma, Jingzhao Zhang",
      "author_detail": {
        "name": "Lesi Chen, Yaohua Ma, Jingzhao Zhang"
      },
      "summary": "In this work, we consider bilevel optimization when the lower-level problem is strongly convex. Recent works show that with a Hessian-vector product (HVP) oracle, one can provably find an $\\epsilon$-stationary point within ${O}(\\epsilon^{-2})$ oracle calls. However, the HVP oracle may be inaccessible or expensive in practice. Kwon et al. (ICML 2023) addressed this issue by proposing a first-order method that can achieve the same goal at a slower rate of $\\tilde{O}(\\epsilon^{-3})$.  In this paper, we incorporate a two-time-scale update to improve their method to achieve the near-optimal $\\tilde{O}(\\epsilon^{-2})$ first-order oracle complexity. Our analysis is highly extensible. In the stochastic setting, our algorithm can achieve the stochastic first-order oracle complexity of $\\tilde {O}(\\epsilon^{-4})$ and $\\tilde {O}(\\epsilon^{-6})$ when the stochastic noises are only in the  upper-level objective and in both level objectives, respectively.  When the objectives have higher-order smoothness conditions, our deterministic method can escape saddle points by injecting noise, and can be accelerated to  achieve a faster rate of $\\tilde {O}(\\epsilon^{-1.75})$ using Nesterov's momentum.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this work, we consider bilevel optimization when the lower-level problem is strongly convex. Recent works show that with a Hessian-vector product (HVP) oracle, one can provably find an $\\epsilon$-stationary point within ${O}(\\epsilon^{-2})$ oracle calls. However, the HVP oracle may be inaccessible or expensive in practice. Kwon et al. (ICML 2023) addressed this issue by proposing a first-order method that can achieve the same goal at a slower rate of $\\tilde{O}(\\epsilon^{-3})$.  In this paper, we incorporate a two-time-scale update to improve their method to achieve the near-optimal $\\tilde{O}(\\epsilon^{-2})$ first-order oracle complexity. Our analysis is highly extensible. In the stochastic setting, our algorithm can achieve the stochastic first-order oracle complexity of $\\tilde {O}(\\epsilon^{-4})$ and $\\tilde {O}(\\epsilon^{-6})$ when the stochastic noises are only in the  upper-level objective and in both level objectives, respectively.  When the objectives have higher-order smoothness conditions, our deterministic method can escape saddle points by injecting noise, and can be accelerated to  achieve a faster rate of $\\tilde {O}(\\epsilon^{-1.75})$ using Nesterov's momentum."
      }
    },
    {
      "title": "Adaptive Distributed Kernel Ridge Regression: A Feasible Distributed Learning Scheme for Data Silos",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Adaptive Distributed Kernel Ridge Regression: A Feasible Distributed Learning Scheme for Data Silos"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0806.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0806.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0806/23-0806.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Shao-Bo Lin, Xiaotong Liu, Di Wang, Hai Zhang, Ding-Xuan Zhou"
        }
      ],
      "author": "Shao-Bo Lin, Xiaotong Liu, Di Wang, Hai Zhang, Ding-Xuan Zhou",
      "author_detail": {
        "name": "Shao-Bo Lin, Xiaotong Liu, Di Wang, Hai Zhang, Ding-Xuan Zhou"
      },
      "summary": "Data silos, mainly caused by privacy and interoperability, significantly constrain collaborations among different organizations with similar data for the same purpose. Distributed learning based on divide-and-conquer provides a promising way to settle the data silos, but it suffers from several challenges, including autonomy, privacy guarantees, and the necessity of collaborations. This paper focuses on developing an adaptive distributed kernel ridge regression (AdaDKRR) by taking autonomy in parameter selection, privacy in communicating non-sensitive information, and the necessity of collaborations for performance improvement into account. We provide both solid theoretical verifications and comprehensive experiments for AdaDKRR to demonstrate its feasibility and effectiveness. Theoretically, we prove that under some mild conditions, AdaDKRR performs similarly to running the optimal learning algorithms on the whole data, verifying the necessity of collaborations and showing that no other distributed learning scheme can essentially beat AdaDKRR under the same conditions. Numerically, we test AdaDKRR on both toy simulations and two real-world applications to show that AdaDKRR is superior to other existing distributed learning schemes. All these results show that AdaDKRR is a feasible scheme to overcome data silos, which are highly desired in numerous application regions such as intelligent decision-making, pricing forecasting, and performance prediction for products.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Data silos, mainly caused by privacy and interoperability, significantly constrain collaborations among different organizations with similar data for the same purpose. Distributed learning based on divide-and-conquer provides a promising way to settle the data silos, but it suffers from several challenges, including autonomy, privacy guarantees, and the necessity of collaborations. This paper focuses on developing an adaptive distributed kernel ridge regression (AdaDKRR) by taking autonomy in parameter selection, privacy in communicating non-sensitive information, and the necessity of collaborations for performance improvement into account. We provide both solid theoretical verifications and comprehensive experiments for AdaDKRR to demonstrate its feasibility and effectiveness. Theoretically, we prove that under some mild conditions, AdaDKRR performs similarly to running the optimal learning algorithms on the whole data, verifying the necessity of collaborations and showing that no other distributed learning scheme can essentially beat AdaDKRR under the same conditions. Numerically, we test AdaDKRR on both toy simulations and two real-world applications to show that AdaDKRR is superior to other existing distributed learning schemes. All these results show that AdaDKRR is a feasible scheme to overcome data silos, which are highly desired in numerous application regions such as intelligent decision-making, pricing forecasting, and performance prediction for products."
      }
    },
    {
      "title": "On Global and Local Convergence of Iterative Linear Quadratic Optimization Algorithms for Discrete Time Nonlinear Control",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "On Global and Local Convergence of Iterative Linear Quadratic Optimization Algorithms for Discrete Time Nonlinear Control"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-1271.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-1271.html",
      "pdf": "http://jmlr.org/papers/volume26/22-1271/22-1271.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Vincent Roulet, Siddhartha Srinivasa, Maryam Fazel, Zaid Harchaoui"
        }
      ],
      "author": "Vincent Roulet, Siddhartha Srinivasa, Maryam Fazel, Zaid Harchaoui",
      "author_detail": {
        "name": "Vincent Roulet, Siddhartha Srinivasa, Maryam Fazel, Zaid Harchaoui"
      },
      "summary": "A classical approach for solving discrete time nonlinear control on a finite horizon consists in repeatedly minimizing linear quadratic approximations of the original problem around current candidate solutions. While widely popular in many domains, such an approach has mainly been analyzed locally. We provide detailed convergence guarantees to stationary points as well as local linear convergence rates for the Iterative Linear Quadratic Regulator (ILQR) algorithm and its Differential Dynamic Programming (DDP) variant. For problems without costs on control variables, we observe that global convergence to minima can be ensured provided that the linearized discrete time dynamics are surjective, costs on the state variables are gradient dominated. We further detail quadratic local convergence when the costs are self-concordant. We show that surjectivity of the linearized dynamics hold for appropriate discretization schemes given the existence of a feedback linearization scheme. We present complexity bounds of algorithms based on linear quadratic approximations through the lens of generalized Gauss-Newton methods. Our analysis uncovers several convergence phases for regularized generalized Gauss-Newton algorithms.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "A classical approach for solving discrete time nonlinear control on a finite horizon consists in repeatedly minimizing linear quadratic approximations of the original problem around current candidate solutions. While widely popular in many domains, such an approach has mainly been analyzed locally. We provide detailed convergence guarantees to stationary points as well as local linear convergence rates for the Iterative Linear Quadratic Regulator (ILQR) algorithm and its Differential Dynamic Programming (DDP) variant. For problems without costs on control variables, we observe that global convergence to minima can be ensured provided that the linearized discrete time dynamics are surjective, costs on the state variables are gradient dominated. We further detail quadratic local convergence when the costs are self-concordant. We show that surjectivity of the linearized dynamics hold for appropriate discretization schemes given the existence of a feedback linearization scheme. We present complexity bounds of algorithms based on linear quadratic approximations through the lens of generalized Gauss-Newton methods. Our analysis uncovers several convergence phases for regularized generalized Gauss-Newton algorithms."
      }
    },
    {
      "title": "A Decentralized Proximal Gradient Tracking Algorithm for Composite Optimization on Riemannian Manifolds",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "A Decentralized Proximal Gradient Tracking Algorithm for Composite Optimization on Riemannian Manifolds"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1989.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1989.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1989/24-1989.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Lei Wang, Le Bao, Xin Liu"
        }
      ],
      "author": "Lei Wang, Le Bao, Xin Liu",
      "author_detail": {
        "name": "Lei Wang, Le Bao, Xin Liu"
      },
      "summary": "This paper focuses on minimizing a smooth function combined with a nonsmooth regularization term on a compact Riemannian submanifold embedded in the Euclidean space under a decentralized setting. Typically, there are two types of approaches at present for tackling such composite optimization problems. The first, subgradient-based approaches, rely on subgradient information of the objective function to update variables, achieving an iteration complexity of $O(\\epsilon^{-4}\\log^2(\\epsilon^{-2}))$. The second, smoothing approaches, involve constructing a smooth approximation of the nonsmooth regularization term, resulting in an iteration complexity of $O(\\epsilon^{-4})$. This paper proposes a proximal gradient type algorithm that fully exploits the composite structure. The global convergence to a stationary point is established with a significantly improved iteration complexity of $O(\\epsilon^{-2})$. To validate the effectiveness and efficiency of our proposed method, we present numerical results from real-world applications, showcasing its superior performance compared to existing approaches.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "This paper focuses on minimizing a smooth function combined with a nonsmooth regularization term on a compact Riemannian submanifold embedded in the Euclidean space under a decentralized setting. Typically, there are two types of approaches at present for tackling such composite optimization problems. The first, subgradient-based approaches, rely on subgradient information of the objective function to update variables, achieving an iteration complexity of $O(\\epsilon^{-4}\\log^2(\\epsilon^{-2}))$. The second, smoothing approaches, involve constructing a smooth approximation of the nonsmooth regularization term, resulting in an iteration complexity of $O(\\epsilon^{-4})$. This paper proposes a proximal gradient type algorithm that fully exploits the composite structure. The global convergence to a stationary point is established with a significantly improved iteration complexity of $O(\\epsilon^{-2})$. To validate the effectiveness and efficiency of our proposed method, we present numerical results from real-world applications, showcasing its superior performance compared to existing approaches."
      }
    },
    {
      "title": "Learning conditional distributions on continuous spaces",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Learning conditional distributions on continuous spaces"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0924.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0924.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0924/24-0924.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Cyril Benezet, Ziteng Cheng, Sebastian Jaimungal"
        }
      ],
      "author": "Cyril Benezet, Ziteng Cheng, Sebastian Jaimungal",
      "author_detail": {
        "name": "Cyril Benezet, Ziteng Cheng, Sebastian Jaimungal"
      },
      "summary": "We investigate sample-based learning of conditional distributions on multi-dimensional unit boxes, allowing for different dimensions of the feature and target spaces. Our approach involves clustering data near varying query points in the feature space to create empirical measures in the target space. We employ two distinct clustering schemes: one based on a fixed-radius ball and the other on nearest neighbors. We establish upper bounds for the convergence rates of both methods and, from these bounds, deduce optimal configurations for the radius and the number of neighbors. We propose to incorporate the nearest neighbors method into neural network training, as our empirical analysis indicates it has better performance in practice. For efficiency, our training process utilizes approximate nearest neighbors search with random binary space partitioning. Additionally, we employ the Sinkhorn algorithm and a sparsity-enforced transport plan. Our empirical findings demonstrate that, with a suitably designed structure, the neural network has the ability to adapt to a suitable level of Lipschitz continuity locally.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We investigate sample-based learning of conditional distributions on multi-dimensional unit boxes, allowing for different dimensions of the feature and target spaces. Our approach involves clustering data near varying query points in the feature space to create empirical measures in the target space. We employ two distinct clustering schemes: one based on a fixed-radius ball and the other on nearest neighbors. We establish upper bounds for the convergence rates of both methods and, from these bounds, deduce optimal configurations for the radius and the number of neighbors. We propose to incorporate the nearest neighbors method into neural network training, as our empirical analysis indicates it has better performance in practice. For efficiency, our training process utilizes approximate nearest neighbors search with random binary space partitioning. Additionally, we employ the Sinkhorn algorithm and a sparsity-enforced transport plan. Our empirical findings demonstrate that, with a suitably designed structure, the neural network has the ability to adapt to a suitable level of Lipschitz continuity locally."
      }
    },
    {
      "title": "A Unified Analysis of Nonstochastic Delayed Feedback for Combinatorial Semi-Bandits, Linear Bandits, and MDPs",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "A Unified Analysis of Nonstochastic Delayed Feedback for Combinatorial Semi-Bandits, Linear Bandits, and MDPs"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0496.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0496.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0496/24-0496.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Lukas Zierahn, Dirk van der Hoeven, Tal Lancewicki, Aviv Rosenberg, Nicolò Cesa-Bianchi"
        }
      ],
      "author": "Lukas Zierahn, Dirk van der Hoeven, Tal Lancewicki, Aviv Rosenberg, Nicolò Cesa-Bianchi",
      "author_detail": {
        "name": "Lukas Zierahn, Dirk van der Hoeven, Tal Lancewicki, Aviv Rosenberg, Nicolò Cesa-Bianchi"
      },
      "summary": "We derive a new analysis of Follow The Regularized Leader (FTRL) for online learning with delayed bandit feedback. By separating the cost of delayed feedback from that of bandit feedback, our analysis allows us to obtain new results in four important settings. We derive the first optimal (up to logarithmic factors) regret bounds for combinatorial semi-bandits with delay and adversarial Markov Decision Processes with delay (both known and unknown transition functions). \nFurthermore, we use our analysis to develop an efficient algorithm for linear bandits with delay achieving near-optimal regret bounds. In order to derive these results we show that FTRL remains stable across multiple rounds under mild assumptions on the regularizer.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We derive a new analysis of Follow The Regularized Leader (FTRL) for online learning with delayed bandit feedback. By separating the cost of delayed feedback from that of bandit feedback, our analysis allows us to obtain new results in four important settings. We derive the first optimal (up to logarithmic factors) regret bounds for combinatorial semi-bandits with delay and adversarial Markov Decision Processes with delay (both known and unknown transition functions). \nFurthermore, we use our analysis to develop an efficient algorithm for linear bandits with delay achieving near-optimal regret bounds. In order to derive these results we show that FTRL remains stable across multiple rounds under mild assumptions on the regularizer."
      }
    },
    {
      "title": "Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0437.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0437.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0437/24-0437.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Rocco Caprio, Juan Kuntz, Samuel Power, Adam M. Johansen"
        }
      ],
      "author": "Rocco Caprio, Juan Kuntz, Samuel Power, Adam M. Johansen",
      "author_detail": {
        "name": "Rocco Caprio, Juan Kuntz, Samuel Power, Adam M. Johansen"
      },
      "summary": "We derive non-asymptotic error bounds for particle gradient descent (PGD,  Kuntz et al. (2023)), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy.  We begin by showing that the flow converges exponentially fast to the free energy's minimizers for models satisfying a condition that generalizes both the log-Sobolev and the Polyak--Łojasiewicz inequalities (LSI and PŁI, respectively). We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the PŁI implies the so-called quadratic growth condition), and applying the extension to our new setting. We also generalize the Bakry--Émery Theorem and show that the LSI/PŁI  extension holds for models with strongly concave log-likelihoods. For such models, we further control PGD's discretization error and obtain the non-asymptotic error bounds. While we are motivated by the study of PGD, we believe that the inequalities and results we extend may be of independent interest.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We derive non-asymptotic error bounds for particle gradient descent (PGD,  Kuntz et al. (2023)), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy.  We begin by showing that the flow converges exponentially fast to the free energy's minimizers for models satisfying a condition that generalizes both the log-Sobolev and the Polyak--Łojasiewicz inequalities (LSI and PŁI, respectively). We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the PŁI implies the so-called quadratic growth condition), and applying the extension to our new setting. We also generalize the Bakry--Émery Theorem and show that the LSI/PŁI  extension holds for models with strongly concave log-likelihoods. For such models, we further control PGD's discretization error and obtain the non-asymptotic error bounds. While we are motivated by the study of PGD, we believe that the inequalities and results we extend may be of independent interest."
      }
    },
    {
      "title": "Linear Hypothesis Testing in High-Dimensional Expected Shortfall Regression with Heavy-Tailed Errors",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Linear Hypothesis Testing in High-Dimensional Expected Shortfall Regression with Heavy-Tailed Errors"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0061.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0061.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0061/24-0061.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Gaoyu Wu, Jelena Bradic, Kean Ming Tan, Wen-Xin Zhou"
        }
      ],
      "author": "Gaoyu Wu, Jelena Bradic, Kean Ming Tan, Wen-Xin Zhou",
      "author_detail": {
        "name": "Gaoyu Wu, Jelena Bradic, Kean Ming Tan, Wen-Xin Zhou"
      },
      "summary": "Expected shortfall (ES) is widely used for characterizing the tail of a distribution across various fields, particularly in financial risk management. In this paper, we explore a two-step procedure that leverages an orthogonality property to reduce sensitivity to nuisance parameters when estimating within a joint quantile and expected shortfall regression framework. For high-dimensional sparse models, we propose a robust $\\ell_1$-penalized two-step approach capable of handling heavy-tailed data distributions. We establish non-asymptotic estimation error bounds and propose an appropriate growth rate for the diverging robustification parameter. To facilitate statistical inference for certain linear combinations of the ES regression coefficients, we construct debiased estimators and develop their asymptotic distributions, which form the basis for constructing valid confidence intervals. We validate the proposed method through simulation studies, demonstrating its effectiveness in high-dimensional linear models with heavy-tailed errors.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Expected shortfall (ES) is widely used for characterizing the tail of a distribution across various fields, particularly in financial risk management. In this paper, we explore a two-step procedure that leverages an orthogonality property to reduce sensitivity to nuisance parameters when estimating within a joint quantile and expected shortfall regression framework. For high-dimensional sparse models, we propose a robust $\\ell_1$-penalized two-step approach capable of handling heavy-tailed data distributions. We establish non-asymptotic estimation error bounds and propose an appropriate growth rate for the diverging robustification parameter. To facilitate statistical inference for certain linear combinations of the ES regression coefficients, we construct debiased estimators and develop their asymptotic distributions, which form the basis for constructing valid confidence intervals. We validate the proposed method through simulation studies, demonstrating its effectiveness in high-dimensional linear models with heavy-tailed errors."
      }
    },
    {
      "title": "Efficient Numerical Integration in Reproducing Kernel Hilbert Spaces via Leverage Scores Sampling",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Efficient Numerical Integration in Reproducing Kernel Hilbert Spaces via Leverage Scores Sampling"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1551.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1551.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1551/23-1551.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Antoine Chatalic, Nicolas Schreuder, Ernesto De Vito, Lorenzo Rosasco"
        }
      ],
      "author": "Antoine Chatalic, Nicolas Schreuder, Ernesto De Vito, Lorenzo Rosasco",
      "author_detail": {
        "name": "Antoine Chatalic, Nicolas Schreuder, Ernesto De Vito, Lorenzo Rosasco"
      },
      "summary": "In this work we consider the problem of numerical integration, i.e., approximating integrals with respect to a target probability measure using only pointwise evaluations of the integrand. We focus on the setting in which the target distribution is only accessible through a set of $n$ i.i.d. observations, and the integrand belongs to a reproducing kernel Hilbert space. We propose an efficient procedure which exploits a small i.i.d. random subset of $m<n$ samples drawn either uniformly or using approximate leverage scores from the initial observations. Our main result is an upper bound on the approximation error of this procedure for both sampling strategies. It yields sufficient conditions on the subsample size to recover the standard (optimal) $n^{−1/2}$ rate while reducing drastically the number of functions evaluations—and thus the overall computational cost. Moreover, we obtain rates with respect to the number $m$ of evaluations of the integrand which adapt to its smoothness, and match known optimal rates for instance for Sobolev spaces. We illustrate our theoretical findings with numerical experiments on real datasets, which highlight the attractive efficiency-accuracy tradeoff of our method compared to existing randomized and greedy quadrature methods. We note that, the problem of numerical integration in RKHS amounts to designing a discrete approximation of the kernel mean embedding of the target distribution. As a consequence, direct applications of our results also include the efficient computation of maximum mean discrepancies between distributions and the design of efficient kernel-based tests.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this work we consider the problem of numerical integration, i.e., approximating integrals with respect to a target probability measure using only pointwise evaluations of the integrand. We focus on the setting in which the target distribution is only accessible through a set of $n$ i.i.d. observations, and the integrand belongs to a reproducing kernel Hilbert space. We propose an efficient procedure which exploits a small i.i.d. random subset of $m<n$ samples drawn either uniformly or using approximate leverage scores from the initial observations. Our main result is an upper bound on the approximation error of this procedure for both sampling strategies. It yields sufficient conditions on the subsample size to recover the standard (optimal) $n^{−1/2}$ rate while reducing drastically the number of functions evaluations—and thus the overall computational cost. Moreover, we obtain rates with respect to the number $m$ of evaluations of the integrand which adapt to its smoothness, and match known optimal rates for instance for Sobolev spaces. We illustrate our theoretical findings with numerical experiments on real datasets, which highlight the attractive efficiency-accuracy tradeoff of our method compared to existing randomized and greedy quadrature methods. We note that, the problem of numerical integration in RKHS amounts to designing a discrete approximation of the kernel mean embedding of the target distribution. As a consequence, direct applications of our results also include the efficient computation of maximum mean discrepancies between distributions and the design of efficient kernel-based tests."
      }
    },
    {
      "title": "Distribution Free Tests for Model Selection Based on Maximum Mean Discrepancy with Estimated Parameters",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Distribution Free Tests for Model Selection Based on Maximum Mean Discrepancy with Estimated Parameters"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1199.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1199.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1199/23-1199.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Florian Brück, Jean-David Fermanian, Aleksey Min"
        }
      ],
      "author": "Florian Brück, Jean-David Fermanian, Aleksey Min",
      "author_detail": {
        "name": "Florian Brück, Jean-David Fermanian, Aleksey Min"
      },
      "summary": "There exist several testing procedures based on the maximum mean discrepancy (MMD) to address the challenge of model specification. However, these testing procedures ignore the presence of estimated parameters in the case of composite null hypotheses. In this paper, we first illustrate the effect of parameter estimation in model specification tests based on the MMD. Second, we propose simple model specification and model selection tests in the case of models with estimated parameters. All our tests are asymptotically standard normal under the null, even when the true underlying distribution belongs to the competing parametric families. A simulation study and a real data analysis illustrate the performance of our tests in terms of power and level.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "There exist several testing procedures based on the maximum mean discrepancy (MMD) to address the challenge of model specification. However, these testing procedures ignore the presence of estimated parameters in the case of composite null hypotheses. In this paper, we first illustrate the effect of parameter estimation in model specification tests based on the MMD. Second, we propose simple model specification and model selection tests in the case of models with estimated parameters. All our tests are asymptotically standard normal under the null, even when the true underlying distribution belongs to the competing parametric families. A simulation study and a real data analysis illustrate the performance of our tests in terms of power and level."
      }
    },
    {
      "title": "Statistical field theory for Markov decision processes under uncertainty",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Statistical field theory for Markov decision processes under uncertainty"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0905.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0905.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0905/23-0905.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "George Stamatescu"
        }
      ],
      "author": "George Stamatescu",
      "author_detail": {
        "name": "George Stamatescu"
      },
      "summary": "A statistical field theory is introduced for finite state and action Markov decision processes with unknown parameters, in a Bayesian setting. The Bellman equation, for policy evaluation and the optimal value function in finite and discounted infinite horizon problems, is studied as a disordered interacting dynamical system. The Markov decision process transition probabilities and mean-rewards are interpreted as quenched random variables and the value functions, or the iterates of the Bellman equation, are deterministic variables that evolve dynamically. The posterior over value functions is then equivalent to the quenched average of Fourier inverse of the Martin-Siggia-Rose-De Dominicis-Janssen generating function. The formalism enables the use of methods from field theory to compute posterior moments of value functions. The paper presents two such methods, corresponding to two distinct asymptotic limits. First, the classical approximation is applied, corresponding to the asymptotic data limit. This approximation recovers so-called plug-in estimators for the mean of the value functions. Second, a dynamic mean field theory is derived, showing that under certain assumptions the state-action values are statistically independent across state-action pairs in the asymptotic state space limit. The state-action value statistics can be computed from a set of self-consistent mean field equations, which we call dynamic mean field programming (DMFP). Collectively, the results provide analytic insight into the structure of model uncertainty in Markov decision processes, and pave the way toward more advanced field theoretic techniques and applications to planning and reinforcement learning problems.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "A statistical field theory is introduced for finite state and action Markov decision processes with unknown parameters, in a Bayesian setting. The Bellman equation, for policy evaluation and the optimal value function in finite and discounted infinite horizon problems, is studied as a disordered interacting dynamical system. The Markov decision process transition probabilities and mean-rewards are interpreted as quenched random variables and the value functions, or the iterates of the Bellman equation, are deterministic variables that evolve dynamically. The posterior over value functions is then equivalent to the quenched average of Fourier inverse of the Martin-Siggia-Rose-De Dominicis-Janssen generating function. The formalism enables the use of methods from field theory to compute posterior moments of value functions. The paper presents two such methods, corresponding to two distinct asymptotic limits. First, the classical approximation is applied, corresponding to the asymptotic data limit. This approximation recovers so-called plug-in estimators for the mean of the value functions. Second, a dynamic mean field theory is derived, showing that under certain assumptions the state-action values are statistically independent across state-action pairs in the asymptotic state space limit. The state-action value statistics can be computed from a set of self-consistent mean field equations, which we call dynamic mean field programming (DMFP). Collectively, the results provide analytic insight into the structure of model uncertainty in Markov decision processes, and pave the way toward more advanced field theoretic techniques and applications to planning and reinforcement learning problems."
      }
    },
    {
      "title": "Bayesian Data Sketching for Varying Coefficient Regression Models",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bayesian Data Sketching for Varying Coefficient Regression Models"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0505.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0505.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0505/23-0505.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Rajarshi Guhaniyogi, Laura Baracaldo, Sudipto Banerjee"
        }
      ],
      "author": "Rajarshi Guhaniyogi, Laura Baracaldo, Sudipto Banerjee",
      "author_detail": {
        "name": "Rajarshi Guhaniyogi, Laura Baracaldo, Sudipto Banerjee"
      },
      "summary": "Varying coefficient models are popular for estimating nonlinear regression functions in functional data models. Their Bayesian variants have received limited attention in large data applications, primarily due to prohibitively slow posterior computations using Markov chain Monte Carlo (MCMC) algorithms. We introduce Bayesian data sketching for varying coefficient models to obviate computational challenges presented by large sample sizes. To address the challenges of analyzing large data, we compress the functional response vector and predictor matrix by a random linear transformation to achieve dimension reduction and conduct inference on the compressed data. Our approach distinguishes itself from several existing methods for analyzing large functional data in that it requires neither the development of new models or algorithms nor any specialized computational hardware while delivering fully model-based Bayesian inference. Well-established methods and algorithms for varying-coefficient regression models can be applied to the compressed data. We establish posterior contraction rates for estimating the varying coefficients and predicting the outcome at new locations with the randomly compressed data model. We use simulation experiments and analyze remote sensed vegetation data to empirically illustrate the inferential and computational efficiency of our approach.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Varying coefficient models are popular for estimating nonlinear regression functions in functional data models. Their Bayesian variants have received limited attention in large data applications, primarily due to prohibitively slow posterior computations using Markov chain Monte Carlo (MCMC) algorithms. We introduce Bayesian data sketching for varying coefficient models to obviate computational challenges presented by large sample sizes. To address the challenges of analyzing large data, we compress the functional response vector and predictor matrix by a random linear transformation to achieve dimension reduction and conduct inference on the compressed data. Our approach distinguishes itself from several existing methods for analyzing large functional data in that it requires neither the development of new models or algorithms nor any specialized computational hardware while delivering fully model-based Bayesian inference. Well-established methods and algorithms for varying-coefficient regression models can be applied to the compressed data. We establish posterior contraction rates for estimating the varying coefficients and predicting the outcome at new locations with the randomly compressed data model. We use simulation experiments and analyze remote sensed vegetation data to empirically illustrate the inferential and computational efficiency of our approach."
      }
    },
    {
      "title": "Bagged k-Distance for Mode-Based Clustering  Using the Probability of Localized Level Sets",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bagged k-Distance for Mode-Based Clustering  Using the Probability of Localized Level Sets"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-1179.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-1179.html",
      "pdf": "http://jmlr.org/papers/volume26/22-1179/22-1179.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Hanyuan Hang"
        }
      ],
      "author": "Hanyuan Hang",
      "author_detail": {
        "name": "Hanyuan Hang"
      },
      "summary": "In this paper, we propose an ensemble learning algorithm named bagged $k$-distance for mode-based clustering (BDMBC) by putting forward a new measure called the probability of localized level sets (PLLS), which enables us to find all clusters for varying densities with a global threshold. On the theoretical side, we show that with a properly chosen number of nearest neighbors $k_D$ in the bagged $k$-distance, the sub-sample size $s$, the bagging rounds $B$, and the number of nearest neighbors $k_L$ for the localized level sets, BDMBC can achieve optimal convergence rates for mode estimation. It turns out that with a relatively small $B$, the sub-sample size $s$ can be much smaller than the number of training data $n$ at each bagging round, and the number of nearest neighbors $k_D$ can be reduced simultaneously. Moreover, we establish fast convergence rates for the level set estimation of the PLLS in terms of Hausdorff distance, which reveals that BDMBC can find localized level sets for varying densities and thus enjoys local adaptivity. On the practical side, we conduct numerical experiments to empirically verify the effectiveness of BDMBC for mode estimation and level set estimation, which demonstrates the promising accuracy and efficiency of our proposed algorithm.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this paper, we propose an ensemble learning algorithm named bagged $k$-distance for mode-based clustering (BDMBC) by putting forward a new measure called the probability of localized level sets (PLLS), which enables us to find all clusters for varying densities with a global threshold. On the theoretical side, we show that with a properly chosen number of nearest neighbors $k_D$ in the bagged $k$-distance, the sub-sample size $s$, the bagging rounds $B$, and the number of nearest neighbors $k_L$ for the localized level sets, BDMBC can achieve optimal convergence rates for mode estimation. It turns out that with a relatively small $B$, the sub-sample size $s$ can be much smaller than the number of training data $n$ at each bagging round, and the number of nearest neighbors $k_D$ can be reduced simultaneously. Moreover, we establish fast convergence rates for the level set estimation of the PLLS in terms of Hausdorff distance, which reveals that BDMBC can find localized level sets for varying densities and thus enjoys local adaptivity. On the practical side, we conduct numerical experiments to empirically verify the effectiveness of BDMBC for mode estimation and level set estimation, which demonstrates the promising accuracy and efficiency of our proposed algorithm."
      }
    },
    {
      "title": "Linear cost and exponentially convergent approximation of Gaussian Matérn processes on intervals",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Linear cost and exponentially convergent approximation of Gaussian Matérn processes on intervals"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1779.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1779.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1779/24-1779.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "David Bolin, Vaibhav Mehandiratta, Alexandre B. Simas"
        }
      ],
      "author": "David Bolin, Vaibhav Mehandiratta, Alexandre B. Simas",
      "author_detail": {
        "name": "David Bolin, Vaibhav Mehandiratta, Alexandre B. Simas"
      },
      "summary": "The computational cost for inference and prediction of statistical models based on Gaussian processes with Matérn covariance functions scales cubically with the number of observations, limiting their applicability to large data sets. The cost can be reduced in certain special cases, but there are no generally applicable exact methods with linear cost. Several approximate methods have been introduced to reduce the cost, but most lack theoretical guarantees for accuracy. We consider Gaussian processes on bounded intervals with Matérn covariance functions and, for the first time, develop a generally applicable method with linear cost and a covariance error that decreases exponentially fast in the order $m$ of the proposed approximation. The method is based on an optimal rational approximation of the spectral density and results in an approximation that can be represented as a sum of $m$ independent Gaussian Markov processes, facilitating usage in general software for statistical inference. Besides theoretical justifications, we demonstrate accuracy empirically through carefully designed simulation studies, which show that the method outperforms state-of-the-art alternatives in accuracy for fixed computational cost in tasks like Gaussian process regression.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The computational cost for inference and prediction of statistical models based on Gaussian processes with Matérn covariance functions scales cubically with the number of observations, limiting their applicability to large data sets. The cost can be reduced in certain special cases, but there are no generally applicable exact methods with linear cost. Several approximate methods have been introduced to reduce the cost, but most lack theoretical guarantees for accuracy. We consider Gaussian processes on bounded intervals with Matérn covariance functions and, for the first time, develop a generally applicable method with linear cost and a covariance error that decreases exponentially fast in the order $m$ of the proposed approximation. The method is based on an optimal rational approximation of the spectral density and results in an approximation that can be represented as a sum of $m$ independent Gaussian Markov processes, facilitating usage in general software for statistical inference. Besides theoretical justifications, we demonstrate accuracy empirically through carefully designed simulation studies, which show that the method outperforms state-of-the-art alternatives in accuracy for fixed computational cost in tasks like Gaussian process regression."
      }
    },
    {
      "title": "Invariant Subspace Decomposition",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Invariant Subspace Decomposition"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0699.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0699.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0699/24-0699.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Margherita Lazzaretto, Jonas Peters, Niklas Pfister"
        }
      ],
      "author": "Margherita Lazzaretto, Jonas Peters, Niklas Pfister",
      "author_detail": {
        "name": "Margherita Lazzaretto, Jonas Peters, Niklas Pfister"
      },
      "summary": "We consider the task of predicting a response $Y$ from a set of covariates $X$ in settings where the conditional distribution of $Y$ given $X$ changes over time. For this to be feasible, assumptions on how the conditional distribution changes over time are required. Existing approaches assume, for example, that changes occur smoothly over time so that short-term prediction using only the recent past becomes feasible. To additionally exploit observations further in the past, we propose a novel invariance-based framework for linear conditionals, called Invariant Subspace Decomposition (ISD), that splits the conditional distribution into a time-invariant and a residual time-dependent component. As we show, this decomposition can be employed both for zero-shot and time-adaptation prediction tasks, that is, settings where either no or a small amount of training data is available at the time points we want to predict $Y$ at, respectively. We propose a practical estimation procedure, which automatically infers the decomposition using tools from approximate joint matrix diagonalization. Furthermore, we provide finite sample guarantees for the proposed estimator and demonstrate empirically that it indeed improves on approaches that do not use the additional invariant structure.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We consider the task of predicting a response $Y$ from a set of covariates $X$ in settings where the conditional distribution of $Y$ given $X$ changes over time. For this to be feasible, assumptions on how the conditional distribution changes over time are required. Existing approaches assume, for example, that changes occur smoothly over time so that short-term prediction using only the recent past becomes feasible. To additionally exploit observations further in the past, we propose a novel invariance-based framework for linear conditionals, called Invariant Subspace Decomposition (ISD), that splits the conditional distribution into a time-invariant and a residual time-dependent component. As we show, this decomposition can be employed both for zero-shot and time-adaptation prediction tasks, that is, settings where either no or a small amount of training data is available at the time points we want to predict $Y$ at, respectively. We propose a practical estimation procedure, which automatically infers the decomposition using tools from approximate joint matrix diagonalization. Furthermore, we provide finite sample guarantees for the proposed estimator and demonstrate empirically that it indeed improves on approaches that do not use the additional invariant structure."
      }
    },
    {
      "title": "Posterior Concentrations of Fully-Connected Bayesian Neural Networks with General Priors on the Weights",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Posterior Concentrations of Fully-Connected Bayesian Neural Networks with General Priors on the Weights"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0425.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0425.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0425/24-0425.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Insung Kong, Yongdai Kim"
        }
      ],
      "author": "Insung Kong, Yongdai Kim",
      "author_detail": {
        "name": "Insung Kong, Yongdai Kim"
      },
      "summary": "Bayesian approaches for training deep neural networks (BNNs) have received significant interest and have been effectively utilized in a wide range of applications. Several studies have examined the properties of posterior concentrations in BNNs. However, most of these studies focus solely on BNN models with sparse or heavy-tailed priors. Surprisingly, there are currently no theoretical results for BNNs using Gaussian priors, which are the most commonly used in practice. The lack of theory arises from the absence of approximation results of Deep Neural Networks (DNNs) that are non-sparse and have bounded parameters. In this paper, we present a new approximation theory for non-sparse DNNs with bounded parameters. Additionally, based on the approximation theory,  we show that BNNs with non-sparse general priors can achieve near-minimax optimal posterior concentration rates around the true model.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bayesian approaches for training deep neural networks (BNNs) have received significant interest and have been effectively utilized in a wide range of applications. Several studies have examined the properties of posterior concentrations in BNNs. However, most of these studies focus solely on BNN models with sparse or heavy-tailed priors. Surprisingly, there are currently no theoretical results for BNNs using Gaussian priors, which are the most commonly used in practice. The lack of theory arises from the absence of approximation results of Deep Neural Networks (DNNs) that are non-sparse and have bounded parameters. In this paper, we present a new approximation theory for non-sparse DNNs with bounded parameters. Additionally, based on the approximation theory,  we show that BNNs with non-sparse general priors can achieve near-minimax optimal posterior concentration rates around the true model."
      }
    },
    {
      "title": "Outlier Robust and Sparse Estimation of Linear Regression Coefficients",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Outlier Robust and Sparse Estimation of Linear Regression Coefficients"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1583.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1583.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1583/23-1583.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Takeyuki Sasai, Hironori Fujisawa"
        }
      ],
      "author": "Takeyuki Sasai, Hironori Fujisawa",
      "author_detail": {
        "name": "Takeyuki Sasai, Hironori Fujisawa"
      },
      "summary": "We consider outlier-robust and sparse estimation of linear regression coefficients, when the covariates and the noises are contaminated by adversarial outliers and noises are sampled from a heavy-tailed distribution. Our results present sharper error bounds under weaker assumptions than prior studies that share similar interests with this study. Our analysis relies on some sharp concentration inequalities resulting from generic chaining.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We consider outlier-robust and sparse estimation of linear regression coefficients, when the covariates and the noises are contaminated by adversarial outliers and noises are sampled from a heavy-tailed distribution. Our results present sharper error bounds under weaker assumptions than prior studies that share similar interests with this study. Our analysis relies on some sharp concentration inequalities resulting from generic chaining."
      }
    },
    {
      "title": "Affine Rank Minimization via Asymptotic Log-Det Iteratively Reweighted Least Squares",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Affine Rank Minimization via Asymptotic Log-Det Iteratively Reweighted Least Squares"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0943.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0943.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0943/23-0943.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Sebastian Krämer"
        }
      ],
      "author": "Sebastian Krämer",
      "author_detail": {
        "name": "Sebastian Krämer"
      },
      "summary": "The affine rank minimization problem is a well-known approach to matrix recovery. While there are various surrogates to this NP-hard problem, we prove that the asymptotic minimization of log-det objective functions indeed always reveals the desired, lowest-rank matrices---whereas such may or may not recover a sought-after ground truth. Concerning commonly applied methods such as iteratively reweighted least squares, one thus remains with two difficult to distinguish concerns: how problematic are local minima inherent to the approach truly; and opposingly, how influential instead is the numerical realization. We first show that comparable solution statements do not hold true for Schatten-$p$ functions, including the nuclear norm, and discuss the role of divergent minimizers. Subsequently, we outline corresponding implications for general optimization approaches as well as the more specific IRLS-$0$ algorithm, emphasizing through examples that the transition of the involved smoothing parameter to zero is frequently a more substantial issue than non-convexity. Lastly, we analyze several presented aspects empirically in a series of numerical experiments. In particular, allowing for instance sufficiently many iterations, one may even observe a phase transition for generic recoverability at the absolute theoretical minimum.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The affine rank minimization problem is a well-known approach to matrix recovery. While there are various surrogates to this NP-hard problem, we prove that the asymptotic minimization of log-det objective functions indeed always reveals the desired, lowest-rank matrices---whereas such may or may not recover a sought-after ground truth. Concerning commonly applied methods such as iteratively reweighted least squares, one thus remains with two difficult to distinguish concerns: how problematic are local minima inherent to the approach truly; and opposingly, how influential instead is the numerical realization. We first show that comparable solution statements do not hold true for Schatten-$p$ functions, including the nuclear norm, and discuss the role of divergent minimizers. Subsequently, we outline corresponding implications for general optimization approaches as well as the more specific IRLS-$0$ algorithm, emphasizing through examples that the transition of the involved smoothing parameter to zero is frequently a more substantial issue than non-convexity. Lastly, we analyze several presented aspects empirically in a series of numerical experiments. In particular, allowing for instance sufficiently many iterations, one may even observe a phase transition for generic recoverability at the absolute theoretical minimum."
      }
    },
    {
      "title": "Causal Effect of Functional Treatment",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Causal Effect of Functional Treatment"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0381.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0381.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0381/23-0381.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Ruoxu Tan, Wei Huang, Zheng Zhang, Guosheng Yin"
        }
      ],
      "author": "Ruoxu Tan, Wei Huang, Zheng Zhang, Guosheng Yin",
      "author_detail": {
        "name": "Ruoxu Tan, Wei Huang, Zheng Zhang, Guosheng Yin"
      },
      "summary": "We study the causal effect with a functional treatment variable, where practical applications often arise in neuroscience, biomedical sciences, etc. Previous research concerning the effect of a functional variable on an outcome is typically restricted to exploring correlation rather than causality. The generalized propensity score, which is often used to calibrate the selection bias, is not directly applicable to a functional treatment variable due to a lack of definition of probability density function for functional data. We propose three estimators for the average dose-response functional based on the functional linear model, namely, the functional stabilized weight estimator, the outcome regression estimator and the doubly robust estimator, each of which has its own merits. We study their theoretical properties, which are corroborated through extensive numerical experiments. A real data application on electroencephalography data and disease severity demonstrates the practical value of our methods.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We study the causal effect with a functional treatment variable, where practical applications often arise in neuroscience, biomedical sciences, etc. Previous research concerning the effect of a functional variable on an outcome is typically restricted to exploring correlation rather than causality. The generalized propensity score, which is often used to calibrate the selection bias, is not directly applicable to a functional treatment variable due to a lack of definition of probability density function for functional data. We propose three estimators for the average dose-response functional based on the functional linear model, namely, the functional stabilized weight estimator, the outcome regression estimator and the doubly robust estimator, each of which has its own merits. We study their theoretical properties, which are corroborated through extensive numerical experiments. A real data application on electroencephalography data and disease severity demonstrates the practical value of our methods."
      }
    },
    {
      "title": "Uplift Model Evaluation with Ordinal Dominance Graphs",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Uplift Model Evaluation with Ordinal Dominance Graphs"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-1455.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-1455.html",
      "pdf": "http://jmlr.org/papers/volume26/22-1455/22-1455.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Brecht Verbeken, Marie-Anne Guerry, Wouter Verbeke, Sam Verboven"
        }
      ],
      "author": "Brecht Verbeken, Marie-Anne Guerry, Wouter Verbeke, Sam Verboven",
      "author_detail": {
        "name": "Brecht Verbeken, Marie-Anne Guerry, Wouter Verbeke, Sam Verboven"
      },
      "summary": "Uplift modelling is a subfield of causal learning that focuses on ranking entities by individual treatment effects. Uplift models are typically evaluated using Qini curves or Qini scores. While intuitive, the theoretical grounding for Qini in the literature is limited, and the mathematical connection to the well-understood Receiver Operating Characteristic (ROC) curve is unclear. In this paper, we introduce pROCini, a novel uplift evaluation metric that improves upon Qini in two important ways. First, it explicitly incorporates more information by taking into account negative outcomes. Second, it leverages this additional information within the Ordinal Dominance Graph framework, which is the basis behind the well known ROC curve, resulting in a mathematically well-behaved metric that facilitates theoretical analysis. We derive confidence bounds for pROCini, exploiting its theoretical properties. Finally, we empirically validate the improved discriminative power of ROCini and pROCini in a simulation study as well as via experiments on real data.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Uplift modelling is a subfield of causal learning that focuses on ranking entities by individual treatment effects. Uplift models are typically evaluated using Qini curves or Qini scores. While intuitive, the theoretical grounding for Qini in the literature is limited, and the mathematical connection to the well-understood Receiver Operating Characteristic (ROC) curve is unclear. In this paper, we introduce pROCini, a novel uplift evaluation metric that improves upon Qini in two important ways. First, it explicitly incorporates more information by taking into account negative outcomes. Second, it leverages this additional information within the Ordinal Dominance Graph framework, which is the basis behind the well known ROC curve, resulting in a mathematically well-behaved metric that facilitates theoretical analysis. We derive confidence bounds for pROCini, exploiting its theoretical properties. Finally, we empirically validate the improved discriminative power of ROCini and pROCini in a simulation study as well as via experiments on real data."
      }
    },
    {
      "title": "High-Dimensional L2-Boosting: Rate of Convergence",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "High-Dimensional L2-Boosting: Rate of Convergence"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/21-0725.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/21-0725.html",
      "pdf": "http://jmlr.org/papers/volume26/21-0725/21-0725.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Ye Luo, Martin Spindler, Jannis Kueck"
        }
      ],
      "author": "Ye Luo, Martin Spindler, Jannis Kueck",
      "author_detail": {
        "name": "Ye Luo, Martin Spindler, Jannis Kueck"
      },
      "summary": "Boosting is one of the most significant developments in machine learning. This paper studies the rate of convergence of L2-Boosting in a high-dimensional setting under early stopping. We close a gap in the literature and provide the rate of convergence of L2-Boosting in a high-dimensional setting under approximate sparsity and without beta-min condition. We also show that the rate of convergence of the classical L2-Boosting depends on the design matrix described by a sparse eigenvalue condition. To show the latter results, we derive new, improved approximation results for the pure greedy algorithm, based on analyzing the revisiting behavior of L2-Boosting. These results might be of independent interest. Moreover, we introduce so-called  \"restricted\" L2-Boosting. The restricted L2-Boosting algorithm sticks to the set of the previously chosen variables, exploits the information contained in these variables first and then only occasionally allows to add new variables to this set. We derive the rate of convergence for restricted L2-Boosting under early stopping which is close to the convergence rate of Lasso in an approximate sparse, high-dimensional setting without beta-min condition. We also introduce feasible rules for early stopping, which can be easily implemented and used in applied work. Finally, we present simulation studies to illustrate the relevance of our theoretical results and to provide insights into the practical aspects of boosting. In these simulation studies, L2-Boosting clearly outperforms Lasso. An empirical illustration and the proofs are contained in the Appendix.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Boosting is one of the most significant developments in machine learning. This paper studies the rate of convergence of L2-Boosting in a high-dimensional setting under early stopping. We close a gap in the literature and provide the rate of convergence of L2-Boosting in a high-dimensional setting under approximate sparsity and without beta-min condition. We also show that the rate of convergence of the classical L2-Boosting depends on the design matrix described by a sparse eigenvalue condition. To show the latter results, we derive new, improved approximation results for the pure greedy algorithm, based on analyzing the revisiting behavior of L2-Boosting. These results might be of independent interest. Moreover, we introduce so-called  \"restricted\" L2-Boosting. The restricted L2-Boosting algorithm sticks to the set of the previously chosen variables, exploits the information contained in these variables first and then only occasionally allows to add new variables to this set. We derive the rate of convergence for restricted L2-Boosting under early stopping which is close to the convergence rate of Lasso in an approximate sparse, high-dimensional setting without beta-min condition. We also introduce feasible rules for early stopping, which can be easily implemented and used in applied work. Finally, we present simulation studies to illustrate the relevance of our theoretical results and to provide insights into the practical aspects of boosting. In these simulation studies, L2-Boosting clearly outperforms Lasso. An empirical illustration and the proofs are contained in the Appendix."
      }
    },
    {
      "title": "Feature Learning in Finite-Width Bayesian Deep Linear Networks with Multiple Outputs and Convolutional Layers",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Feature Learning in Finite-Width Bayesian Deep Linear Networks with Multiple Outputs and Convolutional Layers"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1158.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1158.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1158/24-1158.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Federico Bassetti, Marco Gherardi, Alessandro Ingrosso, Mauro Pastore, Pietro Rotondo"
        }
      ],
      "author": "Federico Bassetti, Marco Gherardi, Alessandro Ingrosso, Mauro Pastore, Pietro Rotondo",
      "author_detail": {
        "name": "Federico Bassetti, Marco Gherardi, Alessandro Ingrosso, Mauro Pastore, Pietro Rotondo"
      },
      "summary": "Deep linear networks have been extensively studied, as they provide simplified models of deep learning. However, little is known in the case of finite-width architectures with multiple outputs and convolutional layers. In this manuscript, we provide rigorous results for the statistics of functions implemented by the aforementioned class of networks, thus moving closer to a complete characterization of feature learning in the Bayesian setting.  Our results include: (i) an exact and elementary non-asymptotic integral representation for the joint prior distribution over the outputs, given in terms of a mixture of Gaussians; (ii) an analytical formula for the posterior distribution in the case of squared error loss function (Gaussian likelihood); (iii) a quantitative description of the feature learning infinite-width regime, using large deviation theory. From a physical perspective, deep architectures with multiple outputs or convolutional layers represent different manifestations of kernel shape renormalization, and our work provides a dictionary that translates this physics intuition and terminology into rigorous Bayesian statistics.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Deep linear networks have been extensively studied, as they provide simplified models of deep learning. However, little is known in the case of finite-width architectures with multiple outputs and convolutional layers. In this manuscript, we provide rigorous results for the statistics of functions implemented by the aforementioned class of networks, thus moving closer to a complete characterization of feature learning in the Bayesian setting.  Our results include: (i) an exact and elementary non-asymptotic integral representation for the joint prior distribution over the outputs, given in terms of a mixture of Gaussians; (ii) an analytical formula for the posterior distribution in the case of squared error loss function (Gaussian likelihood); (iii) a quantitative description of the feature learning infinite-width regime, using large deviation theory. From a physical perspective, deep architectures with multiple outputs or convolutional layers represent different manifestations of kernel shape renormalization, and our work provides a dictionary that translates this physics intuition and terminology into rigorous Bayesian statistics."
      }
    },
    {
      "title": "How good is your Laplace approximation of the Bayesian posterior? Finite-sample computable error bounds for a variety of useful divergences",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "How good is your Laplace approximation of the Bayesian posterior? Finite-sample computable error bounds for a variety of useful divergences"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0619.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0619.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0619/24-0619.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Miko{\\l}aj J. Kasprzak, Ryan Giordano, Tamara Broderick"
        }
      ],
      "author": "Miko{\\l}aj J. Kasprzak, Ryan Giordano, Tamara Broderick",
      "author_detail": {
        "name": "Miko{\\l}aj J. Kasprzak, Ryan Giordano, Tamara Broderick"
      },
      "summary": "The Laplace approximation is a popular method for constructing a Gaussian approximation to the Bayesian posterior and thereby approximating the posterior mean and variance. But approximation quality is a concern. One might consider using rate-of-convergence bounds from certain versions of the Bayesian Central Limit Theorem (BCLT) to provide quality guarantees. But existing bounds require assumptions that are unrealistic even for relatively simple real-life Bayesian analyses; more specifically, existing bounds either (1) require knowing the true data-generating parameter, (2) are asymptotic in the number of samples, (3) do not control the Bayesian posterior mean, or (4) require strongly log concave models to compute. In this work, we provide the first computable bounds on quality that simultaneously (1) do not require knowing the true parameter, (2) apply to finite samples, (3) control posterior means and variances, and (4) apply generally to models that satisfy the conditions of the asymptotic BCLT. Moreover, we substantially improve the dimension dependence of existing bounds; in fact, we achieve the lowest-order dimension dependence possible in the general case. We compute exact constants in our bounds for a variety of standard models, including logistic regression, and numerically demonstrate their utility. We provide a framework for analysis of more complex models.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The Laplace approximation is a popular method for constructing a Gaussian approximation to the Bayesian posterior and thereby approximating the posterior mean and variance. But approximation quality is a concern. One might consider using rate-of-convergence bounds from certain versions of the Bayesian Central Limit Theorem (BCLT) to provide quality guarantees. But existing bounds require assumptions that are unrealistic even for relatively simple real-life Bayesian analyses; more specifically, existing bounds either (1) require knowing the true data-generating parameter, (2) are asymptotic in the number of samples, (3) do not control the Bayesian posterior mean, or (4) require strongly log concave models to compute. In this work, we provide the first computable bounds on quality that simultaneously (1) do not require knowing the true parameter, (2) apply to finite samples, (3) control posterior means and variances, and (4) apply generally to models that satisfy the conditions of the asymptotic BCLT. Moreover, we substantially improve the dimension dependence of existing bounds; in fact, we achieve the lowest-order dimension dependence possible in the general case. We compute exact constants in our bounds for a variety of standard models, including logistic regression, and numerically demonstrate their utility. We provide a framework for analysis of more complex models."
      }
    },
    {
      "title": "Integral Probability Metrics Meet Neural Networks: The Radon-Kolmogorov-Smirnov Test",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Integral Probability Metrics Meet Neural Networks: The Radon-Kolmogorov-Smirnov Test"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0245.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0245.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0245/24-0245.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Seunghoon Paik, Michael Celentano, Alden Green, Ryan J. Tibshirani"
        }
      ],
      "author": "Seunghoon Paik, Michael Celentano, Alden Green, Ryan J. Tibshirani",
      "author_detail": {
        "name": "Seunghoon Paik, Michael Celentano, Alden Green, Ryan J. Tibshirani"
      },
      "summary": "Integral probability metrics (IPMs) constitute a general class of nonparametric two-sample tests that are based on maximizing the mean difference between samples from one distribution $P$ versus another $Q$, over all choices of data transformations $f$ living in some function space $\\mathcal{F}$. Inspired by recent work that connects what are known as functions of Radon bounded variation (RBV) and neural networks (Parhi and Nowak, 2021, 2023), we study the IPM defined by taking $\\mathcal{F}$ to be the unit ball in the RBV space of a given smoothness degree $k \\geq 0$. This test, which we refer to as the Radon-Kolmogorov-Smirnov (RKS) test, can be viewed as a generalization of the well-known and classical Kolmogorov-Smirnov (KS) test to multiple dimensions and higher orders of smoothness. It is also intimately connected to neural networks: we prove that the witness in the RKS test—the function $f$ achieving the maximum mean difference—is always a ridge spline of degree $k$, i.e., a single neuron in a neural network. We can thus leverage the power of modern neural network optimization toolkits to (approximately) maximize the criterion that underlies the RKS test. We prove that the RKS test has asymptotically full power at distinguishing any distinct pair $P \\not= Q$ of distributions, derive its asymptotic null distribution, and carry out experiments to elucidate the strengths and weaknesses of the RKS test versus the more traditional kernel MMD test.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Integral probability metrics (IPMs) constitute a general class of nonparametric two-sample tests that are based on maximizing the mean difference between samples from one distribution $P$ versus another $Q$, over all choices of data transformations $f$ living in some function space $\\mathcal{F}$. Inspired by recent work that connects what are known as functions of Radon bounded variation (RBV) and neural networks (Parhi and Nowak, 2021, 2023), we study the IPM defined by taking $\\mathcal{F}$ to be the unit ball in the RBV space of a given smoothness degree $k \\geq 0$. This test, which we refer to as the Radon-Kolmogorov-Smirnov (RKS) test, can be viewed as a generalization of the well-known and classical Kolmogorov-Smirnov (KS) test to multiple dimensions and higher orders of smoothness. It is also intimately connected to neural networks: we prove that the witness in the RKS test—the function $f$ achieving the maximum mean difference—is always a ridge spline of degree $k$, i.e., a single neuron in a neural network. We can thus leverage the power of modern neural network optimization toolkits to (approximately) maximize the criterion that underlies the RKS test. We prove that the RKS test has asymptotically full power at distinguishing any distinct pair $P \\not= Q$ of distributions, derive its asymptotic null distribution, and carry out experiments to elucidate the strengths and weaknesses of the RKS test versus the more traditional kernel MMD test."
      }
    },
    {
      "title": "On Inference for the Support Vector Machine",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "On Inference for the Support Vector Machine"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1581.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1581.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1581/23-1581.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jakub Rybak, Heather Battey, Wen-Xin Zhou"
        }
      ],
      "author": "Jakub Rybak, Heather Battey, Wen-Xin Zhou",
      "author_detail": {
        "name": "Jakub Rybak, Heather Battey, Wen-Xin Zhou"
      },
      "summary": "The linear support vector machine has a parametrised decision boundary. The paper considers inference for the corresponding parameters, which indicate the effects of individual variables on the decision boundary. The proposed inference is via a convolution-smoothed version of the SVM loss function, this having several inferential advantages over the original SVM, whose associated loss function is not everywhere differentiable. Notably, convolution-smoothing comes with non-asymptotic theoretical guarantees, including a distributional approximation to the parameter estimator that scales more favourably with the dimension of the feature vector. The differentiability of the loss function produces other advantages in some settings; for instance, by facilitating the inclusion of penalties or the synthesis of information from a large number of small samples. The paper closes by relating the linear SVM parameters to those of some probability models for binary outcomes.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The linear support vector machine has a parametrised decision boundary. The paper considers inference for the corresponding parameters, which indicate the effects of individual variables on the decision boundary. The proposed inference is via a convolution-smoothed version of the SVM loss function, this having several inferential advantages over the original SVM, whose associated loss function is not everywhere differentiable. Notably, convolution-smoothing comes with non-asymptotic theoretical guarantees, including a distributional approximation to the parameter estimator that scales more favourably with the dimension of the feature vector. The differentiability of the loss function produces other advantages in some settings; for instance, by facilitating the inclusion of penalties or the synthesis of information from a large number of small samples. The paper closes by relating the linear SVM parameters to those of some probability models for binary outcomes."
      }
    },
    {
      "title": "Random Pruning Over-parameterized Neural Networks Can Improve Generalization: A Training Dynamics Analysis",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Random Pruning Over-parameterized Neural Networks Can Improve Generalization: A Training Dynamics Analysis"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0832.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0832.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0832/23-0832.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Hongru Yang, Yingbin Liang, Xiaojie Guo, Lingfei Wu, Zhangyang Wang"
        }
      ],
      "author": "Hongru Yang, Yingbin Liang, Xiaojie Guo, Lingfei Wu, Zhangyang Wang",
      "author_detail": {
        "name": "Hongru Yang, Yingbin Liang, Xiaojie Guo, Lingfei Wu, Zhangyang Wang"
      },
      "summary": "It has been observed that applying pruning-at-initialization methods and training the sparse networks can sometimes yield slightly better test performance than training the original dense network. Such experimental observations are yet to be understood theoretically. This work makes the first attempt to study this phenomenon. Specifically, we identify a theoretical minimal setting and study a classification task with a one-hidden-layer neural network, which is randomly pruned according to different rates at the initialization. We show that as long as the pruning rate is below a certain threshold, the network provably exhibits good generalization performance after training.More surprisingly, the generalization bound gets better as the pruning rate mildly gets larger. To complement this positive result, we also show a negative result: there exists a large pruning rate such that while gradient descent is still able to drive the training loss toward zero, the generalization performance is no better than random guessing. This further suggests that pruning can change the feature learning process, which leads to the performance drop of the pruned neural network. To our knowledge, this is the first theory work studying how different pruning rates affect neural networks' performance, suggesting that an appropriate pruning rate might improve the neural network's generalization.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "It has been observed that applying pruning-at-initialization methods and training the sparse networks can sometimes yield slightly better test performance than training the original dense network. Such experimental observations are yet to be understood theoretically. This work makes the first attempt to study this phenomenon. Specifically, we identify a theoretical minimal setting and study a classification task with a one-hidden-layer neural network, which is randomly pruned according to different rates at the initialization. We show that as long as the pruning rate is below a certain threshold, the network provably exhibits good generalization performance after training.More surprisingly, the generalization bound gets better as the pruning rate mildly gets larger. To complement this positive result, we also show a negative result: there exists a large pruning rate such that while gradient descent is still able to drive the training loss toward zero, the generalization performance is no better than random guessing. This further suggests that pruning can change the feature learning process, which leads to the performance drop of the pruned neural network. To our knowledge, this is the first theory work studying how different pruning rates affect neural networks' performance, suggesting that an appropriate pruning rate might improve the neural network's generalization."
      }
    },
    {
      "title": "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0058.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0058.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0058/23-0058.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, Thomas Icard"
        }
      ],
      "author": "Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, Thomas Icard",
      "author_detail": {
        "name": "Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaudhary, Sonakshi Chauhan, Jing Huang, Aryaman Arora, Zhengxuan Wu, Noah Goodman, Christopher Potts, Thomas Icard"
      },
      "summary": "Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of polysemantic neurons, the linear representation hypothesis, modular features, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methods in the common language of causal abstraction, namely, activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment search, and steering.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of polysemantic neurons, the linear representation hypothesis, modular features, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methods in the common language of causal abstraction, namely, activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment search, and steering."
      }
    },
    {
      "title": "Implicit vs Unfolded Graph Neural Networks",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Implicit vs Unfolded Graph Neural Networks"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-0459.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-0459.html",
      "pdf": "http://jmlr.org/papers/volume26/22-0459/22-0459.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Yongyi Yang, Tang Liu, Yangkun Wang, Zengfeng Huang, David Wipf"
        }
      ],
      "author": "Yongyi Yang, Tang Liu, Yangkun Wang, Zengfeng Huang, David Wipf",
      "author_detail": {
        "name": "Yongyi Yang, Tang Liu, Yangkun Wang, Zengfeng Huang, David Wipf"
      },
      "summary": "It has been observed that message-passing graph neural networks (GNN) sometimes struggle to maintain a healthy balance between the efficient / scalable modeling of long-range dependencies across nodes while avoiding unintended consequences such oversmoothed node representations, sensitivity to spurious edges, or inadequate model interpretability.  To address these and other issues, two separate strategies have recently been proposed, namely implicit and unfolded GNNs (that we abbreviate to IGNN and UGNN respectively).  The former treats node representations as the fixed points of a deep equilibrium model that can efficiently facilitate arbitrary implicit propagation across the graph with a fixed memory footprint.  In contrast, the latter involves treating graph propagation as unfolded descent iterations as applied to some graph-regularized energy function.  While motivated differently, in this paper we carefully quantify explicit situations where the solutions they produce are equivalent and others where their properties sharply diverge.  This includes the analysis of convergence, representational capacity, and interpretability.  In support of this analysis, we also provide empirical head-to-head comparisons across multiple synthetic and public real-world node classification benchmarks.  These results indicate that while IGNN is substantially more memory-efficient, UGNN models support unique, integrated graph attention mechanisms and propagation rules that can achieve strong node classification accuracy across disparate regimes such as adversarially-perturbed graphs, graphs with heterophily, and graphs involving long-range dependencies.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "It has been observed that message-passing graph neural networks (GNN) sometimes struggle to maintain a healthy balance between the efficient / scalable modeling of long-range dependencies across nodes while avoiding unintended consequences such oversmoothed node representations, sensitivity to spurious edges, or inadequate model interpretability.  To address these and other issues, two separate strategies have recently been proposed, namely implicit and unfolded GNNs (that we abbreviate to IGNN and UGNN respectively).  The former treats node representations as the fixed points of a deep equilibrium model that can efficiently facilitate arbitrary implicit propagation across the graph with a fixed memory footprint.  In contrast, the latter involves treating graph propagation as unfolded descent iterations as applied to some graph-regularized energy function.  While motivated differently, in this paper we carefully quantify explicit situations where the solutions they produce are equivalent and others where their properties sharply diverge.  This includes the analysis of convergence, representational capacity, and interpretability.  In support of this analysis, we also provide empirical head-to-head comparisons across multiple synthetic and public real-world node classification benchmarks.  These results indicate that while IGNN is substantially more memory-efficient, UGNN models support unique, integrated graph attention mechanisms and propagation rules that can achieve strong node classification accuracy across disparate regimes such as adversarially-perturbed graphs, graphs with heterophily, and graphs involving long-range dependencies."
      }
    },
    {
      "title": "Towards Optimal Branching of Linear and Semidefinite Relaxations for Neural Network Robustness Certification",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Towards Optimal Branching of Linear and Semidefinite Relaxations for Neural Network Robustness Certification"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/21-0068.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/21-0068.html",
      "pdf": "http://jmlr.org/papers/volume26/21-0068/21-0068.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi"
        }
      ],
      "author": "Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi",
      "author_detail": {
        "name": "Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi"
      },
      "summary": "In this paper, we study certifying the robustness of ReLU neural networks against adversarial input perturbations. To diminish the relaxation error suffered by the popular linear programming (LP) and semidefinite programming (SDP) certification methods, we take a branch-and-bound approach to propose partitioning the input uncertainty set and solving the relaxations on each part separately. We show that this approach reduces relaxation error, and that the error is eliminated entirely upon performing an LP relaxation with a partition intelligently designed to exploit the nature of the ReLU activations. To scale this approach to large networks, we consider using a coarser partition whereby the number of parts in the partition is reduced. We prove that computing such a coarse partition that directly minimizes the LP relaxation error is NP-hard. By instead minimizing the worst-case LP relaxation error, we develop a closed-form branching scheme in the single-hidden layer case. We extend the analysis to the SDP, where the feasible set geometry is exploited to design a branching scheme that minimizes the worst-case SDP relaxation error. Experiments on MNIST, CIFAR-10, and Wisconsin breast cancer diagnosis classifiers demonstrate significant increases in the percentages of test samples certified. By independently increasing the input size and the number of layers, we empirically illustrate under which regimes the branched LP and branched SDP are best applied. Finally, we extend our LP branching method into a multi-layer branching heuristic, which attains comparable performance to prior state-of-the-art heuristics on large-scale, deep neural network certification benchmarks.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this paper, we study certifying the robustness of ReLU neural networks against adversarial input perturbations. To diminish the relaxation error suffered by the popular linear programming (LP) and semidefinite programming (SDP) certification methods, we take a branch-and-bound approach to propose partitioning the input uncertainty set and solving the relaxations on each part separately. We show that this approach reduces relaxation error, and that the error is eliminated entirely upon performing an LP relaxation with a partition intelligently designed to exploit the nature of the ReLU activations. To scale this approach to large networks, we consider using a coarser partition whereby the number of parts in the partition is reduced. We prove that computing such a coarse partition that directly minimizes the LP relaxation error is NP-hard. By instead minimizing the worst-case LP relaxation error, we develop a closed-form branching scheme in the single-hidden layer case. We extend the analysis to the SDP, where the feasible set geometry is exploited to design a branching scheme that minimizes the worst-case SDP relaxation error. Experiments on MNIST, CIFAR-10, and Wisconsin breast cancer diagnosis classifiers demonstrate significant increases in the percentages of test samples certified. By independently increasing the input size and the number of layers, we empirically illustrate under which regimes the branched LP and branched SDP are best applied. Finally, we extend our LP branching method into a multi-layer branching heuristic, which attains comparable performance to prior state-of-the-art heuristics on large-scale, deep neural network certification benchmarks."
      }
    },
    {
      "title": "GraphNeuralNetworks.jl: Deep Learning on Graphs with Julia",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "GraphNeuralNetworks.jl: Deep Learning on Graphs with Julia"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-2130.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-2130.html",
      "pdf": "http://jmlr.org/papers/volume26/24-2130/24-2130.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Carlo Lucibello, Aurora Rossi"
        }
      ],
      "author": "Carlo Lucibello, Aurora Rossi",
      "author_detail": {
        "name": "Carlo Lucibello, Aurora Rossi"
      },
      "summary": "GraphNeuralNetworks.jl is an open-source framework for deep learning on graphs, written in the Julia programming language. It supports multiple GPU backends, generic sparse or dense graph representations, and offers convenient interfaces for manipulating standard, heterogeneous, and temporal graphs with attributes at the node, edge, and graph levels. The framework allows users to define custom graph convolutional layers using gather/scatter message-passing primitives or optimized fused operations. It also includes several popular layers, enabling efficient experimentation with complex deep architectures. The package is available on GitHub: https://github.com/JuliaGraphs/GraphNeuralNetworks.jl.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "GraphNeuralNetworks.jl is an open-source framework for deep learning on graphs, written in the Julia programming language. It supports multiple GPU backends, generic sparse or dense graph representations, and offers convenient interfaces for manipulating standard, heterogeneous, and temporal graphs with attributes at the node, edge, and graph levels. The framework allows users to define custom graph convolutional layers using gather/scatter message-passing primitives or optimized fused operations. It also includes several popular layers, enabling efficient experimentation with complex deep architectures. The package is available on GitHub: https://github.com/JuliaGraphs/GraphNeuralNetworks.jl."
      }
    },
    {
      "title": "Dynamic angular synchronization under smoothness constraints",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Dynamic angular synchronization under smoothness constraints"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0925.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0925.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0925/24-0925.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Ernesto Araya, Mihai Cucuringu, Hemant Tyagi"
        }
      ],
      "author": "Ernesto Araya, Mihai Cucuringu, Hemant Tyagi",
      "author_detail": {
        "name": "Ernesto Araya, Mihai Cucuringu, Hemant Tyagi"
      },
      "summary": "Given an undirected measurement graph $\\mathcal{H} = ([n], \\mathcal{E})$, \nthe classical angular synchronization problem consists of recovering unknown angles $\\theta_1^*,\\dots,\\theta_n^*$ from a collection of noisy pairwise measurements of the form $(\\theta_i^* - \\theta_j^*) \\mod 2\\pi$, for all $\\{i,j\\} \\in \\mathcal{E}$. This problem arises in a variety of applications, including computer vision, time synchronization of distributed networks, and ranking from pairwise comparisons. In this paper, we consider a dynamic version of this problem where the angles, and also the measurement graphs evolve over $T$ time points. Assuming a smoothness condition on the evolution of the\nlatent angles, we derive three algorithms for joint estimation of the angles over all time points. Moreover, for one of the algorithms, we establish non-asymptotic recovery guarantees for the mean-squared error (MSE) under different statistical models. In particular, we show that the MSE converges to zero as $T$ increases under milder conditions than in the static setting. This includes the setting where the measurement graphs are highly sparse and disconnected, and also when the measurement noise is large and can potentially increase with $T$. We complement our theoretical results with experiments on synthetic data.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Given an undirected measurement graph $\\mathcal{H} = ([n], \\mathcal{E})$, \nthe classical angular synchronization problem consists of recovering unknown angles $\\theta_1^*,\\dots,\\theta_n^*$ from a collection of noisy pairwise measurements of the form $(\\theta_i^* - \\theta_j^*) \\mod 2\\pi$, for all $\\{i,j\\} \\in \\mathcal{E}$. This problem arises in a variety of applications, including computer vision, time synchronization of distributed networks, and ranking from pairwise comparisons. In this paper, we consider a dynamic version of this problem where the angles, and also the measurement graphs evolve over $T$ time points. Assuming a smoothness condition on the evolution of the\nlatent angles, we derive three algorithms for joint estimation of the angles over all time points. Moreover, for one of the algorithms, we establish non-asymptotic recovery guarantees for the mean-squared error (MSE) under different statistical models. In particular, we show that the MSE converges to zero as $T$ increases under milder conditions than in the static setting. This includes the setting where the measurement graphs are highly sparse and disconnected, and also when the measurement noise is large and can potentially increase with $T$. We complement our theoretical results with experiments on synthetic data."
      }
    },
    {
      "title": "Derivative-Informed Neural Operator Acceleration of Geometric MCMC for Infinite-Dimensional Bayesian Inverse Problems",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Derivative-Informed Neural Operator Acceleration of Geometric MCMC for Infinite-Dimensional Bayesian Inverse Problems"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0745.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0745.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0745/24-0745.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Lianghao Cao, Thomas O'Leary-Roseberry, Omar Ghattas"
        }
      ],
      "author": "Lianghao Cao, Thomas O'Leary-Roseberry, Omar Ghattas",
      "author_detail": {
        "name": "Lianghao Cao, Thomas O'Leary-Roseberry, Omar Ghattas"
      },
      "summary": "We propose an operator learning approach to accelerate geometric Markov chain Monte Carlo (MCMC) for solving infinite-dimensional Bayesian inverse problems (BIPs). While geometric MCMC employs high-quality proposals that adapt to posterior local geometry, it requires repeated computations of gradients and Hessians of the log-likelihood, which becomes prohibitive when the parameter-to-observable (PtO) map is defined through expensive-to-solve parametric partial differential equations (PDEs). We consider a delayed-acceptance geometric MCMC method driven by a neural operator surrogate of the PtO map, where the proposal exploits fast surrogate predictions of the log-likelihood and, simultaneously, its gradient and Hessian. To achieve a substantial speedup, the surrogate must accurately approximate the PtO map and its Jacobian, which often demands a prohibitively large number of PtO map samples via conventional operator learning methods. In this work, we present an extension of derivative-informed operator learning [O'Leary-Roseberry et al., J. Comput. Phys., 496 (2024)] that uses joint samples of the PtO map and its Jacobian. This leads to derivative-informed neural operator (DINO) surrogates that accurately predict the observables and posterior local geometry at a significantly lower training cost than conventional methods. Cost and error analysis for reduced basis DINO surrogates are provided. Numerical studies demonstrate that DINO-driven MCMC generates effective posterior samples 3--9 times faster than geometric MCMC and 60--97 times faster than prior geometry-based MCMC. Furthermore, the training cost of DINO surrogates breaks even compared to geometric MCMC after just 10--25 effective posterior samples.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We propose an operator learning approach to accelerate geometric Markov chain Monte Carlo (MCMC) for solving infinite-dimensional Bayesian inverse problems (BIPs). While geometric MCMC employs high-quality proposals that adapt to posterior local geometry, it requires repeated computations of gradients and Hessians of the log-likelihood, which becomes prohibitive when the parameter-to-observable (PtO) map is defined through expensive-to-solve parametric partial differential equations (PDEs). We consider a delayed-acceptance geometric MCMC method driven by a neural operator surrogate of the PtO map, where the proposal exploits fast surrogate predictions of the log-likelihood and, simultaneously, its gradient and Hessian. To achieve a substantial speedup, the surrogate must accurately approximate the PtO map and its Jacobian, which often demands a prohibitively large number of PtO map samples via conventional operator learning methods. In this work, we present an extension of derivative-informed operator learning [O'Leary-Roseberry et al., J. Comput. Phys., 496 (2024)] that uses joint samples of the PtO map and its Jacobian. This leads to derivative-informed neural operator (DINO) surrogates that accurately predict the observables and posterior local geometry at a significantly lower training cost than conventional methods. Cost and error analysis for reduced basis DINO surrogates are provided. Numerical studies demonstrate that DINO-driven MCMC generates effective posterior samples 3--9 times faster than geometric MCMC and 60--97 times faster than prior geometry-based MCMC. Furthermore, the training cost of DINO surrogates breaks even compared to geometric MCMC after just 10--25 effective posterior samples."
      }
    },
    {
      "title": "Wasserstein F-tests for Frechet regression on Bures-Wasserstein manifolds",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Wasserstein F-tests for Frechet regression on Bures-Wasserstein manifolds"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0493.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0493.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0493/24-0493.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Haoshu Xu, Hongzhe Li"
        }
      ],
      "author": "Haoshu Xu, Hongzhe Li",
      "author_detail": {
        "name": "Haoshu Xu, Hongzhe Li"
      },
      "summary": "This paper addresses regression analysis for covariance matrix-valued outcomes with Euclidean covariates, motivated by applications in single-cell genomics and neuroscience where covariance matrices are observed across many samples. Our analysis leverages Fr\\'echet regression on the Bures-Wasserstein manifold to estimate the conditional Fr\\'echet mean given covariates $x$. We establish a non-asymptotic uniform $\\sqrt{n}$-rate of convergence (up to logarithmic factors) over covariates with $\\|x\\| \\lesssim \\sqrt{\\log n}$ and derive a pointwise central limit theorem to enable statistical inference. For testing covariate effects, we devise a novel test whose null distribution converges to a weighted sum of independent chi-square distributions, with power guarantees against a sequence of contiguous alternatives. Simulations validate the accuracy of the asymptotic theory. Finally, we apply our methods to a single-cell gene expression dataset, revealing age-related changes in gene co-expression networks.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "This paper addresses regression analysis for covariance matrix-valued outcomes with Euclidean covariates, motivated by applications in single-cell genomics and neuroscience where covariance matrices are observed across many samples. Our analysis leverages Fr\\'echet regression on the Bures-Wasserstein manifold to estimate the conditional Fr\\'echet mean given covariates $x$. We establish a non-asymptotic uniform $\\sqrt{n}$-rate of convergence (up to logarithmic factors) over covariates with $\\|x\\| \\lesssim \\sqrt{\\log n}$ and derive a pointwise central limit theorem to enable statistical inference. For testing covariate effects, we devise a novel test whose null distribution converges to a weighted sum of independent chi-square distributions, with power guarantees against a sequence of contiguous alternatives. Simulations validate the accuracy of the asymptotic theory. Finally, we apply our methods to a single-cell gene expression dataset, revealing age-related changes in gene co-expression networks."
      }
    },
    {
      "title": "Distributed Stochastic Bilevel Optimization: Improved Complexity and Heterogeneity Analysis",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Distributed Stochastic Bilevel Optimization: Improved Complexity and Heterogeneity Analysis"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0187.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0187.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0187/24-0187.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Youcheng Niu, Jinming Xu, Ying Sun, Yan Huang, Li Chai"
        }
      ],
      "author": "Youcheng Niu, Jinming Xu, Ying Sun, Yan Huang, Li Chai",
      "author_detail": {
        "name": "Youcheng Niu, Jinming Xu, Ying Sun, Yan Huang, Li Chai"
      },
      "summary": "This paper considers solving a class of nonconvex-strongly-convex distributed stochastic bilevel optimization (DSBO) problems with personalized inner-level objectives. Most existing algorithms require computational loops for hypergradient estimation, leading to computational inefficiency. Moreover, the impact of data heterogeneity on convergence in bilevel problems is not explicitly characterized yet. To address these issues, we propose LoPA, a loopless personalized distributed algorithm that leverages a tracking mechanism for iterative approximation of inner-level solutions and Hessian-inverse matrices without relying on extra computation loops. Our theoretical analysis explicitly characterizes the heterogeneity across nodes (denoted by $b$), and establishes a sublinear rate of $\\mathcal{O}( {\\frac{1}{{{{\\left( {1 - \\rho } \\right)}}K}}\\!+ \\!\\frac{{(\\frac{b}{\\sqrt{m}})^{\\frac{2}{3}}  }}{{\\left( {1 - \\rho } \\right)^{\\frac{2}{3}} K^{\\frac{2}{3}} }} \\!+ \\!\\frac{1}{\\sqrt{ K }}( {\\sigma _{\\operatorname{p} }}  + \\frac{1}{\\sqrt{m}}{\\sigma _{\\operatorname{c} }}  ) } )$  without the boundedness of local hypergradients, where ${\\sigma _{\\operatorname{p} }}$ and ${\\sigma _{\\operatorname{c} }}$ represent the gradient sampling variances  associated with the inner- and  outer-level variables, respectively.  We also integrate LoPA with a gradient tracking scheme to eliminate the impact of data heterogeneity, yielding an improved rate of ${{\\mathcal{O}}}(\\frac{{1}}{{ (1-\\rho)^2K }} \\!+\\! \\frac{1}{{\\sqrt{K}}}( \\sigma_{\\rm{p}}  \\!+\\! \\frac{1}{\\sqrt{m}}\\sigma_{\\rm{c}} ) )$. The computational complexity of  LoPA is of ${{\\mathcal{O}}}({\\epsilon^{-2}})$ to an $\\epsilon$-stationary point, matching the communication complexity due to the loopless structure, which outperforms existing counterparts for DSBO. Numerical experiments validate the effectiveness of the proposed algorithm.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "This paper considers solving a class of nonconvex-strongly-convex distributed stochastic bilevel optimization (DSBO) problems with personalized inner-level objectives. Most existing algorithms require computational loops for hypergradient estimation, leading to computational inefficiency. Moreover, the impact of data heterogeneity on convergence in bilevel problems is not explicitly characterized yet. To address these issues, we propose LoPA, a loopless personalized distributed algorithm that leverages a tracking mechanism for iterative approximation of inner-level solutions and Hessian-inverse matrices without relying on extra computation loops. Our theoretical analysis explicitly characterizes the heterogeneity across nodes (denoted by $b$), and establishes a sublinear rate of $\\mathcal{O}( {\\frac{1}{{{{\\left( {1 - \\rho } \\right)}}K}}\\!+ \\!\\frac{{(\\frac{b}{\\sqrt{m}})^{\\frac{2}{3}}  }}{{\\left( {1 - \\rho } \\right)^{\\frac{2}{3}} K^{\\frac{2}{3}} }} \\!+ \\!\\frac{1}{\\sqrt{ K }}( {\\sigma _{\\operatorname{p} }}  + \\frac{1}{\\sqrt{m}}{\\sigma _{\\operatorname{c} }}  ) } )$  without the boundedness of local hypergradients, where ${\\sigma _{\\operatorname{p} }}$ and ${\\sigma _{\\operatorname{c} }}$ represent the gradient sampling variances  associated with the inner- and  outer-level variables, respectively.  We also integrate LoPA with a gradient tracking scheme to eliminate the impact of data heterogeneity, yielding an improved rate of ${{\\mathcal{O}}}(\\frac{{1}}{{ (1-\\rho)^2K }} \\!+\\! \\frac{1}{{\\sqrt{K}}}( \\sigma_{\\rm{p}}  \\!+\\! \\frac{1}{\\sqrt{m}}\\sigma_{\\rm{c}} ) )$. The computational complexity of  LoPA is of ${{\\mathcal{O}}}({\\epsilon^{-2}})$ to an $\\epsilon$-stationary point, matching the communication complexity due to the loopless structure, which outperforms existing counterparts for DSBO. Numerical experiments validate the effectiveness of the proposed algorithm."
      }
    },
    {
      "title": "Learning causal graphs via nonlinear sufficient dimension reduction",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Learning causal graphs via nonlinear sufficient dimension reduction"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0048.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0048.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0048/24-0048.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Eftychia Solea, Bing Li, Kyongwon Kim"
        }
      ],
      "author": "Eftychia Solea, Bing Li, Kyongwon Kim",
      "author_detail": {
        "name": "Eftychia Solea, Bing Li, Kyongwon Kim"
      },
      "summary": "We introduce a new nonparametric methodology for estimating a directed acyclic graph (DAG) from observational data. Our method is nonparametric in nature: it does not impose any specific form on the joint distribution of the underlying DAG. Instead, it relies on a linear operator on reproducing kernel Hilbert spaces to evaluate conditional independence. However, a fully nonparametric approach would involve conditioning on a large number of random variables, subjecting it to the curse of dimensionality. To solve this problem, we apply nonlinear sufficient dimension reduction to reduce the number of variables before evaluating the conditional independence. We develop an estimator for the DAG, based on a linear operator that characterizes conditional independence, and establish the consistency and convergence rates of this estimator, as well as the uniform consistency of the estimated Markov equivalence class. We introduce a modified PC-algorithm to implement the estimating procedure efficiently such that the complexity depends on the sparseness of the underlying true DAG. We demonstrate the effectiveness of our methodology through simulations and a real data analysis.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We introduce a new nonparametric methodology for estimating a directed acyclic graph (DAG) from observational data. Our method is nonparametric in nature: it does not impose any specific form on the joint distribution of the underlying DAG. Instead, it relies on a linear operator on reproducing kernel Hilbert spaces to evaluate conditional independence. However, a fully nonparametric approach would involve conditioning on a large number of random variables, subjecting it to the curse of dimensionality. To solve this problem, we apply nonlinear sufficient dimension reduction to reduce the number of variables before evaluating the conditional independence. We develop an estimator for the DAG, based on a linear operator that characterizes conditional independence, and establish the consistency and convergence rates of this estimator, as well as the uniform consistency of the estimated Markov equivalence class. We introduce a modified PC-algorithm to implement the estimating procedure efficiently such that the complexity depends on the sparseness of the underlying true DAG. We demonstrate the effectiveness of our methodology through simulations and a real data analysis."
      }
    },
    {
      "title": "On Consistent Bayesian Inference from Synthetic Data",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "On Consistent Bayesian Inference from Synthetic Data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1428.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1428.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1428/23-1428.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Ossi Räisä, Joonas Jälkö, Antti Honkela"
        }
      ],
      "author": "Ossi Räisä, Joonas Jälkö, Antti Honkela",
      "author_detail": {
        "name": "Ossi Räisä, Joonas Jälkö, Antti Honkela"
      },
      "summary": "Generating synthetic data, with or without differential privacy, has attracted significant attention as a potential solution to the dilemma between making data easily available, and the privacy of data subjects. Several works have shown that consistency of downstream analyses from synthetic data, including accurate uncertainty estimation, requires accounting for the synthetic data generation. There are very few methods of doing so, most of them for frequentist analysis. In this paper, we study how to perform consistent Bayesian inference from synthetic data. We prove that mixing posterior samples obtained separately from multiple large synthetic data sets, that are sampled from a posterior predictive, converges to the posterior of the downstream analysis under standard regularity conditions when the analyst's model is compatible with the data provider's model. We also present several examples showing how the theory works in practice, and showing how Bayesian inference can fail when the compatibility assumption is not met, or the synthetic data set is not significantly larger than the original.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Generating synthetic data, with or without differential privacy, has attracted significant attention as a potential solution to the dilemma between making data easily available, and the privacy of data subjects. Several works have shown that consistency of downstream analyses from synthetic data, including accurate uncertainty estimation, requires accounting for the synthetic data generation. There are very few methods of doing so, most of them for frequentist analysis. In this paper, we study how to perform consistent Bayesian inference from synthetic data. We prove that mixing posterior samples obtained separately from multiple large synthetic data sets, that are sampled from a posterior predictive, converges to the posterior of the downstream analysis under standard regularity conditions when the analyst's model is compatible with the data provider's model. We also present several examples showing how the theory works in practice, and showing how Bayesian inference can fail when the compatibility assumption is not met, or the synthetic data set is not significantly larger than the original."
      }
    },
    {
      "title": "Optimization Over a Probability Simplex",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Optimization Over a Probability Simplex"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1166.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1166.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1166/23-1166.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "James Chok, Geoffrey M. Vasil"
        }
      ],
      "author": "James Chok, Geoffrey M. Vasil",
      "author_detail": {
        "name": "James Chok, Geoffrey M. Vasil"
      },
      "summary": "We propose a new iteration scheme, the Cauchy-Simplex, to optimize convex problems over the probability simplex $\\{w\\in\\mathbb{R}^n\\ |\\ \\sum_i w_i=1\\ \\textrm{and}\\ w_i\\geq0\\}$.\nSpecifically, we map the simplex to the positive quadrant of a unit sphere, envisage gradient descent in latent variables, and map the result back in a way that only depends on the simplex variable. Moreover, proving rigorous convergence results in this formulation leads inherently to tools from information theory (e.g., cross-entropy and KL divergence). Each iteration of the Cauchy-Simplex consists of simple operations, making it well-suited for high-dimensional problems. In continuous time, we prove that $f(x_T)-f(x^*) = O(1/T)$ for differentiable real-valued convex functions, where $T$ is the number of time steps and $w^*$ is the optimal solution. Numerical experiments of projection onto convex hulls show faster convergence than similar algorithms. Finally, we apply our algorithm to online learning problems and prove the convergence of the average regret for (1) Prediction with expert advice and (2) Universal Portfolios.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We propose a new iteration scheme, the Cauchy-Simplex, to optimize convex problems over the probability simplex $\\{w\\in\\mathbb{R}^n\\ |\\ \\sum_i w_i=1\\ \\textrm{and}\\ w_i\\geq0\\}$.\nSpecifically, we map the simplex to the positive quadrant of a unit sphere, envisage gradient descent in latent variables, and map the result back in a way that only depends on the simplex variable. Moreover, proving rigorous convergence results in this formulation leads inherently to tools from information theory (e.g., cross-entropy and KL divergence). Each iteration of the Cauchy-Simplex consists of simple operations, making it well-suited for high-dimensional problems. In continuous time, we prove that $f(x_T)-f(x^*) = O(1/T)$ for differentiable real-valued convex functions, where $T$ is the number of time steps and $w^*$ is the optimal solution. Numerical experiments of projection onto convex hulls show faster convergence than similar algorithms. Finally, we apply our algorithm to online learning problems and prove the convergence of the average regret for (1) Prediction with expert advice and (2) Universal Portfolios."
      }
    },
    {
      "title": "Laplace Meets Moreau: Smooth Approximation to Infimal Convolutions Using Laplace's Method",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Laplace Meets Moreau: Smooth Approximation to Infimal Convolutions Using Laplace's Method"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0944.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0944.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0944/24-0944.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Ryan J. Tibshirani, Samy Wu Fung, Howard Heaton, Stanley Osher"
        }
      ],
      "author": "Ryan J. Tibshirani, Samy Wu Fung, Howard Heaton, Stanley Osher",
      "author_detail": {
        "name": "Ryan J. Tibshirani, Samy Wu Fung, Howard Heaton, Stanley Osher"
      },
      "summary": "We study approximations to the Moreau envelope---and infimal convolutions more broadly---based on Laplace's method, a classical tool in analysis which ties certain integrals to suprema of their integrands. We believe the connection between Laplace's method and infimal convolutions is generally deserving of more attention in the study of optimization and partial differential equations, since it bears numerous potentially important applications, from proximal-type algorithms to Hamilton-Jacobi equations.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We study approximations to the Moreau envelope---and infimal convolutions more broadly---based on Laplace's method, a classical tool in analysis which ties certain integrals to suprema of their integrands. We believe the connection between Laplace's method and infimal convolutions is generally deserving of more attention in the study of optimization and partial differential equations, since it bears numerous potentially important applications, from proximal-type algorithms to Hamilton-Jacobi equations."
      }
    },
    {
      "title": "Sampling and Estimation on Manifolds using the Langevin Diffusion",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Sampling and Estimation on Manifolds using the Langevin Diffusion"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0829.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0829.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0829/24-0829.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Karthik Bharath, Alexander Lewis, Akash Sharma, Michael V. Tretyakov"
        }
      ],
      "author": "Karthik Bharath, Alexander Lewis, Akash Sharma, Michael V. Tretyakov",
      "author_detail": {
        "name": "Karthik Bharath, Alexander Lewis, Akash Sharma, Michael V. Tretyakov"
      },
      "summary": "Error bounds are derived for sampling and estimation using a discretization of an intrinsically defined Langevin diffusion with invariant measure $\\text{d}\\mu_\\phi \\propto e^{-\\phi} \\mathrm{dvol}_g $ on a compact Riemannian manifold.  Two estimators of linear functionals of $\\mu_\\phi $ based on the discretized Markov process are considered: a time-averaging estimator based on a single trajectory and an ensemble-averaging estimator based on multiple independent trajectories. Imposing no restrictions beyond a nominal level of smoothness on $\\phi$, first-order error bounds, in discretization step size, on the bias and variance/mean-square error of both estimators are derived. The order of error matches the optimal rate in Euclidean and flat spaces, and leads to a first-order bound on distance between the invariant measure $\\mu_\\phi$ and a stationary measure of the discretized Markov process. This order is preserved even upon using retractions when exponential maps are unavailable in closed form, thus enhancing practicality of the proposed algorithms. Generality of the proof techniques, which exploit links between two partial differential equations and the semigroup of operators corresponding to the Langevin diffusion, renders them amenable for the study of a more general class of sampling algorithms related to the Langevin diffusion. Conditions for extending analysis to the case of non-compact manifolds are discussed. Numerical illustrations with distributions, log-concave and otherwise, on the manifolds of positive and negative curvature elucidate on the derived bounds and demonstrate practical utility of the sampling algorithm.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Error bounds are derived for sampling and estimation using a discretization of an intrinsically defined Langevin diffusion with invariant measure $\\text{d}\\mu_\\phi \\propto e^{-\\phi} \\mathrm{dvol}_g $ on a compact Riemannian manifold.  Two estimators of linear functionals of $\\mu_\\phi $ based on the discretized Markov process are considered: a time-averaging estimator based on a single trajectory and an ensemble-averaging estimator based on multiple independent trajectories. Imposing no restrictions beyond a nominal level of smoothness on $\\phi$, first-order error bounds, in discretization step size, on the bias and variance/mean-square error of both estimators are derived. The order of error matches the optimal rate in Euclidean and flat spaces, and leads to a first-order bound on distance between the invariant measure $\\mu_\\phi$ and a stationary measure of the discretized Markov process. This order is preserved even upon using retractions when exponential maps are unavailable in closed form, thus enhancing practicality of the proposed algorithms. Generality of the proof techniques, which exploit links between two partial differential equations and the semigroup of operators corresponding to the Langevin diffusion, renders them amenable for the study of a more general class of sampling algorithms related to the Langevin diffusion. Conditions for extending analysis to the case of non-compact manifolds are discussed. Numerical illustrations with distributions, log-concave and otherwise, on the manifolds of positive and negative curvature elucidate on the derived bounds and demonstrate practical utility of the sampling algorithm."
      }
    },
    {
      "title": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Sharp Bounds for Sequential Federated Learning on Heterogeneous Data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0668.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0668.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0668/24-0668.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Yipeng Li, Xinchen Lyu"
        }
      ],
      "author": "Yipeng Li, Xinchen Lyu",
      "author_detail": {
        "name": "Yipeng Li, Xinchen Lyu"
      },
      "summary": "There are two paradigms in Federated Learning (FL): parallel FL (PFL), where models are trained in a parallel manner across clients, and sequential FL (SFL), where models are trained in a sequential manner across clients. Specifically, in PFL, clients perform local updates independently and send the updated model parameters to a global server for aggregation; in SFL, one client starts its local updates only after receiving the model parameters from the previous client in the sequence. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. To resolve the theoretical dilemma of SFL, we establish sharp convergence guarantees for SFL on heterogeneous data with both upper and lower bounds. Specifically, we derive the upper bounds for the strongly convex, general convex and non-convex objective functions, and construct the matching lower bounds for the strongly convex and general convex objective functions. Then, we compare the upper bounds of SFL with those of PFL, showing that SFL outperforms PFL on heterogeneous data (at least, when the level of heterogeneity is relatively high). Experimental results validate the counterintuitive theoretical finding.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "There are two paradigms in Federated Learning (FL): parallel FL (PFL), where models are trained in a parallel manner across clients, and sequential FL (SFL), where models are trained in a sequential manner across clients. Specifically, in PFL, clients perform local updates independently and send the updated model parameters to a global server for aggregation; in SFL, one client starts its local updates only after receiving the model parameters from the previous client in the sequence. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. To resolve the theoretical dilemma of SFL, we establish sharp convergence guarantees for SFL on heterogeneous data with both upper and lower bounds. Specifically, we derive the upper bounds for the strongly convex, general convex and non-convex objective functions, and construct the matching lower bounds for the strongly convex and general convex objective functions. Then, we compare the upper bounds of SFL with those of PFL, showing that SFL outperforms PFL on heterogeneous data (at least, when the level of heterogeneity is relatively high). Experimental results validate the counterintuitive theoretical finding."
      }
    },
    {
      "title": "Local Linear Recovery Guarantee of Deep Neural Networks at Overparameterization",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Local Linear Recovery Guarantee of Deep Neural Networks at Overparameterization"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0192.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0192.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0192/24-0192.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Yaoyu Zhang, Leyang Zhang, Zhongwang Zhang, Zhiwei Bai"
        }
      ],
      "author": "Yaoyu Zhang, Leyang Zhang, Zhongwang Zhang, Zhiwei Bai",
      "author_detail": {
        "name": "Yaoyu Zhang, Leyang Zhang, Zhongwang Zhang, Zhiwei Bai"
      },
      "summary": "Determining whether deep neural network (DNN) models can reliably recover target functions at overparameterization is a critical yet complex issue in the theory of deep learning. To advance understanding in this area, we introduce a concept we term “local linear recovery” (LLR), a weaker form of target function recovery that renders the problem more amenable to theoretical analysis. In the sense of LLR, we prove that functions expressible by narrower DNNs are guaranteed to be recoverable from fewer samples than model parameters. Specifically, we establish upper limits on the optimistic sample sizes, defined as the smallest sample size necessary to guarantee LLR, for functions in the space of a given DNN. Furthermore, we prove that these upper bounds are achieved in the case of two-layer tanh neural networks. Our research lays a solid groundwork for future investigations into the recovery capabilities of DNNs in overparameterized scenarios.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Determining whether deep neural network (DNN) models can reliably recover target functions at overparameterization is a critical yet complex issue in the theory of deep learning. To advance understanding in this area, we introduce a concept we term “local linear recovery” (LLR), a weaker form of target function recovery that renders the problem more amenable to theoretical analysis. In the sense of LLR, we prove that functions expressible by narrower DNNs are guaranteed to be recoverable from fewer samples than model parameters. Specifically, we establish upper limits on the optimistic sample sizes, defined as the smallest sample size necessary to guarantee LLR, for functions in the space of a given DNN. Furthermore, we prove that these upper bounds are achieved in the case of two-layer tanh neural networks. Our research lays a solid groundwork for future investigations into the recovery capabilities of DNNs in overparameterized scenarios."
      }
    },
    {
      "title": "Stabilizing Sharpness-Aware Minimization Through A Simple Renormalization Strategy",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Stabilizing Sharpness-Aware Minimization Through A Simple Renormalization Strategy"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0065.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0065.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0065/24-0065.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Chengli Tan, Jiangshe Zhang, Junmin Liu, Yicheng Wang, Yunda Hao"
        }
      ],
      "author": "Chengli Tan, Jiangshe Zhang, Junmin Liu, Yicheng Wang, Yunda Hao",
      "author_detail": {
        "name": "Chengli Tan, Jiangshe Zhang, Junmin Liu, Yicheng Wang, Yunda Hao"
      },
      "summary": "Recently, sharpness-aware minimization (SAM) has attracted much attention because of its surprising effectiveness in improving generalization performance. However, compared to stochastic gradient descent (SGD), it is more prone to getting stuck at the saddle points, which as a result may lead to performance degradation. To address this issue, we propose a simple renormalization strategy, dubbed Stable SAM (SSAM), so that the gradient norm of the descent step maintains the same as that of the ascent step. Our strategy is easy to implement and flexible enough to integrate with SAM and its variants, almost at no computational cost. With elementary tools from convex optimization and learning theory, we also conduct a theoretical analysis of sharpness-aware training, revealing that compared to SGD, the effectiveness of SAM is only assured in a limited regime of learning rate. In contrast, we show how SSAM extends this regime of learning rate and then it can consistently perform better than SAM with the minor modification. Finally, we demonstrate the improved performance of SSAM on several representative data sets and tasks.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Recently, sharpness-aware minimization (SAM) has attracted much attention because of its surprising effectiveness in improving generalization performance. However, compared to stochastic gradient descent (SGD), it is more prone to getting stuck at the saddle points, which as a result may lead to performance degradation. To address this issue, we propose a simple renormalization strategy, dubbed Stable SAM (SSAM), so that the gradient norm of the descent step maintains the same as that of the ascent step. Our strategy is easy to implement and flexible enough to integrate with SAM and its variants, almost at no computational cost. With elementary tools from convex optimization and learning theory, we also conduct a theoretical analysis of sharpness-aware training, revealing that compared to SGD, the effectiveness of SAM is only assured in a limited regime of learning rate. In contrast, we show how SSAM extends this regime of learning rate and then it can consistently perform better than SAM with the minor modification. Finally, we demonstrate the improved performance of SSAM on several representative data sets and tasks."
      }
    },
    {
      "title": "Fine-Grained Change Point Detection for Topic Modeling with Pitman-Yor Process",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Fine-Grained Change Point Detection for Topic Modeling with Pitman-Yor Process"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1576.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1576.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1576/23-1576.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Feifei Wang, Zimeng Zhao, Ruimin Ye, Xiaoge Gu, Xiaoling Lu"
        }
      ],
      "author": "Feifei Wang, Zimeng Zhao, Ruimin Ye, Xiaoge Gu, Xiaoling Lu",
      "author_detail": {
        "name": "Feifei Wang, Zimeng Zhao, Ruimin Ye, Xiaoge Gu, Xiaoling Lu"
      },
      "summary": "Identifying change points in dynamic text data is crucial for understanding the evolving nature of topics across various sources, such as news articles, scientific papers, and social media posts. While topic modeling has become a widely used technique for this purpose, capturing fine-grained shifts in individual topics over time remains a significant challenge. Traditional approaches typically use a two-stage process, separating topic modeling and change point detection. However, this separation can lead to information loss and inconsistency in capturing subtle changes in topic evolution. To address this issue, we propose TOPIC-PYP, a change point detection model specifically designed for fine-grained topic-level analysis, i.e., detecting change points for each individual topic. By leveraging the Pitman-Yor process, TOPIC-PYP effectively captures the dynamic evolution of topic meanings over time. Unlike traditional methods, TOPIC-PYP integrates topic modeling and change point detection into a unified framework, facilitating a more comprehensive understanding of the relationship between topic evolution and change points. Experimental evaluations on both synthetic and real-world datasets demonstrate the effectiveness of TOPIC-PYP in accurately detecting change points and generating high-quality topics.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Identifying change points in dynamic text data is crucial for understanding the evolving nature of topics across various sources, such as news articles, scientific papers, and social media posts. While topic modeling has become a widely used technique for this purpose, capturing fine-grained shifts in individual topics over time remains a significant challenge. Traditional approaches typically use a two-stage process, separating topic modeling and change point detection. However, this separation can lead to information loss and inconsistency in capturing subtle changes in topic evolution. To address this issue, we propose TOPIC-PYP, a change point detection model specifically designed for fine-grained topic-level analysis, i.e., detecting change points for each individual topic. By leveraging the Pitman-Yor process, TOPIC-PYP effectively captures the dynamic evolution of topic meanings over time. Unlike traditional methods, TOPIC-PYP integrates topic modeling and change point detection into a unified framework, facilitating a more comprehensive understanding of the relationship between topic evolution and change points. Experimental evaluations on both synthetic and real-world datasets demonstrate the effectiveness of TOPIC-PYP in accurately detecting change points and generating high-quality topics."
      }
    },
    {
      "title": "Deletion Robust Non-Monotone Submodular Maximization over Matroids",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Deletion Robust Non-Monotone Submodular Maximization over Matroids"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1219.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1219.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1219/23-1219.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Paul Dütting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi-Fard, Morteza Zadimoghaddam"
        }
      ],
      "author": "Paul Dütting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi-Fard, Morteza Zadimoghaddam",
      "author_detail": {
        "name": "Paul Dütting, Federico Fusco, Silvio Lattanzi, Ashkan Norouzi-Fard, Morteza Zadimoghaddam"
      },
      "summary": "We study the deletion robust version of submodular maximization under matroid constraints. The goal is to extract a small-size summary of the data set that contains a high-value independent set even after an adversary deletes some elements. We present constant-factor approximation algorithms, whose space complexity depends on the rank $k$ of the matroid, the number $d$ of deleted elements, and the input precision $\\varepsilon$. In the centralized setting we present a $(4.494+O(\\varepsilon))$-approximation algorithm with summary size $O( \\frac{k+d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$ that improves to a $(3.582+O(\\varepsilon))$-approximation with $O(k + \\frac{d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$ summary size when the objective is monotone.  In the streaming setting we provide a $(9.294 + O(\\varepsilon))$-approximation algorithm with summary size and memory $O(k + \\frac{d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$; the approximation factor is then improved to  $(5.582+O(\\varepsilon))$ in the monotone case.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We study the deletion robust version of submodular maximization under matroid constraints. The goal is to extract a small-size summary of the data set that contains a high-value independent set even after an adversary deletes some elements. We present constant-factor approximation algorithms, whose space complexity depends on the rank $k$ of the matroid, the number $d$ of deleted elements, and the input precision $\\varepsilon$. In the centralized setting we present a $(4.494+O(\\varepsilon))$-approximation algorithm with summary size $O( \\frac{k+d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$ that improves to a $(3.582+O(\\varepsilon))$-approximation with $O(k + \\frac{d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$ summary size when the objective is monotone.  In the streaming setting we provide a $(9.294 + O(\\varepsilon))$-approximation algorithm with summary size and memory $O(k + \\frac{d}{\\varepsilon^2}\\log \\frac{k}{\\varepsilon})$; the approximation factor is then improved to  $(5.582+O(\\varepsilon))$ in the monotone case."
      }
    },
    {
      "title": "Instability, Computational Efficiency and Statistical Accuracy",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Instability, Computational Efficiency and Statistical Accuracy"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-0300.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-0300.html",
      "pdf": "http://jmlr.org/papers/volume26/22-0300/22-0300.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Nhat Ho, Koulik Khamaru, Raaz Dwivedi, Martin J. Wainwright, Michael I. Jordan, Bin Yu"
        }
      ],
      "author": "Nhat Ho, Koulik Khamaru, Raaz Dwivedi, Martin J. Wainwright, Michael I. Jordan, Bin Yu",
      "author_detail": {
        "name": "Nhat Ho, Koulik Khamaru, Raaz Dwivedi, Martin J. Wainwright, Michael I. Jordan, Bin Yu"
      },
      "summary": "Many statistical estimators are defined as the fixed point of a data-dependent operator, with estimators based on minimizing a cost function being an important special case.  The limiting performance of such estimators depends on the properties of the population-level operator in the idealized limit of infinitely many samples.  We develop a general framework that yields bounds on statistical accuracy based on the interplay between the deterministic convergence rate of the algorithm at the population level, and its degree of (in)stability when applied to an empirical object based on $n$ samples.  Using this framework, we analyze both stable forms of gradient descent and some higher-order and unstable algorithms, including Newton's method and its cubic-regularized variant, as well as the EM algorithm. We provide applications of our general results to several concrete classes of models, including Gaussian mixture estimation, non-linear regression models, and informative non-response models.  We exhibit cases in which an unstable algorithm can achieve the same statistical accuracy as a stable algorithm in exponentially fewer steps---namely, with the number of iterations being reduced from polynomial to logarithmic in sample size $n$.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Many statistical estimators are defined as the fixed point of a data-dependent operator, with estimators based on minimizing a cost function being an important special case.  The limiting performance of such estimators depends on the properties of the population-level operator in the idealized limit of infinitely many samples.  We develop a general framework that yields bounds on statistical accuracy based on the interplay between the deterministic convergence rate of the algorithm at the population level, and its degree of (in)stability when applied to an empirical object based on $n$ samples.  Using this framework, we analyze both stable forms of gradient descent and some higher-order and unstable algorithms, including Newton's method and its cubic-regularized variant, as well as the EM algorithm. We provide applications of our general results to several concrete classes of models, including Gaussian mixture estimation, non-linear regression models, and informative non-response models.  We exhibit cases in which an unstable algorithm can achieve the same statistical accuracy as a stable algorithm in exponentially fewer steps---namely, with the number of iterations being reduced from polynomial to logarithmic in sample size $n$."
      }
    },
    {
      "title": "Estimation of Local Geometric Structure on Manifolds from Noisy Data",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Estimation of Local Geometric Structure on Manifolds from Noisy Data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/25-0183.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/25-0183.html",
      "pdf": "http://jmlr.org/papers/volume26/25-0183/25-0183.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Yariv Aizenbud, Barak Sober"
        }
      ],
      "author": "Yariv Aizenbud, Barak Sober",
      "author_detail": {
        "name": "Yariv Aizenbud, Barak Sober"
      },
      "summary": "A common observation in data-driven applications is that high-dimensional data have a low intrinsic dimension, at least locally. In this work, we consider the problem of point estimation for manifold-valued data. Namely, given a finite set of noisy samples of $\\mathcal{M}$, a $d$ dimensional submanifold of $\\mathbb{R}^D$, and a point $r$ near the manifold we aim to project $r$ onto the manifold. Assuming that the data was sampled uniformly from a tubular neighborhood of a $k$-times smooth boundaryless and compact manifold, we present an algorithm that takes $r$ from this neighborhood and outputs $\\hat p_n\\in \\mathbb{R}^D$, and $\\widehat{T_{\\hat p_n}\\mathcal{M}}$ an element in the Grassmannian $Gr(d, D)$. We prove that as the number of samples $n\\to\\infty$, the point $\\hat p_n$ converges to $\\mathbf{p}\\in \\mathcal{M}$, the projection of $r$ onto $\\mathcal{M}$, and $\\widehat{T_{\\hat p_n}\\mathcal{M}}$ converges to $T_{\\mathbf{p}}\\mathcal{M}$ (the tangent space at that point) with high probability. Furthermore, we show that $\\hat p_n$ approaches the manifold with an asymptotic rate of $n^{-\\frac{k}{2k + d}}$, and that $\\hat p_n, \\widehat{T_{\\hat p_n}\\mathcal{M}}$ approach $\\mathbf{p}$ and $T_{\\mathbf{p}}\\mathcal{M}$ correspondingly with asymptotic rates of $n^{-\\frac{k-1}{2k + d}}$. %While we These rates coincide with the optimal rates for the estimation of function derivatives.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "A common observation in data-driven applications is that high-dimensional data have a low intrinsic dimension, at least locally. In this work, we consider the problem of point estimation for manifold-valued data. Namely, given a finite set of noisy samples of $\\mathcal{M}$, a $d$ dimensional submanifold of $\\mathbb{R}^D$, and a point $r$ near the manifold we aim to project $r$ onto the manifold. Assuming that the data was sampled uniformly from a tubular neighborhood of a $k$-times smooth boundaryless and compact manifold, we present an algorithm that takes $r$ from this neighborhood and outputs $\\hat p_n\\in \\mathbb{R}^D$, and $\\widehat{T_{\\hat p_n}\\mathcal{M}}$ an element in the Grassmannian $Gr(d, D)$. We prove that as the number of samples $n\\to\\infty$, the point $\\hat p_n$ converges to $\\mathbf{p}\\in \\mathcal{M}$, the projection of $r$ onto $\\mathcal{M}$, and $\\widehat{T_{\\hat p_n}\\mathcal{M}}$ converges to $T_{\\mathbf{p}}\\mathcal{M}$ (the tangent space at that point) with high probability. Furthermore, we show that $\\hat p_n$ approaches the manifold with an asymptotic rate of $n^{-\\frac{k}{2k + d}}$, and that $\\hat p_n, \\widehat{T_{\\hat p_n}\\mathcal{M}}$ approach $\\mathbf{p}$ and $T_{\\mathbf{p}}\\mathcal{M}$ correspondingly with asymptotic rates of $n^{-\\frac{k-1}{2k + d}}$. %While we These rates coincide with the optimal rates for the estimation of function derivatives."
      }
    },
    {
      "title": "Ontolearn---A Framework for Large-scale OWL Class Expression Learning in Python",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Ontolearn---A Framework for Large-scale OWL Class Expression Learning in Python"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1113.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1113.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1113/24-1113.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Caglar Demir, Alkid Baci, N'Dah Jean Kouagou, Leonie Nora Sieger, Stefan Heindorf, Simon Bin, Lukas Blübaum, Alexander Bigerl, Axel-Cyrille Ngonga Ngomo"
        }
      ],
      "author": "Caglar Demir, Alkid Baci, N'Dah Jean Kouagou, Leonie Nora Sieger, Stefan Heindorf, Simon Bin, Lukas Blübaum, Alexander Bigerl, Axel-Cyrille Ngonga Ngomo",
      "author_detail": {
        "name": "Caglar Demir, Alkid Baci, N'Dah Jean Kouagou, Leonie Nora Sieger, Stefan Heindorf, Simon Bin, Lukas Blübaum, Alexander Bigerl, Axel-Cyrille Ngonga Ngomo"
      },
      "summary": "In this paper, we present Ontolearn---a framework for learning OWL class expressions over large knowledge graphs.\nOntolearn contains efficient implementations of recent state-of-the-art symbolic and neuro-symbolic class expression learners including EvoLearner and DRILL.\nA learned OWL class expression can be used to classify instances in the knowledge graph.\nFurthermore, Ontolearn integrates a verbalization module based on an LLM to translate complex OWL class expressions into natural language sentences.\nBy mapping OWL class expressions into respective SPARQL queries, Ontolearn can be easily used to operate over a remote triplestore.\nThe source code of Ontolearn is available at https://github.com/dice-group/Ontolearn.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this paper, we present Ontolearn---a framework for learning OWL class expressions over large knowledge graphs.\nOntolearn contains efficient implementations of recent state-of-the-art symbolic and neuro-symbolic class expression learners including EvoLearner and DRILL.\nA learned OWL class expression can be used to classify instances in the knowledge graph.\nFurthermore, Ontolearn integrates a verbalization module based on an LLM to translate complex OWL class expressions into natural language sentences.\nBy mapping OWL class expressions into respective SPARQL queries, Ontolearn can be easily used to operate over a remote triplestore.\nThe source code of Ontolearn is available at https://github.com/dice-group/Ontolearn."
      }
    },
    {
      "title": "Continuously evolving rewards in an open-ended environment",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Continuously evolving rewards in an open-ended environment"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0847.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0847.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0847/24-0847.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Richard M. Bailey"
        }
      ],
      "author": "Richard M. Bailey",
      "author_detail": {
        "name": "Richard M. Bailey"
      },
      "summary": "Unambiguous identification of the rewards driving behaviours of entities operating in complex open-ended real-world environments is difficult, in part because goals and associated behaviours emerge endogenously and are dynamically updated as environments change. Reproducing such dynamics in models would be useful in many domains, particularly where fixed reward functions limit the adaptive capabilities of agents. Simulation experiments described here assess a candidate algorithm for the dynamic updating of the reward function, RULE: Reward Updating through Learning and Expectation. The approach is tested in a simplified ecosystem-like setting where experiments challenge entities' survival, calling for significant behavioural change. The population of entities successfully demonstrate the abandonment of an initially rewarded but ultimately detrimental behaviour, amplification of beneficial behaviour, and appropriate responses to novel items added to their environment. These adjustments happen through endogenous modification of the entities' reward function, during continuous learning, without external intervention.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Unambiguous identification of the rewards driving behaviours of entities operating in complex open-ended real-world environments is difficult, in part because goals and associated behaviours emerge endogenously and are dynamically updated as environments change. Reproducing such dynamics in models would be useful in many domains, particularly where fixed reward functions limit the adaptive capabilities of agents. Simulation experiments described here assess a candidate algorithm for the dynamic updating of the reward function, RULE: Reward Updating through Learning and Expectation. The approach is tested in a simplified ecosystem-like setting where experiments challenge entities' survival, calling for significant behavioural change. The population of entities successfully demonstrate the abandonment of an initially rewarded but ultimately detrimental behaviour, amplification of beneficial behaviour, and appropriate responses to novel items added to their environment. These adjustments happen through endogenous modification of the entities' reward function, during continuous learning, without external intervention."
      }
    },
    {
      "title": "Recursive Causal Discovery",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Recursive Causal Discovery"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0384.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0384.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0384/24-0384.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Ehsan Mokhtarian, Sepehr Elahi, Sina Akbari, Negar Kiyavash"
        }
      ],
      "author": "Ehsan Mokhtarian, Sepehr Elahi, Sina Akbari, Negar Kiyavash",
      "author_detail": {
        "name": "Ehsan Mokhtarian, Sepehr Elahi, Sina Akbari, Negar Kiyavash"
      },
      "summary": "Causal discovery from observational data, i.e., learning the causal graph from a finite set of samples from the joint distribution of the variables, is often the first step toward the identification and estimation of causal effects, a key requirement in numerous scientific domains. Causal discovery is hampered by two main challenges: limited data results in errors in statistical testing and the computational complexity of the learning task is daunting. This paper builds upon and extends four of our prior publications (Mokhtarian et al., 2021; Akbari et al., 2021; Mokhtarian et al., 2022, 2023a). These works introduced the concept of removable variables, which are the only variables that can be removed recursively for the purpose of causal discovery. Presence and identification of removable variables allow recursive approaches for causal discovery, a promising solution that helps to address the aforementioned challenges by reducing the problem size successively. This reduction not only minimizes conditioning sets in each conditional independence (CI) test, leading to fewer errors but also significantly decreases the number of required CI tests. The worst-case performances of these methods nearly match the lower bound. In this paper, we present a unified framework for the proposed algorithms, refined with additional details and enhancements for a coherent presentation. A comprehensive literature review is also included, comparing the computational complexity of our methods with existing approaches, showcasing their state-of-the-art efficiency. Another contribution of this paper is the release of RCD, a Python package that efficiently implements these algorithms. This package is designed for practitioners and researchers interested in applying these methods in practical scenarios. The package is available at github.com/ban-epfl/rcd, with comprehensive documentation provided at rcdpackage.com.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Causal discovery from observational data, i.e., learning the causal graph from a finite set of samples from the joint distribution of the variables, is often the first step toward the identification and estimation of causal effects, a key requirement in numerous scientific domains. Causal discovery is hampered by two main challenges: limited data results in errors in statistical testing and the computational complexity of the learning task is daunting. This paper builds upon and extends four of our prior publications (Mokhtarian et al., 2021; Akbari et al., 2021; Mokhtarian et al., 2022, 2023a). These works introduced the concept of removable variables, which are the only variables that can be removed recursively for the purpose of causal discovery. Presence and identification of removable variables allow recursive approaches for causal discovery, a promising solution that helps to address the aforementioned challenges by reducing the problem size successively. This reduction not only minimizes conditioning sets in each conditional independence (CI) test, leading to fewer errors but also significantly decreases the number of required CI tests. The worst-case performances of these methods nearly match the lower bound. In this paper, we present a unified framework for the proposed algorithms, refined with additional details and enhancements for a coherent presentation. A comprehensive literature review is also included, comparing the computational complexity of our methods with existing approaches, showcasing their state-of-the-art efficiency. Another contribution of this paper is the release of RCD, a Python package that efficiently implements these algorithms. This package is designed for practitioners and researchers interested in applying these methods in practical scenarios. The package is available at github.com/ban-epfl/rcd, with comprehensive documentation provided at rcdpackage.com."
      }
    },
    {
      "title": "Evaluation of Active Feature Acquisition Methods for Time-varying Feature Settings",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Evaluation of Active Feature Acquisition Methods for Time-varying Feature Settings"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1635.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1635.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1635/23-1635.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Henrik von Kleist, Alireza Zamanian, Ilya Shpitser, Narges Ahmidi"
        }
      ],
      "author": "Henrik von Kleist, Alireza Zamanian, Ilya Shpitser, Narges Ahmidi",
      "author_detail": {
        "name": "Henrik von Kleist, Alireza Zamanian, Ilya Shpitser, Narges Ahmidi"
      },
      "summary": "Machine learning methods often assume that input features are available at no cost. However, in domains like healthcare, where acquiring features could be expensive or harmful, it is necessary to balance a feature's acquisition cost against its predictive value. The task of training an AI agent to decide which features to acquire is called active feature acquisition (AFA). By deploying an AFA agent, we effectively alter the acquisition strategy and trigger a distribution shift. To safely deploy AFA agents under this distribution shift, we present the problem of active feature acquisition performance evaluation (AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating that acquisitions do not affect the underlying feature values; and ii) a no unobserved confounding (NUC) assumption, stating that retrospective feature acquisition decisions were only based on observed features. We show that one can apply missing data methods under the NDE assumption and offline reinforcement learning under the NUC assumption. When NUC and NDE hold, we propose a novel semi-offline reinforcement learning framework. This framework requires a weaker positivity assumption and introduces three new estimators: A direct method (DM), an inverse probability weighting (IPW), and a double reinforcement learning (DRL) estimator.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Machine learning methods often assume that input features are available at no cost. However, in domains like healthcare, where acquiring features could be expensive or harmful, it is necessary to balance a feature's acquisition cost against its predictive value. The task of training an AI agent to decide which features to acquire is called active feature acquisition (AFA). By deploying an AFA agent, we effectively alter the acquisition strategy and trigger a distribution shift. To safely deploy AFA agents under this distribution shift, we present the problem of active feature acquisition performance evaluation (AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating that acquisitions do not affect the underlying feature values; and ii) a no unobserved confounding (NUC) assumption, stating that retrospective feature acquisition decisions were only based on observed features. We show that one can apply missing data methods under the NDE assumption and offline reinforcement learning under the NUC assumption. When NUC and NDE hold, we propose a novel semi-offline reinforcement learning framework. This framework requires a weaker positivity assumption and introduces three new estimators: A direct method (DM), an inverse probability weighting (IPW), and a double reinforcement learning (DRL) estimator."
      }
    },
    {
      "title": "On Adaptive Stochastic Optimization for Streaming Data: A Newton's Method with O(dN) Operations",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "On Adaptive Stochastic Optimization for Streaming Data: A Newton's Method with O(dN) Operations"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1565.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1565.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1565/23-1565.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Antoine Godichon-Baggioni, Nicklas Werge"
        }
      ],
      "author": "Antoine Godichon-Baggioni, Nicklas Werge",
      "author_detail": {
        "name": "Antoine Godichon-Baggioni, Nicklas Werge"
      },
      "summary": "Stochastic optimization methods face new challenges in the realm of streaming data, characterized by a continuous flow of large, high-dimensional data. While first-order methods, like stochastic gradient descent, are the natural choice for such data, they often struggle with ill-conditioned problems. In contrast, second-order methods, such as Newton's method, offer a potential solution but are computationally impractical for large-scale streaming applications. This paper introduces adaptive stochastic optimization methods that effectively address ill-conditioned problems while functioning in a streaming context. Specifically, we present adaptive inversion-free stochastic quasi-Newton methods with computational complexity matching that of first-order methods, $\\mathcal{O}(dN)$, where $d$ represents the number of dimensions/features and $N$ the number of data points. Theoretical analysis establishes their asymptotic efficiency, and empirical studies demonstrate their effectiveness in scenarios with complex covariance structures and poor initializations. In particular, we demonstrate that our adaptive quasi-Newton methods can outperform or match existing first- and second-order methods.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Stochastic optimization methods face new challenges in the realm of streaming data, characterized by a continuous flow of large, high-dimensional data. While first-order methods, like stochastic gradient descent, are the natural choice for such data, they often struggle with ill-conditioned problems. In contrast, second-order methods, such as Newton's method, offer a potential solution but are computationally impractical for large-scale streaming applications. This paper introduces adaptive stochastic optimization methods that effectively address ill-conditioned problems while functioning in a streaming context. Specifically, we present adaptive inversion-free stochastic quasi-Newton methods with computational complexity matching that of first-order methods, $\\mathcal{O}(dN)$, where $d$ represents the number of dimensions/features and $N$ the number of data points. Theoretical analysis establishes their asymptotic efficiency, and empirical studies demonstrate their effectiveness in scenarios with complex covariance structures and poor initializations. In particular, we demonstrate that our adaptive quasi-Newton methods can outperform or match existing first- and second-order methods."
      }
    },
    {
      "title": "Determine the Number of States in Hidden Markov Models via Marginal Likelihood",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Determine the Number of States in Hidden Markov Models via Marginal Likelihood"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0343.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0343.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0343/23-0343.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Yang Chen, Cheng-Der Fuh, Chu-Lan Michael Kao"
        }
      ],
      "author": "Yang Chen, Cheng-Der Fuh, Chu-Lan Michael Kao",
      "author_detail": {
        "name": "Yang Chen, Cheng-Der Fuh, Chu-Lan Michael Kao"
      },
      "summary": "Hidden Markov models (HMM) have been widely used by scientists to model stochastic systems: the underlying process is a discrete Markov chain, and the observations are noisy realizations of the underlying process. Determining the number of hidden states for an HMM is a model selection problem which is yet to be satisfactorily solved, especially for the popular Gaussian HMM with heterogeneous covariance. In this paper, we propose a consistent method for determining the number of hidden states of HMM based on the marginal likelihood, which is obtained by integrating out both the parameters and hidden states. Moreover, we show that the model selection problem of HMM includes the order selection problem of finite mixture models as a special case. We give rigorous proof of the consistency of the proposed marginal likelihood method and provide an efficient computation method for practical implementation. We numerically compare the proposed method with the Bayesian information criterion (BIC), demonstrating the effectiveness of the proposed marginal likelihood method.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Hidden Markov models (HMM) have been widely used by scientists to model stochastic systems: the underlying process is a discrete Markov chain, and the observations are noisy realizations of the underlying process. Determining the number of hidden states for an HMM is a model selection problem which is yet to be satisfactorily solved, especially for the popular Gaussian HMM with heterogeneous covariance. In this paper, we propose a consistent method for determining the number of hidden states of HMM based on the marginal likelihood, which is obtained by integrating out both the parameters and hidden states. Moreover, we show that the model selection problem of HMM includes the order selection problem of finite mixture models as a special case. We give rigorous proof of the consistency of the proposed marginal likelihood method and provide an efficient computation method for practical implementation. We numerically compare the proposed method with the Bayesian information criterion (BIC), demonstrating the effectiveness of the proposed marginal likelihood method."
      }
    },
    {
      "title": "Variance-Aware Estimation of Kernel Mean Embedding",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Variance-Aware Estimation of Kernel Mean Embedding"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0161.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0161.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0161/23-0161.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Geoffrey Wolfer, Pierre Alquier"
        }
      ],
      "author": "Geoffrey Wolfer, Pierre Alquier",
      "author_detail": {
        "name": "Geoffrey Wolfer, Pierre Alquier"
      },
      "summary": "An important feature of kernel mean embeddings (KME) is that the rate of convergence of the empirical KME to the true distribution KME can be bounded independently of the dimension of the space, properties of the distribution and smoothness features of the kernel. We show how to speed-up convergence by leveraging variance information in the reproducing kernel Hilbert space. Furthermore, we show that even when such information is a priori unknown, we can efficiently estimate it from the data, recovering the desiderata of a distribution agnostic bound that enjoys acceleration in fortuitous settings. We further extend our results from independent data to stationary mixing sequences and illustrate our methods in the context of hypothesis testing and robust parametric estimation.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "An important feature of kernel mean embeddings (KME) is that the rate of convergence of the empirical KME to the true distribution KME can be bounded independently of the dimension of the space, properties of the distribution and smoothness features of the kernel. We show how to speed-up convergence by leveraging variance information in the reproducing kernel Hilbert space. Furthermore, we show that even when such information is a priori unknown, we can efficiently estimate it from the data, recovering the desiderata of a distribution agnostic bound that enjoys acceleration in fortuitous settings. We further extend our results from independent data to stationary mixing sequences and illustrate our methods in the context of hypothesis testing and robust parametric estimation."
      }
    },
    {
      "title": "Scaling ResNets in the Large-depth Regime",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Scaling ResNets in the Large-depth Regime"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-0664.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-0664.html",
      "pdf": "http://jmlr.org/papers/volume26/22-0664/22-0664.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Pierre Marion, Adeline Fermanian, Gérard Biau, Jean-Philippe Vert"
        }
      ],
      "author": "Pierre Marion, Adeline Fermanian, Gérard Biau, Jean-Philippe Vert",
      "author_detail": {
        "name": "Pierre Marion, Adeline Fermanian, Gérard Biau, Jean-Philippe Vert"
      },
      "summary": "Deep ResNets are recognized for achieving state-of-the-art results in complex machine learning tasks. However, the remarkable performance of these architectures relies on a training procedure that needs to be carefully crafted to avoid vanishing or exploding gradients, particularly as the depth $L$ increases. No consensus has been reached on how to mitigate this issue, although a widely discussed strategy consists in scaling the output of each layer by a factor $\\alpha_L$. We show in a probabilistic setting that with standard i.i.d. initializations, the only non-trivial dynamics is for $\\alpha_L = \\frac{1}{\\sqrt{L}}$---other choices lead either to explosion or to identity mapping. This scaling factor corresponds in the continuous-time limit to a neural stochastic differential equation, contrarily to a widespread interpretation that deep ResNets are discretizations of neural ordinary differential equations. By contrast, in the latter regime, stability is obtained with specific correlated initializations and $\\alpha_L = \\frac{1}{L}$. Our analysis suggests a strong interplay between scaling and regularity of the weights as a function of the layer index. Finally, in a series of experiments, we exhibit a continuous range of regimes driven by these two parameters, which jointly impact performance before and after training.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Deep ResNets are recognized for achieving state-of-the-art results in complex machine learning tasks. However, the remarkable performance of these architectures relies on a training procedure that needs to be carefully crafted to avoid vanishing or exploding gradients, particularly as the depth $L$ increases. No consensus has been reached on how to mitigate this issue, although a widely discussed strategy consists in scaling the output of each layer by a factor $\\alpha_L$. We show in a probabilistic setting that with standard i.i.d. initializations, the only non-trivial dynamics is for $\\alpha_L = \\frac{1}{\\sqrt{L}}$---other choices lead either to explosion or to identity mapping. This scaling factor corresponds in the continuous-time limit to a neural stochastic differential equation, contrarily to a widespread interpretation that deep ResNets are discretizations of neural ordinary differential equations. By contrast, in the latter regime, stability is obtained with specific correlated initializations and $\\alpha_L = \\frac{1}{L}$. Our analysis suggests a strong interplay between scaling and regularity of the weights as a function of the layer index. Finally, in a series of experiments, we exhibit a continuous range of regimes driven by these two parameters, which jointly impact performance before and after training."
      }
    },
    {
      "title": "A Comparative Evaluation of Quantification Methods",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "A Comparative Evaluation of Quantification Methods"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/21-0241.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/21-0241.html",
      "pdf": "http://jmlr.org/papers/volume26/21-0241/21-0241.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Tobias Schumacher, Markus Strohmaier, Florian Lemmerich"
        }
      ],
      "author": "Tobias Schumacher, Markus Strohmaier, Florian Lemmerich",
      "author_detail": {
        "name": "Tobias Schumacher, Markus Strohmaier, Florian Lemmerich"
      },
      "summary": "Quantification represents the problem of estimating the distribution of class labels on unseen data. It also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. However, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. In this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. We observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and TSMax methods, the DyS framework including the HDy method, Forman's mixture model, and Friedman's method. For the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the HDx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the EM algorithm for quantification, and Friedman's method. We also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. More generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. Our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Quantification represents the problem of estimating the distribution of class labels on unseen data. It also represents a growing research field in supervised machine learning, for which a large variety of different algorithms has been proposed in recent years. However, a comprehensive empirical comparison of quantification methods that supports algorithm selection is not available yet. In this work, we close this research gap by conducting a thorough empirical performance comparison of 24 different quantification methods on in total more than 40 datasets, considering binary as well as multiclass quantification settings. We observe that no single algorithm generally outperforms all competitors, but identify a group of methods that perform best in the binary setting, including the threshold selection-based median sweep and TSMax methods, the DyS framework including the HDy method, Forman's mixture model, and Friedman's method. For the multiclass setting, we observe that a different, broad group of algorithms yields good performance, including the HDx method, the generalized probabilistic adjusted count, the readme method, the energy distance minimization method, the EM algorithm for quantification, and Friedman's method. We also find that tuning the underlying classifiers has in most cases only a limited impact on the quantification performance. More generally, we find that the performance on multiclass quantification is inferior to the results obtained in the binary setting. Our results can guide practitioners who intend to apply quantification algorithms and help researchers identify opportunities for future research."
      }
    },
    {
      "title": "Lightning UQ Box: Uncertainty Quantification for Neural Networks",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Lightning UQ Box: Uncertainty Quantification for Neural Networks"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-2110.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-2110.html",
      "pdf": "http://jmlr.org/papers/volume26/24-2110/24-2110.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Nils Lehmann, Nina Maria Gottschling, Jakob Gawlikowski, Adam J. Stewart, Stefan Depeweg, Eric Nalisnick"
        }
      ],
      "author": "Nils Lehmann, Nina Maria Gottschling, Jakob Gawlikowski, Adam J. Stewart, Stefan Depeweg, Eric Nalisnick",
      "author_detail": {
        "name": "Nils Lehmann, Nina Maria Gottschling, Jakob Gawlikowski, Adam J. Stewart, Stefan Depeweg, Eric Nalisnick"
      },
      "summary": "Although neural networks have shown impressive results in a multitude of application domains, the \"black box\" nature of deep learning and lack of confidence estimates have led to scepticism, especially in domains like medicine and physics where such estimates are critical. Research on uncertainty quantification (UQ) has helped elucidate the reliability of these models, but existing implementations of these UQ methods are sparse and difficult to reuse. To this end, we introduce Lightning UQ Box, a PyTorch-based Python library for deep learning-based UQ methods powered by PyTorch Lightning. Lightning UQ Box supports classification, regression, semantic segmentation, and pixelwise regression applications, and UQ methods from a variety of theoretical motivations. With this library, we provide an entry point for practitioners new to UQ, as well as easy-to-use components and tools for scalable deep learning applications.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Although neural networks have shown impressive results in a multitude of application domains, the \"black box\" nature of deep learning and lack of confidence estimates have led to scepticism, especially in domains like medicine and physics where such estimates are critical. Research on uncertainty quantification (UQ) has helped elucidate the reliability of these models, but existing implementations of these UQ methods are sparse and difficult to reuse. To this end, we introduce Lightning UQ Box, a PyTorch-based Python library for deep learning-based UQ methods powered by PyTorch Lightning. Lightning UQ Box supports classification, regression, semantic segmentation, and pixelwise regression applications, and UQ methods from a variety of theoretical motivations. With this library, we provide an entry point for practitioners new to UQ, as well as easy-to-use components and tools for scalable deep learning applications."
      }
    },
    {
      "title": "Scaling Data-Constrained Language Models",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Scaling Data-Constrained Language Models"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1000.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1000.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1000/24-1000.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Niklas Muennighoff, Alexander M. Rush, Boaz Barak, Teven Le Scao, Aleksandra Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, Colin Raffel"
        }
      ],
      "author": "Niklas Muennighoff, Alexander M. Rush, Boaz Barak, Teven Le Scao, Aleksandra Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, Colin Raffel",
      "author_detail": {
        "name": "Niklas Muennighoff, Alexander M. Rush, Boaz Barak, Teven Le Scao, Aleksandra Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, Colin Raffel"
      },
      "summary": "The current trend of scaling language models involves increasing both parameter count and training data set size. Extrapolating this trend suggests that training data set size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training data set with code data or removing commonly used filters. Models and data sets from our 400 training runs are freely available at https://github.com/huggingface/datablations.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The current trend of scaling language models involves increasing both parameter count and training data set size. Extrapolating this trend suggests that training data set size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training data set with code data or removing commonly used filters. Models and data sets from our 400 training runs are freely available at https://github.com/huggingface/datablations."
      }
    },
    {
      "title": "Curvature-based Clustering on Graphs",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Curvature-based Clustering on Graphs"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0781.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0781.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0781/24-0781.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Yu Tian, Zachary Lubberts, Melanie Weber"
        }
      ],
      "author": "Yu Tian, Zachary Lubberts, Melanie Weber",
      "author_detail": {
        "name": "Yu Tian, Zachary Lubberts, Melanie Weber"
      },
      "summary": "Unsupervised node clustering (or community detection) is a classical graph learning task. In this paper, we study algorithms that exploit the geometry of the graph to identify densely connected substructures, which form clusters or communities. Our method implements discrete Ricci curvatures and their associated geometric flows, under which the edge weights of the graph evolve to reveal its community structure. We consider several discrete curvature notions and analyze the utility of the resulting algorithms. In contrast to prior literature, we study not only single-membership community detection, where each node belongs to exactly one community, but also mixed-membership community detection, where communities may overlap. For the latter, we argue that it is beneficial to perform community detection on the line graph, i.e., the graph's dual. We provide both theoretical and empirical evidence for the utility of our curvature-based clustering algorithms. In addition, we give several results on the relationship between the curvature of a graph and that of its dual, which enable the efficient implementation of our proposed mixed-membership community detection approach and which may be of independent interest for curvature-based network analysis.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Unsupervised node clustering (or community detection) is a classical graph learning task. In this paper, we study algorithms that exploit the geometry of the graph to identify densely connected substructures, which form clusters or communities. Our method implements discrete Ricci curvatures and their associated geometric flows, under which the edge weights of the graph evolve to reveal its community structure. We consider several discrete curvature notions and analyze the utility of the resulting algorithms. In contrast to prior literature, we study not only single-membership community detection, where each node belongs to exactly one community, but also mixed-membership community detection, where communities may overlap. For the latter, we argue that it is beneficial to perform community detection on the line graph, i.e., the graph's dual. We provide both theoretical and empirical evidence for the utility of our curvature-based clustering algorithms. In addition, we give several results on the relationship between the curvature of a graph and that of its dual, which enable the efficient implementation of our proposed mixed-membership community detection approach and which may be of independent interest for curvature-based network analysis."
      }
    },
    {
      "title": "Composite Goodness-of-fit Tests with Kernels",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Composite Goodness-of-fit Tests with Kernels"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0276.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0276.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0276/24-0276.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Oscar Key, Arthur Gretton, François-Xavier Briol, Tamara Fernandez"
        }
      ],
      "author": "Oscar Key, Arthur Gretton, François-Xavier Briol, Tamara Fernandez",
      "author_detail": {
        "name": "Oscar Key, Arthur Gretton, François-Xavier Briol, Tamara Fernandez"
      },
      "summary": "We propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on kernel-based distances such as the maximum mean discrepancy. As our main result, we show that we are able to estimate the parameter and conduct our test on the same data (without data splitting), while maintaining a correct test level. We also prove that the popular wild bootstrap will lead to an overly conservative test, and show that the parametric bootstrap is consistent and can lead to significantly improved performance in practice. Our approach is illustrated on a range of problems, including testing for goodness-of-fit of a non-parametric density model, and an intractable generative model of a biological cellular network.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We propose kernel-based hypothesis tests for the challenging composite testing problem, where we are interested in whether the data comes from any distribution in some parametric family. Our tests make use of minimum distance estimators based on kernel-based distances such as the maximum mean discrepancy. As our main result, we show that we are able to estimate the parameter and conduct our test on the same data (without data splitting), while maintaining a correct test level. We also prove that the popular wild bootstrap will lead to an overly conservative test, and show that the parametric bootstrap is consistent and can lead to significantly improved performance in practice. Our approach is illustrated on a range of problems, including testing for goodness-of-fit of a non-parametric density model, and an intractable generative model of a biological cellular network."
      }
    },
    {
      "title": "PFLlib: A Beginner-Friendly and Comprehensive Personalized Federated Learning Library and Benchmark",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "PFLlib: A Beginner-Friendly and Comprehensive Personalized Federated Learning Library and Benchmark"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1634.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1634.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1634/23-1634.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jianqing Zhang, Yang Liu, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Jian Cao"
        }
      ],
      "author": "Jianqing Zhang, Yang Liu, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Jian Cao",
      "author_detail": {
        "name": "Jianqing Zhang, Yang Liu, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Jian Cao"
      },
      "summary": "Amid the ongoing advancements in Federated Learning (FL), a machine learning paradigm that allows collaborative learning with data privacy protection, personalized FL (pFL) has gained significant prominence as a research direction within the FL domain. Whereas traditional FL (tFL) focuses on jointly learning a global model, pFL aims to balance each client's global and personalized goals in FL settings. To foster the pFL research community, we started and built PFLlib, a comprehensive pFL library with an integrated benchmark platform. In PFLlib, we implemented 37 state-of-the-art FL algorithms (8 tFL algorithms and 29 pFL algorithms) and provided various evaluation environments with three statistically heterogeneous scenarios and 24 datasets. At present, PFLlib has gained more than 1600 stars and 300 forks on GitHub.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Amid the ongoing advancements in Federated Learning (FL), a machine learning paradigm that allows collaborative learning with data privacy protection, personalized FL (pFL) has gained significant prominence as a research direction within the FL domain. Whereas traditional FL (tFL) focuses on jointly learning a global model, pFL aims to balance each client's global and personalized goals in FL settings. To foster the pFL research community, we started and built PFLlib, a comprehensive pFL library with an integrated benchmark platform. In PFLlib, we implemented 37 state-of-the-art FL algorithms (8 tFL algorithms and 29 pFL algorithms) and provided various evaluation environments with three statistically heterogeneous scenarios and 24 datasets. At present, PFLlib has gained more than 1600 stars and 300 forks on GitHub."
      }
    },
    {
      "title": "The Effect of SGD Batch Size on Autoencoder Learning: Sparsity, Sharpness, and Feature Learning",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The Effect of SGD Batch Size on Autoencoder Learning: Sparsity, Sharpness, and Feature Learning"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1022.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1022.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1022/23-1022.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Nikhil Ghosh, Spencer Frei, Wooseok Ha, Bin Yu"
        }
      ],
      "author": "Nikhil Ghosh, Spencer Frei, Wooseok Ha, Bin Yu",
      "author_detail": {
        "name": "Nikhil Ghosh, Spencer Frei, Wooseok Ha, Bin Yu"
      },
      "summary": "In this work, we investigate the dynamics of stochastic gradient descent (SGD) when training a single-neuron autoencoder with linear or ReLU activation on orthogonal data. We show that for this non-convex problem, randomly initialized SGD with a constant step size successfully finds a global minimum for any batch size choice. However, the particular global minimum found depends upon the batch size. In the full-batch setting, we show that the solution is dense (i.e., not sparse) and is highly aligned with its initialized direction, showing that relatively little feature learning occurs. On the other hand, for any batch size strictly smaller than the number of samples, SGD finds a global minimum that is sparse and nearly orthogonal to its initialization, showing that the randomness of stochastic gradients induces a qualitatively different type of \"feature selection\" in this setting. Moreover, if we measure the sharpness of the minimum by the trace of the Hessian, the minima found with full-batch gradient descent are flatter than those found with strictly smaller batch sizes, in contrast to previous works which suggest that large batches lead to sharper minima. To prove convergence of SGD with a constant step size, we introduce a powerful tool from the theory of non-homogeneous random walks which may be of independent interest.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this work, we investigate the dynamics of stochastic gradient descent (SGD) when training a single-neuron autoencoder with linear or ReLU activation on orthogonal data. We show that for this non-convex problem, randomly initialized SGD with a constant step size successfully finds a global minimum for any batch size choice. However, the particular global minimum found depends upon the batch size. In the full-batch setting, we show that the solution is dense (i.e., not sparse) and is highly aligned with its initialized direction, showing that relatively little feature learning occurs. On the other hand, for any batch size strictly smaller than the number of samples, SGD finds a global minimum that is sparse and nearly orthogonal to its initialization, showing that the randomness of stochastic gradients induces a qualitatively different type of \"feature selection\" in this setting. Moreover, if we measure the sharpness of the minimum by the trace of the Hessian, the minima found with full-batch gradient descent are flatter than those found with strictly smaller batch sizes, in contrast to previous works which suggest that large batches lead to sharper minima. To prove convergence of SGD with a constant step size, we introduce a powerful tool from the theory of non-homogeneous random walks which may be of independent interest."
      }
    },
    {
      "title": "Efficient and Robust Transfer Learning of Optimal Individualized Treatment Regimes with Right-Censored Survival Data",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Efficient and Robust Transfer Learning of Optimal Individualized Treatment Regimes with Right-Censored Survival Data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0335.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0335.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0335/23-0335.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Pan Zhao, Julie Josse, Shu Yang"
        }
      ],
      "author": "Pan Zhao, Julie Josse, Shu Yang",
      "author_detail": {
        "name": "Pan Zhao, Julie Josse, Shu Yang"
      },
      "summary": "An individualized treatment regime (ITR) is a decision rule that assigns treatments based on patients' characteristics. The value function of an ITR is the expected outcome in a counterfactual world had this ITR been implemented. Recently, there has been increasing interest in combining heterogeneous data sources, such as leveraging the complementary features of randomized controlled trial (RCT) data and a large observational study (OS). Usually, a covariate shift exists between the source and target population, rendering the source-optimal ITR not optimal for the target population. We present an efficient and robust transfer learning framework for estimating the optimal ITR with right-censored survival data that generalizes well to the target population. The value function accommodates a broad class of functionals of survival distributions, including survival probabilities and restrictive mean survival times (RMSTs). We propose a doubly robust estimator of the value function, and the optimal ITR is learned by maximizing the value function within a pre-specified class of ITRs. We establish the cubic rate of convergence for the estimated parameter indexing the optimal ITR, and show that the proposed optimal value estimator is consistent and asymptotically normal even with flexible machine learning methods for nuisance parameter estimation. We evaluate the empirical performance of the proposed method by simulation studies and a real data application of sodium bicarbonate therapy for patients with severe metabolic acidaemia in the intensive care unit (ICU), combining a RCT and an observational study with heterogeneity.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "An individualized treatment regime (ITR) is a decision rule that assigns treatments based on patients' characteristics. The value function of an ITR is the expected outcome in a counterfactual world had this ITR been implemented. Recently, there has been increasing interest in combining heterogeneous data sources, such as leveraging the complementary features of randomized controlled trial (RCT) data and a large observational study (OS). Usually, a covariate shift exists between the source and target population, rendering the source-optimal ITR not optimal for the target population. We present an efficient and robust transfer learning framework for estimating the optimal ITR with right-censored survival data that generalizes well to the target population. The value function accommodates a broad class of functionals of survival distributions, including survival probabilities and restrictive mean survival times (RMSTs). We propose a doubly robust estimator of the value function, and the optimal ITR is learned by maximizing the value function within a pre-specified class of ITRs. We establish the cubic rate of convergence for the estimated parameter indexing the optimal ITR, and show that the proposed optimal value estimator is consistent and asymptotically normal even with flexible machine learning methods for nuisance parameter estimation. We evaluate the empirical performance of the proposed method by simulation studies and a real data application of sodium bicarbonate therapy for patients with severe metabolic acidaemia in the intensive care unit (ICU), combining a RCT and an observational study with heterogeneity."
      }
    },
    {
      "title": "DAGs as Minimal I-maps for the Induced Models of Causal Bayesian Networks under Conditioning",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "DAGs as Minimal I-maps for the Induced Models of Causal Bayesian Networks under Conditioning"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0002.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0002.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0002/23-0002.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Xiangdong Xie, Jiahua Guo, Yi Sun"
        }
      ],
      "author": "Xiangdong Xie, Jiahua Guo, Yi Sun",
      "author_detail": {
        "name": "Xiangdong Xie, Jiahua Guo, Yi Sun"
      },
      "summary": "Bayesian networks (BNs) are a powerful tool for knowledge representation and reasoning, especially for complex systems.  A critical task in the applications of BNs is conditional inference or inference in the presence of selection bias. However, post-conditioning, the conditional distribution family of a BN can become complex for analysis, and the corresponding induced subgraph may not accurately encode the  conditional independencies  for the remaining variables. In this work, we first investigate the conditions under which a BN remains closed under conditioning, meaning that the induced subgraph is consistent with the structural information of conditional distributions. Conversely, when a BN is not closed, we aim to construct a new directed acyclic graph (DAG) as a minimal $\\mathcal{I}$-map for the conditional model by incorporating directed edges into the original induced graph. We present an equivalent characterization of this minimal $\\mathcal{I}$-map and develop an efficient algorithm for its identification.  The proposed framework improves the efficiency of conditional inference of a BN.  Additionally, the DAG minimal $\\mathcal{I}$-map offers graphical criteria for the safe integration of knowledge from diverse sources (subpopulations/conditional distributions), facilitating correct parameter estimation. Both theoretical analysis and simulation studies demonstrate that using a DAG minimal $\\mathcal{I}$-map for conditional inference is more effective than traditional methods based on the joint distribution of the original BN.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bayesian networks (BNs) are a powerful tool for knowledge representation and reasoning, especially for complex systems.  A critical task in the applications of BNs is conditional inference or inference in the presence of selection bias. However, post-conditioning, the conditional distribution family of a BN can become complex for analysis, and the corresponding induced subgraph may not accurately encode the  conditional independencies  for the remaining variables. In this work, we first investigate the conditions under which a BN remains closed under conditioning, meaning that the induced subgraph is consistent with the structural information of conditional distributions. Conversely, when a BN is not closed, we aim to construct a new directed acyclic graph (DAG) as a minimal $\\mathcal{I}$-map for the conditional model by incorporating directed edges into the original induced graph. We present an equivalent characterization of this minimal $\\mathcal{I}$-map and develop an efficient algorithm for its identification.  The proposed framework improves the efficiency of conditional inference of a BN.  Additionally, the DAG minimal $\\mathcal{I}$-map offers graphical criteria for the safe integration of knowledge from diverse sources (subpopulations/conditional distributions), facilitating correct parameter estimation. Both theoretical analysis and simulation studies demonstrate that using a DAG minimal $\\mathcal{I}$-map for conditional inference is more effective than traditional methods based on the joint distribution of the original BN."
      }
    },
    {
      "title": "Adjusted Expected Improvement for Cumulative Regret Minimization in Noisy Bayesian Optimization",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Adjusted Expected Improvement for Cumulative Regret Minimization in Noisy Bayesian Optimization"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-0523.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-0523.html",
      "pdf": "http://jmlr.org/papers/volume26/22-0523/22-0523.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Shouri Hu, Haowei Wang, Zhongxiang Dai, Bryan Kian Hsiang Low, Szu Hui Ng"
        }
      ],
      "author": "Shouri Hu, Haowei Wang, Zhongxiang Dai, Bryan Kian Hsiang Low, Szu Hui Ng",
      "author_detail": {
        "name": "Shouri Hu, Haowei Wang, Zhongxiang Dai, Bryan Kian Hsiang Low, Szu Hui Ng"
      },
      "summary": "The expected improvement (EI) is one of the most popular acquisition functions for Bayesian optimization (BO) and has demonstrated good empirical performances in many applications for the minimization of simple regret. However, under the evaluation metric of cumulative regret, the performance of EI may not be competitive, and its existing theoretical regret upper bound still has room for improvement. To adapt the EI for better performance under cumulative regret, we introduce a novel quantity called the evaluation cost which is compared against the acquisition function, and with this, develop the expected improvement-cost (EIC) algorithm. In each iteration of EIC, a new point with the largest acquisition function value is sampled, only if that value exceeds its evaluation cost. If none meets this criteria, the current best point is resampled. This evaluation cost quantifies the potential downside of sampling a point, which is important under the cumulative regret metric as the objective function value in every iteration affects the performance measure. We establish in theory a high-probability regret upper bound of EIC based on the maximum information gain, which is tighter than the bound of existing EI-based algorithms. It is also comparable to the regret bound of other popular BO algorithms such as Thompson sampling (GP-TS) and upper confidence bound (GP-UCB). We further perform experiments to illustrate the improvement of EIC over several popular BO algorithms.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The expected improvement (EI) is one of the most popular acquisition functions for Bayesian optimization (BO) and has demonstrated good empirical performances in many applications for the minimization of simple regret. However, under the evaluation metric of cumulative regret, the performance of EI may not be competitive, and its existing theoretical regret upper bound still has room for improvement. To adapt the EI for better performance under cumulative regret, we introduce a novel quantity called the evaluation cost which is compared against the acquisition function, and with this, develop the expected improvement-cost (EIC) algorithm. In each iteration of EIC, a new point with the largest acquisition function value is sampled, only if that value exceeds its evaluation cost. If none meets this criteria, the current best point is resampled. This evaluation cost quantifies the potential downside of sampling a point, which is important under the cumulative regret metric as the objective function value in every iteration affects the performance measure. We establish in theory a high-probability regret upper bound of EIC based on the maximum information gain, which is tighter than the bound of existing EI-based algorithms. It is also comparable to the regret bound of other popular BO algorithms such as Thompson sampling (GP-TS) and upper confidence bound (GP-UCB). We further perform experiments to illustrate the improvement of EIC over several popular BO algorithms."
      }
    },
    {
      "title": "Manifold Fitting under Unbounded Noise",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Manifold Fitting under Unbounded Noise"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/21-0039.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/21-0039.html",
      "pdf": "http://jmlr.org/papers/volume26/21-0039/21-0039.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Zhigang Yao, Yuqing Xia"
        }
      ],
      "author": "Zhigang Yao, Yuqing Xia",
      "author_detail": {
        "name": "Zhigang Yao, Yuqing Xia"
      },
      "summary": "In the field of non-Euclidean statistical analysis, a trend has emerged in recent times, of attempts to recover a low dimensional structure, namely a manifold, underlying the high dimensional data. Recovering the manifold requires the noise to be of a certain concentration and prevailing methods address this requirement by constructing an approximated manifold that is based on the tangent space estimation at each sample point. Although theoretical convergence for these methods is guaranteed, the samples are either noiseless or the noise is bounded. However, if the noise is unbounded, as is commonplace, the tangent space estimation at the noisy samples will be blurred – an undesirable outcome since fitting a manifold from the blurred tangent space might be more greatly compromised in terms of its accuracy. In this paper, we introduce a new manifold-fitting method, whereby the output manifold is constructed by directly estimating the tangent spaces at the projected points on the latent manifold, rather than at the sample points, thus reducing the error caused by the noise. Assuming the noise is unbounded, our new method has a high probability of achieving theoretical convergence, in terms of the upper bound of the distance between the estimated and latent manifold. The smoothness of the estimated manifold is also evaluated by bounding the supremum of twice difference above. Numerical simulations are conducted as part of this new method to help validate our theoretical findings and demonstrate the advantages of our method over other relevant manifold fitting methods. Finally, our method is applied to real data examples.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In the field of non-Euclidean statistical analysis, a trend has emerged in recent times, of attempts to recover a low dimensional structure, namely a manifold, underlying the high dimensional data. Recovering the manifold requires the noise to be of a certain concentration and prevailing methods address this requirement by constructing an approximated manifold that is based on the tangent space estimation at each sample point. Although theoretical convergence for these methods is guaranteed, the samples are either noiseless or the noise is bounded. However, if the noise is unbounded, as is commonplace, the tangent space estimation at the noisy samples will be blurred – an undesirable outcome since fitting a manifold from the blurred tangent space might be more greatly compromised in terms of its accuracy. In this paper, we introduce a new manifold-fitting method, whereby the output manifold is constructed by directly estimating the tangent spaces at the projected points on the latent manifold, rather than at the sample points, thus reducing the error caused by the noise. Assuming the noise is unbounded, our new method has a high probability of achieving theoretical convergence, in terms of the upper bound of the distance between the estimated and latent manifold. The smoothness of the estimated manifold is also evaluated by bounding the supremum of twice difference above. Numerical simulations are conducted as part of this new method to help validate our theoretical findings and demonstrate the advantages of our method over other relevant manifold fitting methods. Finally, our method is applied to real data examples."
      }
    },
    {
      "title": "Learning Global Nash Equilibrium in Team Competitive Games with Generalized Fictitious Cross-Play",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Learning Global Nash Equilibrium in Team Competitive Games with Generalized Fictitious Cross-Play"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1503.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1503.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1503/24-1503.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Zelai Xu, Chao Yu, Yancheng Liang, Yi Wu, Yu Wang"
        }
      ],
      "author": "Zelai Xu, Chao Yu, Yancheng Liang, Yi Wu, Yu Wang",
      "author_detail": {
        "name": "Zelai Xu, Chao Yu, Yancheng Liang, Yi Wu, Yu Wang"
      },
      "summary": "Self-play (SP) is a popular multi-agent reinforcement learning framework for competitive games. Despite the empirical success, the theoretical properties of SP are limited to two-player settings. For team competitive games where two teams of cooperative agents compete with each other, we show a counter-example where SP cannot converge to a global Nash equilibrium (NE) with high probability. Policy-Space Response Oracles (PSRO) is an alternative framework that finds NEs by iteratively learning the best response (BR) to previous policies. PSRO can be directly extended to team competitive games with unchanged convergence properties by learning team BRs, but its repeated training from scratch makes it hard to scale to complex games. In this work, we propose Generalized Fictitious Cross-Play (GFXP), a novel algorithm that inherits benefits from both frameworks. GFXP simultaneously trains an SP-based main policy and a counter population. The main policy is trained by fictitious self-play and cross-play against the counter population, while the counter policies are trained as the BRs to the main policy's checkpoints. We evaluate GFXP in matrix games and gridworld domains where GFXP achieves the lowest exploitabilities. We further conduct experiments in a challenging football game where GFXP defeats SOTA models with over 94% win rate.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Self-play (SP) is a popular multi-agent reinforcement learning framework for competitive games. Despite the empirical success, the theoretical properties of SP are limited to two-player settings. For team competitive games where two teams of cooperative agents compete with each other, we show a counter-example where SP cannot converge to a global Nash equilibrium (NE) with high probability. Policy-Space Response Oracles (PSRO) is an alternative framework that finds NEs by iteratively learning the best response (BR) to previous policies. PSRO can be directly extended to team competitive games with unchanged convergence properties by learning team BRs, but its repeated training from scratch makes it hard to scale to complex games. In this work, we propose Generalized Fictitious Cross-Play (GFXP), a novel algorithm that inherits benefits from both frameworks. GFXP simultaneously trains an SP-based main policy and a counter population. The main policy is trained by fictitious self-play and cross-play against the counter population, while the counter policies are trained as the BRs to the main policy's checkpoints. We evaluate GFXP in matrix games and gridworld domains where GFXP achieves the lowest exploitabilities. We further conduct experiments in a challenging football game where GFXP defeats SOTA models with over 94% win rate."
      }
    },
    {
      "title": "Wasserstein Convergence Guarantees for a General Class of Score-Based Generative Models",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Wasserstein Convergence Guarantees for a General Class of Score-Based Generative Models"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0902.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0902.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0902/24-0902.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Xuefeng Gao, Hoang M. Nguyen, Lingjiong Zhu"
        }
      ],
      "author": "Xuefeng Gao, Hoang M. Nguyen, Lingjiong Zhu",
      "author_detail": {
        "name": "Xuefeng Gao, Hoang M. Nguyen, Lingjiong Zhu"
      },
      "summary": "Score-based generative models are a recent class of deep generative models with state-of-the-art performance in many applications. In this paper, we establish convergence guarantees for a general class of score-based generative models in the 2-Wasserstein distance, assuming accurate score estimates and smooth log-concave data distribution. We specialize our results to several concrete score-based generative models with specific choices of forward processes modeled by stochastic differential equations, and obtain an upper bound on the iteration complexity for each model, which demonstrates the impacts of different choices of the forward processes. We also provide a lower bound when the data distribution is Gaussian. Numerically, we experiment with score-based generative models with different forward processes for unconditional image generation on CIFAR-10. We find that the experimental results are in good agreement with our theoretical predictions on the iteration complexity.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Score-based generative models are a recent class of deep generative models with state-of-the-art performance in many applications. In this paper, we establish convergence guarantees for a general class of score-based generative models in the 2-Wasserstein distance, assuming accurate score estimates and smooth log-concave data distribution. We specialize our results to several concrete score-based generative models with specific choices of forward processes modeled by stochastic differential equations, and obtain an upper bound on the iteration complexity for each model, which demonstrates the impacts of different choices of the forward processes. We also provide a lower bound when the data distribution is Gaussian. Numerically, we experiment with score-based generative models with different forward processes for unconditional image generation on CIFAR-10. We find that the experimental results are in good agreement with our theoretical predictions on the iteration complexity."
      }
    },
    {
      "title": "Extremal graphical modeling with latent variables via convex optimization",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Extremal graphical modeling with latent variables via convex optimization"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0472.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0472.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0472/24-0472.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Sebastian Engelke, Armeen Taeb"
        }
      ],
      "author": "Sebastian Engelke, Armeen Taeb",
      "author_detail": {
        "name": "Sebastian Engelke, Armeen Taeb"
      },
      "summary": "Extremal graphical models encode the conditional independence structure of multivariate extremes and provide a powerful tool for quantifying the risk of rare events. Prior work on learning these graphs from data has focused on the setting where all relevant variables are observed. For the popular class of Husler-Reiss models, we propose the eglatent method, a tractable convex program for learning extremal graphical models in the presence of latent variables. Our approach decomposes the Husler-Reiss precision matrix into a sparse component encoding the graphical structure among the observed variables after conditioning on the latent variables, and a low-rank component encoding the effect of a few latent variables on the observed variables. We provide finite-sample guarantees of eglatent and show that it consistently recovers the conditional graph as well as the number of latent variables. We highlight the improved performances of our approach on synthetic and real data.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Extremal graphical models encode the conditional independence structure of multivariate extremes and provide a powerful tool for quantifying the risk of rare events. Prior work on learning these graphs from data has focused on the setting where all relevant variables are observed. For the popular class of Husler-Reiss models, we propose the eglatent method, a tractable convex program for learning extremal graphical models in the presence of latent variables. Our approach decomposes the Husler-Reiss precision matrix into a sparse component encoding the graphical structure among the observed variables after conditioning on the latent variables, and a low-rank component encoding the effect of a few latent variables on the observed variables. We provide finite-sample guarantees of eglatent and show that it consistently recovers the conditional graph as well as the number of latent variables. We highlight the improved performances of our approach on synthetic and real data."
      }
    },
    {
      "title": "On the Approximation of Kernel functions",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "On the Approximation of Kernel functions"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0270.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0270.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0270/24-0270.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Paul Dommel, Alois Pichler"
        }
      ],
      "author": "Paul Dommel, Alois Pichler",
      "author_detail": {
        "name": "Paul Dommel, Alois Pichler"
      },
      "summary": "Various methods in statistical learning build on kernels considered in reproducing kernel Hilbert spaces. In applications, the kernel is often selected based on characteristics of the problem and the data. This kernel is then employed to infer response variables at points, where no explanatory data were observed. The data considered here are located in compact sets in higher dimensions and the paper addresses approximations of the kernel itself. The new approach considers Taylor series approximations of radial kernel functions. For the Gauss kernel on the unit cube, the paper establishes an upper bound of the associated eigenfunctions, which grows only polynomially with respect to the index. The novel approach substantiates smaller regularization parameters than considered in the literature, overall leading to better approximations. This improvement confirms low rank approximation methods such as the Nyström method.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Various methods in statistical learning build on kernels considered in reproducing kernel Hilbert spaces. In applications, the kernel is often selected based on characteristics of the problem and the data. This kernel is then employed to infer response variables at points, where no explanatory data were observed. The data considered here are located in compact sets in higher dimensions and the paper addresses approximations of the kernel itself. The new approach considers Taylor series approximations of radial kernel functions. For the Gauss kernel on the unit cube, the paper establishes an upper bound of the associated eigenfunctions, which grows only polynomially with respect to the index. The novel approach substantiates smaller regularization parameters than considered in the literature, overall leading to better approximations. This improvement confirms low rank approximation methods such as the Nyström method."
      }
    },
    {
      "title": "Efficient and Robust Semi-supervised Estimation of Average Treatment Effect with Partially Annotated Treatment and Response",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Efficient and Robust Semi-supervised Estimation of Average Treatment Effect with Partially Annotated Treatment and Response"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1587.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1587.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1587/23-1587.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jue Hou, Rajarshi Mukherjee, Tianxi Cai"
        }
      ],
      "author": "Jue Hou, Rajarshi Mukherjee, Tianxi Cai",
      "author_detail": {
        "name": "Jue Hou, Rajarshi Mukherjee, Tianxi Cai"
      },
      "summary": "A notable challenge of leveraging Electronic Health Records (EHR) for treatment effect assessment is the lack of precise information on important clinical variables, including the treatment received and the response. Both treatment information and response cannot be accurately captured by readily available EHR features in many studies and require labor-intensive manual chart review to precisely annotate, which limits the number of available gold standard labels on these key variables. We considered average treatment effect (ATE) estimation when 1) exact treatment and outcome variables are only observed together in a small labeled subset and 2) noisy surrogates of treatment and outcome, such as relevant prescription and diagnosis codes, along with potential confounders are observed for all subjects. We derived the efficient influence function for ATE and used it to construct a semi-supervised multiple machine learning (SMMAL) estimator. We justified that our SMMAL ATE estimator is semi-parametric efficient with B-spline regression under low-dimensional smooth models. We developed the adaptive sparsity/model doubly robust estimation under high-dimensional logistic propensity score and outcome regression models. Results from simulation studies demonstrated the validity of our SMMAL method and its superiority over supervised and unsupervised benchmarks. We applied SMMAL to the assessment of targeted therapies for metastatic colorectal cancer in comparison to chemotherapy.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "A notable challenge of leveraging Electronic Health Records (EHR) for treatment effect assessment is the lack of precise information on important clinical variables, including the treatment received and the response. Both treatment information and response cannot be accurately captured by readily available EHR features in many studies and require labor-intensive manual chart review to precisely annotate, which limits the number of available gold standard labels on these key variables. We considered average treatment effect (ATE) estimation when 1) exact treatment and outcome variables are only observed together in a small labeled subset and 2) noisy surrogates of treatment and outcome, such as relevant prescription and diagnosis codes, along with potential confounders are observed for all subjects. We derived the efficient influence function for ATE and used it to construct a semi-supervised multiple machine learning (SMMAL) estimator. We justified that our SMMAL ATE estimator is semi-parametric efficient with B-spline regression under low-dimensional smooth models. We developed the adaptive sparsity/model doubly robust estimation under high-dimensional logistic propensity score and outcome regression models. Results from simulation studies demonstrated the validity of our SMMAL method and its superiority over supervised and unsupervised benchmarks. We applied SMMAL to the assessment of targeted therapies for metastatic colorectal cancer in comparison to chemotherapy."
      }
    },
    {
      "title": "Nonconvex Stochastic Bregman Proximal Gradient Method with Application to Deep Learning",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Nonconvex Stochastic Bregman Proximal Gradient Method with Application to Deep Learning"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0657.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0657.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0657/23-0657.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Kuangyu Ding, Jingyang Li, Kim-Chuan Toh"
        }
      ],
      "author": "Kuangyu Ding, Jingyang Li, Kim-Chuan Toh",
      "author_detail": {
        "name": "Kuangyu Ding, Jingyang Li, Kim-Chuan Toh"
      },
      "summary": "Stochastic gradient methods for minimizing nonconvex composite objective functions typically rely on the Lipschitz smoothness of the differentiable part, but this assumption fails in many important problem classes like quadratic inverse problems and neural network training, leading to instability of the algorithms in both theory and practice. To address this, we propose a family of stochastic Bregman proximal gradient (SBPG) methods that only require smooth adaptivity. SBPG replaces the quadratic approximation in SGD with a Bregman proximity measure, offering a better approximation model that handles non-Lipschitz gradients in nonconvex objectives. We establish the convergence properties of vanilla SBPG and show it achieves optimal sample complexity in the nonconvex setting. Experimental results on quadratic inverse problems demonstrate SBPG's robustness in terms of stepsize selection and sensitivity to the initial point. Furthermore, we introduce a momentum-based variant, MSBPG, which enhances convergence by relaxing the mini-batch size requirement while preserving the optimal oracle complexity. We apply MSBPG to the training of deep neural networks, utilizing a polynomial kernel function to ensure smooth adaptivity of the loss function. Experimental results on benchmark datasets confirm the effectiveness and robustness of MSBPG in training neural networks. Given its negligible additional computational cost compared to SGD in large-scale optimization, MSBPG shows promise as a universal open-source optimizer for future applications.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Stochastic gradient methods for minimizing nonconvex composite objective functions typically rely on the Lipschitz smoothness of the differentiable part, but this assumption fails in many important problem classes like quadratic inverse problems and neural network training, leading to instability of the algorithms in both theory and practice. To address this, we propose a family of stochastic Bregman proximal gradient (SBPG) methods that only require smooth adaptivity. SBPG replaces the quadratic approximation in SGD with a Bregman proximity measure, offering a better approximation model that handles non-Lipschitz gradients in nonconvex objectives. We establish the convergence properties of vanilla SBPG and show it achieves optimal sample complexity in the nonconvex setting. Experimental results on quadratic inverse problems demonstrate SBPG's robustness in terms of stepsize selection and sensitivity to the initial point. Furthermore, we introduce a momentum-based variant, MSBPG, which enhances convergence by relaxing the mini-batch size requirement while preserving the optimal oracle complexity. We apply MSBPG to the training of deep neural networks, utilizing a polynomial kernel function to ensure smooth adaptivity of the loss function. Experimental results on benchmark datasets confirm the effectiveness and robustness of MSBPG in training neural networks. Given its negligible additional computational cost compared to SGD in large-scale optimization, MSBPG shows promise as a universal open-source optimizer for future applications."
      }
    },
    {
      "title": "Optimizing Data Collection for Machine Learning",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Optimizing Data Collection for Machine Learning"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0292.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0292.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0292/23-0292.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Rafid Mahmood, James Lucas, Jose M. Alvarez, Sanja Fidler, Marc T. Law"
        }
      ],
      "author": "Rafid Mahmood, James Lucas, Jose M. Alvarez, Sanja Fidler, Marc T. Law",
      "author_detail": {
        "name": "Rafid Mahmood, James Lucas, Jose M. Alvarez, Sanja Fidler, Marc T. Law"
      },
      "summary": "Modern deep learning systems require huge data sets to achieve impressive performance, but there is little guidance on how much or what kind of data to collect. Over-collecting data incurs unnecessary present costs, while under-collecting may incur future costs and delay workflows. We propose a new paradigm to model the data collection workflow as a formal optimal data collection problem that allows designers to specify performance targets, collection costs, a time horizon, and penalties for failing to meet the targets. This formulation generalizes to tasks with multiple data sources, such as labeled and unlabeled data used in semi-supervised learning, and can be easily modified to customized analyses such as how to introduce data from new classes to an existing model. To solve our problem, we develop Learn-Optimize-Collect (LOC), which minimizes expected future collection costs. Finally, we numerically compare our framework to the conventional baseline of estimating data requirements by extrapolating from neural scaling laws. We significantly reduce the risks of failing to meet desired performance targets on several classification, segmentation, and detection tasks, while maintaining low total collection costs.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Modern deep learning systems require huge data sets to achieve impressive performance, but there is little guidance on how much or what kind of data to collect. Over-collecting data incurs unnecessary present costs, while under-collecting may incur future costs and delay workflows. We propose a new paradigm to model the data collection workflow as a formal optimal data collection problem that allows designers to specify performance targets, collection costs, a time horizon, and penalties for failing to meet the targets. This formulation generalizes to tasks with multiple data sources, such as labeled and unlabeled data used in semi-supervised learning, and can be easily modified to customized analyses such as how to introduce data from new classes to an existing model. To solve our problem, we develop Learn-Optimize-Collect (LOC), which minimizes expected future collection costs. Finally, we numerically compare our framework to the conventional baseline of estimating data requirements by extrapolating from neural scaling laws. We significantly reduce the risks of failing to meet desired performance targets on several classification, segmentation, and detection tasks, while maintaining low total collection costs."
      }
    },
    {
      "title": "Unbalanced Kantorovich-Rubinstein distance, plan, and barycenter on nite spaces: A statistical perspective",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Unbalanced Kantorovich-Rubinstein distance, plan, and barycenter on nite spaces: A statistical perspective"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-1262.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-1262.html",
      "pdf": "http://jmlr.org/papers/volume26/22-1262/22-1262.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Shayan Hundrieser, Florian Heinemann, Marcel Klatt, Marina Struleva, Axel Munk"
        }
      ],
      "author": "Shayan Hundrieser, Florian Heinemann, Marcel Klatt, Marina Struleva, Axel Munk",
      "author_detail": {
        "name": "Shayan Hundrieser, Florian Heinemann, Marcel Klatt, Marina Struleva, Axel Munk"
      },
      "summary": "We analyze statistical properties of plug-in estimators for unbalanced optimal transport quantities between finitely supported measures in different prototypical sampling models. Specifically, our main results provide non-asymptotic bounds on the expected error of empirical Kantorovich-Rubinstein (KR) distance, plans, and barycenters for mass penalty parameter $C>0$. The impact of the mass penalty parameter $C$ is studied in detail. Based on this analysis, we mathematically justify randomized computational schemes for KR quantities which can be used for fast approximate computations in combination with any exact solver. Using synthetic and real datasets, we empirically analyze the behavior of the expected errors in simulation studies and illustrate the validity of our theoretical bounds.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We analyze statistical properties of plug-in estimators for unbalanced optimal transport quantities between finitely supported measures in different prototypical sampling models. Specifically, our main results provide non-asymptotic bounds on the expected error of empirical Kantorovich-Rubinstein (KR) distance, plans, and barycenters for mass penalty parameter $C>0$. The impact of the mass penalty parameter $C$ is studied in detail. Based on this analysis, we mathematically justify randomized computational schemes for KR quantities which can be used for fast approximate computations in combination with any exact solver. Using synthetic and real datasets, we empirically analyze the behavior of the expected errors in simulation studies and illustrate the validity of our theoretical bounds."
      }
    },
    {
      "title": "Copula-based Sensitivity Analysis for Multi-Treatment Causal Inference with Unobserved Confounding",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Copula-based Sensitivity Analysis for Multi-Treatment Causal Inference with Unobserved Confounding"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-0372.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-0372.html",
      "pdf": "http://jmlr.org/papers/volume26/22-0372/22-0372.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jiajing Zheng, Alexander D'Amour, Alexander Franks"
        }
      ],
      "author": "Jiajing Zheng, Alexander D'Amour, Alexander Franks",
      "author_detail": {
        "name": "Jiajing Zheng, Alexander D'Amour, Alexander Franks"
      },
      "summary": "Recent work has focused on the potential and pitfalls of causal identification in observational studies with multiple simultaneous treatments. Building on previous work, we show that even if the conditional distribution of unmeasured confounders given treatments were known exactly, the causal effects would not in general be identifiable, although they may be partially identified.  Given these results, we propose a sensitivity analysis method for characterizing the effects of potential unmeasured confounding, tailored to the multiple treatment setting, that can be used to characterize a range of causal effects that are compatible with the observed data. Our method is based on a copula factorization of the joint distribution of outcomes, treatments, and confounders, and can be layered on top of arbitrary observed data models. We propose a practical implementation of this approach making use of the Gaussian copula, and establish conditions under which causal effects can be bounded. We also describe approaches for reasoning about effects, including calibrating sensitivity parameters, quantifying robustness of effect estimates, and selecting models that are most consistent with prior hypotheses.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Recent work has focused on the potential and pitfalls of causal identification in observational studies with multiple simultaneous treatments. Building on previous work, we show that even if the conditional distribution of unmeasured confounders given treatments were known exactly, the causal effects would not in general be identifiable, although they may be partially identified.  Given these results, we propose a sensitivity analysis method for characterizing the effects of potential unmeasured confounding, tailored to the multiple treatment setting, that can be used to characterize a range of causal effects that are compatible with the observed data. Our method is based on a copula factorization of the joint distribution of outcomes, treatments, and confounders, and can be layered on top of arbitrary observed data models. We propose a practical implementation of this approach making use of the Gaussian copula, and establish conditions under which causal effects can be bounded. We also describe approaches for reasoning about effects, including calibrating sensitivity parameters, quantifying robustness of effect estimates, and selecting models that are most consistent with prior hypotheses."
      }
    },
    {
      "title": "Rank-one Convexification for Sparse Regression",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Rank-one Convexification for Sparse Regression"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/19-159.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/19-159.html",
      "pdf": "http://jmlr.org/papers/volume26/19-159/19-159.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Alper Atamturk, Andres Gomez"
        }
      ],
      "author": "Alper Atamturk, Andres Gomez",
      "author_detail": {
        "name": "Alper Atamturk, Andres Gomez"
      },
      "summary": "Sparse regression models are increasingly prevalent due to their ease of interpretability and superior out-of-sample performance. However, the exact model of sparse regression with an $\\ell_0$-constraint restricting the support of the estimators is a challenging (\\NP-hard) non-convex optimization problem. In this paper, we derive new strong convex relaxations for sparse regression. These relaxations are based on the convex-hull formulations for rank-one quadratic terms with indicator variables. The new relaxations can be formulated as semidefinite optimization problems in an extended space and are stronger and more general than the state-of-the-art formulations, including the perspective reformulation and formulations with the reverse Huber penalty and the minimax concave penalty functions. Furthermore, the proposed rank-one strengthening can be interpreted as a non-separable, non-convex, unbiased sparsity-inducing regularizer, which dynamically adjusts its penalty according to the shape of the error function without inducing bias for the sparse solutions. In our computational experiments with benchmark datasets, the proposed conic formulations are solved within seconds and result in near-optimal solutions (with 0.4\\% optimality gap on average) for non-convex $\\ell_0$-problems. Moreover, the resulting estimators also outperform alternative convex approaches, such as lasso and elastic net regression, from a statistical perspective, achieving high prediction accuracy and good interpretability.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Sparse regression models are increasingly prevalent due to their ease of interpretability and superior out-of-sample performance. However, the exact model of sparse regression with an $\\ell_0$-constraint restricting the support of the estimators is a challenging (\\NP-hard) non-convex optimization problem. In this paper, we derive new strong convex relaxations for sparse regression. These relaxations are based on the convex-hull formulations for rank-one quadratic terms with indicator variables. The new relaxations can be formulated as semidefinite optimization problems in an extended space and are stronger and more general than the state-of-the-art formulations, including the perspective reformulation and formulations with the reverse Huber penalty and the minimax concave penalty functions. Furthermore, the proposed rank-one strengthening can be interpreted as a non-separable, non-convex, unbiased sparsity-inducing regularizer, which dynamically adjusts its penalty according to the shape of the error function without inducing bias for the sparse solutions. In our computational experiments with benchmark datasets, the proposed conic formulations are solved within seconds and result in near-optimal solutions (with 0.4\\% optimality gap on average) for non-convex $\\ell_0$-problems. Moreover, the resulting estimators also outperform alternative convex approaches, such as lasso and elastic net regression, from a statistical perspective, achieving high prediction accuracy and good interpretability."
      }
    },
    {
      "title": "gsplat: An Open-Source Library for Gaussian Splatting",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "gsplat: An Open-Source Library for Gaussian Splatting"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1476.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1476.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1476/24-1476.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Vickie Ye, Ruilong Li, Justin Kerr, Matias Turkulainen, Brent Yi, Zhuoyang Pan, Otto Seiskari, Jianbo Ye, Jeffrey Hu, Matthew Tancik, Angjoo Kanazawa"
        }
      ],
      "author": "Vickie Ye, Ruilong Li, Justin Kerr, Matias Turkulainen, Brent Yi, Zhuoyang Pan, Otto Seiskari, Jianbo Ye, Jeffrey Hu, Matthew Tancik, Angjoo Kanazawa",
      "author_detail": {
        "name": "Vickie Ye, Ruilong Li, Justin Kerr, Matias Turkulainen, Brent Yi, Zhuoyang Pan, Otto Seiskari, Jianbo Ye, Jeffrey Hu, Matthew Tancik, Angjoo Kanazawa"
      },
      "summary": "gsplat is an open-source library designed for training and developing Gaussian Splatting methods. It features a front-end with Python bindings compatible with the PyTorch library and a back-end with highly optimized CUDA kernels. gsplat offers numerous features that enhance the optimization of Gaussian Splatting models, which include optimization improvements for speed, memory, and convergence times. Experimental results demonstrate that gsplat achieves up to 10% less training time and 4x less memory than the original implementation. Utilized in several research projects, gsplat is actively maintained on GitHub. Source code is available at https://github.com/nerfstudio-project/gsplat under Apache License 2.0. We welcome contributions from the open-source community.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "gsplat is an open-source library designed for training and developing Gaussian Splatting methods. It features a front-end with Python bindings compatible with the PyTorch library and a back-end with highly optimized CUDA kernels. gsplat offers numerous features that enhance the optimization of Gaussian Splatting models, which include optimization improvements for speed, memory, and convergence times. Experimental results demonstrate that gsplat achieves up to 10% less training time and 4x less memory than the original implementation. Utilized in several research projects, gsplat is actively maintained on GitHub. Source code is available at https://github.com/nerfstudio-project/gsplat under Apache License 2.0. We welcome contributions from the open-source community."
      }
    },
    {
      "title": "Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Statistical Inference of Constrained Stochastic Optimization via Sketched Sequential Quadratic Programming"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0530.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0530.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0530/24-0530.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Sen Na, Michael Mahoney"
        }
      ],
      "author": "Sen Na, Michael Mahoney",
      "author_detail": {
        "name": "Sen Na, Michael Mahoney"
      },
      "summary": "We consider online statistical inference of constrained stochastic nonlinear optimization problems. We apply the Stochastic Sequential Quadratic Programming (StoSQP) method to solve these problems, which can be regarded as applying second-order Newton's method to the Karush-Kuhn-Tucker (KKT) conditions. In each iteration, the StoSQP method computes the Newton direction by solving a quadratic program, and then selects a proper adaptive stepsize $\\bar{\\alpha}_t$ to update the primal-dual iterate. To reduce dominant computational cost of the method, we inexactly solve the quadratic program in each iteration by employing an iterative sketching solver. Notably, the approximation error of the sketching solver need not vanish as iterations proceed, meaning that the per-iteration computational cost does not blow up. For the above StoSQP method, we show that under mild assumptions, the rescaled primal-dual sequence $1/\\sqrt{\\bar{\\alpha}_t}\\cdot (x_t -x^\\star, \\lambda_t - \\lambda^\\star)$ converges to a mean-zero Gaussian distribution with a nontrivial covariance matrix depending on the underlying sketching distribution. To perform inference in practice, we also analyze a plug-in covariance matrix estimator. We illustrate the asymptotic normality result of the method both on benchmark nonlinear problems in CUTEst test set and on linearly/nonlinearly constrained regression problems.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We consider online statistical inference of constrained stochastic nonlinear optimization problems. We apply the Stochastic Sequential Quadratic Programming (StoSQP) method to solve these problems, which can be regarded as applying second-order Newton's method to the Karush-Kuhn-Tucker (KKT) conditions. In each iteration, the StoSQP method computes the Newton direction by solving a quadratic program, and then selects a proper adaptive stepsize $\\bar{\\alpha}_t$ to update the primal-dual iterate. To reduce dominant computational cost of the method, we inexactly solve the quadratic program in each iteration by employing an iterative sketching solver. Notably, the approximation error of the sketching solver need not vanish as iterations proceed, meaning that the per-iteration computational cost does not blow up. For the above StoSQP method, we show that under mild assumptions, the rescaled primal-dual sequence $1/\\sqrt{\\bar{\\alpha}_t}\\cdot (x_t -x^\\star, \\lambda_t - \\lambda^\\star)$ converges to a mean-zero Gaussian distribution with a nontrivial covariance matrix depending on the underlying sketching distribution. To perform inference in practice, we also analyze a plug-in covariance matrix estimator. We illustrate the asymptotic normality result of the method both on benchmark nonlinear problems in CUTEst test set and on linearly/nonlinearly constrained regression problems."
      }
    },
    {
      "title": "Sliced-Wasserstein Distances and Flows on Cartan-Hadamard Manifolds",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Sliced-Wasserstein Distances and Flows on Cartan-Hadamard Manifolds"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0359.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0359.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0359/24-0359.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Clément Bonet, Lucas Drumetz, Nicolas Courty"
        }
      ],
      "author": "Clément Bonet, Lucas Drumetz, Nicolas Courty",
      "author_detail": {
        "name": "Clément Bonet, Lucas Drumetz, Nicolas Courty"
      },
      "summary": "While many Machine Learning methods have been developed or transposed on Riemannian manifolds to tackle data with known non-Euclidean geometry, Optimal Transport (OT) methods on such spaces have not received much attention. The main OT tool on these spaces is the Wasserstein distance, which suffers from a heavy computational burden. On Euclidean spaces, a popular alternative is the Sliced-Wasserstein distance, which leverages a closed-form solution of the Wasserstein distance in one dimension, but which is not readily available on manifolds. In this work, we derive general constructions of Sliced-Wasserstein distances on Cartan-Hadamard manifolds, Riemannian manifolds with non-positive curvature, which include among others Hyperbolic spaces or the space of Symmetric Positive Definite matrices. Then, we propose different applications such as classification of documents with a suitably learned ground cost on a manifold, and data set comparison on a product manifold. Additionally, we derive non-parametric schemes to minimize these new distances by approximating their Wasserstein gradient flows.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "While many Machine Learning methods have been developed or transposed on Riemannian manifolds to tackle data with known non-Euclidean geometry, Optimal Transport (OT) methods on such spaces have not received much attention. The main OT tool on these spaces is the Wasserstein distance, which suffers from a heavy computational burden. On Euclidean spaces, a popular alternative is the Sliced-Wasserstein distance, which leverages a closed-form solution of the Wasserstein distance in one dimension, but which is not readily available on manifolds. In this work, we derive general constructions of Sliced-Wasserstein distances on Cartan-Hadamard manifolds, Riemannian manifolds with non-positive curvature, which include among others Hyperbolic spaces or the space of Symmetric Positive Definite matrices. Then, we propose different applications such as classification of documents with a suitably learned ground cost on a manifold, and data set comparison on a product manifold. Additionally, we derive non-parametric schemes to minimize these new distances by approximating their Wasserstein gradient flows."
      }
    },
    {
      "title": "Accelerating optimization over the space of probability measures",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Accelerating optimization over the space of probability measures"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1288.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1288.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1288/23-1288.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Shi Chen, Qin Li, Oliver Tse, Stephen J. Wright"
        }
      ],
      "author": "Shi Chen, Qin Li, Oliver Tse, Stephen J. Wright",
      "author_detail": {
        "name": "Shi Chen, Qin Li, Oliver Tse, Stephen J. Wright"
      },
      "summary": "The acceleration of gradient-based optimization methods is a subject of significant practical and theoretical importance, particularly within machine learning applications. While much attention has been directed towards optimizing within Euclidean space, the need to optimize over spaces of probability measures in machine learning motivates the exploration of accelerated gradient methods in this context, too. To this end, we introduce a Hamiltonian-flow approach analogous to momentum-based approaches in Euclidean space. We demonstrate that, in the continuous-time setting, algorithms based on this approach can achieve convergence rates of arbitrarily high order. We complement our findings with numerical examples.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The acceleration of gradient-based optimization methods is a subject of significant practical and theoretical importance, particularly within machine learning applications. While much attention has been directed towards optimizing within Euclidean space, the need to optimize over spaces of probability measures in machine learning motivates the exploration of accelerated gradient methods in this context, too. To this end, we introduce a Hamiltonian-flow approach analogous to momentum-based approaches in Euclidean space. We demonstrate that, in the continuous-time setting, algorithms based on this approach can achieve convergence rates of arbitrarily high order. We complement our findings with numerical examples."
      }
    },
    {
      "title": "Bayesian Multi-Group Gaussian Process Models for Heterogeneous Group-Structured Data",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bayesian Multi-Group Gaussian Process Models for Heterogeneous Group-Structured Data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0291.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0291.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0291/23-0291.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Didong Li, Andrew Jones, Sudipto Banerjee, Barbara E. Engelhardt"
        }
      ],
      "author": "Didong Li, Andrew Jones, Sudipto Banerjee, Barbara E. Engelhardt",
      "author_detail": {
        "name": "Didong Li, Andrew Jones, Sudipto Banerjee, Barbara E. Engelhardt"
      },
      "summary": "Gaussian processes are pervasive in functional data analysis, machine learning, and spatial statistics for modeling complex dependencies. Scientific data are often heterogeneous in their inputs and contain multiple known discrete groups of samples; thus, it is desirable to leverage the similarity among groups while accounting for heterogeneity across groups. We propose multi-group Gaussian processes (MGGPs) defined over $\\mathbb{R}^p\\times \\mathscr{C}$, where $\\mathscr{C}$ is a finite set representing the group label, by developing general classes of valid (positive definite) covariance functions on such domains. MGGPs are able to accurately recover relationships between the groups and efficiently share strength across samples from all groups during inference, while capturing distinct group-specific behaviors in the conditional posterior distributions. We demonstrate inference in MGGPs through simulation experiments, and we apply our proposed MGGP regression framework to gene expression data to illustrate the behavior and enhanced inferential capabilities of multi-group Gaussian processes by jointly modeling continuous and categorical variables.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Gaussian processes are pervasive in functional data analysis, machine learning, and spatial statistics for modeling complex dependencies. Scientific data are often heterogeneous in their inputs and contain multiple known discrete groups of samples; thus, it is desirable to leverage the similarity among groups while accounting for heterogeneity across groups. We propose multi-group Gaussian processes (MGGPs) defined over $\\mathbb{R}^p\\times \\mathscr{C}$, where $\\mathscr{C}$ is a finite set representing the group label, by developing general classes of valid (positive definite) covariance functions on such domains. MGGPs are able to accurately recover relationships between the groups and efficiently share strength across samples from all groups during inference, while capturing distinct group-specific behaviors in the conditional posterior distributions. We demonstrate inference in MGGPs through simulation experiments, and we apply our proposed MGGP regression framework to gene expression data to illustrate the behavior and enhanced inferential capabilities of multi-group Gaussian processes by jointly modeling continuous and categorical variables."
      }
    },
    {
      "title": "Orthogonal Bases for Equivariant Graph Learning with Provable k-WL Expressive Power",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Orthogonal Bases for Equivariant Graph Learning with Provable k-WL Expressive Power"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0178.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0178.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0178/23-0178.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jia He, Maggie Cheng"
        }
      ],
      "author": "Jia He, Maggie Cheng",
      "author_detail": {
        "name": "Jia He, Maggie Cheng"
      },
      "summary": "Graph neural network (GNN) models have been widely used for learning graph-structured data. Due to the permutation-invariant requirement of graph learning tasks, a basic element in graph neural networks is the invariant and equivariant linear layers. Previous work (Maron et al., 2019b) provided a maximal collection of invariant and equivariant linear layers and a simple deep neural network model, called k-IGN, for graph data defined on k-tuples of nodes. It is shown that the expressive power of k-IGN is at least as good as the  k-Weisfeiler-Leman (WL) algorithm in graph isomorphism tests. However, the dimension of the invariant layer and equivariant layer is the k-th and 2k-th bell numbers, respectively. Such high complexity makes it computationally infeasible for k-IGNs with k >= 3. In this paper, we show that a much smaller dimension for the linear layers is sufficient to achieve the same expressive power. We provide two sets of orthogonal bases for the linear layers, each with only 3(2^k-1)-k basis elements. Based on these linear layers, we develop neural network models GNN-a and GNN-b and show that for the graph data defined on k-tuples of data, GNN-a and GNN-b achieve the expressive power of the k-WL algorithm and the (k+1)-WL algorithm in graph isomorphism tests, respectively. In molecular prediction tasks on benchmark datasets, we demonstrate that low-order neural network models consisting of the proposed linear layers achieve better performance than other neural network models. In particular, order-2 GNN-b and order-3 GNN-a both have 3-WL expressive power, but use a much smaller basis and hence much less computation time than known neural network models.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Graph neural network (GNN) models have been widely used for learning graph-structured data. Due to the permutation-invariant requirement of graph learning tasks, a basic element in graph neural networks is the invariant and equivariant linear layers. Previous work (Maron et al., 2019b) provided a maximal collection of invariant and equivariant linear layers and a simple deep neural network model, called k-IGN, for graph data defined on k-tuples of nodes. It is shown that the expressive power of k-IGN is at least as good as the  k-Weisfeiler-Leman (WL) algorithm in graph isomorphism tests. However, the dimension of the invariant layer and equivariant layer is the k-th and 2k-th bell numbers, respectively. Such high complexity makes it computationally infeasible for k-IGNs with k >= 3. In this paper, we show that a much smaller dimension for the linear layers is sufficient to achieve the same expressive power. We provide two sets of orthogonal bases for the linear layers, each with only 3(2^k-1)-k basis elements. Based on these linear layers, we develop neural network models GNN-a and GNN-b and show that for the graph data defined on k-tuples of data, GNN-a and GNN-b achieve the expressive power of the k-WL algorithm and the (k+1)-WL algorithm in graph isomorphism tests, respectively. In molecular prediction tasks on benchmark datasets, we demonstrate that low-order neural network models consisting of the proposed linear layers achieve better performance than other neural network models. In particular, order-2 GNN-b and order-3 GNN-a both have 3-WL expressive power, but use a much smaller basis and hence much less computation time than known neural network models."
      }
    },
    {
      "title": "Optimal Experiment Design for Causal Effect Identification",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Optimal Experiment Design for Causal Effect Identification"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-1516.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-1516.html",
      "pdf": "http://jmlr.org/papers/volume26/22-1516/22-1516.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Sina Akbari, Jalal Etesami, Negar Kiyavash"
        }
      ],
      "author": "Sina Akbari, Jalal Etesami, Negar Kiyavash",
      "author_detail": {
        "name": "Sina Akbari, Jalal Etesami, Negar Kiyavash"
      },
      "summary": "Pearl’s do calculus is a complete axiomatic approach to learn the identifiable causal effects from observational data. When such an effect is not identifiable, it is necessary to perform a collection of often costly interventions in the system to learn the causal effect. In this work, we consider the problem of designing a collection of interventions with the minimum cost to identify the desired effect. First, we prove that this problem is NP-complete and subsequently propose an algorithm that can either find the optimal solution or a logarithmic-factor approximation of it. This is done by establishing a connection between our problem and the minimum hitting set problem. Additionally, we propose several polynomial time heuristic algorithms to tackle the computational complexity of the problem. Although these algorithms could potentially stumble on sub-optimal solutions, our simulations show that they achieve small regrets on random graphs.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Pearl’s do calculus is a complete axiomatic approach to learn the identifiable causal effects from observational data. When such an effect is not identifiable, it is necessary to perform a collection of often costly interventions in the system to learn the causal effect. In this work, we consider the problem of designing a collection of interventions with the minimum cost to identify the desired effect. First, we prove that this problem is NP-complete and subsequently propose an algorithm that can either find the optimal solution or a logarithmic-factor approximation of it. This is done by establishing a connection between our problem and the minimum hitting set problem. Additionally, we propose several polynomial time heuristic algorithms to tackle the computational complexity of the problem. Although these algorithms could potentially stumble on sub-optimal solutions, our simulations show that they achieve small regrets on random graphs."
      }
    },
    {
      "title": "Mean Aggregator is More Robust than Robust Aggregators under Label Poisoning Attacks on Distributed Heterogeneous Data",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Mean Aggregator is More Robust than Robust Aggregators under Label Poisoning Attacks on Distributed Heterogeneous Data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1307.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1307.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1307/24-1307.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jie Peng, Weiyu Li, Stefan Vlaski, Qing Ling"
        }
      ],
      "author": "Jie Peng, Weiyu Li, Stefan Vlaski, Qing Ling",
      "author_detail": {
        "name": "Jie Peng, Weiyu Li, Stefan Vlaski, Qing Ling"
      },
      "summary": "Robustness to malicious attacks is of paramount importance for distributed learning. Existing works usually consider the classical Byzantine attacks model, which assumes that some workers can send arbitrarily malicious messages to the server and disturb the aggregation steps of the distributed learning process. To defend against such worst-case Byzantine attacks, various robust aggregators have been proposed. They are proven to be effective and much superior to the often-used mean aggregator. In this paper, however, we demonstrate that the robust aggregators are too conservative for a class of weak but practical malicious attacks, known as label poisoning attacks, where the sample labels of some workers are poisoned. Surprisingly, we are able to show that the mean aggregator is more robust than the state-of-the-art robust aggregators in theory, given that the distributed data are sufficiently heterogeneous. In fact, the learning error of the mean aggregator is proven to be order-optimal in this case. Experimental results corroborate our theoretical findings, showing the superiority of the mean aggregator under label poisoning attacks.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Robustness to malicious attacks is of paramount importance for distributed learning. Existing works usually consider the classical Byzantine attacks model, which assumes that some workers can send arbitrarily malicious messages to the server and disturb the aggregation steps of the distributed learning process. To defend against such worst-case Byzantine attacks, various robust aggregators have been proposed. They are proven to be effective and much superior to the often-used mean aggregator. In this paper, however, we demonstrate that the robust aggregators are too conservative for a class of weak but practical malicious attacks, known as label poisoning attacks, where the sample labels of some workers are poisoned. Surprisingly, we are able to show that the mean aggregator is more robust than the state-of-the-art robust aggregators in theory, given that the distributed data are sufficiently heterogeneous. In fact, the learning error of the mean aggregator is proven to be order-optimal in this case. Experimental results corroborate our theoretical findings, showing the superiority of the mean aggregator under label poisoning attacks."
      }
    },
    {
      "title": "The Blessing of Heterogeneity in Federated Q-Learning: Linear Speedup and Beyond",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The Blessing of Heterogeneity in Federated Q-Learning: Linear Speedup and Beyond"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0579.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0579.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0579/24-0579.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jiin Woo, Gauri Joshi, Yuejie Chi"
        }
      ],
      "author": "Jiin Woo, Gauri Joshi, Yuejie Chi",
      "author_detail": {
        "name": "Jiin Woo, Gauri Joshi, Yuejie Chi"
      },
      "summary": "In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning, which exhibit a linear speedup with respect to the number of agents and near-optimal dependencies on other salient problem parameters. In the asynchronous setting, existing analyses of federated Q-learning, which adopt an equally weighted averaging of local Q-estimates, require that every agent covers the entire state-action space. In contrast, our improved sample complexity scales inverse proportionally to the minimum entry of the average stationary state-action occupancy distribution of all agents, thus only requiring the agents to collectively cover the entire state-action space, unveiling the blessing of heterogeneity. However, its sample complexity still suffers when the local trajectories are highly heterogeneous. In response, we propose a novel federated Q-learning algorithm with importance averaging, giving larger weights to more frequently visited state-action pairs, which achieves a robust linear speedup as if all trajectories are centrally processed, regardless of the heterogeneity of local behavior policies.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning, which exhibit a linear speedup with respect to the number of agents and near-optimal dependencies on other salient problem parameters. In the asynchronous setting, existing analyses of federated Q-learning, which adopt an equally weighted averaging of local Q-estimates, require that every agent covers the entire state-action space. In contrast, our improved sample complexity scales inverse proportionally to the minimum entry of the average stationary state-action occupancy distribution of all agents, thus only requiring the agents to collectively cover the entire state-action space, unveiling the blessing of heterogeneity. However, its sample complexity still suffers when the local trajectories are highly heterogeneous. In response, we propose a novel federated Q-learning algorithm with importance averaging, giving larger weights to more frequently visited state-action pairs, which achieves a robust linear speedup as if all trajectories are centrally processed, regardless of the heterogeneity of local behavior policies."
      }
    },
    {
      "title": "depyf: Open the Opaque Box of PyTorch Compiler for Machine Learning Researchers",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "depyf: Open the Opaque Box of PyTorch Compiler for Machine Learning Researchers"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0383.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0383.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0383/24-0383.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Kaichao You, Runsheng Bai, Meng Cao, Jianmin Wang, Ion Stoica, Mingsheng Long"
        }
      ],
      "author": "Kaichao You, Runsheng Bai, Meng Cao, Jianmin Wang, Ion Stoica, Mingsheng Long",
      "author_detail": {
        "name": "Kaichao You, Runsheng Bai, Meng Cao, Jianmin Wang, Ion Stoica, Mingsheng Long"
      },
      "summary": "PyTorch 2.x introduces a compiler designed to accelerate deep learning programs. However, for machine learning researchers, fully leveraging the PyTorch compiler can be challenging due to its operation at the Python bytecode level, making it appear as an opaque box. To address this, we introduce depyf, a tool designed to demystify the inner workings of the PyTorch compiler. depyf decompiles the bytecode generated by PyTorch back into equivalent source code and establishes connections between the code objects in the memory and their counterparts in source code format on the disk. This feature enables users to step through the source code line by line using debuggers, thus enhancing their understanding of the underlying processes. Notably, depyf is non-intrusive and user-friendly, primarily relying on two convenient context managers for its core functionality. The project is openly available at https://github.com/thuml/depyf and is recognized as a PyTorch ecosystem project at https://pytorch.org/blog/introducing-depyf.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "PyTorch 2.x introduces a compiler designed to accelerate deep learning programs. However, for machine learning researchers, fully leveraging the PyTorch compiler can be challenging due to its operation at the Python bytecode level, making it appear as an opaque box. To address this, we introduce depyf, a tool designed to demystify the inner workings of the PyTorch compiler. depyf decompiles the bytecode generated by PyTorch back into equivalent source code and establishes connections between the code objects in the memory and their counterparts in source code format on the disk. This feature enables users to step through the source code line by line using debuggers, thus enhancing their understanding of the underlying processes. Notably, depyf is non-intrusive and user-friendly, primarily relying on two convenient context managers for its core functionality. The project is openly available at https://github.com/thuml/depyf and is recognized as a PyTorch ecosystem project at https://pytorch.org/blog/introducing-depyf."
      }
    },
    {
      "title": "The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "The ODE Method for Stochastic Approximation and Reinforcement Learning with Markovian Noise"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0100.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0100.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0100/24-0100.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Shuze Daniel Liu, Shuhang Chen, Shangtong Zhang"
        }
      ],
      "author": "Shuze Daniel Liu, Shuhang Chen, Shangtong Zhang",
      "author_detail": {
        "name": "Shuze Daniel Liu, Shuhang Chen, Shangtong Zhang"
      },
      "summary": "Stochastic approximation is a class of algorithms that update a vector iteratively, incrementally, and stochastically, including, e.g., stochastic gradient descent and temporal difference learning. One fundamental challenge in analyzing a stochastic approximation algorithm is to establish its stability, i.e., to show that the stochastic vector iterates are bounded almost surely. In this paper, we extend the celebrated Borkar-Meyn theorem for stability from the Martingale difference noise setting to the Markovian noise setting, which greatly improves its applicability in reinforcement learning, especially in those off-policy reinforcement learning algorithms with linear function approximation and eligibility traces. Central to our analysis is the diminishing asymptotic rate of change of a few functions, which is implied by both a form of the strong law of large numbers and a form of the law of the iterated logarithm.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Stochastic approximation is a class of algorithms that update a vector iteratively, incrementally, and stochastically, including, e.g., stochastic gradient descent and temporal difference learning. One fundamental challenge in analyzing a stochastic approximation algorithm is to establish its stability, i.e., to show that the stochastic vector iterates are bounded almost surely. In this paper, we extend the celebrated Borkar-Meyn theorem for stability from the Martingale difference noise setting to the Markovian noise setting, which greatly improves its applicability in reinforcement learning, especially in those off-policy reinforcement learning algorithms with linear function approximation and eligibility traces. Central to our analysis is the diminishing asymptotic rate of change of a few functions, which is implied by both a form of the strong law of large numbers and a form of the law of the iterated logarithm."
      }
    },
    {
      "title": "Improving Graph Neural Networks on Multi-node Tasks with the Labeling Trick",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Improving Graph Neural Networks on Multi-node Tasks with the Labeling Trick"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0560.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0560.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0560/23-0560.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Xiyuan Wang, Pan Li, Muhan Zhang"
        }
      ],
      "author": "Xiyuan Wang, Pan Li, Muhan Zhang",
      "author_detail": {
        "name": "Xiyuan Wang, Pan Li, Muhan Zhang"
      },
      "summary": "In this paper, we study using graph neural networks (GNNs) for multi-node representation learning, where a representation for a set of more than one node (such as a link) is to be learned. Existing GNNs are mainly designed to learn single-node representations. When used for multi-node representation learning, a common practice is to directly aggregate the single-node representations obtained by a GNN. In this paper, we show a fundamental limitation of such an approach, namely the inability to capture the dependence among multiple nodes in the node set. A straightforward solution is to distinguish target nodes from others. Formalizing this idea, we propose \\text{labeling trick}, which first labels nodes in the graph according to their relationships with the target node set before applying a GNN and then aggregates node representations obtained in the labeled graph for multi-node representations. Besides node sets in graphs, we also extend labeling tricks to posets, subsets and hypergraphs. Experiments verify that the labeling trick technique can boost GNNs on various tasks, including undirected link prediction, directed link prediction, hyperedge prediction, and subgraph prediction. Our work explains the superior performance of previous node-labeling-based methods and establishes a theoretical foundation for using GNNs for multi-node representation learning.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this paper, we study using graph neural networks (GNNs) for multi-node representation learning, where a representation for a set of more than one node (such as a link) is to be learned. Existing GNNs are mainly designed to learn single-node representations. When used for multi-node representation learning, a common practice is to directly aggregate the single-node representations obtained by a GNN. In this paper, we show a fundamental limitation of such an approach, namely the inability to capture the dependence among multiple nodes in the node set. A straightforward solution is to distinguish target nodes from others. Formalizing this idea, we propose \\text{labeling trick}, which first labels nodes in the graph according to their relationships with the target node set before applying a GNN and then aggregates node representations obtained in the labeled graph for multi-node representations. Besides node sets in graphs, we also extend labeling tricks to posets, subsets and hypergraphs. Experiments verify that the labeling trick technique can boost GNNs on various tasks, including undirected link prediction, directed link prediction, hyperedge prediction, and subgraph prediction. Our work explains the superior performance of previous node-labeling-based methods and establishes a theoretical foundation for using GNNs for multi-node representation learning."
      }
    },
    {
      "title": "Directed Cyclic Graphs for Simultaneous Discovery of Time-Lagged and Instantaneous Causality from Longitudinal Data Using Instrumental Variables",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Directed Cyclic Graphs for Simultaneous Discovery of Time-Lagged and Instantaneous Causality from Longitudinal Data Using Instrumental Variables"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0272.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0272.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0272/23-0272.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Wei Jin, Yang Ni, Amanda B. Spence, Leah H. Rubin, Yanxun Xu"
        }
      ],
      "author": "Wei Jin, Yang Ni, Amanda B. Spence, Leah H. Rubin, Yanxun Xu",
      "author_detail": {
        "name": "Wei Jin, Yang Ni, Amanda B. Spence, Leah H. Rubin, Yanxun Xu"
      },
      "summary": "We consider the problem of causal discovery from longitudinal observational data. We develop a novel framework that simultaneously discovers the time-lagged causality and the possibly cyclic instantaneous causality. Under common causal discovery assumptions, combined with additional instrumental information typically available in longitudinal data, we prove the proposed model is generally identifiable. To the best of our knowledge, this is the first causal identification theory for directed graphs with general cyclic patterns that achieves unique causal identifiability. Structural learning is carried out in a fully Bayesian fashion. Through extensive simulations and an application to the Women's Interagency HIV Study, we demonstrate the identifiability, utility, and superiority of the proposed model against state-of-the-art alternative methods.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We consider the problem of causal discovery from longitudinal observational data. We develop a novel framework that simultaneously discovers the time-lagged causality and the possibly cyclic instantaneous causality. Under common causal discovery assumptions, combined with additional instrumental information typically available in longitudinal data, we prove the proposed model is generally identifiable. To the best of our knowledge, this is the first causal identification theory for directed graphs with general cyclic patterns that achieves unique causal identifiability. Structural learning is carried out in a fully Bayesian fashion. Through extensive simulations and an application to the Women's Interagency HIV Study, we demonstrate the identifiability, utility, and superiority of the proposed model against state-of-the-art alternative methods."
      }
    },
    {
      "title": "Bayesian Sparse Gaussian Mixture Model for Clustering in High Dimensions",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bayesian Sparse Gaussian Mixture Model for Clustering in High Dimensions"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0142.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0142.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0142/23-0142.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Dapeng Yao, Fangzheng Xie, Yanxun Xu"
        }
      ],
      "author": "Dapeng Yao, Fangzheng Xie, Yanxun Xu",
      "author_detail": {
        "name": "Dapeng Yao, Fangzheng Xie, Yanxun Xu"
      },
      "summary": "We study the sparse high-dimensional Gaussian mixture model when the number of clusters is allowed to grow with the sample size. A minimax lower bound for parameter estimation is established, and we show that a constrained maximum likelihood estimator achieves the minimax lower bound. However, this optimization-based estimator is computationally intractable because the objective function is highly nonconvex and the feasible set involves discrete structures. To address the computational challenge, we propose a computationally tractable Bayesian approach to estimate high-dimensional Gaussian mixtures whose cluster centers exhibit sparsity using a continuous spike-and-slab prior. We further prove that the posterior contraction rate of the proposed Bayesian method is minimax optimal. The mis- clustering rate is obtained as a by-product using tools from matrix perturbation theory. The proposed Bayesian sparse Gaussian mixture model does not require pre-specifying the number of clusters, which can be adaptively estimated. The validity and usefulness of the proposed method is demonstrated through simulation studies and the analysis of a real-world single-cell RNA sequencing data set.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We study the sparse high-dimensional Gaussian mixture model when the number of clusters is allowed to grow with the sample size. A minimax lower bound for parameter estimation is established, and we show that a constrained maximum likelihood estimator achieves the minimax lower bound. However, this optimization-based estimator is computationally intractable because the objective function is highly nonconvex and the feasible set involves discrete structures. To address the computational challenge, we propose a computationally tractable Bayesian approach to estimate high-dimensional Gaussian mixtures whose cluster centers exhibit sparsity using a continuous spike-and-slab prior. We further prove that the posterior contraction rate of the proposed Bayesian method is minimax optimal. The mis- clustering rate is obtained as a by-product using tools from matrix perturbation theory. The proposed Bayesian sparse Gaussian mixture model does not require pre-specifying the number of clusters, which can be adaptively estimated. The validity and usefulness of the proposed method is demonstrated through simulation studies and the analysis of a real-world single-cell RNA sequencing data set."
      }
    },
    {
      "title": "Regularizing Hard Examples Improves Adversarial Robustness",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Regularizing Hard Examples Improves Adversarial Robustness"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-1428.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-1428.html",
      "pdf": "http://jmlr.org/papers/volume26/22-1428/22-1428.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Hyungyu Lee, Saehyung Lee, Ho Bae, Sungroh Yoon"
        }
      ],
      "author": "Hyungyu Lee, Saehyung Lee, Ho Bae, Sungroh Yoon",
      "author_detail": {
        "name": "Hyungyu Lee, Saehyung Lee, Ho Bae, Sungroh Yoon"
      },
      "summary": "Recent studies have validated that pruning hard-to-learn examples from training improves the generalization performance of neural networks (NNs). In this study, we investigate this intriguing phenomenon---the negative effect of hard examples on generalization---in adversarial training. Particularly, we theoretically demonstrate that the increase in the difficulty of hard examples in adversarial training is significantly greater than the increase in the difficulty of easy examples. Furthermore, we verify that hard examples are only fitted through memorization of the label in adversarial training. We conduct both theoretical and empirical analyses of this memorization phenomenon, showing that pruning hard examples in adversarial training can enhance the model's robustness. However, the challenge remains in finding the optimal threshold for removing hard examples that degrade robustness performance. Based upon these observations, we propose a new approach, difficulty proportional label smoothing (DPLS), to adaptively mitigate the negative effect of hard examples, thereby improving the adversarial robustness of NNs. Notably, our experimental result indicates that our method can successfully leverage hard examples while circumventing the negative effect.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Recent studies have validated that pruning hard-to-learn examples from training improves the generalization performance of neural networks (NNs). In this study, we investigate this intriguing phenomenon---the negative effect of hard examples on generalization---in adversarial training. Particularly, we theoretically demonstrate that the increase in the difficulty of hard examples in adversarial training is significantly greater than the increase in the difficulty of easy examples. Furthermore, we verify that hard examples are only fitted through memorization of the label in adversarial training. We conduct both theoretical and empirical analyses of this memorization phenomenon, showing that pruning hard examples in adversarial training can enhance the model's robustness. However, the challenge remains in finding the optimal threshold for removing hard examples that degrade robustness performance. Based upon these observations, we propose a new approach, difficulty proportional label smoothing (DPLS), to adaptively mitigate the negative effect of hard examples, thereby improving the adversarial robustness of NNs. Notably, our experimental result indicates that our method can successfully leverage hard examples while circumventing the negative effect."
      }
    },
    {
      "title": "Random ReLU Neural Networks as Non-Gaussian Processes",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Random ReLU Neural Networks as Non-Gaussian Processes"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0737.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0737.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0737/24-0737.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Rahul Parhi, Pakshal Bohra, Ayoub El Biari, Mehrsa Pourya, Michael Unser"
        }
      ],
      "author": "Rahul Parhi, Pakshal Bohra, Ayoub El Biari, Mehrsa Pourya, Michael Unser",
      "author_detail": {
        "name": "Rahul Parhi, Pakshal Bohra, Ayoub El Biari, Mehrsa Pourya, Michael Unser"
      },
      "summary": "We consider a large class of shallow neural networks with randomly initialized parameters and rectified linear unit activation functions. We prove that these random neural networks are well-defined non-Gaussian processes. As a by-product, we demonstrate that these networks are solutions to stochastic differential equations driven by impulsive white noise (combinations of random Dirac measures). These processes are parameterized by the law of the weights and biases as well as the density of activation thresholds in each bounded region of the input domain. We prove that these processes are isotropic and wide-sense self-similar with Hurst exponent 3/2. We also derive a remarkably simple closed-form expression for their autocovariance function. Our results are fundamentally different from prior work in that we consider a non-asymptotic viewpoint: The number of neurons in each bounded region of the input domain (i.e., the width) is itself a random variable with a Poisson law with mean proportional to the density parameter. Finally, we show that, under suitable hypotheses, as the expected width tends to infinity, these processes can converge in law not only to Gaussian processes, but also to non-Gaussian processes depending on the law of the weights. Our asymptotic results provide a new take on several classical results (wide networks converge to Gaussian processes) as well as some new ones (wide networks can converge to non-Gaussian processes).",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We consider a large class of shallow neural networks with randomly initialized parameters and rectified linear unit activation functions. We prove that these random neural networks are well-defined non-Gaussian processes. As a by-product, we demonstrate that these networks are solutions to stochastic differential equations driven by impulsive white noise (combinations of random Dirac measures). These processes are parameterized by the law of the weights and biases as well as the density of activation thresholds in each bounded region of the input domain. We prove that these processes are isotropic and wide-sense self-similar with Hurst exponent 3/2. We also derive a remarkably simple closed-form expression for their autocovariance function. Our results are fundamentally different from prior work in that we consider a non-asymptotic viewpoint: The number of neurons in each bounded region of the input domain (i.e., the width) is itself a random variable with a Poisson law with mean proportional to the density parameter. Finally, we show that, under suitable hypotheses, as the expected width tends to infinity, these processes can converge in law not only to Gaussian processes, but also to non-Gaussian processes depending on the law of the weights. Our asymptotic results provide a new take on several classical results (wide networks converge to Gaussian processes) as well as some new ones (wide networks can converge to non-Gaussian processes)."
      }
    },
    {
      "title": "Riemannian Bilevel Optimization",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Riemannian Bilevel Optimization"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0397.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0397.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0397/24-0397.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jiaxiang Li, Shiqian Ma"
        }
      ],
      "author": "Jiaxiang Li, Shiqian Ma",
      "author_detail": {
        "name": "Jiaxiang Li, Shiqian Ma"
      },
      "summary": "In this work, we consider the bilevel optimization problem on Riemannian manifolds. We inspect the calculation of the hypergradient of such problems on general manifolds and thus enable the utilization of gradient-based algorithms to solve such problems. The calculation of the hypergradient requires utilizing the notion of Riemannian cross-derivative and we inspect the properties and the numerical calculations of Riemannian cross-derivatives. Algorithms in both deterministic and stochastic settings, named respectively RieBO and RieSBO, are proposed that include the existing Euclidean bilevel optimization algorithms as special cases. Numerical experiments on robust optimization on Riemannian manifolds are presented to show the applicability and efficiency of the proposed methods.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this work, we consider the bilevel optimization problem on Riemannian manifolds. We inspect the calculation of the hypergradient of such problems on general manifolds and thus enable the utilization of gradient-based algorithms to solve such problems. The calculation of the hypergradient requires utilizing the notion of Riemannian cross-derivative and we inspect the properties and the numerical calculations of Riemannian cross-derivatives. Algorithms in both deterministic and stochastic settings, named respectively RieBO and RieSBO, are proposed that include the existing Euclidean bilevel optimization algorithms as special cases. Numerical experiments on robust optimization on Riemannian manifolds are presented to show the applicability and efficiency of the proposed methods."
      }
    },
    {
      "title": "Supervised Learning with Evolving Tasks and Performance Guarantees",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Supervised Learning with Evolving Tasks and Performance Guarantees"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0343.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0343.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0343/24-0343.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Verónica Álvarez, Santiago Mazuelas, Jose A. Lozano"
        }
      ],
      "author": "Verónica Álvarez, Santiago Mazuelas, Jose A. Lozano",
      "author_detail": {
        "name": "Verónica Álvarez, Santiago Mazuelas, Jose A. Lozano"
      },
      "summary": "Multiple supervised learning scenarios are composed by a sequence of classification tasks. For instance, multi-task learning and continual learning aim to learn a sequence of tasks that is either fixed or grows over time. Existing techniques for learning tasks that are in a sequence are tailored to specific scenarios, lacking adaptability to others. In addition, most of existing techniques consider situations in which the order of the tasks in the sequence is not relevant. However, it is common that tasks in a sequence are evolving in the sense that consecutive tasks often have a higher similarity. This paper presents a learning methodology that is applicable to multiple supervised learning scenarios and adapts to evolving tasks. Differently from existing techniques, we provide computable tight performance guarantees and analytically characterize the increase in the effective sample size. Experiments on benchmark datasets show the performance improvement of the proposed methodology in multiple scenarios and the reliability of the presented performance guarantees.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Multiple supervised learning scenarios are composed by a sequence of classification tasks. For instance, multi-task learning and continual learning aim to learn a sequence of tasks that is either fixed or grows over time. Existing techniques for learning tasks that are in a sequence are tailored to specific scenarios, lacking adaptability to others. In addition, most of existing techniques consider situations in which the order of the tasks in the sequence is not relevant. However, it is common that tasks in a sequence are evolving in the sense that consecutive tasks often have a higher similarity. This paper presents a learning methodology that is applicable to multiple supervised learning scenarios and adapts to evolving tasks. Differently from existing techniques, we provide computable tight performance guarantees and analytically characterize the increase in the effective sample size. Experiments on benchmark datasets show the performance improvement of the proposed methodology in multiple scenarios and the reliability of the presented performance guarantees."
      }
    },
    {
      "title": "Error estimation and adaptive tuning for unregularized robust M-estimator",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Error estimation and adaptive tuning for unregularized robust M-estimator"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0060.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0060.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0060/24-0060.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Pierre C. Bellec, Takuya Koriyama"
        }
      ],
      "author": "Pierre C. Bellec, Takuya Koriyama",
      "author_detail": {
        "name": "Pierre C. Bellec, Takuya Koriyama"
      },
      "summary": "We consider unregularized robust M-estimators for linear models under Gaussian design and heavy-tailed noise, in the proportional asymptotics regime where the sample size n and the number of features p are both increasing such that $p/n \\to \\gamma\\in (0,1)$. An estimator of the out-of-sample error of a robust M-estimator is analyzed and proved to be consistent for a large family of loss functions that includes the Huber loss. As an application of this result, we propose an adaptive tuning procedure of the scale parameter $\\lambda>0$ of a given loss function $\\rho$: choosing $\\hat \\lambda$ in a given interval $I$ that minimizes the out-of-sample error estimate of the M-estimator constructed with loss $\\rho_\\lambda(\\cdot) = \\lambda^2 \\rho(\\cdot/\\lambda)$ leads to the optimal out-of-sample error over $I$. The proof relies on a smoothing argument: the unregularized M-estimation objective function is perturbed, or smoothed, with a Ridge penalty that vanishes as $n\\to+\\infty$, and shows that the unregularized M-estimator of interest inherits properties of its smoothed version.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We consider unregularized robust M-estimators for linear models under Gaussian design and heavy-tailed noise, in the proportional asymptotics regime where the sample size n and the number of features p are both increasing such that $p/n \\to \\gamma\\in (0,1)$. An estimator of the out-of-sample error of a robust M-estimator is analyzed and proved to be consistent for a large family of loss functions that includes the Huber loss. As an application of this result, we propose an adaptive tuning procedure of the scale parameter $\\lambda>0$ of a given loss function $\\rho$: choosing $\\hat \\lambda$ in a given interval $I$ that minimizes the out-of-sample error estimate of the M-estimator constructed with loss $\\rho_\\lambda(\\cdot) = \\lambda^2 \\rho(\\cdot/\\lambda)$ leads to the optimal out-of-sample error over $I$. The proof relies on a smoothing argument: the unregularized M-estimation objective function is perturbed, or smoothed, with a Ridge penalty that vanishes as $n\\to+\\infty$, and shows that the unregularized M-estimator of interest inherits properties of its smoothed version."
      }
    },
    {
      "title": "From Sparse to Dense Functional Data in High Dimensions: Revisiting Phase Transitions from a Non-Asymptotic Perspective",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "From Sparse to Dense Functional Data in High Dimensions: Revisiting Phase Transitions from a Non-Asymptotic Perspective"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1578.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1578.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1578/23-1578.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Shaojun Guo, Dong Li, Xinghao Qiao, Yizhu Wang"
        }
      ],
      "author": "Shaojun Guo, Dong Li, Xinghao Qiao, Yizhu Wang",
      "author_detail": {
        "name": "Shaojun Guo, Dong Li, Xinghao Qiao, Yizhu Wang"
      },
      "summary": "Nonparametric estimation of the mean and covariance functions is ubiquitous in functional data analysis and local linear smoothing techniques are most frequently used. Zhang and Wang (2016) explored different types of asymptotic properties of the estimation, which reveal interesting phase transition phenomena based on the relative order of the average sampling frequency per subject $T$ to the number of subjects $n$, partitioning the data into three categories: “sparse”, “semi-dense”, and “ultra-dense”. In an increasingly available high-dimensional scenario, where the number of functional variables $p$ is large in relation to $n$, we revisit this open problem from a non-asymptotic perspective by deriving comprehensive concentration inequalities for the local linear smoothers. Besides being of interest by themselves, our non-asymptotic results lead to elementwise maximum rates of $L_2$ convergence and uniform convergence serving as a fundamentally important tool for further convergence analysis when $p$ grows exponentially with $n$ and possibly $T$. With the presence of extra $\\log p$ terms to account for the high-dimensional effect, we then investigate the scaled phase transitions and the corresponding elementwise maximum rates from sparse to semi-dense to ultra-dense functional data in high dimensions. We also discuss a couple of applications of our theoretical results. Finally, numerical studies are carried out to confirm the established theoretical properties.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Nonparametric estimation of the mean and covariance functions is ubiquitous in functional data analysis and local linear smoothing techniques are most frequently used. Zhang and Wang (2016) explored different types of asymptotic properties of the estimation, which reveal interesting phase transition phenomena based on the relative order of the average sampling frequency per subject $T$ to the number of subjects $n$, partitioning the data into three categories: “sparse”, “semi-dense”, and “ultra-dense”. In an increasingly available high-dimensional scenario, where the number of functional variables $p$ is large in relation to $n$, we revisit this open problem from a non-asymptotic perspective by deriving comprehensive concentration inequalities for the local linear smoothers. Besides being of interest by themselves, our non-asymptotic results lead to elementwise maximum rates of $L_2$ convergence and uniform convergence serving as a fundamentally important tool for further convergence analysis when $p$ grows exponentially with $n$ and possibly $T$. With the presence of extra $\\log p$ terms to account for the high-dimensional effect, we then investigate the scaled phase transitions and the corresponding elementwise maximum rates from sparse to semi-dense to ultra-dense functional data in high dimensions. We also discuss a couple of applications of our theoretical results. Finally, numerical studies are carried out to confirm the established theoretical properties."
      }
    },
    {
      "title": "Locally Private Causal Inference for Randomized Experiments",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Locally Private Causal Inference for Randomized Experiments"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1401.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1401.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1401/23-1401.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Yuki Ohnishi, Jordan Awan"
        }
      ],
      "author": "Yuki Ohnishi, Jordan Awan",
      "author_detail": {
        "name": "Yuki Ohnishi, Jordan Awan"
      },
      "summary": "Local differential privacy is a differential privacy paradigm in which individuals first apply a privacy mechanism to their data (often by adding noise) before transmitting the result to a curator. The noise for privacy results in additional bias and variance in their analyses. Thus it is of great importance for analysts to incorporate the privacy noise into valid inference. In this article, we develop methodologies to infer causal effects from locally privatized data under randomized experiments. First, we present frequentist estimators under various privacy scenarios with their variance estimators and plug-in confidence intervals. We show a na\\\"ive debiased estimator results in inferior mean-squared error (MSE) compared to minimax lower bounds. In contrast, we show that using a customized privacy mechanism, we can match the lower bound, giving minimax optimal inference. We also develop a Bayesian nonparametric methodology along with a blocked Gibbs sampling algorithm, which can be applied to any of our proposed privacy mechanisms, and which performs especially well in terms of MSE for tight privacy budgets. Finally, we present simulation studies to evaluate the performance of our proposed frequentist and Bayesian methodologies for various privacy budgets, resulting in useful suggestions for performing causal inference for privatized data.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Local differential privacy is a differential privacy paradigm in which individuals first apply a privacy mechanism to their data (often by adding noise) before transmitting the result to a curator. The noise for privacy results in additional bias and variance in their analyses. Thus it is of great importance for analysts to incorporate the privacy noise into valid inference. In this article, we develop methodologies to infer causal effects from locally privatized data under randomized experiments. First, we present frequentist estimators under various privacy scenarios with their variance estimators and plug-in confidence intervals. We show a na\\\"ive debiased estimator results in inferior mean-squared error (MSE) compared to minimax lower bounds. In contrast, we show that using a customized privacy mechanism, we can match the lower bound, giving minimax optimal inference. We also develop a Bayesian nonparametric methodology along with a blocked Gibbs sampling algorithm, which can be applied to any of our proposed privacy mechanisms, and which performs especially well in terms of MSE for tight privacy budgets. Finally, we present simulation studies to evaluate the performance of our proposed frequentist and Bayesian methodologies for various privacy budgets, resulting in useful suggestions for performing causal inference for privatized data."
      }
    },
    {
      "title": "Estimating Network-Mediated Causal Effects via Principal Components Network Regression",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Estimating Network-Mediated Causal Effects via Principal Components Network Regression"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1317.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1317.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1317/23-1317.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Alex Hayes, Mark M. Fredrickson, Keith Levin"
        }
      ],
      "author": "Alex Hayes, Mark M. Fredrickson, Keith Levin",
      "author_detail": {
        "name": "Alex Hayes, Mark M. Fredrickson, Keith Levin"
      },
      "summary": "We develop a method to decompose causal effects on a social network into an indirect effect mediated by the network, and a direct effect independent of the social network. To handle the complexity of network structures, we assume that latent social groups act as causal mediators. We develop principal components network regression models to differentiate the social effect from the non-social effect. Fitting the regression models is as simple as principal components analysis followed by ordinary least squares estimation. We prove asymptotic theory for regression coefficients from this procedure and show that it is widely applicable, allowing for a variety of distributions on the regression errors and network edges. We carefully characterize the counterfactual assumptions necessary to use the regression models for causal inference, and show that current approaches to causal network regression may result in over-control bias. The method is very general, so that it is applicable to many types of structured data beyond social networks, such as text, areal data, psychometrics, images and omics.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We develop a method to decompose causal effects on a social network into an indirect effect mediated by the network, and a direct effect independent of the social network. To handle the complexity of network structures, we assume that latent social groups act as causal mediators. We develop principal components network regression models to differentiate the social effect from the non-social effect. Fitting the regression models is as simple as principal components analysis followed by ordinary least squares estimation. We prove asymptotic theory for regression coefficients from this procedure and show that it is widely applicable, allowing for a variety of distributions on the regression errors and network edges. We carefully characterize the counterfactual assumptions necessary to use the regression models for causal inference, and show that current approaches to causal network regression may result in over-control bias. The method is very general, so that it is applicable to many types of structured data beyond social networks, such as text, areal data, psychometrics, images and omics."
      }
    },
    {
      "title": "Selective Inference with Distributed Data",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Selective Inference with Distributed Data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-0309.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-0309.html",
      "pdf": "http://jmlr.org/papers/volume26/23-0309/23-0309.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Sifan Liu, Snigdha Panigrahi"
        }
      ],
      "author": "Sifan Liu, Snigdha Panigrahi",
      "author_detail": {
        "name": "Sifan Liu, Snigdha Panigrahi"
      },
      "summary": "When data are distributed across multiple sites or machines rather than centralized in one location, researchers face the challenge of extracting meaningful information without directly sharing individual data points. While there are many distributed methods for point estimation using sparse regression, few options are available for estimating uncertainties or conducting hypothesis tests based on the estimated sparsity. In this paper, we introduce a procedure for performing selective inference with distributed data. We consider a scenario where each local machine solves a lasso problem and communicates the selected predictors to a central machine. The central machine then aggregates these selected predictors to form a generalized linear model (GLM). Our goal is to provide valid inference for the selected GLM while reusing data that have been used in the model selection process. Our proposed procedure only requires low-dimensional summary statistics from local machines, thus keeping communication costs low and preserving the privacy of individual data sets. Furthermore, this procedure can be applied in scenarios where model selection is repeatedly conducted on randomly subsampled data sets, addressing the p-value lottery problem linked with model selection. We demonstrate the effectiveness of our approach through simulations and an analysis of a medical data set on ICU admissions.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "When data are distributed across multiple sites or machines rather than centralized in one location, researchers face the challenge of extracting meaningful information without directly sharing individual data points. While there are many distributed methods for point estimation using sparse regression, few options are available for estimating uncertainties or conducting hypothesis tests based on the estimated sparsity. In this paper, we introduce a procedure for performing selective inference with distributed data. We consider a scenario where each local machine solves a lasso problem and communicates the selected predictors to a central machine. The central machine then aggregates these selected predictors to form a generalized linear model (GLM). Our goal is to provide valid inference for the selected GLM while reusing data that have been used in the model selection process. Our proposed procedure only requires low-dimensional summary statistics from local machines, thus keeping communication costs low and preserving the privacy of individual data sets. Furthermore, this procedure can be applied in scenarios where model selection is repeatedly conducted on randomly subsampled data sets, addressing the p-value lottery problem linked with model selection. We demonstrate the effectiveness of our approach through simulations and an analysis of a medical data set on ICU admissions."
      }
    },
    {
      "title": "Two-Timescale Gradient Descent Ascent Algorithms for Nonconvex Minimax Optimization",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Two-Timescale Gradient Descent Ascent Algorithms for Nonconvex Minimax Optimization"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-0863.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-0863.html",
      "pdf": "http://jmlr.org/papers/volume26/22-0863/22-0863.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Tianyi Lin, Chi Jin, Michael I. Jordan"
        }
      ],
      "author": "Tianyi Lin, Chi Jin, Michael I. Jordan",
      "author_detail": {
        "name": "Tianyi Lin, Chi Jin, Michael I. Jordan"
      },
      "summary": "We provide a unified analysis of two-timescale gradient descent ascent (TTGDA) for solving structured nonconvex minimax optimization problems in the form of $\\min_x \\max_{y \\in Y} f(x, y)$, where the objective function $f(x, y)$ is nonconvex in $x$ and concave in $y$, and the constraint set $Y \\subseteq \\mathbb{R}^n$ is convex and bounded. In the convex-concave setting, the single-timescale gradient descent ascent (GDA) algorithm is widely used in applications and has been shown to have strong convergence guarantees. In more general settings, however, it can fail to converge. Our contribution is to design TTGDA algorithms that are effective beyond the convex-concave setting, efficiently finding a stationary point of the function $\\Phi(\\cdot) := \\max_{y \\in Y} f(\\cdot, y)$. We also establish theoretical bounds on the complexity of solving both smooth and nonsmooth nonconvex-concave minimax optimization problems. To the best of our knowledge, this is the first systematic analysis of TTGDA for nonconvex minimax optimization, shedding light on its superior performance in training generative adversarial networks (GANs) and in other real-world application problems.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "We provide a unified analysis of two-timescale gradient descent ascent (TTGDA) for solving structured nonconvex minimax optimization problems in the form of $\\min_x \\max_{y \\in Y} f(x, y)$, where the objective function $f(x, y)$ is nonconvex in $x$ and concave in $y$, and the constraint set $Y \\subseteq \\mathbb{R}^n$ is convex and bounded. In the convex-concave setting, the single-timescale gradient descent ascent (GDA) algorithm is widely used in applications and has been shown to have strong convergence guarantees. In more general settings, however, it can fail to converge. Our contribution is to design TTGDA algorithms that are effective beyond the convex-concave setting, efficiently finding a stationary point of the function $\\Phi(\\cdot) := \\max_{y \\in Y} f(\\cdot, y)$. We also establish theoretical bounds on the complexity of solving both smooth and nonsmooth nonconvex-concave minimax optimization problems. To the best of our knowledge, this is the first systematic analysis of TTGDA for nonconvex minimax optimization, shedding light on its superior performance in training generative adversarial networks (GANs) and in other real-world application problems."
      }
    },
    {
      "title": "An Axiomatic Definition of Hierarchical Clustering",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "An Axiomatic Definition of Hierarchical Clustering"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-1052.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-1052.html",
      "pdf": "http://jmlr.org/papers/volume26/24-1052/24-1052.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Ery Arias-Castro, Elizabeth Coda"
        }
      ],
      "author": "Ery Arias-Castro, Elizabeth Coda",
      "author_detail": {
        "name": "Ery Arias-Castro, Elizabeth Coda"
      },
      "summary": "In this paper, we take an axiomatic approach to defining a population hierarchical clustering for piecewise constant densities, and in a similar manner to Lebesgue integration, extend this definition to more general densities. When the density satisfies some mild conditions, e.g., when it has connected support, is continuous, and vanishes only at infinity, or when the connected components of the density satisfy these conditions, our axiomatic definition results in Hartigan's definition of cluster tree.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "In this paper, we take an axiomatic approach to defining a population hierarchical clustering for piecewise constant densities, and in a similar manner to Lebesgue integration, extend this definition to more general densities. When the density satisfies some mild conditions, e.g., when it has connected support, is continuous, and vanishes only at infinity, or when the connected components of the density satisfy these conditions, our axiomatic definition results in Hartigan's definition of cluster tree."
      }
    },
    {
      "title": "Test-Time Training on Video Streams",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Test-Time Training on Video Streams"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0439.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0439.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0439/24-0439.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Renhao Wang, Yu Sun, Arnuv Tandon, Yossi Gandelsman, Xinlei Chen, Alexei A. Efros, Xiaolong Wang"
        }
      ],
      "author": "Renhao Wang, Yu Sun, Arnuv Tandon, Yossi Gandelsman, Xinlei Chen, Alexei A. Efros, Xiaolong Wang",
      "author_detail": {
        "name": "Renhao Wang, Yu Sun, Arnuv Tandon, Yossi Gandelsman, Xinlei Chen, Alexei A. Efros, Xiaolong Wang"
      },
      "summary": "Prior work has established Test-Time Training (TTT) as a general framework to further improve a trained model at test time. Before making a prediction on each test instance, the model is first trained on the same instance using a self-supervised task such as reconstruction. We extend TTT to the streaming setting, where multiple test instances - video frames in our case - arrive in temporal order. Our extension is online TTT: The current model is initialized from the previous model, then trained on the current frame and a small window of frames immediately before. Online TTT significantly outperforms the fixed-model baseline for four tasks, on three real-world datasets. The improvements are more than 2.2x and 1.5x for instance and panoptic segmentation. Surprisingly, online TTT also outperforms its offline variant that accesses strictly more information, training on all frames from the entire test video regardless of temporal order. This finding challenges those in prior work using synthetic videos. We formalize a notion of locality as the advantage of online over offline TTT, and analyze its role with ablations and a theory based on bias-variance trade-off.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Prior work has established Test-Time Training (TTT) as a general framework to further improve a trained model at test time. Before making a prediction on each test instance, the model is first trained on the same instance using a self-supervised task such as reconstruction. We extend TTT to the streaming setting, where multiple test instances - video frames in our case - arrive in temporal order. Our extension is online TTT: The current model is initialized from the previous model, then trained on the current frame and a small window of frames immediately before. Online TTT significantly outperforms the fixed-model baseline for four tasks, on three real-world datasets. The improvements are more than 2.2x and 1.5x for instance and panoptic segmentation. Surprisingly, online TTT also outperforms its offline variant that accesses strictly more information, training on all frames from the entire test video regardless of temporal order. This finding challenges those in prior work using synthetic videos. We formalize a notion of locality as the advantage of online over offline TTT, and analyze its role with ablations and a theory based on bias-variance trade-off."
      }
    },
    {
      "title": "Adaptive Client Sampling in Federated Learning via Online Learning with Bandit Feedback",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Adaptive Client Sampling in Federated Learning via Online Learning with Bandit Feedback"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0385.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0385.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0385/24-0385.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Boxin Zhao, Lingxiao Wang, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Chaochao Chen, Mladen Kolar"
        }
      ],
      "author": "Boxin Zhao, Lingxiao Wang, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Chaochao Chen, Mladen Kolar",
      "author_detail": {
        "name": "Boxin Zhao, Lingxiao Wang, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Chaochao Chen, Mladen Kolar"
      },
      "summary": "Due to the high cost of communication, federated learning (FL) systems need to sample a subset of clients that are involved in each round of training. As a result, client sampling plays an important role in FL systems as it affects the convergence rate of optimization algorithms used to train machine learning models. Despite its importance, there is limited work on how to sample clients effectively. In this paper, we cast client sampling as an online learning task with bandit feedback, which we solve with an online stochastic mirror descent (OSMD) algorithm designed to minimize the sampling variance. We then theoretically show how our sampling method can improve the convergence speed of federated optimization algorithms over the widely used uniform sampling. Through both simulated and real data experiments, we empirically illustrate the advantages of the proposed client sampling algorithm over uniform sampling and existing online learning-based sampling strategies. The proposed adaptive sampling procedure is applicable beyond the FL problem studied here and can be used to improve the performance of stochastic optimization procedures such as stochastic gradient descent and stochastic coordinate descent.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Due to the high cost of communication, federated learning (FL) systems need to sample a subset of clients that are involved in each round of training. As a result, client sampling plays an important role in FL systems as it affects the convergence rate of optimization algorithms used to train machine learning models. Despite its importance, there is limited work on how to sample clients effectively. In this paper, we cast client sampling as an online learning task with bandit feedback, which we solve with an online stochastic mirror descent (OSMD) algorithm designed to minimize the sampling variance. We then theoretically show how our sampling method can improve the convergence speed of federated optimization algorithms over the widely used uniform sampling. Through both simulated and real data experiments, we empirically illustrate the advantages of the proposed client sampling algorithm over uniform sampling and existing online learning-based sampling strategies. The proposed adaptive sampling procedure is applicable beyond the FL problem studied here and can be used to improve the performance of stochastic optimization procedures such as stochastic gradient descent and stochastic coordinate descent."
      }
    },
    {
      "title": "A Random Matrix Approach to Low-Multilinear-Rank Tensor Approximation",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "A Random Matrix Approach to Low-Multilinear-Rank Tensor Approximation"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0193.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0193.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0193/24-0193.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Hugo Lebeau, Florent Chatelain, Romain Couillet"
        }
      ],
      "author": "Hugo Lebeau, Florent Chatelain, Romain Couillet",
      "author_detail": {
        "name": "Hugo Lebeau, Florent Chatelain, Romain Couillet"
      },
      "summary": "This work presents a comprehensive understanding of the estimation of a planted low-rank signal from a general spiked tensor model near the computational threshold. Relying on standard tools from the theory of large random matrices, we characterize the large-dimensional spectral behavior of the unfoldings of the data tensor and exhibit relevant signal-to-noise ratios governing the detectability of the principal directions of the signal. These results allow to accurately predict the reconstruction performance of truncated multilinear SVD (MLSVD) in the non-trivial regime. This is particularly important since it serves as an initialization of the higher-order orthogonal iteration (HOOI) scheme, whose convergence to the best low-multilinear-rank approximation depends entirely on its initialization. We give a sufficient condition for the convergence of HOOI and show that the number of iterations before convergence tends to $1$ in the large-dimensional limit.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "This work presents a comprehensive understanding of the estimation of a planted low-rank signal from a general spiked tensor model near the computational threshold. Relying on standard tools from the theory of large random matrices, we characterize the large-dimensional spectral behavior of the unfoldings of the data tensor and exhibit relevant signal-to-noise ratios governing the detectability of the principal directions of the signal. These results allow to accurately predict the reconstruction performance of truncated multilinear SVD (MLSVD) in the non-trivial regime. This is particularly important since it serves as an initialization of the higher-order orthogonal iteration (HOOI) scheme, whose convergence to the best low-multilinear-rank approximation depends entirely on its initialization. We give a sufficient condition for the convergence of HOOI and show that the number of iterations before convergence tends to $1$ in the large-dimensional limit."
      }
    },
    {
      "title": "Memory Gym: Towards Endless Tasks to Benchmark Memory Capabilities of Agents",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Memory Gym: Towards Endless Tasks to Benchmark Memory Capabilities of Agents"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/24-0043.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/24-0043.html",
      "pdf": "http://jmlr.org/papers/volume26/24-0043/24-0043.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Marco Pleines, Matthias Pallasch, Frank Zimmer, Mike Preuss"
        }
      ],
      "author": "Marco Pleines, Matthias Pallasch, Frank Zimmer, Mike Preuss",
      "author_detail": {
        "name": "Marco Pleines, Matthias Pallasch, Frank Zimmer, Mike Preuss"
      },
      "summary": "Memory Gym presents a suite of 2D partially observable environments, namely Mortar Mayhem, Mystery Path, and Searing Spotlights, designed to benchmark memory capabilities in decision-making agents. These environments, originally with finite tasks, are expanded into innovative, endless formats, mirroring the escalating challenges of cumulative memory games such as “I packed my bag”. This progression in task design shifts the focus from merely assessing sample efficiency to also probing the levels of memory effectiveness in dynamic, prolonged scenarios. To address the gap in available memory-based Deep Reinforcement Learning baselines, we introduce an implementation within the open-source CleanRL library that integrates Transformer-XL (TrXL) with Proximal Policy Optimization. This approach utilizes TrXL as a form of episodic memory, employing a sliding window technique. Our comparative study between the Gated Recurrent Unit (GRU) and TrXL reveals varied performances across our finite and endless tasks. TrXL, on the finite environments, demonstrates superior effectiveness over GRU, but only when utilizing an auxiliary loss to reconstruct observations. Notably, GRU makes a remarkable resurgence in all endless tasks, consistently outperforming TrXL by significant margins. Website and Source Code: https://marcometer.github.io/jmlr_2024.github.io/",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Memory Gym presents a suite of 2D partially observable environments, namely Mortar Mayhem, Mystery Path, and Searing Spotlights, designed to benchmark memory capabilities in decision-making agents. These environments, originally with finite tasks, are expanded into innovative, endless formats, mirroring the escalating challenges of cumulative memory games such as “I packed my bag”. This progression in task design shifts the focus from merely assessing sample efficiency to also probing the levels of memory effectiveness in dynamic, prolonged scenarios. To address the gap in available memory-based Deep Reinforcement Learning baselines, we introduce an implementation within the open-source CleanRL library that integrates Transformer-XL (TrXL) with Proximal Policy Optimization. This approach utilizes TrXL as a form of episodic memory, employing a sliding window technique. Our comparative study between the Gated Recurrent Unit (GRU) and TrXL reveals varied performances across our finite and endless tasks. TrXL, on the finite environments, demonstrates superior effectiveness over GRU, but only when utilizing an auxiliary loss to reconstruct observations. Notably, GRU makes a remarkable resurgence in all endless tasks, consistently outperforming TrXL by significant margins. Website and Source Code: https://marcometer.github.io/jmlr_2024.github.io/"
      }
    },
    {
      "title": "Enhancing Graph Representation Learning with Localized Topological Features",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Enhancing Graph Representation Learning with Localized Topological Features"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1424.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1424.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1424/23-1424.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Zuoyu Yan, Qi Zhao, Ze Ye, Tengfei Ma, Liangcai Gao, Zhi Tang, Yusu Wang, Chao Chen"
        }
      ],
      "author": "Zuoyu Yan, Qi Zhao, Ze Ye, Tengfei Ma, Liangcai Gao, Zhi Tang, Yusu Wang, Chao Chen",
      "author_detail": {
        "name": "Zuoyu Yan, Qi Zhao, Ze Ye, Tengfei Ma, Liangcai Gao, Zhi Tang, Yusu Wang, Chao Chen"
      },
      "summary": "Representation learning on graphs is a fundamental problem that can be crucial in various tasks. Graph neural networks, the dominant approach for graph representation learning, are limited in their representation power. Therefore, it can be beneficial to explicitly extract and incorporate high-order topological and geometric information into these models. In this paper, we propose a principled approach to extract the rich connectivity information of graphs based on the theory of persistent homology. Our method utilizes the topological features to enhance the representation learning of graph neural networks and achieve state-of-the-art performance on various node classification and link prediction benchmarks. We also explore the option of end-to-end learning of the topological features, i.e., treating topological computation as a differentiable operator during learning. Our theoretical analysis and empirical study provide insights and potential guidelines for employing topological features in graph learning tasks.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Representation learning on graphs is a fundamental problem that can be crucial in various tasks. Graph neural networks, the dominant approach for graph representation learning, are limited in their representation power. Therefore, it can be beneficial to explicitly extract and incorporate high-order topological and geometric information into these models. In this paper, we propose a principled approach to extract the rich connectivity information of graphs based on the theory of persistent homology. Our method utilizes the topological features to enhance the representation learning of graph neural networks and achieve state-of-the-art performance on various node classification and link prediction benchmarks. We also explore the option of end-to-end learning of the topological features, i.e., treating topological computation as a differentiable operator during learning. Our theoretical analysis and empirical study provide insights and potential guidelines for employing topological features in graph learning tasks."
      }
    },
    {
      "title": "Deep Out-of-Distribution Uncertainty Quantification via Weight Entropy Maximization",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Deep Out-of-Distribution Uncertainty Quantification via Weight Entropy Maximization"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1359.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1359.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1359/23-1359.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Antoine de Mathelin, François Deheeger, Mathilde Mougeot, Nicolas Vayatis"
        }
      ],
      "author": "Antoine de Mathelin, François Deheeger, Mathilde Mougeot, Nicolas Vayatis",
      "author_detail": {
        "name": "Antoine de Mathelin, François Deheeger, Mathilde Mougeot, Nicolas Vayatis"
      },
      "summary": "This paper deals with uncertainty quantification and out-of-distribution detection in deep learning using Bayesian and ensemble methods. It proposes a practical solution to the lack of prediction diversity observed recently for standard approaches when used out-of-distribution (Ovadia et al., 2019; Liu et al., 2021). Considering that this issue is mainly related to a lack of weight diversity, we claim that standard methods sample in \"over-restricted\" regions of the weight space due to the use of \"over-regularization\" processes, such as weight decay and zero-mean centered Gaussian priors. We propose to solve the problem by adopting the maximum entropy principle for the weight distribution, with the underlying idea to maximize the weight diversity. Under this paradigm, the epistemic uncertainty is described by the weight distribution of maximal entropy that produces neural networks \"consistent\" with the training observations. Considering stochastic neural networks, a practical optimization is derived to build such a distribution, defined as a trade-off between the average empirical risk and the weight distribution entropy. We provide both theoretical and numerical results to assess the efficiency of the approach. In particular, the proposed algorithm appears in the top three best methods in all configurations of an extensive out-of-distribution detection benchmark including more than thirty competitors.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "This paper deals with uncertainty quantification and out-of-distribution detection in deep learning using Bayesian and ensemble methods. It proposes a practical solution to the lack of prediction diversity observed recently for standard approaches when used out-of-distribution (Ovadia et al., 2019; Liu et al., 2021). Considering that this issue is mainly related to a lack of weight diversity, we claim that standard methods sample in \"over-restricted\" regions of the weight space due to the use of \"over-regularization\" processes, such as weight decay and zero-mean centered Gaussian priors. We propose to solve the problem by adopting the maximum entropy principle for the weight distribution, with the underlying idea to maximize the weight diversity. Under this paradigm, the epistemic uncertainty is described by the weight distribution of maximal entropy that produces neural networks \"consistent\" with the training observations. Considering stochastic neural networks, a practical optimization is derived to build such a distribution, defined as a trade-off between the average empirical risk and the weight distribution entropy. We provide both theoretical and numerical results to assess the efficiency of the approach. In particular, the proposed algorithm appears in the top three best methods in all configurations of an extensive out-of-distribution detection benchmark including more than thirty competitors."
      }
    },
    {
      "title": "DisC2o-HD: Distributed causal inference with covariates shift for analyzing real-world high-dimensional data",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "DisC2o-HD: Distributed causal inference with covariates shift for analyzing real-world high-dimensional data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-1254.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-1254.html",
      "pdf": "http://jmlr.org/papers/volume26/23-1254/23-1254.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Jiayi Tong, Jie Hu, George Hripcsak, Yang Ning, Yong Chen"
        }
      ],
      "author": "Jiayi Tong, Jie Hu, George Hripcsak, Yang Ning, Yong Chen",
      "author_detail": {
        "name": "Jiayi Tong, Jie Hu, George Hripcsak, Yang Ning, Yong Chen"
      },
      "summary": "High-dimensional healthcare data, such as electronic health records (EHR) data and claims data, present two primary challenges due to the large number of variables and the need to consolidate data from multiple clinical sites. The third key challenge is the potential existence of heterogeneity in terms of covariate shift. In this paper, we propose a distributed learning algorithm accounting for covariate shift to estimate the average treatment effect (ATE) for high-dimensional data, named DisC2o-HD. Leveraging the surrogate likelihood method, our method calibrates the estimates of the propensity score and outcome models to approximately attain the desired covariate balancing property, while accounting for the covariate shift across multiple clinical sites. We show that our distributed covariate balancing propensity score estimator can approximate the pooled estimator, which is obtained by pooling the data from multiple sites together. The proposed estimator remains consistent if either the propensity score model or the outcome regression model is correctly specified. The semiparametric efficiency bound is achieved when both the propensity score and the outcome models are correctly specified. We conduct simulation studies to demonstrate the performance of the proposed algorithm; additionally, we conduct an empirical study to present the readiness of implementation and validity.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "High-dimensional healthcare data, such as electronic health records (EHR) data and claims data, present two primary challenges due to the large number of variables and the need to consolidate data from multiple clinical sites. The third key challenge is the potential existence of heterogeneity in terms of covariate shift. In this paper, we propose a distributed learning algorithm accounting for covariate shift to estimate the average treatment effect (ATE) for high-dimensional data, named DisC2o-HD. Leveraging the surrogate likelihood method, our method calibrates the estimates of the propensity score and outcome models to approximately attain the desired covariate balancing property, while accounting for the covariate shift across multiple clinical sites. We show that our distributed covariate balancing propensity score estimator can approximate the pooled estimator, which is obtained by pooling the data from multiple sites together. The proposed estimator remains consistent if either the propensity score model or the outcome regression model is correctly specified. The semiparametric efficiency bound is achieved when both the propensity score and the outcome models are correctly specified. We conduct simulation studies to demonstrate the performance of the proposed algorithm; additionally, we conduct an empirical study to present the readiness of implementation and validity."
      }
    },
    {
      "title": "Bayes Meets Bernstein at the Meta Level: an Analysis of Fast Rates in Meta-Learning with PAC-Bayes",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bayes Meets Bernstein at the Meta Level: an Analysis of Fast Rates in Meta-Learning with PAC-Bayes"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/23-025.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/23-025.html",
      "pdf": "http://jmlr.org/papers/volume26/23-025/23-025.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Charles Riou, Pierre Alquier, Badr-Eddine Chérief-Abdellatif"
        }
      ],
      "author": "Charles Riou, Pierre Alquier, Badr-Eddine Chérief-Abdellatif",
      "author_detail": {
        "name": "Charles Riou, Pierre Alquier, Badr-Eddine Chérief-Abdellatif"
      },
      "summary": "Bernstein's condition is a key assumption that guarantees fast rates in machine learning. For example, under this condition, the Gibbs posterior with prior $\\pi$ has an excess risk in $O(d_{\\pi}/n)$, as opposed to $O(\\sqrt{d_{\\pi}/n})$ in the general case, where $n$ denotes the number of observations and $d_{\\pi}$ is a complexity parameter which depends on the prior $\\pi$. In this paper, we examine the Gibbs posterior in the context of meta-learning, i.e., when learning the prior $\\pi$ from $T$ previous tasks. Our main result is that Bernstein's condition always holds at the meta level, regardless of its validity at the observation level. This implies that the additional cost to learn the Gibbs prior $\\pi$, which will reduce the term $d_\\pi$ across tasks, is in $O(1/T)$, instead of the expected $O(1/\\sqrt{T})$. We further illustrate how this result improves on the standard rates in three different settings: discrete priors, Gaussian priors and mixture of Gaussian priors.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bernstein's condition is a key assumption that guarantees fast rates in machine learning. For example, under this condition, the Gibbs posterior with prior $\\pi$ has an excess risk in $O(d_{\\pi}/n)$, as opposed to $O(\\sqrt{d_{\\pi}/n})$ in the general case, where $n$ denotes the number of observations and $d_{\\pi}$ is a complexity parameter which depends on the prior $\\pi$. In this paper, we examine the Gibbs posterior in the context of meta-learning, i.e., when learning the prior $\\pi$ from $T$ previous tasks. Our main result is that Bernstein's condition always holds at the meta level, regardless of its validity at the observation level. This implies that the additional cost to learn the Gibbs prior $\\pi$, which will reduce the term $d_\\pi$ across tasks, is in $O(1/T)$, instead of the expected $O(1/\\sqrt{T})$. We further illustrate how this result improves on the standard rates in three different settings: discrete priors, Gaussian priors and mixture of Gaussian priors."
      }
    },
    {
      "title": "Efficiently Escaping Saddle Points in Bilevel Optimization",
      "title_detail": {
        "type": "text/plain",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Efficiently Escaping Saddle Points in Bilevel Optimization"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "http://jmlr.org/papers/v26/22-0136.html"
        }
      ],
      "link": "http://jmlr.org/papers/v26/22-0136.html",
      "pdf": "http://jmlr.org/papers/volume26/22-0136/22-0136.pdf",
      "published": "2025",
      "published_parsed": [
        2025,
        1,
        1,
        0,
        0,
        0,
        2,
        1,
        0
      ],
      "authors": [
        {
          "name": "Minhui Huang, Xuxing Chen, Kaiyi Ji, Shiqian Ma, Lifeng Lai"
        }
      ],
      "author": "Minhui Huang, Xuxing Chen, Kaiyi Ji, Shiqian Ma, Lifeng Lai",
      "author_detail": {
        "name": "Minhui Huang, Xuxing Chen, Kaiyi Ji, Shiqian Ma, Lifeng Lai"
      },
      "summary": "Bilevel optimization is one of the fundamental problems in machine learning and optimization. Recent theoretical developments in bilevel optimization focus on finding the first-order stationary points for nonconvex-strongly-convex cases. In this paper, we analyze algorithms that can escape saddle points in nonconvex-strongly-convex bilevel optimization. Specifically, we show that the perturbed approximate implicit differentiation (AID) with a warm start strategy finds an $\\epsilon$-approximate local minimum of bilevel optimization in $\\tilde{O}(\\epsilon^{-2})$ iterations with high probability. Moreover, we propose an inexact NEgative-curvature-Originated-from-Noise Algorithm (iNEON), an algorithm that can escape saddle point and find local minimum of stochastic bilevel optimization. As a by-product, we provide the first nonasymptotic analysis of perturbed multi-step gradient descent ascent (GDmax) algorithm that converges to local minimax point for minimax problems.",
      "summary_detail": {
        "type": "text/html",
        "language": null,
        "base": "http://www.jmlr.org/jmlr.xml",
        "value": "Bilevel optimization is one of the fundamental problems in machine learning and optimization. Recent theoretical developments in bilevel optimization focus on finding the first-order stationary points for nonconvex-strongly-convex cases. In this paper, we analyze algorithms that can escape saddle points in nonconvex-strongly-convex bilevel optimization. Specifically, we show that the perturbed approximate implicit differentiation (AID) with a warm start strategy finds an $\\epsilon$-approximate local minimum of bilevel optimization in $\\tilde{O}(\\epsilon^{-2})$ iterations with high probability. Moreover, we propose an inexact NEgative-curvature-Originated-from-Noise Algorithm (iNEON), an algorithm that can escape saddle point and find local minimum of stochastic bilevel optimization. As a by-product, we provide the first nonasymptotic analysis of perturbed multi-step gradient descent ascent (GDmax) algorithm that converges to local minimax point for minimax problems."
      }
    }
  ]
}