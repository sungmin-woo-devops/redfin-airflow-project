{
  "feed": {
    "language": "en",
    "title": "MIT News - Artificial intelligence",
    "title_detail": {
      "type": "text/plain",
      "language": "en",
      "base": "https://news.mit.edu",
      "value": "MIT News - Artificial intelligence"
    },
    "links": [
      {
        "rel": "alternate",
        "type": "text/html",
        "href": "https://news.mit.edu/rss/topic/artificial-intelligence2"
      },
      {
        "href": "https://news.mit.edu/rss/topic/artificial-intelligence2",
        "rel": "self",
        "type": "application/rss+xml"
      }
    ],
    "link": "https://news.mit.edu/rss/topic/artificial-intelligence2",
    "subtitle": "MIT news feed about: Artificial intelligence",
    "subtitle_detail": {
      "type": "text/html",
      "language": "en",
      "base": "https://news.mit.edu",
      "value": "MIT news feed about: Artificial intelligence"
    },
    "updated": "Tue, 26 Aug 2025 13:00:00 +0000",
    "updated_parsed": [
      2025,
      8,
      26,
      13,
      0,
      0,
      1,
      238,
      0
    ]
  },
  "entries": [
    {
      "title": "Simpler models can outperform deep learning at climate prediction",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Simpler models can outperform deep learning at climate prediction"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/simpler-models-can-outperform-deep-learning-climate-prediction-0826"
        }
      ],
      "link": "https://news.mit.edu/2025/simpler-models-can-outperform-deep-learning-climate-prediction-0826",
      "summary": "New research shows the natural variability in climate data can cause AI models to struggle at predicting local temperature and rainfall.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Simple climate prediction models can outperform deep-learning approaches when predicting future temperature changes, but deep learning has potential for estimating more complex variables like rainfall, according to an MIT study."
      },
      "published": "Tue, 26 Aug 2025 09:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        26,
        13,
        0,
        0,
        1,
        238,
        0
      ],
      "id": "https://news.mit.edu/2025/simpler-models-can-outperform-deep-learning-climate-prediction-0826",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Environmental scientists are increasingly using enormous artificial intelligence models to make predictions about changes in weather and climate, but a new study by MIT researchers shows that bigger models are not always better.</p><p>The team demonstrates that, in certain climate scenarios, much simpler, physics-based models can generate more accurate predictions than state-of-the-art deep-learning models.</p><p>Their analysis also reveals that a benchmarking technique commonly used to evaluate machine-learning techniques for climate predictions can be distorted by natural variations in the data, like fluctuations in weather patterns. This could lead someone to believe a deep-learning model makes more accurate predictions when that is not the case.</p><p>The researchers developed a more robust way of evaluating these techniques, which shows that, while simple models are more accurate when estimating regional surface temperatures, deep-learning approaches can be the best choice for estimating local rainfall.</p><p>They used these results to enhance a simulation tool known as a&nbsp;<a href=\"https://bc3.mit.edu/demos/en-roads/\" target=\"_blank\">climate emulator</a>, which can rapidly simulate the effect of human activities onto a future climate.</p><p>The researchers see their work as a “cautionary tale” about the risk of deploying large AI models for climate science. While deep-learning models have shown incredible success in domains such as natural language, climate science contains a proven set of physical laws and approximations, and the challenge becomes how to incorporate those into AI models.</p><p>“We are trying to develop models that are going to be useful and relevant for the kinds of things that decision-makers need going forward when making climate policy choices. While it might be attractive to use the latest, big-picture machine-learning model on a climate problem, what this study shows is that stepping back and really thinking about the problem fundamentals is important and useful,” says study senior author Noelle Selin, a professor in the MIT Institute for Data, Systems, and Society (IDSS) and the Department of Earth, Atmospheric and Planetary Sciences (EAPS), and director of the Center for Sustainability Science and Strategy.</p><p>Selin’s co-authors are lead author Björn Lütjens, a former EAPS postdoc who is now a research scientist at IBM Research; senior author Raffaele Ferrari, the Cecil and Ida Green Professor of Oceanography in EAPS and co-director of the Lorenz Center; and Duncan Watson-Parris, assistant professor at the University of California at San Diego. Selin and Ferrari are also co-principal investigators of the <a href=\"https://climategrandchallenges.mit.edu/flagship-projects/bringing-computation-to-the-climate-challenge/\" target=\"_blank\">Bringing Computation to the Climate Challenge</a> project, out of which this research emerged. The <a href=\"https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024MS004619\" target=\"_blank\">paper</a> appears today in the <em>Journal of Advances in Modeling Earth Systems</em>.</p><p><strong>Comparing emulators</strong></p><p>Because the Earth’s climate is so complex, running a state-of-the-art climate model to predict how pollution levels will impact environmental factors like temperature can take weeks on the world’s most powerful supercomputers.</p><p>Scientists often create climate emulators, simpler approximations of a state-of-the art climate model, which are faster and more accessible. A policymaker could use a climate emulator to see how alternative assumptions on greenhouse gas emissions would affect future temperatures, helping them develop regulations.</p><p>But an emulator isn’t very useful if it makes inaccurate predictions about the local impacts of climate change. While deep learning has become increasingly popular for emulation, few studies have explored whether these models perform better than tried-and-true approaches.</p><p>The MIT researchers performed such a study. They compared a traditional technique called linear pattern scaling (LPS) with a deep-learning model using a common benchmark dataset for evaluating climate emulators.</p><p>Their results showed that LPS outperformed deep-learning models on predicting nearly all parameters they tested, including temperature and precipitation.</p><p>“Large AI methods are very appealing to scientists, but they rarely solve a completely new problem, so implementing an existing solution first is necessary to find out whether the complex machine-learning approach actually improves upon it,” says Lütjens.</p><p>Some initial results seemed to fly in the face of the researchers’ domain knowledge. The powerful deep-learning model should have been more accurate when making predictions about precipitation, since those data don’t follow a linear pattern.</p><p>They found that the high amount of natural variability in climate model runs can cause the deep learning model to perform poorly on unpredictable long-term oscillations, like El Niño/La Niña. This skews the benchmarking scores in favor of LPS, which averages out those oscillations.</p><p><strong>Constructing a new evaluation</strong></p><p>From there, the researchers constructed a new evaluation with more data that address natural climate variability. With this new evaluation, the deep-learning model performed slightly better than LPS for local precipitation, but LPS was still more accurate for temperature predictions.</p><p>“It is important to use the modeling tool that is right for the problem, but in order to do that you also have to set up the problem the right way in the first place,” Selin says.</p><p>Based on these results, the researchers incorporated LPS into a climate emulation platform to predict local temperature changes in different emission scenarios.</p><p>“We are not advocating that LPS should always be the goal. It still has limitations. For instance, LPS doesn’t predict variability or extreme weather events,”&nbsp;Ferrari adds.</p><p>Rather, they hope their results emphasize the need to develop better benchmarking techniques, which could provide a fuller picture of which climate emulation technique is best suited for a particular situation.</p><p>“With an improved climate emulation benchmark, we could use more complex machine-learning methods to explore problems that are currently very hard to address, like the impacts of aerosols or estimations of extreme precipitation,” Lütjens says.</p><p>Ultimately, more accurate benchmarking techniques will help ensure policymakers are making decisions based on the best available information.</p><p>The researchers hope others build on their analysis, perhaps by studying additional improvements to climate emulation methods and benchmarks. Such research could explore impact-oriented metrics like drought indicators and wildfire risks, or new variables like regional wind speeds.</p><p>This research is funded, in part, by Schmidt Sciences, LLC, and is part of the MIT Climate Grand Challenges team for “Bringing Computation to the Climate Challenge.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/MIT-Climate-Emulators-01-press.jpg?itok=EtBcQ0D-",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: MIT News; iStock"
        }
      ],
      "credit": "Credit: MIT News; iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Climate change",
          "scheme": "https://news.mit.edu/topic/climate-change",
          "label": null
        },
        {
          "term": "Emissions",
          "scheme": "https://news.mit.edu/topic/emissions",
          "label": null
        },
        {
          "term": "Pollution",
          "scheme": "https://news.mit.edu/topic/pollution",
          "label": null
        },
        {
          "term": "Public health",
          "scheme": "https://news.mit.edu/topic/public-health",
          "label": null
        },
        {
          "term": "Sustainability",
          "scheme": "https://news.mit.edu/topic/sustainability",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Computer modeling",
          "scheme": "https://news.mit.edu/topic/computer-modeling",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Earth and atmospheric sciences",
          "scheme": "https://news.mit.edu/topic/earth-atmosphere",
          "label": null
        },
        {
          "term": "EAPS",
          "scheme": "https://news.mit.edu/topic/eaps",
          "label": null
        },
        {
          "term": "IDSS",
          "scheme": "https://news.mit.edu/topic/idss",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        }
      ]
    },
    {
      "title": "New technologies tackle brain health assessment for the military",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "New technologies tackle brain health assessment for the military"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/new-technologies-tackle-brain-health-assessment-for-military-0825"
        }
      ],
      "link": "https://news.mit.edu/2025/new-technologies-tackle-brain-health-assessment-for-military-0825",
      "summary": "Tools build on years of research at Lincoln Laboratory to develop a rapid brain health screening capability and may also be applicable to civilian settings such as sporting events and medical offices.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Lincoln Laboratory researchers are building rapid brain health screening capabilities for military service members."
      },
      "published": "Mon, 25 Aug 2025 17:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        25,
        21,
        0,
        0,
        0,
        237,
        0
      ],
      "id": "https://news.mit.edu/2025/new-technologies-tackle-brain-health-assessment-for-military-0825",
      "guidislink": false,
      "authors": [
        {
          "name": "Anne McGovern | MIT Lincoln Laboratory"
        }
      ],
      "author": "Anne McGovern | MIT Lincoln Laboratory",
      "author_detail": {
        "name": "Anne McGovern | MIT Lincoln Laboratory"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Cognitive readiness denotes a person's ability to respond and adapt to the changes around them. This includes functions like keeping balance after tripping, or making the right decision in a challenging situation based on knowledge and past experiences. For military service members, cognitive readiness is crucial for their health and safety, as well as mission success. Injury to the brain is a major contributor to cognitive impairment, and between 2000 and 2024,&nbsp;<a href=\"https://health.mil/Military-Health-Topics/Centers-of-Excellence/Traumatic-Brain-Injury-Center-of-Excellence/DOD-TBI-Worldwide-Numbers\">more than 500,000</a> military service members were diagnosed with traumatic brain injury (TBI) — caused by anything from a fall during training to blast exposure on the battlefield. While impairment from factors like sleep deprivation can be treated through rest and recovery, others caused by injury may require more intense and prolonged medical attention.</p><p>\"Current cognitive readiness tests administered to service members lack the sensitivity to detect subtle shifts in cognitive performance that may occur in individuals exposed to operational hazards,\" says Christopher Smalt, a researcher in the laboratory's <a href=\"https://www.ll.mit.edu/r-d/biotechnology-and-human-systems/human-health-and-performance-systems\">Human Health and Performance Systems Group.</a> \"Unfortunately, the cumulative effects of these exposures are often not well-documented during military service or after transition to Veterans Affairs, making it challenging to provide effective support.\"</p><p>Smalt is part of a team at the laboratory developing a suite of portable diagnostic tests that provide near-real-time screening for brain injury and cognitive health. One of these tools, called READY, is a smartphone or tablet app that helps identify a potential change in cognitive performance in less than 90 seconds. Another tool, called MINDSCAPE — which is being developed in collaboration with Richard Fletcher, a visiting scientist in the&nbsp;<a href=\"https://www.ll.mit.edu/r-d/engineering/rapid-prototyping\">Rapid Prototyping Group</a> who leads the&nbsp;<a href=\"https://mobilehealthlab.com/\">Mobile Technology Lab</a> at the&nbsp;<a href=\"https://autoid.mit.edu/\">MIT Auto-ID Laboratory</a>, and his students — uses virtual reality (VR) technology for a more in-depth analysis to pinpoint specific conditions such as TBI, post-traumatic stress disorder, or sleep deprivation. Using these tests, medical personnel on the battlefield can make quick and effective decisions for treatment triage.</p><p>Both READY and MINDSCAPE are a response to a series of Congressional legislation mandates, military program requirements, and mission-driven health needs to improve brain health screening capabilities for service members.</p><p><strong>Cognitive readiness biomarkers</strong></p><p>The READY and MINDSCAPE platforms incorporate more than a decade of laboratory research on finding the right indicators of cognitive readiness to build into rapid testing applications.&nbsp;<a href=\"https://www.ll.mit.edu/biographies/thomas-f-quatieri\">Thomas Quatieri</a> oversaw this work and identified balance, eye movement, and speech as three reliable biomarkers. He is leading the effort at Lincoln Laboratory to develop READY.</p><p>\"READY stands for Rapid Evaluation of Attention for DutY, and is built on the premise that attention is the key to being 'ready' for a mission,\" he says. \"In one view, we can think of attention as the mental state that allows you to focus on a task.\"</p><p>For someone to be attentive, their brain must continuously anticipate and process incoming sensory information and then instruct the body to respond appropriately. For example, if a friend yells \"catch\" and then throws a ball in your direction, in order to catch that ball, your brain must process the incoming auditory and visual data, predict in advance what may happen in the next few moments, and then direct your body to respond with an action that synchronizes those sensory data. The result? You realize from hearing the word \"catch\" and seeing the moving ball that your friend is throwing the ball to you, and you reach out a hand to catch it just in time.</p><p>\"An unhealthy or fatigued brain — caused by TBI or sleep deprivation, for example — may have challenges within a neurosensory feed-forward [prediction] or feedback [error] system, thus hampering the person's ability to attend,\" Quatieri says.</p><p>READY's three tests measure a person’s ability to track a moving dot with their eye, balance, and hold a vowel fixed at one pitch. The app then uses the data to calculate a variability or \"wobble\" indicator, which represents changes from the test taker's baseline or from expected results based on others with similar demographics, or the general population. The results are displayed to the user as an indication of the patient's level of attention.</p><p>If the READY screen shows an impairment, the administrator can then direct the subject to follow up with MINDSCAPE, which stands for Mobile Interface for Neurological Diagnostic Situational Cognitive Assessment and Psychological Evaluation. MINDSCAPE uses VR technology to administer additional, in-depth tests to measure cognitive functions such as reaction time and working memory. These standard neurocognitive tests are recorded with multimodal physiological sensors, such as electroencephalography (EEG), photoplethysmography, and pupillometry, to better pinpoint diagnosis.</p><p><strong>Holistic and adaptable</strong></p><p>A key advantage of READY and MINDSCAPE is their ability to leverage existing technologies, allowing for rapid deployment in the field. By utilizing sensors and capabilities already integrated into smartphones, tablets, and VR devices, these assessment tools can be easily adapted for use in operational settings at a significantly reduced cost.</p><p>\"We can immediately apply our advanced algorithms to the data collected from these devices, without the need for costly and time-consuming hardware development,\" Smalt says. \"By harnessing the capabilities of commercially available technologies, we can quickly provide valuable insights and improve upon traditional assessment methods.\"</p><p>Bringing new capabilities and AI for brain-health sensing into operational environments is a theme across several projects at the laboratory. Another example is&nbsp;<a href=\"https://www.ll.mit.edu/news/fifteen-lincoln-laboratory-technologies-receive-rd-100-awards\">EYEBOOM</a> (Electrooculography and Balance Blast Overpressure Monitoring System), a wearable technology developed for the U.S. Special Forces to monitor blast exposure. EYEBOOM continuously monitors a wearer's eye and body movements as they experience blast energy, and warns of potential harm. For this program, the laboratory developed an algorithm that could identify a potential change in physiology resulting from blast exposure during operations, rather than waiting for a check-in.</p><p>All three technologies are in development to be versatile, so they can be adapted for other relevant uses. For example, a workflow could pair EYEBOOM's monitoring capabilities with the READY and MINDSCAPE tests: EYEBOOM would continuously monitor for exposure risk and then prompt the wearer to seek additional assessment.</p><p>\"A lot of times, research focuses on one specific modality, whereas what we do at the laboratory is search for a holistic solution that can be applied for many different purposes,\" Smalt says.</p><p>MINDSCAPE is undergoing testing at the&nbsp;<a href=\"https://walterreed.tricare.mil/\">Walter Reed National Military Center</a> this year. READY will be tested with the&nbsp;U.S. Army Research Institute of Environmental Medicine (USARIEM) in 2026 in the context of sleep deprivation. Smalt and Quatieri also see the technologies finding use in civilian settings — on sporting event sidelines, in doctors' offices, or wherever else there is a need to assess brain readiness.</p><p>MINDSCAPE is being developed with clinical validation and support from Stefanie Kuchinsky at the Walter Reed National Military Medical Center. Quatieri and his team are developing the READY tests in collaboration with Jun Maruta and Jam Ghajar from the&nbsp;<a href=\"https://braintrauma.org/\">Brain Trauma Foundation</a> (BTF), and Kristin Heaton from USARIEM. The tests are supported by concurrent evidence-based guidelines lead by the BTF and the&nbsp;<a href=\"https://mtbi2.usuhs.edu/\">Military TBI Initiative</a> at Uniform Services University.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/mit-lincoln-Brain-Health-Military.jpg?itok=gtPYkumz",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: Tammy Ko/Lincoln Laboratory"
        }
      ],
      "credit": "Image: Tammy Ko/Lincoln Laboratory",
      "tags": [
        {
          "term": "Brain and cognitive sciences",
          "scheme": "https://news.mit.edu/topic/brain-cognitive",
          "label": null
        },
        {
          "term": "Neuroscience",
          "scheme": "https://news.mit.edu/topic/neuroscience",
          "label": null
        },
        {
          "term": "Diagnostic devices",
          "scheme": "https://news.mit.edu/topic/diagnostic-devices",
          "label": null
        },
        {
          "term": "Biomedical sensors",
          "scheme": "https://news.mit.edu/topic/biomedical-sensors",
          "label": null
        },
        {
          "term": "Augmented and virtual reality",
          "scheme": "https://news.mit.edu/topic/augmented-and-virtual-reality",
          "label": null
        },
        {
          "term": "Health",
          "scheme": "https://news.mit.edu/topic/health2",
          "label": null
        },
        {
          "term": "Security studies and military",
          "scheme": "https://news.mit.edu/topic/security-studies",
          "label": null
        },
        {
          "term": "Mobile applications",
          "scheme": "https://news.mit.edu/topic/mobile-applications",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Collaboration",
          "scheme": "https://news.mit.edu/topic/collaboration",
          "label": null
        },
        {
          "term": "Invention",
          "scheme": "https://news.mit.edu/topic/invention",
          "label": null
        },
        {
          "term": "Health care",
          "scheme": "https://news.mit.edu/topic/health-care",
          "label": null
        },
        {
          "term": "Sports and fitness",
          "scheme": "https://news.mit.edu/topic/sports",
          "label": null
        },
        {
          "term": "Lincoln Laboratory",
          "scheme": "https://news.mit.edu/topic/lincoln-laboratory-0",
          "label": null
        }
      ]
    },
    {
      "title": "Can large language models figure out the real world?",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Can large language models figure out the real world?"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/can-large-language-models-figure-out-real-world-0825"
        }
      ],
      "link": "https://news.mit.edu/2025/can-large-language-models-figure-out-real-world-0825",
      "summary": "New test could help determine if AI systems that make accurate predictions in one area can understand it well enough to apply that ability to a different area.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Researchers at MIT and Harvard University have devised a new approach to assessing how deeply predictive AI systems understand their subject matter, and whether they can apply knowledge from one domain to a slightly different one."
      },
      "published": "Mon, 25 Aug 2025 16:30:00 -0400",
      "published_parsed": [
        2025,
        8,
        25,
        20,
        30,
        0,
        0,
        237,
        0
      ],
      "id": "https://news.mit.edu/2025/can-large-language-models-figure-out-real-world-0825",
      "guidislink": false,
      "authors": [
        {
          "name": "David Chandler | Laboratory for Information and Decision Systems"
        }
      ],
      "author": "David Chandler | Laboratory for Information and Decision Systems",
      "author_detail": {
        "name": "David Chandler | Laboratory for Information and Decision Systems"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Back in the 17th century, German astronomer Johannes Kepler figured out the laws of motion that made it possible to accurately predict where our solar system’s planets would appear in the sky as they orbit the sun. But it wasn’t until decades later, when Isaac Newton formulated the universal laws of gravitation, that the underlying principles were understood. Although they were inspired by Kepler’s laws, they went much further, and made it possible to apply the same formulas to everything from the trajectory of a cannon ball to the way the moon’s pull controls the tides on Earth — or how to launch a satellite from Earth to the surface of the moon or planets.</p><p>Today’s sophisticated artificial intelligence systems have gotten very good at making the kind of specific predictions that resemble Kepler’s orbit predictions. But do they know why these predictions work, with the kind of deep understanding that comes from basic principles like Newton’s laws? As the world grows ever-more dependent on these kinds of AI systems, researchers are struggling to try to measure just how they do what they do, and how deep their understanding of the real world actually is.</p><p>Now, researchers in MIT’s Laboratory for Information and Decision Systems (LIDS) and at Harvard University have devised a new approach to assessing how deeply these predictive systems understand their subject matter, and whether they can apply knowledge from one domain to a slightly different one. And by and large the answer at this point, in the examples they studied, is — not so much.</p><p>The <a href=\"https://icml.cc/virtual/2025/poster/44374\">findings were presented</a> at the International Conference on Machine Learning, in Vancouver, British Columbia, last month by Harvard postdoc Keyon Vafa, MIT graduate student in electrical engineering and computer science and LIDS affiliate Peter G. Chang, MIT assistant professor and LIDS principal investigator Ashesh Rambachan, and MIT professor, LIDS principal investigator, and senior author Sendhil Mullainathan.</p><p>“Humans all the time have been able to make this transition from good predictions to world models,” says Vafa, the study’s lead author. So the question their team was addressing was, “have foundation models — has AI — been able to make that leap from predictions to world models? And we’re not asking are they capable, or can they, or will they. It’s just, have they done it so far?” he says.</p><p>“We know how to test whether an algorithm predicts well. But what we need is a way to test for whether it has understood well,” says Mullainathan, the Peter de Florez Professor with dual appointments in the MIT departments of Economics and Electrical Engineering and Computer Science and the senior author on the study. “Even defining what understanding means was a challenge.”&nbsp;</p><p>In the Kepler versus Newton analogy, Vafa says, “they both had models that worked really well on one task, and that worked essentially the same way on that task. What Newton offered was ideas that were able to generalize to new tasks.” That capability, when applied to the predictions made by various AI systems, would entail having it develop a world model so it can “transcend the task that you’re working on and be able to generalize to new kinds of problems and paradigms.”</p><p>Another analogy that helps to illustrate the point is the difference between centuries of accumulated knowledge of how to selectively breed crops and animals, versus Gregor Mendel’s insight into the underlying laws of genetic inheritance.</p><p>“There is a lot of excitement in the field about using foundation models to not just perform tasks, but to learn something about the world,” for example in the natural sciences, he says. “It would need to adapt, have a world model to adapt to any possible task.”</p><p>Are AI systems anywhere near the ability to reach such generalizations? To test the question, the team looked at different examples of predictive AI systems, at different levels of complexity. On the very simplest of examples, the systems succeeded in creating a realistic model of the simulated system, but as the examples got more complex that ability faded fast.</p><p>The team developed a new metric, a way of measuring quantitatively how well a system approximates real-world conditions. They call the measurement inductive bias — that is, a tendency or bias toward responses that reflect reality, based on inferences developed from looking at vast amounts of data on specific cases.</p><p>The simplest level of examples they looked at was known as a lattice model. In a one-dimensional lattice, something can move only along a line. Vafa compares it to a frog jumping between lily pads in a row. As the frog jumps or sits, it calls out what it’s doing — right, left, or stay. If it reaches the last lily pad in the row, it can only stay or go back. If someone, or an AI system, can just hear the calls, without knowing anything about the number of lily pads, can it figure out the configuration? The answer is yes: Predictive models do well at reconstructing the “world” in such a simple case. But even with lattices, as you increase the number of dimensions, the systems no longer can make that leap.</p><p>“For example, in a two-state or three-state lattice, we showed that the model does have a pretty good inductive bias toward the actual state,” says Chang. “But as we increase the number of states, then it starts to have a divergence from real-world models.”</p><p>A more complex problem is a system that can play the board game Othello, which involves players alternately placing black or white disks on a grid. The AI models can accurately predict what moves are allowable at a given point, but it turns out they do badly at inferring what the overall arrangement of pieces on the board is, including ones that are currently blocked from play.</p><p>The team then looked at five different categories of predictive models actually in use, and again, the more complex the systems involved, the more poorly the predictive modes performed at matching the true underlying world model.</p><p>With this new metric of inductive bias, “our hope is to provide a kind of test bed where you can evaluate different models, different training approaches, on problems where we know what the true world model is,” Vafa says. If it performs well on these cases where we already know the underlying reality, then we can have greater faith that its predictions may be useful even in cases “where we don’t really know what the truth is,” he says.</p><p>People are already trying to use these kinds of predictive AI systems to aid in scientific discovery, including such things as properties of chemical compounds that have never actually been created, or of potential pharmaceutical compounds, or for predicting the folding behavior and properties of unknown protein molecules. “For the more realistic problems,” Vafa says, “even for something like basic mechanics, we found that there seems to be a long way to go.”</p><p>Chang says, “There’s been a lot of hype around foundation models, where people are trying to build domain-specific foundation models — biology-based foundation models, physics-based foundation models, robotics foundation models, foundation models for other types of domains where people have been collecting a ton of data” and training these models to make predictions, “and then hoping that it acquires some knowledge of the domain itself, to be used for other downstream tasks.”</p><p>This work shows there’s a long way to go, but it also helps to show a path forward. “Our paper suggests that we can apply our metrics to evaluate how much the representation is learning, so that we can come up with better ways of training foundation models, or at least evaluate the models that we’re training currently,” Chang says. “As an engineering field, once we have a metric for something, people are really, really good at optimizing that metric.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/Foundation-models.jpg?itok=IXXXhTI8",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: iStock"
        }
      ],
      "credit": "Image: iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Economics",
          "scheme": "https://news.mit.edu/topic/economics",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "School of Humanities Arts and Social Sciences",
          "scheme": "https://news.mit.edu/topic/school-humanities-arts-and-social-sciences",
          "label": null
        }
      ]
    },
    {
      "title": "A new model predicts how molecules will dissolve in different solvents",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new model predicts how molecules will dissolve in different solvents"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/new-model-predicts-how-molecules-will-dissolve-in-different-solvents-0819"
        }
      ],
      "link": "https://news.mit.edu/2025/new-model-predicts-how-molecules-will-dissolve-in-different-solvents-0819",
      "summary": "Solubility predictions could make it easier to design and synthesize new drugs, while minimizing the use of more hazardous solvents.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT chemical engineers created a computational model that can predict how well a given molecule will dissolve in an organic solvent."
      },
      "published": "Tue, 19 Aug 2025 05:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        19,
        9,
        0,
        0,
        1,
        231,
        0
      ],
      "id": "https://news.mit.edu/2025/new-model-predicts-how-molecules-will-dissolve-in-different-solvents-0819",
      "guidislink": false,
      "authors": [
        {
          "name": "Anne Trafton | MIT News"
        }
      ],
      "author": "Anne Trafton | MIT News",
      "author_detail": {
        "name": "Anne Trafton | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Using machine learning, MIT chemical engineers have created a computational model that can predict how well any given molecule will dissolve in an organic solvent — a key step in the synthesis of nearly any pharmaceutical. This type of prediction could make it much easier to develop new ways to produce drugs and other useful molecules.</p><p>The new model, which predicts how much of a solute will dissolve in a particular solvent, should help chemists to choose the right solvent for any given reaction in their synthesis, the researchers say. Common organic solvents include ethanol and acetone, and there are hundreds of others that can also be used in chemical reactions.</p><p>“Predicting solubility really is a rate-limiting step in synthetic planning and manufacturing of chemicals, especially drugs, so there’s been a longstanding interest in being able to make better predictions of solubility,” says Lucas Attia, an MIT graduate student and one of the lead authors of the new study.</p><p>The researchers have made their&nbsp;<a href=\"https://askcos.mit.edu/solprop?tab=solpred\" target=\"_blank\">model</a> freely available, and many companies and labs have already started using it. The model could be particularly useful for identifying solvents that are less hazardous than some of the most commonly used industrial solvents, the researchers say.</p><p>“There are some solvents which are known to dissolve most things. They’re really useful, but they’re damaging to the environment, and they’re damaging to people, so many companies require that you have to minimize the amount of those solvents that you use,” says Jackson Burns, an MIT graduate student who is also a lead author of the paper. “Our model is extremely useful in being able to identify the next-best solvent, which is hopefully much less damaging to the environment.”</p><p>William Green, the Hoyt Hottel Professor of Chemical Engineering and director of the MIT Energy Initiative, is the senior author of the <a href=\"https://www.nature.com/articles/s41467-025-62717-7\" target=\"_blank\">study</a>, which appears today in <em>Nature Communications</em>. Patrick Doyle, the Robert T. Haslam Professor of Chemical Engineering, is also an author of the paper.</p><p><strong>Solving solubility</strong></p><p>The new model grew out of a project that Attia and Burns worked on together in an MIT course&nbsp;on applying machine learning to chemical engineering problems. Traditionally, chemists have predicted solubility with a tool known as the Abraham Solvation Model, which can be used to estimate a molecule’s overall solubility by adding up the contributions of chemical structures within the molecule. While these predictions are useful, their accuracy is limited.</p><p>In the past few years, researchers have begun using machine learning to try to make more accurate solubility predictions. Before Burns and Attia began working on their new model, the state-of-the-art model for predicting solubility was a model developed in Green’s lab in 2022.</p><p>That model, known as SolProp, works by predicting a set of related properties and combining them, using thermodynamics, to ultimately predict the solubility. However, the model has difficulty predicting solubility for solutes that it hasn’t seen before.</p><p>“For drug and chemical discovery pipelines where you’re developing a new molecule, you want to be able to predict ahead of time what its solubility looks like,” Attia says.</p><p>Part of the reason that existing solubility models haven’t worked well is because there wasn’t a comprehensive dataset to train them on. However, in 2023 a new dataset called BigSolDB was released, which compiled data from nearly 800 published papers, including information on solubility for about 800 molecules dissolved about more than 100 organic solvents that are commonly used in synthetic chemistry.</p><p>Attia and Burns decided to try training two different types of models on this data. Both of these models represent the chemical structures of molecules using numerical representations known as embeddings, which incorporate information such as the number of atoms in a molecule and which atoms are bound to which other atoms. Models can then use these representations to predict a variety of chemical properties.</p><p>One of the models used in this study, known as FastProp and developed by Burns and others in Green’s lab, incorporates “static embeddings.” This means that the model already knows the embedding for each molecule before it starts doing any kind of analysis.</p><p>The other model, ChemProp, learns an embedding for each molecule during the training, at the same time that it learns to associate the features of the embedding with a trait such as solubility. This model, developed across multiple MIT labs, has already been used for tasks such as antibiotic discovery, lipid nanoparticle design, and predicting chemical reaction rates.</p><p>The researchers trained both types of models on over 40,000 data points from BigSolDB, including information on the effects of temperature, which plays a significant role in solubility. Then, they tested the models on about 1,000 solutes that had been withheld from the training data. They found that the models’ predictions were two to three times more accurate than those of SolProp, the previous best model, and the new models were especially accurate at predicting variations in solubility due to temperature.</p><p>“Being able to accurately reproduce those small variations in solubility due to temperature, even when the overarching experimental noise is very large, was a really positive sign that the network had correctly learned an underlying solubility prediction function,” Burns says.</p><p><strong>Accurate predictions</strong></p><p>The researchers had expected that the model based on ChemProp, which is able to learn new representations as it goes along, would be able to make more accurate predictions. However, to their surprise, they found that the two models performed essentially the same. That suggests that the main limitation on their performance is the quality of the data, and that the models are performing as well as theoretically possible based on the data that they’re using, the researchers say.</p><p>“ChemProp should always outperform any static embedding when you have sufficient data,” Burns says. “We were blown away to see that the static and learned embeddings were statistically indistinguishable in performance across all the different subsets, which indicates to us that that the data limitations that are present in this space dominated the model performance.”</p><p>The models could become more accurate, the researchers say, if better training and testing data were available — ideally, data obtained by one person or a group of people all trained to perform the experiments the same way.</p><p>“One of the big limitations of using these kinds of compiled datasets is that different labs use different methods and experimental conditions when they perform solubility tests. That contributes to this variability between different datasets,” Attia says.</p><p>Because the model based on FastProp makes its predictions faster and has code that is easier for other users to adapt, the researchers decided to make that one, known as FastSolv, available to the public. Multiple pharmaceutical companies have already begun using it.</p><p>“There are applications throughout the drug discovery pipeline,” Burns says.&nbsp;“We’re also excited to see, outside of formulation and drug discovery, where people may use this model.”</p><p>The research was funded, in part, by the U.S. Department of Energy.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/MIT-Predict-Solubility-01-press.jpg?itok=NlJyl9z7",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: Courtesy of the researchers; MIT News"
        }
      ],
      "credit": "Image: Courtesy of the researchers; MIT News",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Chemical engineering",
          "scheme": "https://news.mit.edu/topic/chemical-engineering",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Drug development",
          "scheme": "https://news.mit.edu/topic/drug-development",
          "label": null
        },
        {
          "term": "Pharmaceuticals",
          "scheme": "https://news.mit.edu/topic/pharmaceuticals",
          "label": null
        },
        {
          "term": "Chemistry",
          "scheme": "https://news.mit.edu/topic/chemistry-0",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Cleaner industry",
          "scheme": "https://news.mit.edu/topic/cleaner-industry",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        }
      ]
    },
    {
      "title": "Researchers glimpse the inner workings of protein language models",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Researchers glimpse the inner workings of protein language models"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/researchers-glimpse-inner-workings-protein-language-models-0818"
        }
      ],
      "link": "https://news.mit.edu/2025/researchers-glimpse-inner-workings-protein-language-models-0818",
      "summary": "A new approach can reveal the features AI models use to predict proteins that might make good drug or vaccine targets.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Understanding what is happening inside the “black box” of large protein models could help researchers to choose better models for a particular task, helping to streamline the process of identifying new drugs or vaccine targets."
      },
      "published": "Mon, 18 Aug 2025 15:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        18,
        19,
        0,
        0,
        0,
        230,
        0
      ],
      "id": "https://news.mit.edu/2025/researchers-glimpse-inner-workings-protein-language-models-0818",
      "guidislink": false,
      "authors": [
        {
          "name": "Anne Trafton | MIT News"
        }
      ],
      "author": "Anne Trafton | MIT News",
      "author_detail": {
        "name": "Anne Trafton | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Within the past few years, models that can predict the structure or function of proteins have been widely used for a variety of biological applications, such as identifying drug targets and designing new therapeutic antibodies.</p><p>These models, which are based on large language models (LLMs), can make very accurate predictions of a protein’s suitability for a given application. However, there’s no way to determine how these models make their predictions or which protein features play the most important role in those decisions.</p><p>In a new study, MIT researchers have used a novel technique to open up that “black box” and allow them to determine what features a protein language model takes into account when making predictions. Understanding what is happening inside that black box&nbsp;could help researchers to choose better models for a particular task, helping to streamline the process of identifying new drugs or vaccine targets.</p><p>“Our work has broad implications for enhanced explainability in downstream tasks that rely on these representations,” says Bonnie Berger, the Simons Professor of Mathematics, head of the Computation and Biology group in MIT’s Computer Science and Artificial Intelligence Laboratory, and the senior author of the study. “Additionally, identifying features that protein language models track has the potential to reveal novel biological insights from these representations.”</p><p>Onkar Gujral, an MIT graduate student, is the lead author of the open-access <a href=\"https://www.pnas.org/doi/10.1073/pnas.2506316122\" target=\"_blank\">study</a>, which appears this week in the <em>Proceedings of the National Academy of Sciences.</em> Mihir Bafna, an MIT graduate student in electrical engineering and computer science, and Eric Alm, an MIT professor of biological engineering, are also authors of the paper.</p><p><strong>Opening the black box</strong></p><p>In 2018, Berger and former MIT graduate student Tristan Bepler PhD ’20 <a href=\"https://openreview.net/revisions?id=SygLehCqtm\" target=\"_blank\">introduced</a> the first protein language model. Their model, like subsequent protein models that accelerated the development of&nbsp;AlphaFold, such as&nbsp;ESM2 and OmegaFold, was based on LLMs. These models, which include ChatGPT, can analyze huge amounts of text and figure out which words are most likely to appear together.</p><p>Protein language models use a similar approach, but instead of analyzing words, they analyze amino acid sequences. Researchers have used these models to predict the structure and function of proteins, and for applications such as identifying proteins that might bind to particular drugs.</p><p>In a&nbsp;<a href=\"https://news.mit.edu/2021/model-viruses-escape-immune-0114\" target=\"_blank\">2021 study</a>, Berger and colleagues used a protein language model to predict which sections of viral surface proteins are less likely to mutate in a way that enables viral escape. This allowed them to identify possible targets for vaccines against influenza, HIV, and SARS-CoV-2.</p><p>However, in all of these studies, it has been impossible to know how the models were making their predictions.</p><p>“We would get out some prediction at the end, but we had absolutely no idea what was happening in the individual components of this black box,” Berger says.</p><p>In the new study, the researchers wanted to dig into how protein language models make their predictions. Just like LLMs, protein language models encode information as representations that consist of a pattern of activation of different “nodes” within a neural network. These nodes are analogous to the networks of neurons that store memories and other information within the brain.</p><p>The inner workings of LLMs are not easy to interpret, but within the past couple of years, researchers have begun using a type of algorithm known as a sparse autoencoder to help shed some light on how those models make their predictions. The new study from Berger’s lab is the first to use this algorithm on protein language models.</p><p>Sparse autoencoders work by adjusting how a protein is represented within a neural network. Typically, a given protein will be represented by a pattern of activation of a constrained number of neurons, for example, 480. A sparse autoencoder will expand that representation into a much larger number of nodes, say 20,000.</p><p>When information about a protein is encoded by only 480 neurons, each node lights up for multiple features, making it very difficult to know what features each node is encoding. However, when the neural network is expanded to 20,000 nodes, this extra space along with a sparsity constraint gives the information room to “spread out.” Now, a feature of the protein that was previously encoded by multiple nodes can occupy a single node.</p><p>“In a sparse representation, the neurons lighting up are doing so in a more meaningful manner,” Gujral says. “Before the sparse representations are created, the networks pack information so tightly together that it's hard to interpret the neurons.”</p><p><strong>Interpretable models</strong></p><p>Once the researchers obtained sparse representations of many proteins, they used an AI assistant called Claude (related to the popular Anthropic chatbot of the same name), to analyze the representations. In this case, they asked Claude to compare the sparse representations with the known features of each protein, such as molecular function, protein family, or location within a cell.</p><p>By analyzing thousands of representations, Claude can determine which nodes correspond to specific protein features, then describe them in plain English. For example, the algorithm might say, “This neuron appears to be detecting proteins involved in transmembrane transport of ions or amino acids, particularly those located in the plasma membrane.”</p><p>This process makes the nodes far more “interpretable,” meaning the researchers can tell what each node is encoding. They found that the features most likely to be encoded by these nodes were protein family and certain functions, including several different metabolic and biosynthetic processes.</p><p>“When you train a sparse autoencoder, you aren’t training it to be interpretable, but it turns out that by incentivizing the representation to be really sparse, that ends up resulting in interpretability,” Gujral says.</p><p>Understanding what features a particular protein model is encoding could help researchers choose the right model for a particular task, or tweak the type of input they give the model, to generate the best results. Additionally, analyzing the features that a model encodes could one day help biologists to learn more about the proteins that they are studying.</p><p>“At some point when the models get a lot more powerful, you could learn more biology than you already know, from opening up the models,” Gujral says.</p><p>The research was funded by the National Institutes of Health.&nbsp;</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/MIT-model-interpret-01-press.jpg?itok=nA-s3rBF",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: MIT News; iStock"
        }
      ],
      "credit": "Image: MIT News; iStock",
      "tags": [
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Proteins",
          "scheme": "https://news.mit.edu/topic/proteins",
          "label": null
        },
        {
          "term": "Drug discovery",
          "scheme": "https://news.mit.edu/topic/drug-discovery",
          "label": null
        },
        {
          "term": "Mathematics",
          "scheme": "https://news.mit.edu/topic/mathematics",
          "label": null
        },
        {
          "term": "Biological engineering",
          "scheme": "https://news.mit.edu/topic/biological-engineering",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "National Institutes of Health (NIH)",
          "scheme": "https://news.mit.edu/topic/nih",
          "label": null
        }
      ]
    },
    {
      "title": "How AI could speed the development of RNA vaccines and other RNA therapies",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "How AI could speed the development of RNA vaccines and other RNA therapies"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/how-ai-could-speed-development-rna-vaccines-and-other-rna-therapies-0815"
        }
      ],
      "link": "https://news.mit.edu/2025/how-ai-could-speed-development-rna-vaccines-and-other-rna-therapies-0815",
      "summary": "MIT engineers used a machine-learning model to design nanoparticles that can deliver RNA to cells more efficiently.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "“What we did was apply machine-learning tools to help accelerate the identification of optimal ingredient mixtures in lipid nanoparticles to help target a different cell type or help incorporate different materials, much faster than previously was possible,” says Giovanni Traverso."
      },
      "published": "Fri, 15 Aug 2025 05:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        15,
        9,
        0,
        0,
        4,
        227,
        0
      ],
      "id": "https://news.mit.edu/2025/how-ai-could-speed-development-rna-vaccines-and-other-rna-therapies-0815",
      "guidislink": false,
      "authors": [
        {
          "name": "Anne Trafton | MIT News"
        }
      ],
      "author": "Anne Trafton | MIT News",
      "author_detail": {
        "name": "Anne Trafton | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Using artificial intelligence, MIT researchers have come up with a new way to design nanoparticles that can more efficiently deliver RNA vaccines and other types of RNA therapies.</p><p>After training a machine-learning model to analyze thousands of existing delivery particles, the researchers used it to predict new materials that would work even better. The model also enabled the researchers to identify particles that would work well in different types of cells, and to discover ways to incorporate new types of materials into the particles.</p><p>“What we did was apply machine-learning tools to help accelerate the identification of optimal ingredient mixtures in lipid nanoparticles to help target a different cell type or help incorporate different materials, much faster than previously was possible,” says Giovanni Traverso,&nbsp;an associate professor of mechanical engineering at MIT, a gastroenterologist at Brigham and Women’s Hospital,&nbsp;and the senior author of the study.</p><p>This approach could dramatically speed the process of developing new RNA vaccines, as well as therapies that could be used to treat obesity, diabetes, and other metabolic disorders, the researchers say.</p><p>Alvin Chan, a former MIT postdoc who is now an assistant professor at Nanyang Technological University, and Ameya Kirtane, a former MIT postdoc who is now an assistant professor at the University of Minnesota, are the lead authors of the new open-access study, which <a href=\"https://www.nature.com/articles/s41565-025-01975-4\" target=\"_blank\">appears today</a> in <em>Nature Nanotechnology</em>.</p><p><strong>Particle predictions</strong></p><p>RNA vaccines, such as the vaccines for SARS-CoV-2, are usually packaged in lipid nanoparticles (LNPs) for delivery. These particles protect mRNA from being broken down in the body and help it to enter cells once injected.</p><p>Creating particles that handle these jobs more efficiently could help researchers to develop even more effective vaccines. Better delivery vehicles could also make it easier to develop mRNA therapies that encode genes for proteins that could help to treat a variety of diseases.</p><p>In 2024, Traverso’s lab launched a multiyear&nbsp;<a href=\"https://news.mit.edu/2024/mit-led-team-receives-funding-new-treatments-metabolic-disease-0205\" target=\"_blank\">research program</a>, funded by the U.S. Advanced Research Projects Agency for Health (ARPA-H), to develop new ingestible devices that could achieve oral delivery of RNA treatments and vaccines.</p><p>“Part of what we’re trying to do is develop ways of producing more protein, for example, for therapeutic applications. Maximizing the efficiency is important to be able to boost how much we can have the cells produce,” Traverso says.</p><p>A typical LNP consists of four components — a cholesterol, a helper lipid, an ionizable lipid, and a lipid that is attached to polyethylene glycol (PEG). Different variants of each of these components can be swapped in to create a huge number of possible combinations. Changing up these formulations and testing each one individually is very time-consuming, so Traverso, Chan, and their colleagues decided to turn to artificial intelligence to help speed up the process.</p><p>“Most AI models in drug discovery focus on optimizing a single compound at a time, but that approach doesn’t work for lipid nanoparticles, which are made of multiple interacting components,” Chan says. “To tackle this, we developed a new model called COMET, inspired by the same transformer architecture that powers large language models like ChatGPT. Just as those models understand how words combine to form meaning, COMET learns how different chemical components come together in a nanoparticle to influence its properties — like how well it can deliver RNA into cells.”</p><p>To generate training data for their machine-learning model, the researchers created a library of about 3,000 different LNP formulations. The team tested each of these 3,000 particles in the lab to see how efficiently they could deliver their payload to cells, then fed all of this data into a machine-learning model.</p><p>After the model was trained, the researchers asked it to predict new formulations that would work better than existing LNPs. They tested those predictions by using the new formulations to deliver mRNA encoding a fluorescent protein to mouse skin cells grown in a lab dish. They found that the LNPs predicted by the model did indeed work better than the particles in the training data, and in some cases better than LNP formulations that are used commercially.</p><p><strong>Accelerated development</strong></p><p>Once the researchers showed that the model could accurately predict particles that would efficiently deliver mRNA, they began asking additional questions. First, they wondered if they could train the model on nanoparticles that incorporate a fifth component: a type of polymer known as branched poly beta amino esters (PBAEs).</p><p>Research by Traverso and his colleagues has shown that these polymers can effectively deliver nucleic acids on their own, so they wanted to explore whether adding them to LNPs could improve LNP performance. The MIT team created a set of about 300 LNPs that also include these polymers, which they used to train the model. The resulting model could then predict additional formulations with PBAEs that would work better.</p><p>Next, the researchers set out to train the model to make predictions about LNPs that would work best in different types of cells, including a type of cell called Caco-2, which is derived from colorectal cancer cells. Again, the model was able to predict LNPs that would efficiently deliver mRNA to these cells.</p><p>Lastly, the researchers used the model to predict which LNPs could best withstand lyophilization — a freeze-drying process often used to extend the shelf-life of medicines.</p><p>“This is a tool that allows us to adapt it to a whole different set of questions and help accelerate development. We did a large training set that went into the model, but then you can do much more focused experiments and get outputs that are helpful on very different kinds of questions,” Traverso says.</p><p>He and his colleagues are now working on incorporating some of these particles into potential treatments for diabetes and obesity, which are two of the primary targets of the ARPA-H funded project. Therapeutics that could be delivered using this approach include GLP-1 mimics with similar effects to Ozempic.</p><p>This research was funded by the GO Nano Marble Center at the Koch Institute, the Karl van Tassel Career Development Professorship, the MIT Department of Mechanical Engineering, Brigham and Women’s Hospital, and ARPA-H.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/MIT-AI-Nanoparticles-01-press.jpg?itok=s93vqVvn",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: Courtesy of the researchers; MIT News"
        }
      ],
      "credit": "Image: Courtesy of the researchers; MIT News",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "RNA",
          "scheme": "https://news.mit.edu/topic/rna",
          "label": null
        },
        {
          "term": "Vaccines",
          "scheme": "https://news.mit.edu/topic/vaccines",
          "label": null
        },
        {
          "term": "Mechanical engineering",
          "scheme": "https://news.mit.edu/topic/mechanical-engineering",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Drug delivery",
          "scheme": "https://news.mit.edu/topic/drug-delivery",
          "label": null
        },
        {
          "term": "Drug discovery",
          "scheme": "https://news.mit.edu/topic/drug-discovery",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        }
      ]
    },
    {
      "title": "Using generative AI, researchers design compounds that can kill drug-resistant bacteria",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Using generative AI, researchers design compounds that can kill drug-resistant bacteria"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/using-generative-ai-researchers-design-compounds-kill-drug-resistant-bacteria-0814"
        }
      ],
      "link": "https://news.mit.edu/2025/using-generative-ai-researchers-design-compounds-kill-drug-resistant-bacteria-0814",
      "summary": "The team used two different AI approaches to design novel antibiotics, including one that showed promise against MRSA.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "With help from artificial intelligence, MIT researchers have discovered novel antibiotics that can combat two hard-to-treat infections: a drug-resistant form of gonorrhea and multi-drug-resistant Staphylococcus aureus (MRSA)."
      },
      "published": "Thu, 14 Aug 2025 11:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        14,
        15,
        0,
        0,
        3,
        226,
        0
      ],
      "id": "https://news.mit.edu/2025/using-generative-ai-researchers-design-compounds-kill-drug-resistant-bacteria-0814",
      "guidislink": false,
      "authors": [
        {
          "name": "Anne Trafton | MIT News"
        }
      ],
      "author": "Anne Trafton | MIT News",
      "author_detail": {
        "name": "Anne Trafton | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>With help from artificial intelligence, MIT researchers have designed novel antibiotics that can combat two hard-to-treat infections: drug-resistant <em>Neisseria gonorrhoeae</em> and multi-drug-resistant <em>Staphylococcus aureus&nbsp;</em>(MRSA).</p><p>Using generative AI algorithms, the research team designed more than 36 million possible compounds and computationally screened them for antimicrobial properties. The top candidates they discovered are structurally distinct from any existing antibiotics, and they appear to work by novel mechanisms that disrupt bacterial cell membranes.</p><p>This approach allowed the researchers to generate and evaluate theoretical compounds that have never been seen before — a strategy that they now hope to apply to identify and design compounds with activity against other species of bacteria.</p><p>“We’re excited about the new possibilities that this project opens up for antibiotics development. Our work shows the power of AI from a drug design standpoint, and enables us to exploit much larger chemical spaces that were previously inaccessible,” says James Collins,&nbsp;the Termeer Professor of Medical Engineering and Science in MIT’s Institute for Medical Engineering and Science (IMES) and Department of Biological Engineering, and a member of the Broad Institute.</p><p>Collins is the senior author of the study, which <a href=\"https://www.cell.com/cell/abstract/S0092-8674(25)00855-4\" target=\"_blank\">appears today</a> in <em>Cell</em>. The paper’s lead authors are MIT postdoc Aarti Krishnan, former postdoc Melis Anahtar ’08, and Jacqueline Valeri PhD ’23.</p><p><strong>Exploring chemical space</strong></p><p>Over the past 45 years, a few dozen&nbsp;new antibiotics have been approved by the FDA, but most of these are variants of existing antibiotics. At the same time, bacterial resistance to many of these drugs has been growing. Globally, it is estimated that drug-resistant bacterial infections cause nearly 5 million deaths per year.</p><p>In hopes of finding new antibiotics to fight this growing problem, Collins and others at MIT’s&nbsp;<a href=\"https://www.audaciousproject.org/grantees/collins-lab\" target=\"_blank\">Antibiotics-AI Project</a> have harnessed the power of AI to screen huge libraries of existing chemical compounds. This work has yielded several promising drug candidates, including&nbsp;<a href=\"https://news.mit.edu/2020/artificial-intelligence-identifies-new-antibiotic-0220\" target=\"_blank\">halicin</a> and&nbsp;<a href=\"https://news.mit.edu/2023/using-ai-scientists-combat-drug-resistant-infections-0525\" target=\"_blank\">abaucin</a>.</p><p>To build on that progress, Collins and his colleagues decided to expand their search into molecules that can’t be found in any chemical libraries. By using AI to generate hypothetically possible molecules that don’t exist or haven’t been discovered, they realized that it should be possible to explore a much greater diversity of potential drug compounds.</p><p>In their new study, the researchers employed two different approaches: First, they directed generative AI algorithms to design molecules based on a specific chemical fragment that showed antimicrobial activity, and second, they let the algorithms freely generate molecules, without having to include a specific fragment.</p><p>For the fragment-based approach, the researchers sought to identify molecules that could kill <em>N. gonorrhoeae</em>,&nbsp;a Gram-negative bacterium that causes gonorrhea. They began by assembling a library of about 45 million known chemical fragments, consisting of all possible combinations of 11 atoms of carbon, nitrogen, oxygen, fluorine, chlorine, and sulfur, along with fragments from Enamine’s REadily AccessibLe (REAL) space.</p><p>Then, they screened the library using machine-learning models that Collins’ lab has previously trained to predict antibacterial activity against <em>N. gonorrhoeae</em>. This resulted in nearly 4 million fragments. They narrowed down that pool by removing any fragments predicted to be cytotoxic to human cells, displayed chemical liabilities, and were known to be similar to existing antibiotics. This left them with about 1 million candidates.</p><p>“We wanted to get rid of anything that would look like an existing antibiotic, to help address the antimicrobial resistance crisis in a fundamentally different way. By venturing into underexplored areas of chemical space, our goal was to uncover novel mechanisms of action,” Krishnan says.</p><p>Through several rounds of additional experiments and computational analysis, the researchers identified a fragment they called F1 that appeared to have promising activity against <em>N. gonorrhoeae</em>. They used this fragment as the basis for generating additional compounds, using two different generative AI algorithms.</p><p>One of those algorithms, known as chemically reasonable mutations (CReM), works by starting with a particular molecule containing F1 and then generating new molecules by adding, replacing, or deleting atoms and chemical groups. The second algorithm, F-VAE (fragment-based variational autoencoder), takes a chemical fragment and builds it into a complete molecule. It does so by learning patterns of how fragments are commonly modified, based on its pretraining on more than 1 million molecules from the ChEMBL database.</p><p>Those two algorithms generated about 7 million candidates containing F1, which the researchers then computationally screened for activity against <em>N. gonorrhoeae</em>. This screen yielded about 1,000 compounds, and the researchers selected 80 of those to see if they could be produced by chemical synthesis vendors. Only two of these could be synthesized, and one of them, named NG1, was very effective at killing <em>N. gonorrhoeae</em> in a lab dish and in a mouse model of drug-resistant gonorrhea infection.</p><p>Additional experiments revealed that NG1 interacts with a protein called LptA, a novel drug target involved in the synthesis of the bacterial outer membrane. It appears that the drug works by interfering with membrane synthesis, which is fatal to cells.</p><p><strong>Unconstrained design</strong></p><p>In a second round of studies, the researchers explored the potential of using generative AI to freely design molecules, using Gram-positive bacteria, <em>S. aureus</em> as their target.</p><p>Again, the researchers used CReM and VAE to generate molecules, but this time with no constraints other than the general rules of how atoms can join to form chemically plausible molecules. Together, the models generated more than 29 million compounds. The researchers then applied the same filters that they did to the <em>N. gonorrhoeae</em> candidates, but focusing on <em>S. aureus</em>, eventually narrowing the pool down to about 90 compounds.</p><p>They were able to synthesize and test 22 of these molecules, and six of them showed strong antibacterial activity against multi-drug-resistant <em>S. aureus&nbsp;</em>grown in a lab dish. They also found that the top candidate, named DN1, was able to clear a methicillin-resistant <em>S. aureus</em> (MRSA) skin infection in a mouse model. These molecules also appear to interfere with bacterial cell membranes, but with broader effects not limited to interaction with one specific protein.</p><p>Phare Bio, a nonprofit that is also part of the Antibiotics-AI Project, is now working on further modifying NG1 and DN1 to make them suitable for additional testing.</p><p>“In a collaboration with Phare Bio, we are exploring analogs, as well as working on advancing the best candidates preclinically, through medicinal chemistry work,” Collins says. “We are also excited about applying the platforms that Aarti and the team have developed toward other bacterial pathogens of interest, notably <em>Mycobacterium tuberculosis</em> and <em>Pseudomonas aeruginosa</em>.”</p><p>The research was funded, in part, by the U.S. Defense&nbsp;Threat Reduction Agency, the&nbsp;National Institutes of Health,&nbsp;the&nbsp;Audacious Project, Flu Lab, the Sea Grape Foundation, Rosamund Zander and Hansjorg Wyss for the Wyss Foundation, and an anonymous donor.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/MIT-Novel-Antibiotics-01.jpg?itok=hrC95Mtj",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: iStock, MIT News"
        }
      ],
      "credit": "Credit: iStock, MIT News",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Drug resistance",
          "scheme": "https://news.mit.edu/topic/drug-resistance",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Microbes",
          "scheme": "https://news.mit.edu/topic/microbes",
          "label": null
        },
        {
          "term": "Disease",
          "scheme": "https://news.mit.edu/topic/disease",
          "label": null
        },
        {
          "term": "Medicine",
          "scheme": "https://news.mit.edu/topic/medicine",
          "label": null
        },
        {
          "term": "Bacteria",
          "scheme": "https://news.mit.edu/topic/bacteria",
          "label": null
        },
        {
          "term": "Antibiotics",
          "scheme": "https://news.mit.edu/topic/antibiotics",
          "label": null
        },
        {
          "term": "Drug development",
          "scheme": "https://news.mit.edu/topic/drug-development",
          "label": null
        },
        {
          "term": "Biological engineering",
          "scheme": "https://news.mit.edu/topic/biological-engineering",
          "label": null
        },
        {
          "term": "Institute for Medical Engineering and Science (IMES)",
          "scheme": "https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "National Institutes of Health (NIH)",
          "scheme": "https://news.mit.edu/topic/nih",
          "label": null
        },
        {
          "term": "Broad Institute",
          "scheme": "https://news.mit.edu/topic/broad-institute",
          "label": null
        }
      ]
    },
    {
      "title": "A new way to test how well AI systems classify text",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new way to test how well AI systems classify text"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/new-way-test-how-well-ai-systems-classify-text-0813"
        }
      ],
      "link": "https://news.mit.edu/2025/new-way-test-how-well-ai-systems-classify-text-0813",
      "summary": "As large language models increasingly dominate our everyday lives, new systems for checking their reliability are more important than ever.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new approach measures how well text classifiers are doing their job, and shows how to make them more accurate."
      },
      "published": "Wed, 13 Aug 2025 15:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        13,
        19,
        0,
        0,
        2,
        225,
        0
      ],
      "id": "https://news.mit.edu/2025/new-way-test-how-well-ai-systems-classify-text-0813",
      "guidislink": false,
      "authors": [
        {
          "name": "David Chandler | MIT Laboratory for Information and Decision Systems"
        }
      ],
      "author": "David Chandler | MIT Laboratory for Information and Decision Systems",
      "author_detail": {
        "name": "David Chandler | MIT Laboratory for Information and Decision Systems"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Is this movie review a rave or a pan? Is this news story about business or technology? Is this online chatbot conversation veering off into giving financial advice? Is this online medical information site giving out misinformation?</p><p>These kinds of automated conversations, whether they involve seeking a movie or restaurant review or getting information about your bank account or health records, are becoming increasingly prevalent. More than ever, such evaluations are being made by highly sophisticated algorithms, known as text classifiers, rather than by human beings. But how can we tell how accurate these classifications really are?</p><p>Now, a team at MIT’s Laboratory for Information and Decision Systems (LIDS) has come up with an innovative approach to not only measure how well these classifiers are doing their job, but then go one step further and show how to make them more accurate.</p><p>The new evaluation and remediation software was led and developed by Lei Xu alongside the research conducted by Sarah Alnegheimish, Kalyan Veeramachaneni, a principal research scientist at LIDS and senior author, with two others. The software package is being made freely available for download by anyone who wants to use it.</p><p>A standard method for testing these classification systems is to create what are known as&nbsp;synthetic examples — sentences that closely resemble ones that have already been classified. For example, researchers might take a sentence that has already been tagged by a classifier program as being a rave review, and see if changing a word or a few words while retaining the same meaning could fool the classifier into deeming it a pan. Or a sentence that was determined to be misinformation might get misclassified as accurate. This ability to fool the classifiers makes these adversarial examples.</p><p>People have tried various ways to find the vulnerabilities in these classifiers, Veeramachaneni says. But existing methods of finding these vulnerabilities have a hard time with this task and miss many examples that they should catch, he says.</p><p>Increasingly, companies are trying to use such evaluation tools in real time, monitoring the output of chatbots used for various purposes to try to make sure they are not putting out improper responses. For example, a bank might use a chatbot to respond to routine customer queries such as checking account balances or applying for a credit card, but it wants to ensure that its responses could never be interpreted as financial advice, which could expose the company to liability. “Before showing the chatbot’s response to the end user, they want to use the text classifier to detect whether it’s giving financial advice or not,” Veeramachaneni says. But then it’s important to test that classifier to see how reliable its evaluations are.</p><p>“These chatbots, or summarization engines or whatnot are being set up across the board,” he says, to deal with external customers and within an organization as well, for example providing information about HR issues. It’s important to put these text classifiers into the loop to detect things that they are not supposed to say, and filter those out before the output gets transmitted to the user.</p><p>That’s where the use of adversarial examples comes in — those sentences that have already been classified but then produce a different response when they are slightly modified while retaining the same meaning. How can people confirm that the meaning is the same? By using another large language model (LLM) that interprets and compares meanings. So, if the LLM says the two sentences mean the same thing, but the classifier labels them differently, “that is a sentence that is adversarial — it can fool the classifier,” Veeramachaneni says. And when the researchers examined these adversarial sentences, “we found that most of the time, this was just a one-word change,” although the people using LLMs to generate these alternate sentences often didn’t realize that.</p><p>Further investigation, using LLMs to analyze many thousands of examples, showed that certain specific words had an outsized influence in changing the classifications, and therefore the testing of a classifier’s accuracy could focus on this small subset of words that seem to make the most difference. They found that one-tenth of 1 percent of all the 30,000 words in the system’s vocabulary could account for almost half of all these reversals of classification, in some specific applications.</p><p>Lei Xu PhD ’23, a recent graduate from LIDS who performed much of the analysis as part of his thesis work, “used a lot of interesting estimation techniques to figure out what are the most powerful words that can change the overall classification, that can fool the classifier,” Veeramachaneni says. The goal is to make it possible to do much more narrowly targeted searches, rather than combing through all possible word substitutions, thus making the computational task of generating adversarial examples much more manageable. “He’s using large language models, interestingly enough, as a way to understand the power of a single word.”</p><p>Then, also using LLMs, he&nbsp;searches for other words that are closely related to these powerful words, and so on, allowing for an overall ranking of words according to their influence on the outcomes. Once these adversarial sentences have been found, they can be used in turn to retrain the classifier to take them into account, increasing the robustness of the classifier against those mistakes.</p><p>Making classifiers more accurate may not sound like a big deal if it’s just a matter of classifying news articles into categories, or deciding whether reviews of anything from movies to restaurants are positive or negative. But increasingly, classifiers are being used in settings where the outcomes really do matter, whether preventing the inadvertent release of sensitive medical, financial, or security information, or helping to guide important research, such as into properties of chemical compounds or the folding of proteins for biomedical applications, or in identifying and blocking hate speech or known misinformation.</p><p>As a result of this research, the team introduced a new metric, which they call p, which provides a measure of how robust a given classifier is against single-word attacks. And because of the importance of such misclassifications, the research team has made its products available as open access for anyone to use. The package consists of two components: SP-Attack, which generates adversarial sentences to test classifiers in any particular application, and SP-Defense, which aims to improve the robustness of the classifier by generating and using adversarial sentences to retrain the model.</p><p>In some tests, where competing methods of testing classifier outputs allowed a 66 percent success rate by adversarial attacks, this team’s system cut that attack success rate almost in half, to 33.7 percent. In other applications, the improvement was as little as a 2 percent difference, but even that can be quite important, Veeramachaneni says, since these systems are being used for so many billions of interactions that even a small percentage can affect millions of transactions.</p><p>The team’s results were published on July 7 in the journal <em>Expert Systems</em> in a paper by Xu, Veeramachaneni, and Alnegheimish of LIDS, along with Laure Berti-Equille at IRD in Marseille, France, and Alfredo Cuesta-Infante at the Universidad Rey Juan Carlos, in Spain.&nbsp;</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/mit-lids-text-classifier.jpg?itok=EFDHW0eB",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: iStock"
        }
      ],
      "credit": "Image: iStock",
      "tags": [
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "IDSS",
          "scheme": "https://news.mit.edu/topic/idss",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Open access",
          "scheme": "https://news.mit.edu/topic/open-access",
          "label": null
        }
      ]
    },
    {
      "title": "MIT gears up to transform manufacturing",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT gears up to transform manufacturing"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/mit-gears-transform-manufacturing-0813"
        }
      ],
      "link": "https://news.mit.edu/2025/mit-gears-transform-manufacturing-0813",
      "summary": "The Initiative for New Manufacturing is convening experts across the Institute to drive a transformation of production across the U.S. and the world.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "John Hart is head of the Department of Mechanical Engineering and faculty co-director of the Initiative for New Manufacturing."
      },
      "published": "Wed, 13 Aug 2025 15:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        13,
        19,
        0,
        0,
        2,
        225,
        0
      ],
      "id": "https://news.mit.edu/2025/mit-gears-transform-manufacturing-0813",
      "guidislink": false,
      "authors": [
        {
          "name": "Eric Bender | MIT Industrial Liaison Program"
        }
      ],
      "author": "Eric Bender | MIT Industrial Liaison Program",
      "author_detail": {
        "name": "Eric Bender | MIT Industrial Liaison Program"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>“Manufacturing is the engine of society, and it is the backbone of robust, resilient economies,” says John Hart, head of MIT’s Department of Mechanical Engineering (MechE) and faculty co-director of the MIT <a href=\"http://inm.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Initiative for New Manufacturing</a> (INM). “With manufacturing a lively topic in today’s news, there’s a renewed appreciation and understanding of the importance of manufacturing to innovation, to economic and national security, and to daily lives.”</p><p>Launched this May, INM will “help create a transformation of manufacturing through new technology, through development of talent, and through an understanding of how to scale manufacturing in a way that enables imparts higher productivity and resilience, drives adoption of new technologies, and creates good jobs,” Hart says.</p><p>INM is one of MIT’s strategic initiatives and builds on the successful three-year-old Manufacturing@MIT program. “It’s a recognition by MIT that manufacturing is an Institute-wide theme and an Institute-wide priority, and that manufacturing connects faculty and students across campus,” says Hart. Alongside Hart, INM’s faculty co-directors are Institute Professor Suzanne Berger and Chris Love, professor of chemical engineering.</p><p>The initiative is pursuing four main themes: reimagining manufacturing technologies and systems, elevating the productivity and human experience of manufacturing, scaling up new manufacturing, and transforming the manufacturing base.</p><p><strong>Breaking manufacturing barriers for corporations</strong></p><p>Amgen, Autodesk, Flex, GE Vernova, PTC, Sanofi, and Siemens are founding members of INM’s industry consortium. These industry partners will work closely with MIT faculty, researchers,&nbsp;and students across many aspects of manufacturing-related research, both in broad-scale initiatives and in particular areas of shared interests. Membership requires a minimum three-year commitment of $500,000 a year to manufacturing-related activities at MIT, including the INM membership fee of $275,000 per year, which supports several core activities that engage the industry members.</p><p>One major thrust for INM industry collaboration is the deployment and adoption of AI and automation in manufacturing. This effort will include seed research projects at MIT, collaborative case studies, and shared strategy development.</p><p>INM also offers companies participation in the MIT-wide New Manufacturing Research effort, which is studying the trajectories of specific manufacturing industries and examining cross-cutting themes such as technology and financing.</p><p>Additionally, INM will concentrate on education for all professions in manufacturing, with alliances bringing together corporations, community colleges, government agencies, and other partners. “We'll scale our curriculum to broader audiences, from aspiring manufacturing workers and aspiring production line supervisors all the way up to engineers and executives,” says Hart.</p><p>In workforce training, INM will collaborate with companies broadly to help understand the challenges and frame its overall workforce agenda, and with individual firms on specific challenges, such as acquiring suitably prepared employees for a new factory.</p><p>Importantly, industry partners will also engage directly with students. Founding member Flex, for instance, hosted MIT researchers and students at the Flex Institute of Technology in Sorocaba, Brazil, developing new solutions for electronics manufacturing.</p><p>“History shows that you need to innovate in manufacturing alongside the innovation in products,” Hart comments. “At MIT, as more students take classes in manufacturing, they’ll think more about key manufacturing issues as they decide what research problems they want to solve, or what choices they make as they prototype their devices. The same is true for industry — companies that operate at the frontier of manufacturing, whether through internal capabilities or their supply chains, are positioned to be on the frontier of product innovation and overall growth.”</p><p>“We’ll have an opportunity to bring manufacturing upstream to the early stage of research, designing new processes and new devices with scalability in mind,” he says.</p><p>Additionally, MIT expects to open new manufacturing-related labs and to further broaden cooperation with industry at existing shared facilities, such as MIT.nano. Hart says that facilities will also invite tighter collaborations with corporations — not just providing advanced equipment, but working jointly on, say, new technologies for weaving textiles, or speeding up battery manufacturing.</p><p><strong>Homing in on the United States</strong></p><p>INM is a global project that brings a particular focus on the United States, which remains the world’s second-largest manufacturing economy, but has suffered a significant decline in manufacturing employment and innovation.</p><p>One key to reversing this trend and reinvigorating the U.S. manufacturing base is advocacy for manufacturing’s critical role in society and the career opportunities it offers.</p><p>“No one really disputes the importance of manufacturing,” Hart says. “But we need to elevate interest in manufacturing as a rewarding career, from the production workers to manufacturing engineers and leaders, through advocacy, education programs, and buy-in from industry, government, and academia.”</p><p>MIT is in a unique position to convene industry, academic, and government stakeholders in manufacturing to work together on this vital issue, he points out.</p><p>Moreover, in times of radical and rapid changes in manufacturing, “we need to focus on deploying new technologies into factories and supply chains,” Hart says. “Technology is not all of the solution, but for the U.S. to expand our manufacturing base, we need to do it with technology as a key enabler, embracing companies of all sizes, including small and medium enterprises.”</p><p>“As AI becomes more capable, and automation becomes more flexible and more available, these are key building blocks upon which you can address manufacturing challenges,” he says. “AI and automation offer new accelerated ways to develop, deploy, and monitor production processes, which present a huge opportunity and, in some cases, a necessity.”</p><p>“While manufacturing is always a combination of old technology, new technology, established practice, and new ways of thinking, digital technology gives manufacturers an opportunity to leapfrog competitors,” Hart says. “That’s very, very powerful for the U.S. and any company, or country, that aims to create differentiated capabilities.”</p><p>Fortunately, in recent years, investors have increasingly bought into new manufacturing in the United States. “They see the opportunity to re-industrialize, to build the factories and production systems of the future,” Hart says.</p><p>“That said, building new manufacturing is capital-intensive, and takes time,” he adds. “So that’s another area where it’s important to convene stakeholders and to think about how startups and growth-stage companies build their capital portfolios, how large industry can support an ecosystem of small businesses and young companies, and how to develop talent to support those growing companies.”</p><p>All these concerns and opportunities in the manufacturing ecosystem play to MIT’s strengths. “MIT’s DNA of cross-disciplinary collaboration and working with industry can let us create a lot of impact,” Hart emphasizes. “We can understand the practical challenges. We can also explore breakthrough ideas in research and cultivate successful outcomes, all the way to new companies and partnerships. Sometimes those are seen as disparate approaches, but we like to bring them together.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/john-hart-mit-00.png?itok=W2PumkXm",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo: David Sella"
        }
      ],
      "credit": "Photo: David Sella",
      "tags": [
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "Chemical engineering",
          "scheme": "https://news.mit.edu/topic/chemical-engineering",
          "label": null
        },
        {
          "term": "Mechanical engineering",
          "scheme": "https://news.mit.edu/topic/mechanical-engineering",
          "label": null
        },
        {
          "term": "MIT.nano",
          "scheme": "https://news.mit.edu/topic/mitnano",
          "label": null
        },
        {
          "term": "Education, teaching, academics",
          "scheme": "https://news.mit.edu/topic/education",
          "label": null
        },
        {
          "term": "Industry",
          "scheme": "https://news.mit.edu/topic/industry",
          "label": null
        },
        {
          "term": "Manufacturing",
          "scheme": "https://news.mit.edu/topic/manufacturing",
          "label": null
        },
        {
          "term": "Collaboration",
          "scheme": "https://news.mit.edu/topic/collaboration",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Labor and jobs",
          "scheme": "https://news.mit.edu/topic/labor-jobs",
          "label": null
        },
        {
          "term": "Technology and policy",
          "scheme": "https://news.mit.edu/topic/technology-and-policy",
          "label": null
        },
        {
          "term": "Political science",
          "scheme": "https://news.mit.edu/topic/political-science",
          "label": null
        },
        {
          "term": "School of Humanities Arts and Social Sciences",
          "scheme": "https://news.mit.edu/topic/school-humanities-arts-and-social-sciences",
          "label": null
        }
      ]
    },
    {
      "title": "Eco-driving measures could significantly reduce vehicle emissions",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Eco-driving measures could significantly reduce vehicle emissions"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/eco-driving-measures-could-significantly-reduce-vehicle-emissions-0807"
        }
      ],
      "link": "https://news.mit.edu/2025/eco-driving-measures-could-significantly-reduce-vehicle-emissions-0807",
      "summary": "New research shows automatically controlling vehicle speeds to mitigate traffic at intersections can cut carbon emissions between 11 and 22 percent.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Implementing co-driving techniques can significantly reduce intersection carbon dioxide emissions without impacting traffic throughput or safety, according to new MIT research."
      },
      "published": "Thu, 07 Aug 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        7,
        4,
        0,
        0,
        3,
        219,
        0
      ],
      "id": "https://news.mit.edu/2025/eco-driving-measures-could-significantly-reduce-vehicle-emissions-0807",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Any motorist who has ever waited through multiple cycles for a traffic light to turn green knows how annoying signalized intersections can be. But sitting at intersections isn’t just a drag on drivers’ patience — unproductive vehicle idling could contribute as much as 15 percent of the carbon dioxide emissions from U.S. land transportation.</p><p>A large-scale modeling study led by MIT researchers reveals that eco-driving measures, which can involve dynamically adjusting vehicle speeds to reduce stopping and excessive acceleration, could significantly reduce those CO<sub>2</sub> emissions.</p><p>Using a powerful artificial intelligence method called deep reinforcement learning, the researchers conducted an in-depth impact assessment of the factors affecting vehicle emissions in three major U.S. cities.</p><p>Their analysis indicates that fully adopting eco-driving measures could cut annual city-wide intersection carbon emissions by 11 to 22 percent, without slowing traffic throughput or affecting vehicle and traffic safety.</p><p>Even if only 10 percent of vehicles on the road employ eco-driving, it would result in 25 to 50 percent of the total reduction in CO2 emissions, the researchers found.</p><p>In addition, dynamically optimizing speed limits at about 20 percent of intersections provides 70 percent of the total emission benefits. This indicates that eco-driving measures could be implemented gradually while still having measurable, positive impacts on mitigating climate change and improving public health.</p><img alt=\"Two intersections with lots of cars; the 100% adoption has less traffic.\" height=\"333\" src=\"https://news.mit.edu/sites/default/files/images/inline/eco-driving.gif\" width=\"521\" /><p>“Vehicle-based control strategies like eco-driving can move the needle on climate change reduction. We’ve shown here that modern machine-learning tools, like deep reinforcement learning, can accelerate the kinds of analysis that support sociotechnical decision making. This is just the tip of the iceberg,” says senior author Cathy Wu, the Class of 1954 Career Development Associate Professor in Civil and Environmental Engineering (CEE) and the Institute for Data, Systems, and Society (IDSS) at MIT, and a member of the Laboratory for Information and Decision Systems (LIDS).</p><p>She is joined on the paper by lead author Vindula Jayawardana, an MIT graduate student; as well as MIT graduate students Ao Qu, Cameron Hickert, and Edgar Sanchez; MIT undergraduate Catherine Tang; Baptiste Freydt, a graduate student at ETH Zurich; and Mark Taylor and Blaine Leonard of the Utah Department of Transportation. The <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0968090X25001500\" target=\"_blank\">research appears</a> in <em>Transportation Research Part C: Emerging Technologies</em>.</p><p><strong>A multi-part modeling study</strong></p><p>Traffic control measures typically call to mind fixed infrastructure, like stop signs and traffic signals. But as vehicles become more technologically advanced, it presents an opportunity for eco-driving, which is a catch-all term for vehicle-based traffic control measures like the use of dynamic speeds to reduce energy consumption.</p><p>In the near term, eco-driving could involve speed guidance in the form of vehicle dashboards or smartphone apps. In the longer term, eco-driving could involve intelligent speed commands that directly control the acceleration of semi-autonomous and fully autonomous vehicles through vehicle-to-infrastructure communication systems.</p><p>“Most prior work has focused on how<em>&nbsp;</em>to implement eco-driving. We shifted the frame to consider the question of should<em>&nbsp;</em>we implement eco-driving. If we were to deploy this technology at scale, would it make a difference?” Wu says.</p><p>To answer that question, the researchers embarked on a multifaceted modeling study that would take the better part of four years to complete.</p><p>They began by identifying 33 factors that influence vehicle emissions, including temperature, road grade, intersection topology, age of the vehicle, traffic demand, vehicle types, driver behavior, traffic signal timing, road geometry, etc.</p><p>“One of the biggest challenges was making sure we were diligent and didn’t leave out any major factors,” Wu says.</p><p>Then they used data from OpenStreetMap, U.S. geological surveys, and other sources to create digital replicas of more than 6,000 signalized intersections in three cities — Atlanta, San Francisco, and Los Angeles — and simulated more than a million traffic scenarios.</p><p>The researchers used deep reinforcement learning to optimize each scenario for eco-driving to achieve the maximum emissions benefits.</p><p>Reinforcement learning optimizes the vehicles’ driving behavior through trial-and-error interactions with a high-fidelity traffic simulator, rewarding vehicle behaviors that are more energy-efficient while penalizing those that are not.</p><p>The researchers cast the problem as a decentralized cooperative multi-agent control problem, where the vehicles cooperate to achieve overall energy efficiency, even among non-participating vehicles, and they act in a decentralized manner, avoiding the need for costly communication between vehicles.</p><p>However, training vehicle behaviors that generalize across diverse intersection traffic scenarios was a major challenge. The researchers observed that some scenarios are more similar to one another than others, such as scenarios with the same number of lanes or the same number of traffic signal phases.</p><p>As such, the researchers trained separate reinforcement learning models for different clusters of traffic scenarios, yielding better emission benefits overall.</p><p>But even with the help of AI, analyzing citywide traffic at the network level would be so computationally intensive it could take another decade to unravel, Wu says.</p><p>Instead, they broke the problem down and solved each eco-driving scenario at the individual intersection level.</p><p>“We carefully constrained the impact of eco-driving control at each intersection on neighboring intersections. In this way, we dramatically simplified the problem, which enabled us to perform this analysis at scale, without introducing unknown network effects,” she says.</p><p><strong>Significant emissions benefits</strong></p><p>When they analyzed the results, the researchers found that full adoption of eco-driving could result in intersection emissions reductions of between 11 and 22 percent.</p><p>These benefits differ depending on the layout of a city’s streets. A denser city like San Francisco has less room to implement eco-driving between intersections, offering a possible explanation for reduced emission savings, while Atlanta could see greater benefits given its higher speed limits.</p><p>Even if only 10 percent of vehicles employ eco-driving, a city could still realize 25 to 50 percent of the total emissions benefit because of car-following dynamics: Non-eco-driving vehicles would follow controlled eco-driving vehicles as they optimize speed to pass smoothly through intersections, reducing their carbon emissions as well.</p><p>In some cases, eco-driving could also increase vehicle throughput by minimizing emissions. However, Wu cautions that increasing throughput could result in more drivers taking to the roads, reducing emissions benefits.</p><p>And while their analysis of widely used safety metrics known as surrogate safety measures, such as time to collision, suggest that eco-driving is as safe as human driving, it could cause unexpected behavior in human drivers. More research is needed to fully understand potential safety impacts, Wu says.</p><p>Their results also show that eco-driving could provide even greater benefits when combined with alternative transportation decarbonization solutions. For instance, 20 percent eco-driving adoption in San Francisco would cut emission levels by 7 percent, but when combined with the projected adoption of hybrid and electric vehicles, it would cut emissions by 17 percent.</p><p>“This is a first attempt to systematically quantify network-wide environmental benefits of eco-driving. This is a great research effort that will serve as a key reference for others to build on in the assessment of eco-driving systems,” says Hesham Rakha, the Samuel L. Pritchard Professor of Engineering at Virginia Tech, who was not involved with this research.</p><p>And while the researchers focus on carbon emissions, the benefits are highly correlated with improvements in fuel consumption, energy use, and air quality.</p><p>“This is almost a free intervention. We already have smartphones in our cars, and we are rapidly adopting cars with more advanced automation features. For something to scale quickly in practice, it must be relatively simple to implement and shovel-ready. Eco-driving fits that bill,” Wu says.</p><p>This work is funded, in part, by Amazon and the Utah Department of Transportation.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/MIT-EcoDriving-01-press.jpg?itok=qAjylkrY",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: iStock; MIT News"
        }
      ],
      "credit": "Image: iStock; MIT News",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Transportation",
          "scheme": "https://news.mit.edu/topic/transportation",
          "label": null
        },
        {
          "term": "Cities",
          "scheme": "https://news.mit.edu/topic/cities",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Autonomous vehicles",
          "scheme": "https://news.mit.edu/topic/autonomous-vehicles",
          "label": null
        },
        {
          "term": "Emissions",
          "scheme": "https://news.mit.edu/topic/emissions",
          "label": null
        },
        {
          "term": "Sustainability",
          "scheme": "https://news.mit.edu/topic/sustainability",
          "label": null
        },
        {
          "term": "Climate change",
          "scheme": "https://news.mit.edu/topic/climate-change",
          "label": null
        },
        {
          "term": "Computer modeling",
          "scheme": "https://news.mit.edu/topic/computer-modeling",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "IDSS",
          "scheme": "https://news.mit.edu/topic/idss",
          "label": null
        },
        {
          "term": "Civil and environmental engineering",
          "scheme": "https://news.mit.edu/topic/civil-engineering",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        }
      ]
    },
    {
      "title": "School of Architecture and Planning welcomes new faculty for 2025",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "School of Architecture and Planning welcomes new faculty for 2025"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/school-architecture-planning-welcomes-new-faculty-0806"
        }
      ],
      "link": "https://news.mit.edu/2025/school-architecture-planning-welcomes-new-faculty-0806",
      "summary": "Four new professors join the Department of Architecture and MIT Media Lab.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "New MIT faculty for 2025 in the School of Architecture and Planning (clockwise from top left): Karrie Karahalios, Pat Pataranutaporn, Holly Samuelson, and Mariana Popescu"
      },
      "published": "Wed, 06 Aug 2025 16:10:00 -0400",
      "published_parsed": [
        2025,
        8,
        6,
        20,
        10,
        0,
        2,
        218,
        0
      ],
      "id": "https://news.mit.edu/2025/school-architecture-planning-welcomes-new-faculty-0806",
      "guidislink": false,
      "authors": [
        {
          "name": "School of Architecture and Planning"
        }
      ],
      "author": "School of Architecture and Planning",
      "author_detail": {
        "name": "School of Architecture and Planning"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Four new faculty members join the School of Architecture and Planning (SA+P) this fall, offering the MIT community creativity, knowledge, and scholarship in multidisciplinary roles.</p><p>“These individuals add considerable strength and depth to our faculty,” says Hashim Sarkis, dean of the School of Architecture and Planning. “We are excited for the academic vigor they bring to research and teaching.”</p><p><a href=\"https://www.media.mit.edu/posts/karrie-karahalios-announce/\" target=\"_blank\"><strong>Karrie G. Karahalios</strong></a> ’94, MEng ’95, SM ’97, PhD ’04 joins the MIT Media Lab as a full professor of media arts and sciences. Karahalios is a pioneer in the exploration of social media and of how people communicate in environments that are increasingly mediated by algorithms that, as she has written, “shape the world around us.” Her work combines computing, systems, artificial intelligence, anthropology, sociology, psychology, game theory, design, and infrastructure studies. Karahalios’ work has received numerous honors including the National Science Foundation CAREER Award, Alfred P. Sloan Research Fellowship, SIGMOD Best Paper Award, and recognition as an ACM Distinguished Member.</p><p><a href=\"https://www.media.mit.edu/posts/patpat-professorship-appointment/\" target=\"_blank\"><strong>Pat Pataranutaporn</strong></a> SM ’20, PhD ’24 joins the MIT Media Lab as an assistant professor of media arts and sciences. A visionary technologist, scientist, and designer, Pataranutaporn explores the frontier of human-AI interaction, inventing and investigating AI systems that support human thriving. His research focuses on how personalized AI systems can amplify human cognition, from learning and decision-making to self-development, reflection, and well-being. Pataranutaporn will co-direct the Advancing Humans with AI Program.</p><p><a href=\"https://maadpope.com/\" target=\"_blank\"><strong>Mariana Popescu</strong></a> joins the&nbsp;Department of Architecture as an assistant professor with a shared appointment in the MIT Schwarzman College of Computing in the Department of Electrical Engineering and Computer Science. Popescu&nbsp;is a computational architect and structural designer with a strong interest and experience in innovative ways of approaching the fabrication process and use of materials in construction.&nbsp;Her area of expertise is computational and parametric design, with a focus on digital fabrication and sustainable design. Her extensive involvement in projects related to promoting sustainability has led to a multilateral development of skills, which combine the fields of architecture, engineering, computational design, and digital fabrication.&nbsp;Popescu earned her doctorate at ETH Zurich. She was&nbsp;<a href=\"https://www.technologyreview.com/innovator/mariana-popescu/\" target=\"_blank\">named a “Pioneer”</a> on the <em>MIT Technology Review</em> global list of “35 innovators under 35” in 2019.</p><p><a href=\"https://www.hollysamuelson.com/\" target=\"_blank\"><strong>Holly Samuelson</strong></a> joins the Department of Architecture as an associate professor&nbsp;in the Building Technology Program at MIT, teaching architectural technology courses. Her teaching and research focus on issues of building design that impact human and environmental health. Her current projects harness advanced building simulation to investigate issues of greenhouse gas emissions, heat vulnerability, and indoor environmental quality while considering the future of buildings in a changing electricity grid. Samuelson has co-authored over 40 peer-reviewed papers, winning a best paper award from the journal <em>Energy and Building</em>. As a recognized expert in architectural technology, she has been featured in news outlets including <em>The Washington Post</em>, <em>The Boston Globe</em>, the BBC, and <em>The Wall Street Journal</em>. Samuelson earned her doctor of design from Harvard University Graduate School of Design.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/MIT-NewSAP25-01-press.jpg?itok=WM1Acq8D",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Images courtesy of the School of Architecture and Planning"
        }
      ],
      "credit": "Images courtesy of the School of Architecture and Planning",
      "tags": [
        {
          "term": "Faculty",
          "scheme": "https://news.mit.edu/topic/faculty",
          "label": null
        },
        {
          "term": "Alumni/ae",
          "scheme": "https://news.mit.edu/topic/alumni",
          "label": null
        },
        {
          "term": "Architecture",
          "scheme": "https://news.mit.edu/topic/architecture",
          "label": null
        },
        {
          "term": "Media Lab",
          "scheme": "https://news.mit.edu/topic/media-lab-0",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Social media",
          "scheme": "https://news.mit.edu/topic/social-media",
          "label": null
        },
        {
          "term": "Computer modeling",
          "scheme": "https://news.mit.edu/topic/computer-modeling",
          "label": null
        },
        {
          "term": "Game theory",
          "scheme": "https://news.mit.edu/topic/game-theory",
          "label": null
        },
        {
          "term": "Communications",
          "scheme": "https://news.mit.edu/topic/communications-0",
          "label": null
        },
        {
          "term": "Human-computer interaction",
          "scheme": "https://news.mit.edu/topic/human-computer-interaction",
          "label": null
        },
        {
          "term": "Design",
          "scheme": "https://news.mit.edu/topic/design",
          "label": null
        },
        {
          "term": "Building",
          "scheme": "https://news.mit.edu/topic/building",
          "label": null
        },
        {
          "term": "Construction",
          "scheme": "https://news.mit.edu/topic/construction",
          "label": null
        },
        {
          "term": "Fabrication",
          "scheme": "https://news.mit.edu/topic/fabrication",
          "label": null
        },
        {
          "term": "Environment",
          "scheme": "https://news.mit.edu/topic/environment",
          "label": null
        },
        {
          "term": "Sustainability",
          "scheme": "https://news.mit.edu/topic/sustainability",
          "label": null
        },
        {
          "term": "School of Architecture and Planning",
          "scheme": "https://news.mit.edu/topic/school-architecture-and-planning",
          "label": null
        }
      ]
    },
    {
      "title": "Helping data storage keep up with the AI revolution",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Helping data storage keep up with the AI revolution"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/cloudian-helps-data-storage-keep-up-with-ai-revolution-0806"
        }
      ],
      "link": "https://news.mit.edu/2025/cloudian-helps-data-storage-keep-up-with-ai-revolution-0806",
      "summary": "Storage systems from Cloudian, co-founded by an MIT alumnus, are helping businesses feed data-hungry AI models and agents at scale.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "The company has developed a scalable storage system for businesses that helps data flow seamlessly between storage and AI models."
      },
      "published": "Wed, 06 Aug 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        8,
        6,
        4,
        0,
        0,
        2,
        218,
        0
      ],
      "id": "https://news.mit.edu/2025/cloudian-helps-data-storage-keep-up-with-ai-revolution-0806",
      "guidislink": false,
      "authors": [
        {
          "name": "Zach Winn | MIT News"
        }
      ],
      "author": "Zach Winn | MIT News",
      "author_detail": {
        "name": "Zach Winn | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Artificial intelligence is changing the way businesses store and access their data. That’s because traditional data storage systems were designed to handle simple commands from a handful of users at once, whereas today, AI systems with millions of agents need to continuously access and process large amounts of data in parallel. Traditional data storage systems now have layers of complexity, which slows AI systems down because data must pass through multiple tiers before reaching the graphical processing units (GPUs) that are the brain cells of AI.</p><p>Cloudian, co-founded by Michael Tso ’93, SM ’93 and Hiroshi Ohta, is helping storage keep up with the AI revolution. The company has developed a scalable storage system for businesses that helps data flow seamlessly between storage and AI models. The system reduces complexity by applying parallel computing to data storage, consolidating AI functions and data onto a single parallel-processing platform that stores, retrieves, and processes scalable datasets, with direct, high-speed transfers between storage and GPUs and CPUs.</p><p>Cloudian’s integrated storage-computing platform simplifies the process of building commercial-scale AI tools and gives businesses a storage foundation that can keep up with the rise of AI.</p><p>“One of the things people miss about AI is that it’s all about the data,” Tso says. “You can’t get a 10 percent improvement in AI performance with 10 percent more data or even 10 times more data — you need 1,000 times more data. Being able to store that data in a way that’s easy to manage, and in such a way that you can embed computations into it so you can run operations while the data is coming in without moving the data — that’s where this industry is going.”</p><p><strong>From MIT to industry</strong></p><p>As an undergraduate at MIT in the 1990s, Tso was introduced by Professor William Dally to parallel computing — a type of computation in which many calculations occur simultaneously. Tso also worked on parallel computing with Associate Professor Greg Papadopoulos.</p><p>“It was an incredible time because most schools had one super-computing project going on — MIT had four,” Tso recalls.</p><p>As a graduate student, Tso worked with MIT senior research scientist David Clark, a computing pioneer who contributed to the internet’s early architecture, particularly the transmission control protocol (TCP) that delivers data between systems.</p><p>“As a graduate student at MIT, I worked on disconnected and intermittent networking operations for large scale distributed systems,” Tso says. “It’s funny — 30 years on, that’s what I’m still doing today.”</p><p>Following his graduation, Tso worked at Intel’s Architecture Lab, where he invented data synchronization algorithms used by Blackberry. He also created specifications for Nokia that ignited the ringtone download industry. He then joined Inktomi, a startup co-founded by Eric Brewer SM ’92, PhD ’94 that pioneered search and web content distribution technologies.</p><p>In 2001, Tso started Gemini Mobile Technologies with Joseph Norton ’93, SM ’93 and others. The company went on to build the world’s largest mobile messaging systems to handle the massive data growth from camera phones. Then, in the late 2000s, cloud computing became a powerful way for businesses to rent virtual servers as they grew their operations. Tso noticed the amount of data being collected was growing far faster than the speed of networking, so he decided to pivot the company.</p><p>“Data is being created in a lot of different places, and that data has its own gravity: It’s going to cost you money and time to move it,” Tso explains. “That means the end state is a distributed cloud that reaches out to edge devices and servers. You have to bring the cloud to the data, not the data to the cloud.”</p><p>Tso officially launched Cloudian out of Gemini Mobile Technologies in 2012, with a new emphasis on helping customers with scalable, distributed, cloud-compatible data storage.</p><p>“What we didn’t see when we first started the company was that AI was going to be the ultimate use case for data on the edge,” Tso says.</p><p>Although Tso’s research at MIT began more than two decades ago, he sees strong connections between what he worked on and the industry today.</p><p>“It’s like my whole life is playing back because David Clark and I were dealing with disconnected and intermittently connected networks, which are part of every edge use case today, and Professor Dally was working on very fast, scalable interconnects,” Tso says, noting that Dally is now the senior vice president and chief scientist at the leading AI company NVIDIA. “Now, when you look at the modern NVIDIA chip architecture and the way they do interchip communication, it’s got Dally’s work all over it. With Professor Papadopoulos, I worked on accelerate application software with parallel computing hardware without having to rewrite the applications, and that’s exactly the problem we are trying to solve with NVIDIA. Coincidentally, all the stuff I was doing at MIT is playing out.”</p><p>Today Cloudian’s platform uses an object storage architecture in which all kinds of data —documents, videos, sensor data — are stored as a unique object with metadata. Object storage can manage massive datasets in a flat file stucture, making it ideal for unstructured data and AI systems, but it traditionally hasn’t been able to send data directly to AI models without the data first being copied into a computer’s memory system, creating latency and energy bottlenecks for businesses.</p><p>In July, Cloudian announced that it has extended its object storage system with a vector database that stores data in a form which is immediately usable by AI models. As the data are ingested, Cloudian is computing in real-time the vector form of that data to power AI tools like recommender engines, search, and AI assistants. Cloudian also announced a partnership with NVIDIA that allows its storage system to work directly with the AI company’s GPUs. Cloudian says the new system enables even faster AI operations and reduces computing costs.</p><p>“NVIDIA contacted us about a year and a half ago because GPUs are useful only with data that keeps them busy,” Tso says. “Now that people are realizing it’s easier to move the AI to the data than it is to move huge datasets. Our storage systems embed a lot of AI functions, so we’re able to pre- and post-process data for AI near where we collect and store the data.”</p><p><strong>AI-first storage</strong></p><p>Cloudian is helping about 1,000 companies around the world get more value out of their data, including large manufacturers, financial service providers, health care organizations, and government agencies.</p><p>Cloudian’s storage platform is helping one large automaker, for instance, use AI to determine when each of its manufacturing robots need to be serviced. Cloudian is also working with the National Library of Medicine to store research articles and patents, and the National Cancer Database to store DNA sequences of tumors — rich datasets that AI models could process to help research develop new treatments or gain new insights.</p><p>“GPUs have been an incredible enabler,” Tso says. “Moore’s Law doubles the amount of compute every two years, but GPUs are able to parallelize operations on chips, so you can network GPUs together and shatter Moore’s Law. That scale is pushing AI to new levels of intelligence, but the only way to make GPUs work hard is to feed them data at the same speed that they compute — and the only way to do that is to get rid of all the layers between them and your data.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202508/MIT-Cloudian-01.jpg?itok=j9Gg2rpo",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: iStock"
        }
      ],
      "credit": "Credit: iStock",
      "tags": [
        {
          "term": "Alumni/ae",
          "scheme": "https://news.mit.edu/topic/alumni",
          "label": null
        },
        {
          "term": "Startups",
          "scheme": "https://news.mit.edu/topic/startups",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "Innovation and Entrepreneurship (I&E)",
          "scheme": "https://news.mit.edu/topic/innovation",
          "label": null
        }
      ]
    },
    {
      "title": "MIT tool visualizes and edits “physically impossible” objects",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT tool visualizes and edits “physically impossible” objects"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/mit-meschers-tool-visualizes-edits-physically-impossible-objects-0804"
        }
      ],
      "link": "https://news.mit.edu/2025/mit-meschers-tool-visualizes-edits-physically-impossible-objects-0804",
      "summary": "By visualizing Escher-like optical illusions in 2.5 dimensions, the “Meschers” tool could help scientists understand physics-defying shapes and spark new designs.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "“Meschers” can create multi-dimensional versions of objects that break the laws of physics with convoluted geometries, such as buildings you might see in an M.C. Escher illustration (left) and objects that are shaded in impossible ways (center and right)."
      },
      "published": "Mon, 04 Aug 2025 16:40:00 -0400",
      "published_parsed": [
        2025,
        8,
        4,
        20,
        40,
        0,
        0,
        216,
        0
      ],
      "id": "https://news.mit.edu/2025/mit-meschers-tool-visualizes-edits-physically-impossible-objects-0804",
      "guidislink": false,
      "authors": [
        {
          "name": "Alex Shipps | MIT CSAIL"
        }
      ],
      "author": "Alex Shipps | MIT CSAIL",
      "author_detail": {
        "name": "Alex Shipps | MIT CSAIL"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\" id=\"docs-internal-guid-00f766d6-7fff-403a-378d-5aaf2f5b25af\">M.C. Escher’s artwork is a gateway into a world of depth-defying optical illusions, featuring “impossible objects” that break the laws of physics with convoluted geometries. What you perceive his illustrations to be depends on your point of view — for example, a person seemingly walking upstairs may be heading down the steps if you tilt your head&nbsp;<a href=\"https://www.nga.gov/collection/art-object-page.54256.html\">sideways</a>.&nbsp;<br /><br />Computer graphics scientists and designers can recreate these illusions in 3D, but only by bending or cutting a real shape and positioning it at a particular angle. This workaround has downsides, though: Changing the smoothness or lighting of the structure will expose that it isn’t actually an optical illusion, which also means you can’t accurately solve geometry problems on it.<br /><br />Researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a unique approach to represent “impossible” objects in a more versatile way. Their “<a href=\"https://anadodik.github.io/publication/meschers/\">Meschers</a>” tool converts images and 3D models into 2.5-dimensional structures, creating Escher-like depictions of things like windows, buildings, and even donuts. The approach helps users relight, smooth out, and study unique geometries while preserving their optical illusion.<br /><br />This tool could assist geometry researchers with calculating the distance between two points on a curved impossible surface (“geodesics”) and simulating how heat dissipates over it (“heat diffusion”). It could also help artists and computer graphics scientists create physics-breaking designs in multiple dimensions.<br /><br />Lead author and MIT PhD student Ana Dodik aims to design computer graphics tools that aren’t limited to replicating reality, enabling artists to express their intent independently of whether a shape can be realized in the physical world. “Using Meschers, we’ve unlocked a new class of shapes for artists to work with on the computer,” she says. “They could also help perception scientists understand the point at which an object truly becomes impossible.”</p><p dir=\"ltr\">Dodik and her colleagues will present their&nbsp;<a href=\"https://anadodik.github.io/publication/meschers/Meschers.pdf\">paper</a> at the SIGGRAPH conference in August.</p><p dir=\"ltr\"><strong>Making impossible objects possible</strong></p><p dir=\"ltr\">Impossible objects can’t be fully replicated in 3D. Their constituent parts often look plausible, but these parts don’t glue together properly when assembled in 3D. But what can be computationally imitated, as the CSAIL researchers found out, is the process of how we perceive these shapes.<br /><br />Take the&nbsp;<a href=\"https://www.illusionsindex.org/i/impossible-triangle\">Penrose Triangle</a>, for instance. The object as a whole is physically impossible because the depths don’t “add up,” but we can recognize real-world 3D shapes (like its three L-shaped corners) within it. These smaller regions can be realized in 3D — a property called “local consistency” — but when we try to assemble them together, they don’t form a globally consistent shape.<br /><br />The Meschers approach models’ locally consistent regions without forcing them to be globally consistent, piecing together an Escher-esque structure. Behind the scenes, Meschers represents impossible objects as if we know their x and y coordinates in the image, as well as differences in z coordinates (depth) between neighboring pixels; the tool uses these differences in depth to reason about impossible objects indirectly.<br /><br /><strong>The many uses of Meschers</strong><br /><br />In addition to rendering impossible objects, Meschers can subdivide their structures into smaller shapes for more precise geometry calculations and smoothing operations. This process enabled the researchers to reduce visual imperfections of impossible shapes, such as a red heart outline they thinned out.<br /><br />The researchers also tested their tool on an “impossibagel,” where a bagel is shaded in a physically impossible way. Meschers helped Dodik and her colleagues simulate heat diffusion and calculate geodesic distances between different points of the model.<br /><br />“Imagine you’re an ant traversing this bagel, and you want to know how long it’ll take you to get across, for example,” says Dodik. “In the same way, our tool could help mathematicians analyze the underlying geometry of impossible shapes up close, much like how we study real-world ones.”</p><p dir=\"ltr\">Much like a magician, the tool can create optical illusions out of otherwise practical objects, making it easier for computer graphics artists to create impossible objects. It can also use “inverse rendering” tools to convert drawings and images of impossible objects into high-dimensional designs.&nbsp;<br /><br />“Meschers demonstrates how computer graphics tools don’t have to be constrained by the rules of physical reality,” says senior author Justin Solomon, associate professor of electrical engineering and computer science and leader of the CSAIL Geometric Data Processing Group. “Incredibly, artists using Meschers can reason about shapes that we will never find in the real world.”</p><p dir=\"ltr\">Meschers can also aid computer graphics artists with tweaking the shading of their creations, while still preserving an optical illusion. This versatility would allow creatives to change the lighting of their art to depict a wider variety of scenes (like a sunrise or sunset) — as Meschers demonstrated by relighting a model of a dog on a skateboard.</p><p dir=\"ltr\">Despite its versatility, Meschers is just the start for Dodik and her colleagues. The team is considering designing an interface to make the tool easier to use while building more elaborate scenes. They’re also working with perception scientists to see how the computer graphics tool can be used more broadly.</p><p>Dodik and Solomon wrote the paper with CSAIL affiliates Isabella Yu ’24, SM ’25; PhD student Kartik Chandra SM ’23; MIT professors Jonathan Ragan-Kelley and Joshua Tenenbaum; and MIT Assistant Professor Vincent Sitzmann.&nbsp;<br /><br />Their work was supported, in part, by the MIT Presidential Fellowship, the Mathworks Fellowship, the Hertz Foundation, the U.S. National Science Foundation, the Schmidt Sciences AI2050 fellowship, MIT Quest for Intelligence, the U.S. Army Research Office, U.S. Air Force Office of Scientific Research, SystemsThatLearn@CSAIL initiative, Google, the MIT–IBM Watson AI Laboratory, from the Toyota–CSAIL Joint Research Center, Adobe Systems, the Singapore Defence Science and Technology Agency, and the U.S. Intelligence Advanced Research Projects Activity.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/mit-csail-Meschers.jpg?itok=mwr0SOLG",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: Alex Shipps/MIT CSAIL, using assets from Pixabay and the researchers"
        }
      ],
      "credit": "Image: Alex Shipps/MIT CSAIL, using assets from Pixabay and the researchers",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Mathematics",
          "scheme": "https://news.mit.edu/topic/mathematics",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Arts",
          "scheme": "https://news.mit.edu/topic/arts",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Computer graphics",
          "scheme": "https://news.mit.edu/topic/computer-graphics",
          "label": null
        },
        {
          "term": "Computer vision",
          "scheme": "https://news.mit.edu/topic/computer-vision",
          "label": null
        },
        {
          "term": "National Science Foundation (NSF)",
          "scheme": "https://news.mit.edu/topic/nsf",
          "label": null
        },
        {
          "term": "MIT-IBM Watson AI Lab",
          "scheme": "https://news.mit.edu/topic/mit-ibm-watson-ai-lab",
          "label": null
        },
        {
          "term": "Quest for Intelligence",
          "scheme": "https://news.mit.edu/topic/quest-intelligence",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        }
      ]
    },
    {
      "title": "New algorithms enable efficient machine learning with symmetric data",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "New algorithms enable efficient machine learning with symmetric data"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/new-algorithms-enable-efficient-machine-learning-with-symmetric-data-0730"
        }
      ],
      "link": "https://news.mit.edu/2025/new-algorithms-enable-efficient-machine-learning-with-symmetric-data-0730",
      "summary": "This new approach could lead to enhanced AI models for drug and materials discovery.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new study by MIT researchers shows the first method for machine learning with symmetry that is provably efficient in terms of both the amount of computation and data needed."
      },
      "published": "Wed, 30 Jul 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        30,
        4,
        0,
        0,
        2,
        211,
        0
      ],
      "id": "https://news.mit.edu/2025/new-algorithms-enable-efficient-machine-learning-with-symmetric-data-0730",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>If you rotate an image of a molecular structure, a human can tell the rotated image is still the same molecule, but a machine-learning model might think it is a new data point. In computer science parlance, the molecule is “symmetric,” meaning the fundamental structure of that molecule remains the same if it undergoes certain transformations, like rotation.</p><p>If a drug discovery model doesn’t understand symmetry, it could make inaccurate predictions about molecular properties. But despite some empirical successes, it’s been unclear whether there is a computationally efficient method to train a good model that is guaranteed to respect symmetry.<br /><br />A new study by MIT researchers answers this question, and shows the first method for machine learning with symmetry that is provably efficient in terms of both the amount of computation and data needed.</p><p>These results clarify a foundational question, and they could aid researchers in the development of more powerful machine-learning models that are designed to handle symmetry. Such models would be useful in a variety of applications, from discovering new materials to identifying astronomical anomalies to unraveling complex climate patterns.</p><p>“These symmetries are important because they are some sort of information that nature is telling us about the data, and we should take it into account in our machine-learning models. We’ve now shown that it is possible to do machine-learning with symmetric data in an efficient way,” says Behrooz Tahmasebi, an MIT graduate student and co-lead author of this study.</p><p>He is joined on the <a href=\"https://arxiv.org/pdf/2502.19758\" target=\"_blank\">paper</a> by co-lead author and MIT graduate student Ashkan Soleymani; Stefanie Jegelka, an associate professor of electrical engineering and computer science (EECS) and a member of the Institute for Data, Systems, and Society (IDSS) and the Computer Science and Artificial Intelligence Laboratory (CSAIL); and senior author Patrick Jaillet, the Dugald C. Jackson Professor of Electrical Engineering and Computer Science and a principal investigator in the Laboratory for Information and Decision Systems (LIDS). The research was recently presented at the International Conference on Machine Learning.</p><p><strong>Studying symmetry</strong></p><p>Symmetric data appear in many domains, especially the natural sciences and physics. A model that recognizes symmetries is able to identify an object, like a car, no matter where that object is placed in an image, for example.</p><p>Unless a machine-learning model is designed to handle symmetry, it could be less accurate and prone to failure when faced with new symmetric data in real-world situations. On the flip side, models that take advantage of symmetry could be faster and require fewer data for training.</p><p>But training a model to process symmetric data is no easy task.</p><p>One common approach is called data augmentation, where researchers transform each symmetric data point into multiple data points to help the model generalize better to new data. For instance, one could rotate a molecular structure many times to produce new training data, but if researchers want the model to be guaranteed to respect symmetry, this can be computationally prohibitive.</p><p>An alternative approach is to encode symmetry into the model’s architecture. A well-known example of this is a graph neural network (GNN), which inherently handles symmetric data because of how it is designed.</p><p>“Graph neural networks are fast and efficient, and they take care of symmetry quite well, but nobody really knows what these models are learning or why they work. Understanding GNNs is a main motivation of our work, so we started with a theoretical evaluation of what happens when data are symmetric,” Tahmasebi says.</p><p>They explored the statistical-computational tradeoff in machine learning with symmetric data. This tradeoff means methods that require fewer data can be more computationally expensive, so researchers need to find the right balance.</p><p>Building on this theoretical evaluation, the researchers designed an efficient algorithm for machine learning with symmetric data.</p><p><strong>Mathematical combinations</strong></p><p>To do this, they borrowed ideas from algebra to shrink and simplify the problem. Then, they reformulated the problem using ideas from geometry that effectively capture symmetry.</p><p>Finally, they combined the algebra and the geometry into an optimization problem that can be solved efficiently, resulting in their new algorithm.</p><p>“Most of the theory and applications were focusing on either algebra or geometry. Here we just combined them,” Tahmasebi says.</p><p>The algorithm requires fewer data samples for training than classical approaches, which would improve a model’s accuracy and ability to adapt to new applications.</p><p>By proving that scientists can develop efficient algorithms for machine learning with symmetry, and demonstrating how it can be done, these results could lead to the development of new neural network architectures that could be more accurate and less resource-intensive than current models.</p><p>Scientists could also use this analysis as a starting point to examine the inner workings of GNNs, and how their operations differ from the algorithm the MIT researchers developed.</p><p>“Once we know that better, we can design more interpretable, more robust, and more efficient neural network architectures,” adds Soleymani.</p><p>This research is funded, in part, by the National Research Foundation of Singapore, DSO National Laboratories of Singapore, the U.S. Office of Naval Research, the U.S. National Science Foundation, and an Alexander von Humboldt Professorship.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT_Learning-Symmetric-01.jpg?itok=jTPWN5G8",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: iStock, MIT News"
        }
      ],
      "credit": "Credit: iStock, MIT News",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "IDSS",
          "scheme": "https://news.mit.edu/topic/idss",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "National Science Foundation (NSF)",
          "scheme": "https://news.mit.edu/topic/nsf",
          "label": null
        }
      ]
    },
    {
      "title": "“FUTURE PHASES” showcases new frontiers in music technology and interactive performance",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "“FUTURE PHASES” showcases new frontiers in music technology and interactive performance"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/future-phases-showcase-new-frontiers-music-technology-interactive-performance-0729"
        }
      ],
      "link": "https://news.mit.edu/2025/future-phases-showcase-new-frontiers-music-technology-interactive-performance-0729",
      "summary": "Groundbreaking MIT concert, featuring electronic and computer-generated music, was a part of the 2025 International Computer Music Conference.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A Far Cry performs “EV6” as part of the “FUTURE PHASES” concert at MIT."
      },
      "published": "Tue, 29 Jul 2025 17:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        29,
        21,
        0,
        0,
        1,
        210,
        0
      ],
      "id": "https://news.mit.edu/2025/future-phases-showcase-new-frontiers-music-technology-interactive-performance-0729",
      "guidislink": false,
      "authors": [
        {
          "name": "MIT Music and Theater Arts"
        }
      ],
      "author": "MIT Music and Theater Arts",
      "author_detail": {
        "name": "MIT Music and Theater Arts"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Music technology took center stage at MIT during “FUTURE PHASES,” an evening of works for string orchestra and electronics, presented by the&nbsp;<a href=\"https://musictech.mit.edu/\">MIT Music Technology and Computation Graduate Program</a> as part of the 2025 International Computer Music Conference (ICMC).&nbsp;</p><p>The well-attended event was held last month in the Thomas Tull Concert Hall within the new Edward and Joyce Linde Music Building. Produced in collaboration with the MIT Media Lab’s Opera of the Future Group and Boston’s self-conducted chamber orchestra A Far Cry, “FUTURE PHASES” was the first event to be presented by the MIT Music Technology and Computation Graduate Program in MIT Music’s new space.</p><p>“FUTURE PHASES” offerings included two new works by MIT composers: the world premiere of&nbsp;“EV6,” by MIT Music’s Kenan Sahin Distinguished Professor Evan Ziporyn and professor of the practice Eran Egozy; and the U.S. premiere of&nbsp;“FLOW Symphony,” by the MIT Media Lab’s Muriel R. Cooper Professor of Music and Media Tod Machover. Three additional works were selected by a jury from&nbsp;<a href=\"https://icmc2025.sites.northeastern.edu/special-call-for-scores-mit/\">an open call</a> for works:&nbsp;“The Wind Will Carry Us Away,” by Ali Balighi; “A Blank Page,” by Celeste Betancur&nbsp;Gutiérrez and Luna Valentin; and “Coastal Portrait: Cycles and Thresholds,”&nbsp;by Peter Lane. Each work was performed by&nbsp;Boston’s own&nbsp;multi-Grammy-nominated string orchestra, A Far Cry.</p><p>“The ICMC is all about presenting the latest research, compositions, and performances in electronic music,” says Egozy,&nbsp;director of the new Music Technology and Computation Graduate Program at MIT. When approached to be a part of this year’s conference, “it seemed the perfect opportunity to showcase MIT’s commitment&nbsp;to music technology, and in particular the exciting new areas being developed right now: a new master’s program in music technology and computation, the new Edward and Joyce Linde Music Building with its enhanced music technology facilities, and new faculty arriving at MIT with joint appointments between <a href=\"https://mta.mit.edu/\">MIT Music and Theater Arts</a> (MTA) and the Department of Electrical Engineering and Computer Science (EECS).” These recently hired professors include Anna Huang, a keynote speaker for the conference and creator of the machine learning model&nbsp;Coconet that powered Google’s first AI Doodle, the <a href=\"https://magenta.tensorflow.org/coconet\">Bach Doodle</a>.</p><p>Egozy emphasizes the uniqueness of this occasion: “You have to understand that this is a very special situation. Having a full 18-member string orchestra [A Far Cry] perform new works that include electronics does not happen very often. In most cases, ICMC performances consist either entirely of electronics and computer-generated music, or perhaps a small ensemble of two-to-four musicians. So the opportunity we could present to the larger community of music technology was particularly exciting.”</p><p>To take advantage of this exciting opportunity, an open call was put out internationally to select the other pieces that would accompany Ziporyn and Egozy’s “EV6” and Machover’s “FLOW Symphony.” Three pieces were selected from a total of 46 entries to be a part of the evening’s program by a panel of judges that included Egozy, Machover, and other distinguished composers and technologists.</p><p>“We received a huge variety of works from this call,” says Egozy. “We saw all kinds of musical styles and ways that electronics would be used. No two pieces were very similar to each other, and I think because of that, our audience got a sense of how varied and interesting a concert can be for this format. A Far Cry was really the unifying presence. They played all pieces with great passion and nuance. They have a way of really drawing audiences into the music. And, of course, with the Thomas Tull Concert Hall being in the round, the audience felt even more connected to the music.”</p><p>Egozy continues, “we took advantage of the technology built into the Thomas Tull Concert Hall, which has 24 built-in speakers for surround sound allowing us to broadcast unique, amplified sound to every seat in the house. Chances are that every person might have experienced the sound slightly differently, but there was always some sense of a multidimensional evolution of sound and music as the pieces unfolded.”</p><p>The five works of the evening employed a range of technological components that included playing synthesized, prerecorded, or electronically manipulated sounds; attaching microphones to instruments for use in real-time signal processing algorithms; broadcasting custom-generated musical notation to&nbsp;the musicians; utilizing generative AI to process live sound and play it back in interesting and unpredictable ways; and audience participation, where spectators use their cellphones as musical instruments to become a part of the ensemble.</p><p>Ziporyn and Egozy’s piece, “EV6<em>,”</em> took particular advantage of this last innovation: “Evan and I had previously collaborated on a system called&nbsp;<a href=\"https://musictech.mit.edu/tutti/\">Tutti</a>, which means ‘together’ in Italian. Tutti gives an audience the ability to use their smartphones as musical instruments so that we can all play together.” Egozy developed the technology, which was first used in the MIT Campaign for a Better World in 2017. The original application involved a three-minute piece for cellphones only. “But for this concert,” Egozy explains, “Evan had the idea that we could use the same technology to write a new piece — this time, for audience phones and a live string orchestra as well.”</p><p>To explain the piece’s title, Ziporyn says, “I drive an EV6; it’s my first electric car, and when I first got it, it felt like I was driving an iPhone. But of course it’s still just a car: it’s got wheels and an engine, and it gets me from one place to another. It seemed like a good metaphor for this piece, in which a lot of the sound is literally played on cellphones, but still has to work like any other piece of music. It’s also a bit of an homage to David Bowie’s song ‘TVC 15,’ which is about falling in love with a robot.”</p><p>Egozy adds, “We wanted audience members to feel what it is like to play together in an orchestra. Through this technology, each audience member becomes a part of an orchestral section (winds, brass, strings, etc.). As they play together, they can hear their whole section playing similar music while also hearing other sections in different parts of the hall play different music. This allows an audience to feel a responsibility to their section, hear how music can move between different sections of an orchestra, and experience the thrill of live performance. In ‘EV6,’ this experience was even more electrifying because everyone in the audience got to play with a live string orchestra — perhaps for the first time in recorded history.”</p><p>After the concert, guests were treated to six music technology demonstrations that showcased the research of undergraduate and graduate students from both the MIT Music program and the MIT Media Lab. These included a gamified interface for harnessing just intonation systems (Antonis Christou); insights from a human-AI co-created concert (Lancelot Blanchard and Perry Naseck); a system for analyzing piano playing data across campus (Ayyub Abdulrezak ’24, MEng ’25); capturing music features from audio using latent frequency-masked autoencoders (Mason Wang); a device that turns any surface into a drum machine (Matthew Caren ’25); and a play-along interface for learning traditional Senegalese rhythms (Mariano Salcedo ’25). This last example led to the creation of Senegroove, a drumming-based application specifically designed for an upcoming edX online course taught by ethnomusicologist and MIT associate professor in music Patricia Tang, and world-renowned Senegalese drummer and MIT lecturer in music Lamine Touré, who provided performance videos of the foundational rhythms used in the system.</p><p>Ultimately, Egozy muses, “'FUTURE PHASES' showed how having the right space — in this case, the new Edward and Joyce Linde Music Building — really can be a driving force for new ways of thinking, new projects, and new ways of collaborating. My hope is that everyone in the MIT community, the Boston area, and beyond soon discovers what a truly amazing place and space we have built, and are still building here, for music and music technology at MIT.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT-MTA-6-13-25-335_0.jpg?itok=X_GvlV7G",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo: Jonathan Sachs"
        }
      ],
      "credit": "Photo: Jonathan Sachs",
      "tags": [
        {
          "term": "Performances",
          "scheme": "https://news.mit.edu/topic/performances",
          "label": null
        },
        {
          "term": "Music",
          "scheme": "https://news.mit.edu/topic/music2",
          "label": null
        },
        {
          "term": "Arts",
          "scheme": "https://news.mit.edu/topic/arts",
          "label": null
        },
        {
          "term": "Music technology",
          "scheme": "https://news.mit.edu/topic/music",
          "label": null
        },
        {
          "term": "Electronics",
          "scheme": "https://news.mit.edu/topic/electronics",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Media Lab",
          "scheme": "https://news.mit.edu/topic/media-lab-0",
          "label": null
        },
        {
          "term": "Music and theater arts",
          "scheme": "https://news.mit.edu/topic/music-and-theater-arts",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "School of Architecture and Planning",
          "scheme": "https://news.mit.edu/topic/school-architecture-and-planning",
          "label": null
        },
        {
          "term": "School of Humanities Arts and Social Sciences",
          "scheme": "https://news.mit.edu/topic/school-humanities-arts-and-social-sciences",
          "label": null
        }
      ]
    },
    {
      "title": "Robot, know thyself: New vision-based system teaches machines to understand their bodies",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Robot, know thyself: New vision-based system teaches machines to understand their bodies"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/vision-based-system-teaches-machines-understand-their-bodies-0724"
        }
      ],
      "link": "https://news.mit.edu/2025/vision-based-system-teaches-machines-understand-their-bodies-0724",
      "summary": "Neural Jacobian Fields, developed by MIT CSAIL researchers, can learn to control any robot from a single camera, without any other sensors.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A 3D-printed robotic arm holds a pencil as it trains using random movements and a single camera — part of a new control system called Neural Jacobian Fields (NJF). Rather than relying on sensors or hand-coded models, NJF allows robots to learn how their bodies move in response to motor commands purely from visual observation, offering a pathway to more flexible, affordable, and self-aware robots."
      },
      "published": "Thu, 24 Jul 2025 15:30:00 -0400",
      "published_parsed": [
        2025,
        7,
        24,
        19,
        30,
        0,
        3,
        205,
        0
      ],
      "id": "https://news.mit.edu/2025/vision-based-system-teaches-machines-understand-their-bodies-0724",
      "guidislink": false,
      "authors": [
        {
          "name": "Rachel Gordon | MIT CSAIL"
        }
      ],
      "author": "Rachel Gordon | MIT CSAIL",
      "author_detail": {
        "name": "Rachel Gordon | MIT CSAIL"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\" id=\"docs-internal-guid-ebea3a61-7fff-ad11-8889-4ee6f72a24bc\">In an office at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL), a soft robotic hand carefully curls its fingers to grasp a small object. The intriguing part isn’t the mechanical design or embedded sensors — in fact, the hand contains none. Instead, the entire system relies on a single camera that watches the robot’s movements and uses that visual data to control it.</p><p dir=\"ltr\">This capability comes from a new system CSAIL scientists developed, offering a different perspective on robotic control. Rather than using hand-designed models or complex sensor arrays, it allows robots to learn how their bodies respond to control commands, solely through vision. The approach, called Neural Jacobian Fields (NJF), gives robots a kind of bodily self-awareness. An <a href=\"https://www.nature.com/articles/s41586-025-09170-0\">open-access paper about the work</a> was published in&nbsp;<em>Nature</em> on June 25.</p><p dir=\"ltr\">“This work points to a shift from programming robots to teaching robots,” says Sizhe Lester Li, MIT PhD student in electrical engineering and computer science, CSAIL affiliate, and lead researcher on the work. “Today, many robotics tasks require extensive engineering and coding. In the future, we envision showing a robot what to do, and letting it learn how to achieve the goal autonomously.”</p><p dir=\"ltr\">The motivation stems from a simple but powerful reframing: The main barrier to affordable, flexible robotics isn't hardware — it’s control of capability, which could be achieved in multiple ways. Traditional robots are built to be rigid and sensor-rich, making it easier to construct a digital twin, a precise mathematical replica used for control. But when a robot is soft, deformable, or irregularly shaped, those assumptions fall apart. Rather than forcing robots to match our models, NJF flips the script — giving robots the ability to learn their own internal model from observation.</p><p dir=\"ltr\"><strong>Look and learn</strong></p><p dir=\"ltr\">This decoupling of modeling and hardware design could significantly expand the design space for robotics. In soft and bio-inspired robots, designers often embed sensors or reinforce parts of the structure just to make modeling feasible. NJF lifts that constraint. The system doesn’t need onboard sensors or design tweaks to make control possible. Designers are freer to explore unconventional, unconstrained morphologies without worrying about whether they’ll be able to model or control them later.</p><p dir=\"ltr\">“Think about how you learn to control your fingers: you wiggle, you observe, you adapt,” says Li. “That’s what our system does. It experiments with random actions and figures out which controls move which parts of the robot.”</p><p dir=\"ltr\">The system has proven robust across a range of robot types. The team tested NJF on a pneumatic soft robotic hand capable of pinching and grasping, a rigid Allegro hand, a 3D-printed robotic arm, and even a rotating platform with no embedded sensors. In every case, the system learned both the robot’s shape and how it responded to control signals, just from vision and random motion.</p><p dir=\"ltr\">The researchers see potential far beyond the lab. Robots equipped with NJF could one day perform agricultural tasks with centimeter-level localization accuracy, operate on construction sites without elaborate sensor arrays, or navigate dynamic environments where traditional methods break down.</p><p dir=\"ltr\">At the core of NJF is a neural network that captures two intertwined aspects of a robot’s embodiment: its three-dimensional geometry and its sensitivity to control inputs. The system builds on neural radiance fields (NeRF), a technique that reconstructs 3D scenes from images by mapping spatial coordinates to color and density values. NJF extends this approach by learning not only the robot’s shape, but also a Jacobian field, a function that predicts how any point on the robot’s body moves in response to motor commands.</p><p dir=\"ltr\">To train the model, the robot performs random motions while multiple cameras record the outcomes. No human supervision or prior knowledge of the robot’s structure is required — the system simply infers the relationship between control signals and motion by watching.</p><p dir=\"ltr\">Once training is complete, the robot only needs a single monocular camera for real-time closed-loop control, running at about 12 Hertz. This allows it to continuously observe itself, plan, and act responsively. That speed makes NJF more viable than many physics-based simulators for soft robots, which are often too computationally intensive for real-time use.</p><p dir=\"ltr\">In early simulations, even simple 2D fingers and sliders were able to learn this mapping using just a few examples. By modeling how specific points deform or shift in response to action, NJF builds a dense map of controllability. That internal model allows it to generalize motion across the robot’s body, even when the data are noisy or incomplete.</p><p dir=\"ltr\">“What’s really interesting is that the system figures out on its own which motors control which parts of the robot,” says Li. “This isn’t programmed — it emerges naturally through learning, much like a person discovering the buttons on a new device.”</p><p dir=\"ltr\"><strong>The future is soft</strong></p><p dir=\"ltr\">For decades, robotics has favored rigid, easily modeled machines — like the industrial arms found in factories — because their properties simplify control. But the field has been moving toward soft, bio-inspired robots that can adapt to the real world more fluidly. The trade-off? These robots are harder to model.</p><p dir=\"ltr\">“Robotics today often feels out of reach because of costly sensors and complex programming. Our goal with Neural Jacobian Fields is to lower the barrier, making robotics affordable, adaptable, and accessible to more people. Vision is a resilient, reliable sensor,” says senior author and MIT Assistant Professor Vincent Sitzmann, who leads the Scene Representation group. “It opens the door to robots that can operate in messy, unstructured environments, from farms to construction sites, without expensive infrastructure.”</p><p dir=\"ltr\">“Vision alone can provide the cues needed for localization and control — eliminating the need for GPS, external tracking systems, or complex onboard sensors. This opens the door to robust, adaptive behavior in unstructured environments, from drones navigating indoors or underground without maps to mobile manipulators working in cluttered homes or warehouses, and even legged robots traversing uneven terrain,” says co-author Daniela Rus, MIT professor of electrical engineering and computer science and director of CSAIL. “By learning from visual feedback, these systems develop internal models of their own motion and dynamics, enabling flexible, self-supervised operation where traditional localization methods would fail.”</p><p dir=\"ltr\">While training NJF currently requires multiple cameras and must be redone for each robot, the researchers are already imagining a more accessible version. In the future, hobbyists could record a robot’s random movements with their phone, much like you’d take a video of a rental car before driving off, and use that footage to create a control model, with no prior knowledge or special equipment required.</p><p dir=\"ltr\">The system doesn’t yet generalize across different robots, and it lacks force or tactile sensing, limiting its effectiveness on contact-rich tasks. But the team is exploring new ways to address these limitations: improving generalization, handling occlusions, and extending the model’s ability to reason over longer spatial and temporal horizons.</p><p dir=\"ltr\">“Just as humans develop an intuitive understanding of how their bodies move and respond to commands, NJF gives robots that kind of embodied self-awareness through vision alone,” says Li. “This understanding is a foundation for flexible manipulation and control in real-world environments. Our work, essentially, reflects a broader trend in robotics: moving away from manually programming detailed models toward teaching robots through observation and interaction.”</p><p dir=\"ltr\">This paper brought together the computer vision and self-supervised learning work from the Sitzmann lab and the expertise in soft robots from the Rus lab. Li, Sitzmann, and Rus co-authored the paper with CSAIL affiliates Annan Zhang SM ’22, a PhD student in electrical engineering and computer science (EECS); Boyuan Chen, a PhD student in EECS; Hanna Matusik, an undergraduate researcher in mechanical engineering; and Chao Liu, a postdoc in the Senseable City Lab at MIT.&nbsp;<br /><br />The research was supported by the Solomon Buchsbaum Research Fund through MIT’s Research Support Committee, an MIT Presidential Fellowship, the National Science Foundation, and the Gwangju Institute of Science and Technology.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/njf-mit-csail-00_0.png?itok=rLY1yOfT",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image courtesy of the researchers."
        }
      ],
      "credit": "Image courtesy of the researchers.",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Robotics",
          "scheme": "https://news.mit.edu/topic/robotics",
          "label": null
        },
        {
          "term": "Mechanical engineering",
          "scheme": "https://news.mit.edu/topic/mechanical-engineering",
          "label": null
        },
        {
          "term": "Computer vision",
          "scheme": "https://news.mit.edu/topic/computer-vision",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        }
      ]
    },
    {
      "title": "Pedestrians now walk faster and linger less, researchers find",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Pedestrians now walk faster and linger less, researchers find"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/pedestrians-now-walk-faster-and-linger-less-researchers-find-0724"
        }
      ],
      "link": "https://news.mit.edu/2025/pedestrians-now-walk-faster-and-linger-less-researchers-find-0724",
      "summary": "A computer vision study compares changes in pedestrian behavior since 1980, providing information for urban designers about creating public spaces.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new study finds that people walk faster and linger less in urban settings."
      },
      "published": "Thu, 24 Jul 2025 13:45:00 -0400",
      "published_parsed": [
        2025,
        7,
        24,
        17,
        45,
        0,
        3,
        205,
        0
      ],
      "id": "https://news.mit.edu/2025/pedestrians-now-walk-faster-and-linger-less-researchers-find-0724",
      "guidislink": false,
      "authors": [
        {
          "name": "Peter Dizikes | MIT News"
        }
      ],
      "author": "Peter Dizikes | MIT News",
      "author_detail": {
        "name": "Peter Dizikes | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>City life is often described as “fast-paced.” A new study suggests that’s more true than ever.</p><p>The research, co-authored by MIT scholars, shows that the average walking speed of pedestrians in three northeastern U.S. cities increased 15 percent from 1980 to 2010. The number of people lingering in public spaces declined by 14 percent in that time as well.</p><p>The researchers used machine-learning tools to assess 1980s-era video footage captured by renowned urbanist William Whyte, in Boston, New York, and Philadelphia. They compared the old material with newer videos from the same locations.</p><p>“Something has changed over the past 40 years,” says MIT professor of the practice Carlo Ratti, a co-author of the new study. “How fast we walk, how people meet in public space — what we’re seeing here is that public spaces are working in somewhat different ways, more as a thoroughfare and less a space of encounter.”</p><p>The paper, “<a href=\"https://www.pnas.org/doi/10.1073/pnas.2424662122\" target=\"_blank\">Exploring the social life of urban spaces through AI</a>,” is published this week in the <em>Proceedings of the National Academy of Sciences</em>. The co-authors are Arianna Salazar-Miranda MCP ’16, PhD ’23, an assistant professor at Yale University’s School of the Environment; Zhuanguan Fan of the University of Hong Kong; Michael Baick; Keith N. Hampton, a professor at Michigan State University; Fabio Duarte, associate director of the Senseable City Lab; Becky P.Y. Loo of the University of Hong Kong; Edward Glaeser,&nbsp;the&nbsp;Fred and Eleanor Glimp Professor of Economics at Harvard University; and Ratti, who is also director of MIT’s Senseable City Lab.</p><p>The results could help inform urban planning, as designers seek to create new public areas or modify existing ones.</p><p>“Public space is such an important element of civic life, and today partly because it counteracts the polarization of digital space,” says Salazar-Miranda. “The more we can keep improving public space, the more we can make our cities suited for convening.”</p><p><strong>Meet you at the Met</strong></p><p>Whyte was a prominent social thinker whose famous 1956 book, “The Organization Man,” probing the apparent culture of corporate conformity in the U.S., became a touchstone of its decade.</p><p>However, Whyte spent the latter decades of his career focused on urbanism. The footage he filmed, from 1978 through 1980, was archived by a Brooklyn-based nonprofit organization called the Project for Public Spaces and later digitized by Hampton and his students.</p><p>Whyte chose to make his recording at four spots in the three cities combined: Boston’s Downtown Crossing area; New York City’s Bryant Park; the steps of the Metropolitan Museum of Art in New York, a famous gathering point and people-watching spot; and Philadelphia’s Chestnut Street.</p><p>In 2010, a group led by Hampton then shot new footage at those locations, at the same times of day Whyte had, to compare and contrast current-day dynamics with those of Whyte’s time. To conduct the study, the co-authors used computer vision and AI models to summarize and quantify the activity in the videos.</p><p>The researchers have found that some things have not changed greatly. The percentage of people walking alone barely moved, from 67 percent in 1980 to 68 percent in 2010. On the other hand, the percentage of individuals entering these public spaces who became part of a group declined a bit. In 1980, 5.5 percent of the people approaching these spots met up with a group; in 2010, that was down to 2 percent.</p><p>“Perhaps there’s a more transactional nature to public space today,” Ratti says.</p><p><strong>Fewer outdoor groups: Anomie or Starbucks?</strong></p><p>If people’s behavioral patterns have altered since 1980, it’s natural to ask why. Certainly some of the visible changes seem consistent with the pervasive use of cellphones; people organize their social lives by phone now, and perhaps zip around more quickly from place to place as a result.</p><p>“When you look at the footage from William Whyte, the people in public spaces were looking at each other more,” Ratti says. “It was a place you could start a conversation or run into a friend. You couldn’t do things online then. Today, behavior is more predicated on texting first, to meet in public space.”</p><p>As the scholars note, if groups of people hang out together slightly less often in public spaces, there could be still another reason for that: Starbucks and its competitors. As the paper states, outdoor group socializing may be less common due to “the proliferation of coffee shops and other indoor venues. Instead of lingering on sidewalks, people may have moved their social interactions into air-conditioned, more comfortable private spaces.”</p><p>Certainly coffeeshops were far less common in big cities in 1980, and the big chain coffeeshops did not exist.</p><p>On the other hand, public-space behavior might have been evolving all this time regardless of Starbucks and the like. The researchers say the new study offers a proof-of-concept for its method and has encouraged them to conduct additional work. Ratti, Duarte, and other researchers from MIT’s Senseable City Lab have turned their attention to an extensive survey of European public spaces in an attempt to shed more light on the interaction between people and the public forum.</p><p>“We are collecting footage from 40 squares in Europe,” Duarte says. “The question is: How can we learn at a larger scale? This is in part what we’re doing.”&nbsp;</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT_Urban-Walking-01.jpg?itok=YTbccwQn",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: iStock"
        }
      ],
      "credit": "Credit: iStock",
      "tags": [
        {
          "term": "Urban studies and planning",
          "scheme": "https://news.mit.edu/topic/urban-studies",
          "label": null
        },
        {
          "term": "Cities",
          "scheme": "https://news.mit.edu/topic/cities",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Computer vision",
          "scheme": "https://news.mit.edu/topic/computer-vision",
          "label": null
        },
        {
          "term": "Technology and society",
          "scheme": "https://news.mit.edu/topic/technology-society",
          "label": null
        },
        {
          "term": "Social media",
          "scheme": "https://news.mit.edu/topic/social-media",
          "label": null
        },
        {
          "term": "School of Architecture and Planning",
          "scheme": "https://news.mit.edu/topic/school-architecture-and-planning",
          "label": null
        }
      ]
    },
    {
      "title": "New machine-learning application to help researchers predict chemical properties",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "New machine-learning application to help researchers predict chemical properties"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/chemxploreml-app-helps-predict-chemical-properties-0724"
        }
      ],
      "link": "https://news.mit.edu/2025/chemxploreml-app-helps-predict-chemical-properties-0724",
      "summary": "ChemXploreML makes advanced chemical predictions easier and faster — without requiring deep programming skills.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT researchers developed ChemXploreML, a new desktop application that provides an automated and user-friendly approach to predicting molecular properties using machine learning, making advanced machine-learning methods accessible to chemists without requiring extensive programming expertise."
      },
      "published": "Thu, 24 Jul 2025 13:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        24,
        17,
        0,
        0,
        3,
        205,
        0
      ],
      "id": "https://news.mit.edu/2025/chemxploreml-app-helps-predict-chemical-properties-0724",
      "guidislink": false,
      "authors": [
        {
          "name": "Danielle Randall Doughty | Department of Chemistry"
        }
      ],
      "author": "Danielle Randall Doughty | Department of Chemistry",
      "author_detail": {
        "name": "Danielle Randall Doughty | Department of Chemistry"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\">One of the shared, fundamental goals of most chemistry researchers is the need to predict a molecule’s properties, such as its boiling or melting point. Once researchers can pinpoint that prediction, they’re able to move forward with their work yielding discoveries that lead to medicines, materials, and more. Historically, however, the traditional methods of unveiling these predictions are associated with a significant cost — expending time and wear and tear on equipment, in addition to funds.</p><p dir=\"ltr\">Enter a branch of artificial intelligence known as machine learning (ML). ML has lessened the burden of molecule property prediction to a degree, but the advanced tools that most effectively expedite the process — by learning from existing data to make rapid predictions for new molecules — require the user to have a significant level of programming expertise. This creates an accessibility barrier for many chemists, who may not have the significant computational proficiency required to navigate the prediction pipeline.&nbsp;</p><p dir=\"ltr\">To alleviate this challenge, researchers in the <a href=\"https://mcguirelab.mit.edu/\">McGuire Research Group</a> at MIT have created <a href=\"https://aravindhnivas.github.io/ChemXploreML-docs/\">ChemXploreML</a>, a user-friendly desktop app that helps chemists make these critical predictions without requiring advanced programming skills. Freely available, easy to download, and functional on mainstream platforms, this app is also built to operate entirely offline, which helps keep research data proprietary. The exciting new technology is outlined in an <a href=\"https://pubs.acs.org/doi/10.1021/acs.jcim.5c00516\">article published recently in&nbsp;the <em>Journal of Chemical Information and Modeling</em></a>.</p><p dir=\"ltr\">One specific hurdle in chemical machine learning is translating molecular structures into a numerical language that computers can understand. ChemXploreML automates this complex process with powerful, built-in \"molecular embedders\" that transform chemical structures into informative numerical vectors. Next, the software implements state-of-the-art algorithms to identify patterns and accurately predict molecular properties like boiling and melting points, all through an intuitive, interactive graphical interface.&nbsp;</p><p dir=\"ltr\">\"The goal of ChemXploreML is to democratize the use of machine learning in the chemical sciences,” says&nbsp;Aravindh Nivas Marimuthu, a postdoc in the McGuire Group and lead author of the article. “By creating an intuitive, powerful, and offline-capable desktop application, we are putting state-of-the-art predictive modeling directly into the hands of chemists, regardless of their programming background. This work not only accelerates the search for new drugs and materials by making the screening process faster and cheaper, but its flexible design also opens doors for future innovations.”&nbsp;</p><p dir=\"ltr\">ChemXploreML is designed to to evolve over time, so as future techniques and algorithms are developed, they can be seamlessly integrated into the app, ensuring that researchers are always able to access and implement the most up-to-date methods. The application was tested on five key molecular properties of organic compounds — melting point, boiling point, vapor pressure, critical temperature, and critical pressure — and achieved high accuracy scores of up to 93 percent for the critical temperature. The researchers also demonstrated that a new, more compact method of representing molecules (VICGAE) was nearly as accurate as standard methods, such as Mol2Vec, but was up to 10 times faster.</p><p dir=\"ltr\">“We envision a future where any researcher can easily customize and apply machine learning to solve unique challenges, from developing sustainable materials to exploring the complex chemistry of interstellar space,” says Marimuthu. Joining him on the paper is senior author and Class of 1943 Career Development Assistant Professor of Chemistry Brett McGuire.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/chemxploreml-desktop-00_0.jpg?itok=mT00j-9C",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image courtesy of the researchers."
        }
      ],
      "credit": "Image courtesy of the researchers.",
      "tags": [
        {
          "term": "Chemistry",
          "scheme": "https://news.mit.edu/topic/chemistry-0",
          "label": null
        },
        {
          "term": "Apps",
          "scheme": "https://news.mit.edu/topic/apps",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Software",
          "scheme": "https://news.mit.edu/topic/software",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Open source",
          "scheme": "https://news.mit.edu/topic/open-source",
          "label": null
        },
        {
          "term": "Invention",
          "scheme": "https://news.mit.edu/topic/invention",
          "label": null
        },
        {
          "term": "Drug discovery",
          "scheme": "https://news.mit.edu/topic/drug-discovery",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        }
      ]
    },
    {
      "title": "School of Architecture and Planning recognizes faculty with academic promotions in 2025",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "School of Architecture and Planning recognizes faculty with academic promotions in 2025"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/school-architecture-planning-recognizes-faculty-academic-promotions-0722"
        }
      ],
      "link": "https://news.mit.edu/2025/school-architecture-planning-recognizes-faculty-academic-promotions-0722",
      "summary": "The faculty members’ work comprises multifaceted research and scholarship across a wide range of disciplines.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Top row, from left to right: Marcelo Coelho, Carlo Ratti, Albert Saiz, and Holly Samuelson. Bottom row, from left to right: Deblina Sarkar, Rafi Segal, and Delia Wendel"
      },
      "published": "Tue, 22 Jul 2025 10:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        22,
        14,
        0,
        0,
        1,
        203,
        0
      ],
      "id": "https://news.mit.edu/2025/school-architecture-planning-recognizes-faculty-academic-promotions-0722",
      "guidislink": false,
      "authors": [
        {
          "name": "The Phong Justin Ngo | School of Architecture and Planning"
        }
      ],
      "author": "The Phong Justin Ngo | School of Architecture and Planning",
      "author_detail": {
        "name": "The Phong Justin Ngo | School of Architecture and Planning"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Seven faculty in the MIT School of Architecture and Planning (SA+P) have been honored for their contributions through promotions, effective July 1. Three faculty promotions are in the Department of Architecture; three are in the Department of Urban Studies and Planning; and one is in the Program in Media Arts and Sciences.</p><p>“Whether architects, urbanists, computer scientists, or nanotechnologists, they represent our school at its best, in its breadth of inquiry and mission to improve the relationship between human beings and their environments,” says SA+P Dean Hashim Sarkis.</p><p><strong>Department of Architecture</strong></p><p><a href=\"https://architecture.mit.edu/people/marcelo-coelho\"><strong>Marcelo Coelho</strong></a> has been promoted to associate professor of the practice. Coelho is the director of the <a href=\"https://designintelligence.mit.edu/\">Design Intelligence Lab</a>, which explores the intersection of human and machine intelligence across design, AI, and fabrication. His work ranges from light-based installations to physical computing. Recognition for his work includes two Prix Ars Electronica awards and <em>Fast Company</em>’s Innovation by Design Award. Coelho’s experimental approach redefines creative processes, transforming how we imagine and interact with intelligent systems. Coelho teaches courses that bring together industrial design, user experience, and artificial intelligence.</p><p><a href=\"https://architecture.mit.edu/people/holly-samuelson\"><strong>Holly Samuelson</strong></a> has been promoted to associate professor without tenure. Samuelson has co-authored over 40 peer-reviewed papers, winning a Best Paper award from the journal <em>Energy and Building.</em> As a recognized expert in architectural technology, she has been featured in media outlets such as <em>The Washington Post</em>, <em>The Boston Globe</em>, the BBC, and <em>The Wall Street Journal</em>.</p><p><a href=\"https://architecture.mit.edu/people/rafi-segal\"><strong>Rafi Segal</strong></a> has been promoted to full professor. An award-winning designer, Segal works across architectural and urban scales, with projects ranging from Villa 003 in the ORDOS 100 series to the Kitgum Peace Museum in Uganda, the Ashdod Museum of Art in Israel, and the winning design proposal for the National Library of Israel in Jerusalem. His current work includes planning a new communal neighborhood for an Israeli kibbutz and curating the first exhibition on Alfred Neumann’s 1960s architecture.</p><p><strong>Department of Urban Studies and Planning (DUSP)</strong></p><p><a href=\"https://dusp.mit.edu/people/carlo-ratti\"><strong>Carlo Ratti</strong></a> has been reappointed as professor of the practice. Ratti is the director of the <a href=\"http://senseable.mit.edu/\">Senseable City Lab</a> and a founding partner of the international design office Carlo Ratti Associati. He has co-authored over 500 publications and holds several patents. His work has been exhibited globally, including at the Venice Biennale, the Museum of Modern Art in New York City, and the Design Museum in Barcelona. Two of his projects, the Digital Water Pavilion and the Copenhagen Wheel, were named among <em>TIME Magazine</em>’s “Best Inventions of the Year.” He is the curator of the 2025 Venice Biennale’s <a href=\"https://carlorattiassociati.com/project/intelligens-natural-artificial-collective-biennale-architettura-2\">19th International Architecture Exhibition</a>.</p><p><a href=\"https://dusp.mit.edu/people/albert-saiz\"><strong>Albert Saiz</strong></a> has been promoted to full professor. Saiz serves as the director of MIT’s <a href=\"https://urbaneconomics.mit.edu/\">Urban Economics Lab</a>, which conducts research on real estate economics, urban economics, housing markets, local public finance, zoning regulations, global real estate, and demographic trends affecting urban and real estate development worldwide. He also contributes to the broader research community as a visiting scholar at the Federal Reserve Bank of Philadelphia, a research fellow at the Institute for the Analysis of Labor, and editor for the <em>Journal of Housing Economics</em>.</p><p><a href=\"https://dusp.mit.edu/people/delia-wendel\"><strong>Delia Wendel</strong></a>&nbsp;has been promoted to associate professor without tenure. Wendel’s research engages three main areas: forms of community repair after conflict and disaster, African urbanism, and spatial politics. Her interdisciplinary work draws together urban studies, critical peace studies, architectural history, cultural geography, and anthropology.&nbsp;At MIT DUSP, she leads the Planning for Peace critical collective and oversees the Mellon Foundation and the MIT Center for Art, Science and Technology-funded research and exhibition project, Memory Atlas for Repair. She also serves as the managing editor of <em>Projections,</em> the department’s annual peer-reviewed journal on critical issues in urban studies and planning.</p><p><strong>Program in Media Arts and Sciences</strong></p><p><a href=\"https://www.media.mit.edu/people/deblina/overview/\"><strong>Deblina Sarkar</strong></a> has been promoted to associate professor without tenure. As the director of the <a href=\"https://www.media.mit.edu/groups/nano-cybernetic-biotrek/overview/\">Nano-Cybernetic Biotrek Lab</a> at the MIT Media Lab, she merges nanoelectronics, physics, and biology to create groundbreaking technologies, from ultra-thin quantum transistors to the first antenna that operates inside living cells. Her interdisciplinary work has earned her major honors, including the National Institutes of Health Director’s New Innovator Award and the IEEE Early Career Award in Nanotechnology.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/mit-sap-faculty-promotions.jpg?itok=AwYauNn7",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photos courtesy of the School of Architecture and Planning."
        }
      ],
      "credit": "Photos courtesy of the School of Architecture and Planning.",
      "tags": [
        {
          "term": "School of Architecture and Planning",
          "scheme": "https://news.mit.edu/topic/school-architecture-and-planning",
          "label": null
        },
        {
          "term": "Architecture",
          "scheme": "https://news.mit.edu/topic/architecture",
          "label": null
        },
        {
          "term": "Urban studies and planning",
          "scheme": "https://news.mit.edu/topic/urban-studies",
          "label": null
        },
        {
          "term": "Center for Real Estate",
          "scheme": "https://news.mit.edu/topic/center-real-estate-0",
          "label": null
        },
        {
          "term": "Media Lab",
          "scheme": "https://news.mit.edu/topic/media-lab-0",
          "label": null
        },
        {
          "term": "MIT Morningside Academy for Design",
          "scheme": "https://news.mit.edu/topic/mit-morningside-academy-design",
          "label": null
        },
        {
          "term": "Real estate",
          "scheme": "https://news.mit.edu/topic/real-estate",
          "label": null
        },
        {
          "term": "Housing",
          "scheme": "https://news.mit.edu/topic/housing",
          "label": null
        },
        {
          "term": "Design",
          "scheme": "https://news.mit.edu/topic/design",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Nanoscience and nanotechnology",
          "scheme": "https://news.mit.edu/topic/nanotech",
          "label": null
        },
        {
          "term": "Faculty",
          "scheme": "https://news.mit.edu/topic/faculty",
          "label": null
        },
        {
          "term": "Awards, honors and fellowships",
          "scheme": "https://news.mit.edu/topic/awards",
          "label": null
        },
        {
          "term": "Education, teaching, academics",
          "scheme": "https://news.mit.edu/topic/education",
          "label": null
        }
      ]
    },
    {
      "title": "A new way to edit or generate images",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new way to edit or generate images"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/new-way-edit-or-generate-images-0721"
        }
      ],
      "link": "https://news.mit.edu/2025/new-way-edit-or-generate-images-0721",
      "summary": "MIT researchers found that special kinds of neural networks, called encoders or “tokenizers,” can do much more than previously realized.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A system capable of generating images normally requires a tokenizer, which compresses and encodes visual data, along with a generator that can combine and arrange these compact representations in order to create novel images. MIT researchers discovered a new method to create, convert, and “inpaint” images without using a generator at all. This image shows how an input image can be gradually modified by optimizing tokens."
      },
      "published": "Mon, 21 Jul 2025 15:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        21,
        19,
        0,
        0,
        0,
        202,
        0
      ],
      "id": "https://news.mit.edu/2025/new-way-edit-or-generate-images-0721",
      "guidislink": false,
      "authors": [
        {
          "name": "Steve Nadis | MIT CSAIL | Laboratory for Information and Decision Systems"
        }
      ],
      "author": "Steve Nadis | MIT CSAIL | Laboratory for Information and Decision Systems",
      "author_detail": {
        "name": "Steve Nadis | MIT CSAIL | Laboratory for Information and Decision Systems"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>AI image generation — which relies on neural networks to create new images from a variety of inputs, including text prompts — is projected to become a billion-dollar industry by the end of this decade. Even with today’s technology, if you wanted to make a fanciful picture of, say, a friend planting a flag on Mars or heedlessly flying into a black hole, it could take less than a second. However, before they can perform tasks like that, image generators are commonly trained on massive datasets containing millions of images that are often paired with associated text. Training these generative models can be an arduous chore that takes weeks or months, consuming vast computational resources in the process.</p><p>But what if it were possible to generate images through AI methods without using a generator at all? That real possibility, along with other intriguing ideas, was described in a <a href=\"https://arxiv.org/pdf/2506.08257\">research paper</a> presented at the International Conference on Machine Learning (ICML 2025), which was held in Vancouver, British Columbia, earlier this summer. The paper, describing novel techniques for manipulating and generating images, was written by Lukas Lao Beyer, a graduate student researcher in MIT’s Laboratory for Information and Decision Systems (LIDS); Tianhong Li, a postdoc at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL); Xinlei Chen of Facebook AI Research; Sertac Karaman, an MIT professor of aeronautics and astronautics and the director of LIDS; and Kaiming He, an MIT associate professor of electrical engineering and computer science.</p><p>This group effort had its origins in a class project for a graduate seminar on deep generative models that Lao Beyer took last fall. In conversations during the semester, it became apparent to both Lao Beyer and He, who taught the seminar, that this research had real potential, which went far beyond the confines of a typical homework assignment. Other collaborators were soon brought into the endeavor.</p><p>The starting point for Lao Beyer’s inquiry was a June 2024 paper, written by researchers from the Technical University of Munich and the Chinese company ByteDance, which introduced a new way of representing visual information called a one-dimensional tokenizer. With this device, which is also a kind of neural network, a 256x256-pixel image can be translated into a sequence of just 32 numbers, called tokens. “I wanted to understand how such a high level of compression could be achieved, and what the tokens themselves actually represented,” says Lao Beyer.</p><p>The previous generation of tokenizers would typically break up the same image into an array of 16x16 tokens — with each token encapsulating information, in highly condensed form, that corresponds to a specific portion of the original image. The new 1D tokenizers can encode an image more efficiently, using far fewer tokens overall, and these tokens are able to capture information about the entire image, not just a single quadrant. Each of these tokens, moreover, is a 12-digit number consisting of 1s and 0s, allowing for 2<sup>12</sup> (or about 4,000) possibilities altogether. “It’s like a vocabulary of 4,000 words that makes up an abstract, hidden language spoken by the computer,” He explains. “It’s not like a human language, but we can still try to find out what it means.”</p><p>That’s exactly what Lao Beyer had initially set out to explore — work that provided the seed for the ICML 2025 paper. The approach he took was pretty straightforward. If you want to find out what a particular token does, Lao Beyer says, “you can just take it out, swap in some random value, and see if there is a recognizable change in the output.” Replacing one token, he found, changes the image quality, turning a low-resolution image into a high-resolution image or vice versa. Another token affected the blurriness in the background, while another still influenced the brightness. He also found a token that’s related to the “pose,” meaning that, in the image of a robin, for instance, the bird’s head might shift from right to left.</p><p>“This was a never-before-seen result, as no one had observed visually identifiable changes from manipulating tokens,” Lao Beyer says. The finding raised the possibility of a new approach to editing images. And the MIT group has shown, in fact, how this process can be streamlined and automated, so that tokens don’t have to be modified by hand, one at a time.</p><p>He and his colleagues achieved an even more consequential result involving image generation. A system capable of generating images normally requires a tokenizer, which compresses and encodes visual data, along with a generator that can combine and arrange these compact representations in order to create novel images. The MIT researchers found a way to create images without using a generator at all. Their new approach makes use of a 1D tokenizer and a so-called detokenizer (also known as a decoder), which can reconstruct an image from a string of tokens. However, with guidance provided by an off-the-shelf neural network called CLIP —&nbsp;which cannot generate images on its own, but can measure how well a given image matches a certain text prompt&nbsp;— the team was able to convert an image of a red panda, for example, into a tiger. In addition, they could create images of a tiger, or any other desired form, starting completely from scratch — from a situation in which all the tokens are initially assigned random values (and then iteratively tweaked so that the reconstructed image increasingly matches the desired text prompt).</p><p>The group demonstrated that with this same setup — relying on a tokenizer and detokenizer, but no generator — they could also do “inpainting,” which means filling in parts of images that had somehow been blotted out. Avoiding the use of a generator for certain tasks could lead to a significant reduction in computational costs because generators, as mentioned, normally require extensive training.</p><p>What might seem odd about this team’s contributions, He explains, “is that we didn’t invent anything new. We didn’t invent a 1D tokenizer, and we didn’t invent the CLIP model, either. But we did discover that new capabilities can arise when you put all these pieces together.”</p><p>“This work redefines the role of tokenizers,” comments&nbsp;Saining Xie, a computer scientist at New York University. “It shows that&nbsp;image tokenizers — tools usually used just to compress images — can actually do a lot more. The fact that a simple (but highly compressed) 1D tokenizer can handle tasks like inpainting or text-guided editing, without needing to train a full-blown generative model, is pretty surprising.”</p><p>Zhuang Liu of Princeton University agrees, saying that the work of the MIT group&nbsp;“shows that we can generate and manipulate the images in a way that is much easier than we previously thought. Basically, it demonstrates that image generation can be a byproduct of a very effective image compressor, potentially reducing the cost of generating images several-fold.”</p><p>There could be many applications outside the field of computer vision, Karaman suggests. “For instance,&nbsp;we could consider tokenizing the actions of robots or self-driving cars in the same way, which may rapidly broaden the impact of this work.”</p><p>Lao Beyer is thinking along similar lines,&nbsp;noting that the&nbsp;extreme amount of compression afforded by 1D tokenizers allows you to do “some amazing things,” which could be applied to other fields. For example, in the area of self-driving cars, which is one of his research interests, the tokens could represent, instead of images, the different routes that a vehicle might take.</p><p>Xie is also intrigued by the applications that may come from these innovative ideas. “There are some really cool use cases this could unlock,” he says.&nbsp;</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/mit-token-opt3.jpg?itok=A759koh8",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image courtesy of the authors."
        }
      ],
      "credit": "Image courtesy of the authors.",
      "tags": [
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "Aeronautical and astronautical engineering",
          "scheme": "https://news.mit.edu/topic/aeronautics",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Computer vision",
          "scheme": "https://news.mit.edu/topic/computer-vision",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        }
      ]
    },
    {
      "title": "MIT Learn offers “a whole new front door to the Institute”",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT Learn offers “a whole new front door to the Institute”"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/mit-learn-offers-whole-new-front-door-institute-0721"
        }
      ],
      "link": "https://news.mit.edu/2025/mit-learn-offers-whole-new-front-door-institute-0721",
      "summary": "The AI-enabled platform serves as a hub for MIT’s lifelong learning opportunities.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT Learn offers more than 12,700 educational resources — including introductory and advanced courses, courseware, videos, podcasts, and more — from departments across MIT."
      },
      "published": "Mon, 21 Jul 2025 15:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        21,
        19,
        0,
        0,
        0,
        202,
        0
      ],
      "id": "https://news.mit.edu/2025/mit-learn-offers-whole-new-front-door-institute-0721",
      "guidislink": false,
      "authors": [
        {
          "name": "Sara Feijo | MIT Open Learning"
        }
      ],
      "author": "Sara Feijo | MIT Open Learning",
      "author_detail": {
        "name": "Sara Feijo | MIT Open Learning"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\">In 2001, MIT became the first higher education institution to provide educational resources for free to anyone in the world. Fast forward 24 years: The Institute has now launched a dynamic AI-enabled website for its non-degree learning opportunities, making it easier for learners around the world to discover the courses and resources available on MIT’s various learning platforms.</p><p dir=\"ltr\"><a href=\"https://learn.mit.edu/\">MIT Learn</a> enables learners to access more than 12,700 educational resources — including introductory and advanced courses, courseware, videos, podcasts, and more — from departments across the Institute. MIT Learn is designed to seamlessly connect the existing Institute’s learning platforms in one place.</p><p dir=\"ltr\">“With MIT Learn, we’re opening access to MIT’s digital learning opportunities for millions around the world,” says Dimitris Bertsimas, vice provost for open learning. “MIT Learn elevates learning with personalized recommendations powered by AI, guiding each learner toward deeper understanding. It is a stepping stone toward a broader vision of making these opportunities even more accessible to global learners through one unified learning platform.”</p><p dir=\"ltr\">The goal for MIT Learn is twofold: to allow learners to find what they want to fulfill their curiosity, and to enable learners to develop a long-term relationship with MIT as a source of educational experiences.&nbsp;</p><p dir=\"ltr\">“By fostering long-term connections between learners and MIT, we not only provide a pathway to continued learning, but also advance MIT’s mission to disseminate knowledge globally,” says Ferdi Alimadhi, chief technology officer for MIT Open Learning and the lead of the MIT Learn project. “With this initial launch of MIT Learn, we’re introducing AI-powered features that leverage emerging technologies to help learners discover the right content, engage with it more deeply, and stay supported as they shape their own educational journeys.”&nbsp;</p><p dir=\"ltr\">With its sophisticated search, browse, and discovery capability, MIT Learn allows learners to explore topics without having to understand MIT’s organizational structure or know the names of departments and programs. An AI-powered recommendation feature called “Ask Tim” complements the site’s traditional search and browsing tools, helping learners quickly find courses and resources aligned with their personal and professional goals. Learners can also prompt “Ask Tim” for a summary of a course’s structure, topics, and expectations, leading to more-informed decisions before enrolling.</p><p dir=\"ltr\">In select offerings, such as <a href=\"https://learn.mit.edu/search?resource=16639\">Molecular Biology: DNA Replication and Repair</a>, <a href=\"https://learn.mit.edu/search?resource=16799\">Genetics: The Fundamentals</a>, and <a href=\"https://learn.mit.edu/search?resource=16794\">Cell Biology: Transport and Signaling</a>, learners can interact with an AI assistant by asking questions about a lecture, requesting flashcards of key concepts, and obtaining instant summaries. These select offerings also feature an AI tutor to support learners as they work through problem sets, guiding them toward the next step without giving away the answers. These features, Alimadhi says, are being introduced in a limited set of courses and modules to allow the MIT Open Learning team to gather insights and improve the learning experience before expanding more broadly.</p><p dir=\"ltr\">“MIT Learn is a whole new front door to the Institute,” says Christopher Capozzola, senior associate dean for open learning, who worked with faculty across the Institute on the project. “Just as the Kendall Square renovations transformed the way that people interact with our physical campus, MIT Learn transforms how people engage with what we offer digitally.”</p><p dir=\"ltr\">Learners who choose to create an account on MIT Learn receive personalized course recommendations and can create and curate lists of educational resources, follow their specific areas of interest, and receive notifications when new MIT content is available. They can also personalize their learning experience based on their specific interests and choose the format that is best suited to them.</p><p dir=\"ltr\">\"From anywhere and for anyone, MIT Learn makes lifelong learning more accessible and personalized, building on the Institute’s decades of global leadership in open learning,” says MIT Provost Anantha Chandrakasan.</p><p dir=\"ltr\">MIT Learn was designed to account for a learner’s evolving needs throughout their learning journey. It highlights supplemental study materials for middle schoolers, high schoolers, and college students, upskilling opportunities for early-career professionals, reskilling programs for those considering a career shift, and resources for educators.</p><p dir=\"ltr\">“MIT has an amazing collection of learning opportunities, covering a wide range of formats,” says Eric Grimson, chancellor for academic advancement, who oversaw the initial development of MIT Learn during his time as interim vice president for open learning. “The sheer size of that collection can be daunting, so creating a platform that brings all of those offerings together, in an easily searchable framework, greatly enhances our ability to serve learners.”</p><p dir=\"ltr\">According to Peter Hirst, senior associate dean for executive education at MIT Sloan School of Management, one of the Institute's incredible strengths is its sheer volume and diversity of expertise, research, and learning opportunities. But it can be challenging to discover and follow all those opportunities — even for people who are immersed in the on-campus experience. MIT Learn, he says, is a solution to this problem.</p><p dir=\"ltr\">“MIT Learn gathers all the knowledge and learning resources offered across all of MIT into a learner-friendly, curatable repository that enables anyone and everyone, whatever their interests or learning needs,&nbsp;to explore and engage in the wide range of learning resources and public certificate programs that MIT has to offer and that can help them achieve their goals,” Hirst says.</p><p dir=\"ltr\">MIT Learn was spearheaded by MIT Open Learning, which aims to transform teaching and learning on and off the Institute’s campus. MIT Learn was developed with the direction of former provost Cynthia Barnhart, and in cooperation with MIT Sloan Executive Education and MIT Professional Education. During the design phase, OpenCourseWare Faculty Advisory Committee Chair Michael Short and&nbsp;<em>MITx</em>&nbsp;Faculty Advisory Committee Chair Caspar Hare contributed key insights, along with other numerous faculty involved with Open Learning’s product offerings, including OpenCourseWare,&nbsp;<em>MITx</em>, and MicroMasters programs. MIT Learn is also informed by the insights of the Ad Hoc Committee on&nbsp;<em>MITx</em>&nbsp;and&nbsp;<em>MITx</em> Online.</p><p dir=\"ltr\">“For over 20 years, MIT staff and faculty have been creating a wealth of online resources, from lecture videos to practice problems, and from single online courses to entire credential-earning programs,” says Sara Fisher Ellison, a member of the Ad Hoc Committee on&nbsp;<em>MITx</em>&nbsp;and&nbsp;<em>MITx</em> Online and the faculty lead for the online&nbsp;<em>MITx</em> MicroMasters Program in Data, Economics, and Design of Policy. “Making these resources findable, searchable, and broadly available is a natural extension of MIT’s core educational mission. MIT Learn is a big, important step in that direction. We are excited for the world to see what we have to offer.”</p><p dir=\"ltr\">Looking ahead, MIT Learn will also feature selected content from the MIT Press. As MIT Learn continues to grow, Open Learning is exploring collaborations with departments across the Institute with the goal of offering the fullest possible range of educational materials from MIT to learners around the world.</p><p dir=\"ltr\">“MIT Learn is the latest step in a long tradition of the Institute providing innovative ways for learners to access knowledge,” Barnhart says. “This AI-enabled platform delivers on the Institute’s commitment to help people launch into learning journeys that can unlock life-changing opportunities.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT_Learn_07212025_0.jpg?itok=n_sg0sxG",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image courtesy of MIT Open Learning."
        }
      ],
      "credit": "Image courtesy of MIT Open Learning.",
      "tags": [
        {
          "term": "MIT Sloan School of Management",
          "scheme": "https://news.mit.edu/topic/mit-sloan-school-management",
          "label": null
        },
        {
          "term": "MITx",
          "scheme": "https://news.mit.edu/topic/mitx",
          "label": null
        },
        {
          "term": "MIT Press",
          "scheme": "https://news.mit.edu/topic/mit-press",
          "label": null
        },
        {
          "term": "Office of Open Learning",
          "scheme": "https://news.mit.edu/topic/office-open-learning",
          "label": null
        },
        {
          "term": "OpenCourseWare",
          "scheme": "https://news.mit.edu/topic/opencourseware",
          "label": null
        },
        {
          "term": "Education, teaching, academics",
          "scheme": "https://news.mit.edu/topic/education",
          "label": null
        },
        {
          "term": "STEM education",
          "scheme": "https://news.mit.edu/topic/stem-education",
          "label": null
        },
        {
          "term": "K-12 education",
          "scheme": "https://news.mit.edu/topic/k-12-education",
          "label": null
        },
        {
          "term": "Classes and programs",
          "scheme": "https://news.mit.edu/topic/classes-and-programs",
          "label": null
        },
        {
          "term": "Learning",
          "scheme": "https://news.mit.edu/topic/learning",
          "label": null
        },
        {
          "term": "Online learning",
          "scheme": "https://news.mit.edu/topic/onlinelearning",
          "label": null
        },
        {
          "term": "Open access",
          "scheme": "https://news.mit.edu/topic/open-access",
          "label": null
        },
        {
          "term": "Massive open online courses (MOOCs)",
          "scheme": "https://news.mit.edu/topic/massive-open-online-courses-moocs",
          "label": null
        },
        {
          "term": "Human-computer interaction",
          "scheme": "https://news.mit.edu/topic/human-computer-interaction",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Global",
          "scheme": "https://news.mit.edu/topic/global",
          "label": null
        },
        {
          "term": "MIT Professional Education",
          "scheme": "https://news.mit.edu/topic/mit-professional-education-0",
          "label": null
        }
      ]
    },
    {
      "title": "The unique, mathematical shortcuts language models use to predict dynamic scenarios",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "The unique, mathematical shortcuts language models use to predict dynamic scenarios"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/unique-mathematical-shortcuts-language-models-use-to-predict-dynamic-scenarios-0721"
        }
      ],
      "link": "https://news.mit.edu/2025/unique-mathematical-shortcuts-language-models-use-to-predict-dynamic-scenarios-0721",
      "summary": "Language models follow changing situations using clever arithmetic, instead of sequential tracking. By controlling when these approaches are used, engineers could improve the systems’ capabilities.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Researchers from MIT CSAIL and Department of Electrical Engineering and Computer Science evaluated how closely language models could keep track of objects that change position rapidly. They found that they could steer the models toward or away from particular approaches, improving the system’s predictive capabilities."
      },
      "published": "Mon, 21 Jul 2025 08:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        21,
        12,
        0,
        0,
        0,
        202,
        0
      ],
      "id": "https://news.mit.edu/2025/unique-mathematical-shortcuts-language-models-use-to-predict-dynamic-scenarios-0721",
      "guidislink": false,
      "authors": [
        {
          "name": "Alex Shipps | MIT CSAIL"
        }
      ],
      "author": "Alex Shipps | MIT CSAIL",
      "author_detail": {
        "name": "Alex Shipps | MIT CSAIL"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\" id=\"docs-internal-guid-5c520fa2-7fff-f3a1-cecc-40dddcfcf883\">Let’s say you’re reading a story, or playing a game of chess. You may not have noticed, but each step of the way, your mind kept track of how the situation (or “state of the world”) was changing. You can imagine this as a sort of sequence of events list, which we use to update our prediction of what will happen next.<br /><br />Language models like ChatGPT also track changes inside their own “mind” when finishing off a block of code or anticipating what you’ll write next. They typically make educated guesses using transformers — internal architectures that help the models understand sequential data — but the systems are sometimes incorrect because of flawed thinking patterns. Identifying and tweaking these underlying mechanisms helps language models become more reliable prognosticators, especially with more dynamic tasks like forecasting weather and financial markets.<br /><br />But do these AI systems process developing situations like we do? A new&nbsp;<a href=\"https://arxiv.org/html/2503.02854v1\">paper</a> from researchers in MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Department of Electrical Engineering and Computer Science shows that the models instead use clever mathematical shortcuts between each progressive step in a sequence, eventually making reasonable predictions. The team made this observation by going under the hood of language models, evaluating how closely they could keep track of objects that change position rapidly. Their findings show that engineers can control when language models use particular workarounds as a way to improve the systems’ predictive capabilities.<br /><br /><strong>Shell games</strong></p><p dir=\"ltr\" id=\"docs-internal-guid-5c520fa2-7fff-f3a1-cecc-40dddcfcf883\">The researchers analyzed the inner workings of these models using a clever experiment reminiscent of a classic concentration game. Ever had to guess the final location of an object after it’s placed under a cup and shuffled with identical containers? The team used a similar test, where the model guessed the final arrangement of particular digits (also called a permutation). The models were given a starting sequence, such as “42135,” and instructions about when and where to move each digit, like moving the “4” to the third position and onward, without knowing the final result.<br /><br />In these experiments, transformer-based models gradually learned to predict the correct final arrangements. Instead of shuffling the digits based on the instructions they were given, though, the systems aggregated information between successive states (or individual steps within the sequence) and calculated the final permutation.</p><p dir=\"ltr\">One go-to pattern the team observed, called the “Associative Algorithm,” essentially organizes nearby steps into groups and then calculates a final guess. You can think of this process as being structured like a tree, where the initial numerical arrangement is the “root.” As you move up the tree, adjacent steps are grouped into different branches and multiplied together. At the top of the tree is the final combination of numbers, computed by multiplying each resulting sequence on the branches together.<br /><br />The other way language models guessed the final permutation was through a crafty mechanism called the “Parity-Associative Algorithm,” which essentially whittles down options before grouping them. It determines whether the final arrangement is the result of an even or odd number of rearrangements of individual digits. Then, the mechanism groups adjacent sequences from different steps before multiplying them, just like the Associative Algorithm.<br /><br />“These behaviors tell us that transformers perform simulation by associative scan. Instead of following state changes step-by-step, the models organize them into hierarchies,” says MIT PhD student and CSAIL affiliate Belinda Li SM ’23, a lead author on the paper. “How do we encourage transformers to learn better state tracking? Instead of imposing that these systems form inferences about data in a human-like, sequential way, perhaps we should cater to the approaches they naturally use when tracking state changes.”<br /><br />“One avenue of research has been to expand test-time computing along the depth dimension, rather than the token dimension — by increasing the number of transformer layers rather than the number of chain-of-thought tokens during test-time reasoning,” adds Li. “Our work suggests that this approach would allow transformers to build deeper reasoning trees.”<br /><br /><strong>Through the looking glass</strong><br /><br />Li and her co-authors observed how the Associative and Parity-Associative algorithms worked using tools that allowed them to peer inside the “mind” of language models.&nbsp;</p><p dir=\"ltr\">They first used a method called “probing,” which shows what information flows through an AI system. Imagine you could look into a model’s brain to see its thoughts at a specific moment — in a similar way, the technique maps out the system’s mid-experiment predictions about the final arrangement of digits.</p><p dir=\"ltr\">A tool called “activation patching” was then used to show where the language model processes changes to a situation. It involves meddling with some of the system’s “ideas,” injecting incorrect information into certain parts of the network while keeping other parts constant, and seeing how the system will adjust its predictions.</p><p dir=\"ltr\">These tools revealed when the algorithms would make errors and when the systems “figured out” how to correctly guess the final permutations. They observed that the Associative Algorithm learned faster than the Parity-Associative Algorithm, while also performing better on longer sequences. Li attributes the latter’s difficulties with more elaborate instructions to an over-reliance on heuristics (or rules that allow us to compute a reasonable solution fast) to predict permutations.</p><p dir=\"ltr\">“We’ve found that when language models use a heuristic early on in training, they’ll start to build these tricks into their mechanisms,” says Li. “However, those models tend to generalize worse than ones that don’t rely on heuristics. We found that certain pre-training objectives can deter or encourage these patterns, so in the future, we may look to design techniques that discourage models from picking up bad habits.”</p><p dir=\"ltr\">The researchers note that their experiments were done on small-scale language models fine-tuned on synthetic data, but found the model size had little effect on the results. This suggests that fine-tuning larger language models, like GPT 4.1, would likely yield similar results. The team plans to examine their hypotheses more closely by testing language models of different sizes that haven’t been fine-tuned, evaluating their performance on dynamic real-world tasks such as tracking code and following how stories evolve.<br /><br />Harvard University postdoc Keyon Vafa, who was not involved in the paper, says that the researchers’ findings could create opportunities to advance language models. “Many uses of large language models rely on tracking state: anything from providing recipes to writing code to keeping track of details in a conversation,” he says. “This paper makes significant progress in understanding how language models perform these tasks. This progress provides us with interesting insights into what language models are doing and offers promising new strategies for improving them.”</p><p>Li wrote the paper with MIT undergraduate student Zifan “Carl” Guo and senior author Jacob Andreas, who is an MIT associate professor of electrical engineering and computer science and CSAIL principal investigator. Their research was supported, in part, by Open Philanthropy, the MIT Quest for Intelligence, the National Science Foundation, the Clare Boothe Luce Program for Women in STEM, and a Sloan Research Fellowship.<br /><br />The researchers presented their research at the International Conference on Machine Learning (ICML) this week.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/mit-csail-llms.jpg?itok=h_Eov8uW",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image designed by Alex Shipps, using assets from Shutterstock and Pixabay."
        }
      ],
      "credit": "Image designed by Alex Shipps, using assets from Shutterstock and Pixabay.",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Quest for Intelligence",
          "scheme": "https://news.mit.edu/topic/quest-intelligence",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "National Science Foundation (NSF)",
          "scheme": "https://news.mit.edu/topic/nsf",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        }
      ]
    },
    {
      "title": "Model predicts long-term effects of nuclear waste on underground disposal systems",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Model predicts long-term effects of nuclear waste on underground disposal systems"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/model-predicts-long-term-effects-nuclear-waste-underground-disposal-systems-0718"
        }
      ],
      "link": "https://news.mit.edu/2025/model-predicts-long-term-effects-nuclear-waste-underground-disposal-systems-0718",
      "summary": "The simulations matched results from an underground lab experiment in Switzerland, suggesting modeling could be used to validate the safety of nuclear disposal sites.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new study, co-authored by MIT researchers, aims to improve confidence among policymakers and the public in the long-term safety of underground nuclear waste disposal."
      },
      "published": "Fri, 18 Jul 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        18,
        4,
        0,
        0,
        4,
        199,
        0
      ],
      "id": "https://news.mit.edu/2025/model-predicts-long-term-effects-nuclear-waste-underground-disposal-systems-0718",
      "guidislink": false,
      "authors": [
        {
          "name": "Zach Winn | MIT News"
        }
      ],
      "author": "Zach Winn | MIT News",
      "author_detail": {
        "name": "Zach Winn | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>As countries across the world experience a resurgence in nuclear energy projects, the questions of where and how to dispose of nuclear waste remain as politically fraught as ever. The United States, for instance, has indefinitely stalled its only long-term underground nuclear waste repository. Scientists are using both modeling and experimental methods to study the effects of underground nuclear waste disposal and ultimately, they hope, build public trust in the decision-making process.</p><p>New research from scientists at MIT, Lawrence Berkeley National Lab, and the University of Orléans makes progress in that direction. The study shows that simulations of underground nuclear waste interactions, generated by new, high-performance-computing software, aligned well with experimental results from a research facility in Switzerland.</p><p>The study, which was co-authored by MIT PhD student Dauren Sarsenbayev and Assistant Professor Haruko Wainwright, along with&nbsp;Christophe Tournassat and&nbsp;Carl Steefel, <a href=\"https://www.pnas.org/doi/10.1073/pnas.2511885122\" target=\"_blank\">appears in the journal <em>PNAS</em></a>.</p><p>“These powerful new computational tools, coupled with real-world experiments like those at the Mont Terri research site in Switzerland, help us understand how radionuclides will migrate in coupled underground systems,” says Sarsenbayev, who is first author of the new study.</p><p>The authors hope the research will improve confidence among policymakers and the public in the long-term safety of underground nuclear waste disposal.</p><p>“This research — coupling both computation and experiments — is important to improve our confidence in waste disposal safety assessments,” says Wainwright. “With nuclear energy re-emerging as a key source for tackling climate change and ensuring energy security, it is critical to validate disposal pathways.”</p><p><strong>Comparing simulations with experiments</strong></p><p>Disposing of nuclear waste in deep underground geological formations is currently considered the safest long-term solution for managing high-level radioactive waste. As such, much effort has been put into studying the migration behaviors of radionuclides from nuclear waste within various natural and engineered geological materials.</p><p>Since its founding in 1996, the Mont Terri research site in northern Switzerland has served as an important test bed for an international consortium of researchers interested in studying materials like Opalinus clay — a thick, water-tight claystone abundant in the tunneled areas of the mountain.</p><p>“It is widely regarded as one of the most valuable real-world experiment sites because it provides us with decades of datasets around the interactions of cement and clay, and those are the key materials proposed to be used by countries across the world for engineered barrier systems and geological repositories for nuclear waste,” explains Sarsenbayev.</p><p>For their study, Sarsenbayev and Wainwright collaborated with co-authors Tournassat and Steefel, who have developed high-performance computing software to improve modeling of interactions between the nuclear waste and both engineered and natural materials.</p><p>To date, several challenges have limited scientists’ understanding of how nuclear waste reacts with cement-clay barriers. For one thing, the barriers are made up of irregularly mixed materials deep underground. Additionally, the existing class of models commonly used to simulate radionuclide interactions with cement-clay do not take into account electrostatic effects associated with the negatively charged clay minerals in the barriers.</p><p>Tournassat and Steefel’s new software accounts for electrostatic effects, making it the only one that can simulate those interactions in three-dimensional space. The software, called CrunchODiTi, was developed from established software known as CrunchFlow and was most recently updated this year. It is designed to be run on many high-performance computers at once in parallel.</p><p>For the study, the researchers looked at a 13-year-old experiment, with an initial focus on cement-clay rock interactions. Within the last several years, a mix of both negatively and positively charged ions were added to the borehole located near the center of the cement emplaced in the formation. The researchers focused on a 1-centimeter-thick zone between the radionuclides and cement-clay referred to as the “skin.” They compared their experimental results to the software simulation, finding the two datasets aligned.</p><p>“The results are quite significant because previously, these models wouldn’t fit field data very well,” Sarsenbayev says. “It’s interesting how fine-scale phenomena at the ‘skin’ between cement and clay, the physical and chemical properties of which changes over time, could be used to reconcile the experimental and simulation data.”&nbsp;</p><p>The experimental results showed the model successfully accounted for electrostatic effects associated with the clay-rich formation and the interaction between materials in Mont Terri over time.</p><p>“This is all driven by decades of work to understand what happens at these interfaces,” Sarsenbayev says. “It’s been hypothesized that there is mineral precipitation and porosity clogging at this interface, and our results strongly suggest that.”</p><p>“This application requires millions of degrees of freedom because these multibarrier systems require high resolution and a lot of computational power,” Sarsenbayev says. “This software is really ideal for the Mont Terri experiment.”</p><p><strong>Assessing waste disposal plans</strong></p><p>The new model could now replace older models that have been used to conduct safety and performance assessments of underground geological repositories.</p><p>“If the U.S. eventually decides to dispose nuclear waste in a geological repository, then these models could dictate the most appropriate materials to use,” Sarsenbayev says. “For instance, right now clay is considered an appropriate storage material, but salt formations are another potential medium that could be used. These models allow us to see the fate of radionuclides over millennia. We can use them to understand interactions at timespans that vary from months to years to many millions of years.”</p><p>Sarsenbayev says the model is reasonably accessible to other researchers and that future efforts may focus on the use of machine learning to develop less computationally expensive surrogate models.</p><p>Further data from the experiment will be available later this month. The team plans to compare those data to additional simulations.</p><p>“Our collaborators will basically get this block of cement and clay, and they’ll be able to run experiments to determine the exact thickness of the skin along with all of the minerals and processes present at this interface,”<strong>&nbsp;</strong>Sarsenbayev says. “It’s a huge project and it takes time, but we wanted to share initial data and this software as soon as we could.”</p><p>For now, the researchers hope their study leads to a long-term solution for storing nuclear waste that policymakers and the public can support.</p><p>“This is an interdisciplinary study that includes real world experiments showing we’re able to predict radionuclides’ fate in the subsurface,” Sarsenbayev says. “The motto of MIT’s Department of Nuclear Science and Engineering is ‘Science. Systems. Society.’ I think this merges all three domains.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT-Waste-Storage-01.jpg?itok=lR_HzoIX",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: iStock"
        }
      ],
      "credit": "Credit: iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Nuclear science and engineering",
          "scheme": "https://news.mit.edu/topic/nuclear-engineering",
          "label": null
        },
        {
          "term": "Nuclear power and reactors",
          "scheme": "https://news.mit.edu/topic/nuclear-power-and-reactors",
          "label": null
        },
        {
          "term": "Nuclear security and policy",
          "scheme": "https://news.mit.edu/topic/nuclear-security-and-policy",
          "label": null
        },
        {
          "term": "Energy",
          "scheme": "https://news.mit.edu/topic/energy",
          "label": null
        },
        {
          "term": "Computer modeling",
          "scheme": "https://news.mit.edu/topic/computer-modeling",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        }
      ]
    },
    {
      "title": "This “smart coach” helps LLMs switch between text and code",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "This “smart coach” helps LLMs switch between text and code"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/smart-coach-helps-llms-switch-between-text-and-code-0717"
        }
      ],
      "link": "https://news.mit.edu/2025/smart-coach-helps-llms-switch-between-text-and-code-0717",
      "summary": "The CodeSteer system could boost large language models’ accuracy when solving complex problems, such as scheduling shipments in a supply chain.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "CodeSteer is a smart assistant developed by MIT researchers that guides an LLM to switch between code and text generation until it correctly answers a query."
      },
      "published": "Thu, 17 Jul 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        17,
        4,
        0,
        0,
        3,
        198,
        0
      ],
      "id": "https://news.mit.edu/2025/smart-coach-helps-llms-switch-between-text-and-code-0717",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Large language models (LLMs) excel at using textual reasoning to understand the context of a document and provide a logical answer about its contents. But these same LLMs often struggle to correctly answer even the simplest math problems.</p><p>Textual reasoning is usually a less-than-ideal way to deliberate over computational or algorithmic tasks. While some LLMs can generate code like Python to handle symbolic queries, the models don’t always know when to use code, or what kind of code would work best.</p><p>LLMs, it seems, may need a coach to steer them toward the best technique.</p><p>Enter <a href=\"https://github.com/yongchao98/CodeSteer-v1.0\" target=\"_blank\">CodeSteer</a>, a smart assistant developed by MIT researchers that guides an LLM to switch between code and text generation until it correctly answers a query.</p><p>CodeSteer, itself a smaller LLM, automatically generates a series of prompts to iteratively steer a larger LLM. It reviews the model’s current and previous answers after each round and provides guidance for how it can fix or refine that solution until it deems the answer is correct.</p><p>The researchers found that augmenting a larger LLM with CodeSteer boosted its accuracy on symbolic tasks, like multiplying numbers, playing Sudoku, and stacking blocks, by more than 30 percent. It also enabled less sophisticated models to outperform more advanced models with enhanced reasoning skills.</p><p>This advance could improve the problem-solving capabilities of LLMs for complex tasks that are especially difficult to solve with textual reasoning alone, such as generating paths for robots in uncertain environments or scheduling shipments in an international supply chain.</p><p>“There is a race to develop better and better models that are capable of doing everything, but we’ve taken a complementary approach. Researchers have spent years developing effective technologies and tools to tackle problems in many domains. We want to enable LLMs to select the right tools and methods, and make use of others’ expertise to enhance their own capabilities,” says Chuchu Fan, an associate professor of aeronautics and astronautics (AeroAstro) and principal investigator in the MIT Laboratory for Information and Decision Systems (LIDS).</p><p>Fan, the senior author of the study, is joined on <a href=\"https://arxiv.org/pdf/2502.04350\" target=\"_blank\">a paper about the work</a> by LIDS graduate student Yongchao Chen; AeroAstro graduate student Yilun Hao; University of Illinois at Urbana-Champaign graduate student Yueying Liu; and MIT-IBM Watson AI Lab Research Scientist Yang Zhang. The research will be presented at the International Conference on Machine Learning.</p><p><strong>An LLM “trainer”</strong>&nbsp;&nbsp;</p><p>Ask an LLM which number is bigger, 9.11 or 9.9, and it will often give the wrong answer by using textual reasoning. But ask it to use code to answer the same question, and it can generate and execute a Python script to compare the two numbers, easily solving the problem.</p><p>Initially trained to understand and predict human language, LLMs are more likely to answer queries using text, even when code would be more effective. And while they have learned to generate code through fine-tuning, these models often generate an incorrect or less efficient version of the code.</p><p>Rather than trying to retrain a powerful LLM like GPT-4 or Claude to improve these capabilities, the MIT researchers fine-tune a smaller, lightweight LLM to guide a larger model between text and code. Fine-tuning a smaller model doesn’t change the larger LLM, so there is no risk it would undermine the larger model’s other abilities.</p><p>“We were also inspired by humans. In sports, a trainer may not be better than the star athlete on the team, but the trainer can still give helpful suggestions to guide the athlete. This steering method works for LLMs, too,” Chen says.</p><p>This trainer, CodeSteer, works in conjunction with the larger LLM. It first reviews a query and determines whether text or code is suitable for this problem, and which sort of code would be best.</p><p>Then it generates a prompt for the larger LLM, telling it to use a coding method or textual reasoning to answer the query. The larger model follows this prompt to answer the query and sends the result back to CodeSteer, which reviews it.</p><p>If the answer is not correct, CodeSteer will continue prompting the LLM to try different things that might fix the problem, such as incorporating a search algorithm or constraint into its Python code, until the answer is correct.</p><p>“We found that oftentimes, the larger LLM will try to be lazy and use a shorter, less efficient code that will not carry the correct symbolic calculation. We’ve designed CodeSteer to avoid this phenomenon,” Chen says.</p><p>A symbolic checker evaluates the code’s complexity and sends a signal to CodeSteer if it is too simple or inefficient. The researchers also incorporate a self-answer checker into CodeSteer, which prompts the LLM to generate code that calculates the answer to verify it is correct.</p><p><strong>Tackling complex tasks</strong></p><p>As the researchers designed CodeSteer, they couldn’t find suitable symbolic datasets to fine-tune and test the model, since many existing benchmarks don’t point out whether a certain query could be best solved with text or code.</p><p>So, they gathered a corpus of 37 complex symbolic tasks, including spatial reasoning, mathematics, order reasoning, and optimization, and built their own dataset, called SymBench. They implemented a fine-tuning approach that leverages SymBench to maximize the performance of CodeSteer.</p><p>In their experiments, CodeSteer outperformed all nine baseline methods they evaluated and boosted average accuracy from 53.3 percent to 86.4 percent. It maintains similar performance even on unseen tasks, and on a variety of LLMs.</p><p>In addition, a general-purpose model augmented with CodeSteer can achieve higher accuracy than state-of-the-art models designed to focus on complex reasoning and planning, while requiring much less computation.</p><p>“Our method uses an LLM’s own capabilities. By augmenting an LLM with the ability to smartly use coding, we can take a model that is already very strong and improve its performance even more,” Chen says.</p><p>In the future, the researchers want to streamline CodeSteer to speed up its iterative prompting process. In addition, they are studying how to effectively fine-tune a unified model with the ability to switch between textual reasoning and code generation, rather than relying on a separate assistant.</p><p>“The authors present an elegant solution to the critical challenge of tool utilization in LLMs. This simple yet impactful method enables state-of-the-art LLMs to achieve significant performance improvements without requiring direct fine-tuning,” says Jinsung Yoon, a staff research scientist at Google Cloud AI, who was not involved with this work. “This research represents a substantial contribution that promises to significantly enhance the application of LLMs to a diverse range of tasks with which they currently struggle.”</p><p>“Their success in training a smaller, specialized model to strategically guide larger, advanced models is particularly impactful,” adds Chi Wang, a senior staff scientist at Google DeepMind who was not involved with this work. “This intelligent collaboration among diverse AI ‘agents’ paves the way for more robust and versatile applications in complex real-world scenarios.”</p><p>This research is supported, in part, by the U.S. Office of Naval Research and the MIT-IBM Watson AI Lab.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT_Symbolic-LLMs-01.jpg?itok=ATMqgM63",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: Christine Daniloff, MIT; iStock"
        }
      ],
      "credit": "Credit: Christine Daniloff, MIT; iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Mathematics",
          "scheme": "https://news.mit.edu/topic/mathematics",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "MIT-IBM Watson AI Lab",
          "scheme": "https://news.mit.edu/topic/mit-ibm-watson-ai-lab",
          "label": null
        }
      ]
    },
    {
      "title": "Can AI really code? Study maps the roadblocks to autonomous software engineering",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Can AI really code? Study maps the roadblocks to autonomous software engineering"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/can-ai-really-code-study-maps-roadblocks-to-autonomous-software-engineering-0716"
        }
      ],
      "link": "https://news.mit.edu/2025/can-ai-really-code-study-maps-roadblocks-to-autonomous-software-engineering-0716",
      "summary": "A team of researchers has mapped the challenges of AI in software development, and outlined a research agenda to move the field forward.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new paper by MIT CSAIL researchers maps the many software-engineering tasks beyond code generation, identifies bottlenecks, and highlights research directions to overcome them. The goal: to let humans focus on high-level design, while routine work is automated."
      },
      "published": "Wed, 16 Jul 2025 16:55:00 -0400",
      "published_parsed": [
        2025,
        7,
        16,
        20,
        55,
        0,
        2,
        197,
        0
      ],
      "id": "https://news.mit.edu/2025/can-ai-really-code-study-maps-roadblocks-to-autonomous-software-engineering-0716",
      "guidislink": false,
      "authors": [
        {
          "name": "Rachel Gordon | MIT CSAIL"
        }
      ],
      "author": "Rachel Gordon | MIT CSAIL",
      "author_detail": {
        "name": "Rachel Gordon | MIT CSAIL"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\" id=\"docs-internal-guid-3c70286d-7fff-a737-d9dc-ea0a5bb6f3af\">Imagine a future where artificial intelligence quietly shoulders the drudgery of software development: refactoring tangled code, migrating legacy systems, and hunting down race conditions, so that human engineers can devote themselves to architecture, design, and the genuinely novel problems still beyond a machine’s reach. Recent advances appear to have nudged that future tantalizingly close, but a new paper by researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and several collaborating institutions argues that this potential future reality demands a hard look at present-day challenges.&nbsp;</p><p dir=\"ltr\">Titled “<a href=\"https://arxiv.org/pdf/2503.22625\" target=\"_blank\">Challenges and Paths Towards AI for Software Engineering</a>,” the work maps the many software-engineering tasks beyond code generation, identifies current bottlenecks, and highlights research directions to overcome them, aiming to let humans focus on high-level design while routine work is automated.&nbsp;</p><p dir=\"ltr\">“Everyone is talking about how we don’t need programmers anymore, and there’s all this automation now available,” says Armando Solar‑Lezama, MIT professor of electrical engineering and computer science, CSAIL principal investigator, and senior author of the study. “On the one hand, the field has made tremendous progress. We have tools that are way more powerful than any we’ve seen before. But there’s also a long way to go toward really getting the full promise of automation that we would expect.”</p><p dir=\"ltr\">Solar-Lezama argues that popular narratives often shrink software engineering to “the undergrad programming part: someone hands you a spec for a little function and you implement it, or solving LeetCode-style programming interviews.” Real practice is far broader. It includes everyday refactors that polish design, plus sweeping migrations that move millions of lines from COBOL to Java and reshape entire businesses. It requires nonstop testing and analysis — fuzzing, property-based testing, and other methods — to catch concurrency bugs, or patch zero-day flaws. And it involves the maintenance grind: documenting decade-old code, summarizing change histories for new teammates, and reviewing pull requests for style, performance, and security.</p><p dir=\"ltr\">Industry-scale code optimization — think re-tuning GPU kernels or the relentless, multi-layered refinements behind Chrome’s V8 engine — remains stubbornly hard to evaluate. Today’s headline metrics were designed for short, self-contained problems, and while multiple-choice tests still dominate natural-language research, they were never the norm in AI-for-code. The field’s de facto yardstick, SWE-Bench, simply asks a model to patch a GitHub issue: useful, but still akin to the “undergrad programming exercise” paradigm. It touches only a few hundred lines of code, risks data leakage from public repositories, and ignores other real-world contexts — AI-assisted refactors, human–AI pair programming, or performance-critical rewrites that span millions of lines. Until benchmarks expand to capture those higher-stakes scenarios, measuring progress — and thus accelerating it — will remain an open challenge.</p><p dir=\"ltr\">If measurement is one obstacle, human‑machine communication is another. First author Alex  Gu, an MIT graduate student in electrical engineering and computer science, sees today’s interaction as “a thin line of communication.” When he asks a system to generate code, he often receives a large, unstructured file and even a set of unit tests, yet those tests tend to be superficial. This gap extends to the AI’s ability to effectively use the wider suite of software engineering tools, from debuggers to static analyzers, that humans rely on for precise control and deeper understanding. “I don’t really have much control over what the model writes,” he says. “Without a channel for the AI to expose its own confidence — ‘this part’s correct … this part, maybe double‑check’ — developers risk blindly trusting hallucinated logic that compiles, but collapses in production. Another critical aspect is having the AI know when to defer to the user for clarification.”&nbsp;</p><p dir=\"ltr\">Scale compounds these difficulties. Current AI models struggle profoundly with large code bases, often spanning millions of lines. Foundation models learn from public GitHub, but “every company’s code base is kind of different and unique,” Gu says, making proprietary coding conventions and specification requirements fundamentally out of distribution. The result is code that looks plausible yet calls non‑existent functions, violates internal style rules, or fails continuous‑integration pipelines. This often leads to AI-generated code that “hallucinates,” meaning it creates content that looks plausible but doesn’t align with the specific internal conventions, helper functions, or architectural patterns of a given company.&nbsp;</p><p dir=\"ltr\">Models will also often retrieve incorrectly, because it retrieves code with a similar name (syntax) rather than functionality and logic, which is what a model might need to know how to write the function. “Standard retrieval techniques are very easily fooled by pieces of code that are doing the same thing but look different,” says Solar‑Lezama.&nbsp;</p><p dir=\"ltr\">The authors mention that since there is no silver bullet to these issues, they’re calling instead for community‑scale efforts: richer, having data that captures the process of developers writing code (for example, which code developers keep versus throw away, how code gets refactored over time, etc.), shared evaluation suites that measure progress on refactor quality, bug‑fix longevity, and migration correctness; and transparent tooling that lets models expose uncertainty and invite human steering rather than passive acceptance. Gu frames the agenda as a “call to action” for larger open‑source collaborations that no single lab could muster alone. Solar‑Lezama imagines incremental advances—“research results taking bites out of each one of these challenges separately”—that feed back into commercial tools and gradually move AI from autocomplete sidekick toward genuine engineering partner.</p><p dir=\"ltr\">“Why does any of this matter? Software already underpins finance, transportation, health care, and the minutiae of daily life, and the human effort required to build and maintain it safely is becoming a bottleneck. An AI that can shoulder the grunt work — and do so without introducing hidden failures — would free developers to focus on creativity, strategy, and ethics” says Gu. “But that future depends on acknowledging that code completion is the easy part; the hard part is everything else. Our goal isn’t to replace programmers. It’s to amplify them. When AI can tackle the tedious and the terrifying, human engineers can finally spend their time on what only humans can do.”</p><p dir=\"ltr\">“With so many new works emerging in AI for coding, and the community often chasing the latest trends, it can be hard to step back and reflect on which problems are most important to tackle,” says Baptiste Rozière, an AI scientist at Mistral AI, who wasn’t involved in the paper. “I enjoyed reading this paper because it offers a clear overview of the key tasks and challenges in AI for software engineering. It also outlines promising directions for future research in the field.”</p><p dir=\"ltr\">Gu and Solar-Lezama wrote the paper with University of California at Berkeley Professor Koushik Sen and PhD students Naman Jain and Manish Shetty, Cornell University Assistant Professor Kevin Ellis and PhD student Wen-Ding Li, Stanford University Assistant Professor Diyi Yang and PhD student Yijia Shao, and incoming Johns Hopkins University assistant professor Ziyang Li. Their work was supported, in part, by the National Science Foundation (NSF), SKY Lab industrial sponsors and affiliates, Intel Corp. through an NSF grant, and the Office of Naval Research.<br /><br />The researchers are presenting their work at the International Conference on Machine Learning (ICML).&nbsp;</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/mit-csail-%20AI-coding.jpg?itok=xzvXTUmh",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: Alex Shipps/MIT CSAIL, using assets from Shutterstock and Pixabay"
        }
      ],
      "credit": "Image: Alex Shipps/MIT CSAIL, using assets from Shutterstock and Pixabay",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Software",
          "scheme": "https://news.mit.edu/topic/software",
          "label": null
        },
        {
          "term": "Programming",
          "scheme": "https://news.mit.edu/topic/programming",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Programming languages",
          "scheme": "https://news.mit.edu/topic/programming-languages",
          "label": null
        },
        {
          "term": "Human-computer interaction",
          "scheme": "https://news.mit.edu/topic/human-computer-interaction",
          "label": null
        },
        {
          "term": "National Science Foundation (NSF)",
          "scheme": "https://news.mit.edu/topic/nsf",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        }
      ]
    },
    {
      "title": "How to more efficiently study complex treatment interactions",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "How to more efficiently study complex treatment interactions"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/more-efficiently-studying-complex-treatment-interactions-0716"
        }
      ],
      "link": "https://news.mit.edu/2025/more-efficiently-studying-complex-treatment-interactions-0716",
      "summary": "A new approach for testing multiple treatment combinations at once could help scientists develop drugs for cancer or genetic disorders.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new experimental design framework could enable scientists to efficiently estimate how combinations of interventions will affect a group of cells, reducing the cost of experiments and providing less biased data that could be used to understand disease mechanisms or develop new treatments."
      },
      "published": "Wed, 16 Jul 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        16,
        4,
        0,
        0,
        2,
        197,
        0
      ],
      "id": "https://news.mit.edu/2025/more-efficiently-studying-complex-treatment-interactions-0716",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>MIT researchers have developed a new theoretical framework for studying the mechanisms of treatment interactions. Their approach allows scientists to efficiently estimate how combinations of treatments will affect a group of units, such as cells, enabling a researcher to perform fewer costly experiments while gathering more accurate data.</p><p>As an example, to study how interconnected genes affect cancer cell growth, a biologist might need to use a combination of treatments to target multiple genes at once. But because there could be billions of potential combinations for each round of the experiment, choosing a subset of combinations to test might bias the data their experiment generates.&nbsp;</p><p>In contrast, the new framework considers the scenario where the user can efficiently design an unbiased experiment by assigning all treatments in parallel, and can control the outcome by adjusting the rate of each treatment.</p><p>The MIT researchers theoretically proved a near-optimal strategy in this framework and performed a series of simulations to test it in a multiround experiment. Their method minimized the error rate in each instance.</p><p>This technique could someday help scientists better understand disease mechanisms and develop new medicines to treat cancer or genetic disorders.</p><p>“We’ve introduced a concept people can think more about as they study the optimal way to select combinatorial treatments at each round of an experiment. Our hope is this can someday be used to solve biologically relevant questions,” says graduate student Jiaqi Zhang, an Eric and Wendy Schmidt Center Fellow and co-lead author of a <a href=\"https://arxiv.org/pdf/2506.03363\" target=\"_blank\">paper</a> on this experimental design framework.</p><p>She is joined on the paper by co-lead author Divya Shyamal, an MIT undergraduate; and senior author Caroline Uhler, the Andrew and Erna Viterbi Professor of Engineering in EECS and the MIT Institute for Data, Systems, and Society (IDSS), who is also director of the Eric and Wendy Schmidt Center and a researcher at MIT’s Laboratory for Information and Decision Systems (LIDS). The research was recently presented at the International Conference on Machine Learning.</p><p><strong>Simultaneous treatments</strong></p><p>Treatments can interact with each other in complex ways. For instance, a scientist trying to determine whether a certain gene contributes to a particular disease symptom may have to target several genes simultaneously to study the effects.</p><p>To do this, scientists use what are known as combinatorial perturbations, where they apply multiple treatments at once to the same group of cells.</p><p>“Combinatorial perturbations will give you a high-level network of how different genes interact, which provides an understanding of how a cell functions,” Zhang explains.</p><p>Since genetic experiments are costly and time-consuming, the scientist aims to select the best subset of treatment combinations to test, which is a steep challenge due to the huge number of possibilities.</p><p>Picking a suboptimal subset can generate biased results by focusing only on combinations the user selected in advance.</p><p>The MIT researchers approached this problem differently by looking at a probabilistic framework. Instead of focusing on a selected subset, each unit randomly takes up combinations of treatments based on user-specified dosage levels for each treatment.</p><p>The user sets dosage levels based on the goal of their experiment — perhaps this scientist wants to study the effects of four different drugs on cell growth. The probabilistic approach generates less biased data because it does not restrict the experiment to a predetermined subset of treatments.</p><p>The dosage levels are like probabilities, and each cell receives a random combination of treatments. If the user sets a high dosage, it is more likely most of the cells will take up that treatment. A smaller subset of cells will take up that treatment if the dosage is low.</p><p>“From there, the question is how do we design the dosages so that we can estimate the outcomes as accurately as possible? This is where our theory comes in,” Shyamal adds.</p><p>Their theoretical framework shows the best way to design these dosages so one can learn the most about the characteristic or trait they are studying.</p><p>After each round of the experiment, the user collects the results and feeds those back into the experimental framework. It will output the ideal dosage strategy for the next round, and so on, actively adapting the strategy over multiple rounds.</p><p><strong>Optimizing dosages, minimizing error</strong></p><p>The researchers proved their theoretical approach generates optimal dosages, even when the dosage levels are affected by a limited supply of treatments or when noise in the experimental outcomes varies at each round.</p><p>In simulations, this new approach had the lowest error rate when comparing estimated and actual outcomes of multiround experiments, outperforming two baseline methods.</p><p>In the future, the researchers want to enhance their experimental framework to consider interference between units and the fact that certain treatments can lead to selection bias. They would also like to apply this technique in a real experimental setting.</p><p>“This is a new approach to a very interesting problem that is hard to solve. Now, with this new framework in hand, we can think more about the best way to design experiments for many different applications,” Zhang says.</p><p>This research is funded, in part, by the Advanced Undergraduate Research Opportunities Program at MIT, Apple, the National Institutes of Health, the Office of Naval Research, the Department of Energy, the Eric and Wendy Schmidt Center at the Broad Institute, and a Simons Investigator Award.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT-Combinatoral-Interventions-01-press.jpg?itok=HNOFnzAd",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: MIT News; iStock"
        }
      ],
      "credit": "Image: MIT News; iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Biological engineering",
          "scheme": "https://news.mit.edu/topic/biological-engineering",
          "label": null
        },
        {
          "term": "Cells",
          "scheme": "https://news.mit.edu/topic/cells",
          "label": null
        },
        {
          "term": "Biology",
          "scheme": "https://news.mit.edu/topic/biology",
          "label": null
        },
        {
          "term": "Diagnostics",
          "scheme": "https://news.mit.edu/topic/diagnostics",
          "label": null
        },
        {
          "term": "Health",
          "scheme": "https://news.mit.edu/topic/health2",
          "label": null
        },
        {
          "term": "Disease",
          "scheme": "https://news.mit.edu/topic/disease",
          "label": null
        },
        {
          "term": "Medicine",
          "scheme": "https://news.mit.edu/topic/medicine",
          "label": null
        },
        {
          "term": "Pharmaceuticals",
          "scheme": "https://news.mit.edu/topic/pharmaceuticals",
          "label": null
        },
        {
          "term": "Genetics",
          "scheme": "https://news.mit.edu/topic/genetics",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "IDSS",
          "scheme": "https://news.mit.edu/topic/idss",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "Broad Institute",
          "scheme": "https://news.mit.edu/topic/broad-institute",
          "label": null
        },
        {
          "term": "National Institutes of Health (NIH)",
          "scheme": "https://news.mit.edu/topic/nih",
          "label": null
        },
        {
          "term": "Department of Energy (DoE)",
          "scheme": "https://news.mit.edu/topic/doe",
          "label": null
        }
      ]
    },
    {
      "title": "New AI system uncovers hidden cell subtypes, boosts precision medicine",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "New AI system uncovers hidden cell subtypes, boosts precision medicine"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/ai-system-uncovers-hidden-cell-subtypes-boosts-precision-medicine-0711"
        }
      ],
      "link": "https://news.mit.edu/2025/ai-system-uncovers-hidden-cell-subtypes-boosts-precision-medicine-0711",
      "summary": "CellLENS reveals hidden patterns in cell behavior within tissues, offering deeper insights into cell heterogeneity — vital for advancing cancer immunotherapy.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "In this view of cHL (classic Hodgkin Lymphoma) tissue, CellLENS identified subtle but distinct CD4 T cell subpopulations infiltrating a tumor, lingering at tumor boundaries, and found at a distance from tumors. CellLENS enables the potential precision therapy strategies against specific immune cell populations in the tissue environment."
      },
      "published": "Fri, 11 Jul 2025 14:40:00 -0400",
      "published_parsed": [
        2025,
        7,
        11,
        18,
        40,
        0,
        4,
        192,
        0
      ],
      "id": "https://news.mit.edu/2025/ai-system-uncovers-hidden-cell-subtypes-boosts-precision-medicine-0711",
      "guidislink": false,
      "authors": [
        {
          "name": "Karen Baird | Department of Chemistry"
        }
      ],
      "author": "Karen Baird | Department of Chemistry",
      "author_detail": {
        "name": "Karen Baird | Department of Chemistry"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>In order to produce effective targeted therapies for cancer, scientists need to isolate the genetic and phenotypic characteristics of cancer cells, both within and across different tumors, because those differences impact how tumors respond to treatment.</p><p>Part of this work requires a deep understanding of the RNA or protein molecules each cancer cell expresses, where it is located in the tumor, and what it looks like under a microscope.</p><p>Traditionally, scientists have looked at one or more of these aspects separately, but now a new deep learning AI tool, CellLENS (Cell Local Environment and Neighborhood Scan), fuses all three domains together, using a combination of convolutional neural networks and graph neural networks to build a comprehensive digital profile for every single cell. This allows the system to group cells with similar biology — effectively separating even those that appear very similar in isolation, but behave differently depending on their surroundings.</p><p>The study, <a href=\"https://pubmed.ncbi.nlm.nih.gov/40404817/\" target=\"_blank\">published recently in <em>Nature Immunology</em></a>, details the results of a collaboration between researchers from MIT, Harvard Medical School, Yale University, Stanford University, and University of Pennsylvania — an effort led by Bokai Zhu, an MIT postdoc and member of the <a href=\"https://www.broadinstitute.org/\" rel=\"noopener\" target=\"_blank\">Broad Institute of MIT and Harvard</a> and the&nbsp;<a href=\"https://ragoninstitute.org/\" rel=\"noopener\" target=\"_blank\">Ragon Institute of MGH, MIT, and Harvard</a>.</p><p>Zhu explains the impact of this new tool: “Initially we would say, oh, I found a cell. This is called a T cell. Using the same dataset, by applying CellLENS, now I can say this is a T cell, and it is currently attacking a specific tumor boundary in a patient.</p><p>“I can use existing information to better define what a cell is, what is the subpopulation of that cell, what that cell is doing, and what is the potential functional readout of that cell. This method may be used to identify a new biomarker, which provides specific and detailed information about diseased cells, allowing for more targeted therapy development.”</p><p>This is a critical advance because current methodologies often miss critical molecular or contextual information — for example, immunotherapies may target cells that only exist at the boundary of a tumor, limiting efficacy. By using deep learning, the researchers can detect many different layers of information with CellLENS, including morphology and where the cell is spatially in a tissue.</p><p>When applied to samples from healthy tissue and several types of cancer, including lymphoma and liver cancer, CellLENS uncovered rare immune cell subtypes and revealed how their activity and location relate to disease processes — such as tumor infiltration or immune suppression.</p><p>These discoveries could help scientists better understand how the immune system interacts with tumors and pave the way for more precise cancer diagnostics and immunotherapies.</p><p>“I’m extremely excited by the potential of new AI tools, like CellLENS, to help us more holistically understand aberrant cellular behaviors within tissues,” says co-author&nbsp;<a href=\"https://chemistry.mit.edu/profile/alex-k-shalek/\">Alex K. Shalek</a>, the director of the&nbsp;<a href=\"https://imes.mit.edu/\">Institute for Medical Engineering and Science</a>&nbsp;(IMES), the J. W. Kieckhefer Professor in IMES and Chemistry, and an extramural member of the&nbsp;<a href=\"https://ki.mit.edu/\">Koch Institute for Integrative Cancer Research at MIT</a>, as well as an Institute member of the&nbsp;Broad Institute&nbsp;and a member of the&nbsp;Ragon Institute. “We can now measure a tremendous amount of information about individual cells and their tissue contexts with cutting-edge, multi-omic assays. Effectively leveraging that data to nominate new therapeutic leads is a critical step in developing improved interventions. When coupled with the right input data and careful downsteam validations, such tools promise to accelerate our ability to positively impact human health and wellness.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/mit-CellLENS-tool.jpg?itok=NeodS5gh",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image courtesy of the Department of Chemistry."
        }
      ],
      "credit": "Image courtesy of the Department of Chemistry.",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Immunology",
          "scheme": "https://news.mit.edu/topic/immunology",
          "label": null
        },
        {
          "term": "Cells",
          "scheme": "https://news.mit.edu/topic/cells",
          "label": null
        },
        {
          "term": "Cancer",
          "scheme": "https://news.mit.edu/topic/cancer-research",
          "label": null
        },
        {
          "term": "Chemistry",
          "scheme": "https://news.mit.edu/topic/chemistry-0",
          "label": null
        },
        {
          "term": "Health sciences and technology",
          "scheme": "https://news.mit.edu/topic/health",
          "label": null
        },
        {
          "term": "Medicine",
          "scheme": "https://news.mit.edu/topic/medicine",
          "label": null
        },
        {
          "term": "Broad Institute",
          "scheme": "https://news.mit.edu/topic/broad-institute",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Ragon Institute",
          "scheme": "https://news.mit.edu/topic/ragon-institute",
          "label": null
        },
        {
          "term": "Institute for Medical Engineering and Science (IMES)",
          "scheme": "https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        }
      ]
    },
    {
      "title": "Changing the conversation in health care",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Changing the conversation in health care"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/changing-conversation-health-care-0709"
        }
      ],
      "link": "https://news.mit.edu/2025/changing-conversation-health-care-0709",
      "summary": "The Language/AI Incubator, an MIT Human Insight Collaborative project, is investigating how AI can improve communications among patients and practitioners.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "The Language/AI Incubator argues that AI’s facility with language can help medical professionals and their patients navigate health-care challenges more carefully."
      },
      "published": "Wed, 09 Jul 2025 16:50:00 -0400",
      "published_parsed": [
        2025,
        7,
        9,
        20,
        50,
        0,
        2,
        190,
        0
      ],
      "id": "https://news.mit.edu/2025/changing-conversation-health-care-0709",
      "guidislink": false,
      "authors": [
        {
          "name": "Benjamin Daniel | School of Humanities, Arts, and Social Sciences"
        }
      ],
      "author": "Benjamin Daniel | School of Humanities, Arts, and Social Sciences",
      "author_detail": {
        "name": "Benjamin Daniel | School of Humanities, Arts, and Social Sciences"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\">Generative artificial intelligence is transforming the ways humans write, read, speak, think, empathize, and act within and across languages and cultures. In health care, gaps in communication between patients and practitioners can worsen patient outcomes and prevent improvements in practice and care. The Language/AI Incubator, made possible through funding from the&nbsp;<a href=\"https://shass.mit.edu/human-insight-collaborative/\" target=\"_blank\">MIT Human Insight Collaborative</a> (MITHIC), offers a potential response to these challenges.&nbsp;</p><p dir=\"ltr\">The project envisions a research community rooted in the humanities that will foster interdisciplinary collaboration across MIT to deepen understanding of generative AI’s impact on cross-linguistic and cross-cultural communication. The project’s focus on health care and communication seeks to build bridges across socioeconomic, cultural, and linguistic strata.</p><p dir=\"ltr\">The incubator is co-led by&nbsp;<a href=\"https://imes.mit.edu/people/celi-leo\">Leo Celi</a>, a physician and the research director and senior research scientist with the&nbsp;<a href=\"https://imes.mit.edu/\" target=\"_blank\">Institute for Medical Engineering and Science</a> (IMES), and&nbsp;<a href=\"https://languages.mit.edu/people/per-urlaub/\" target=\"_blank\">Per Urlaub</a>, professor of the practice in German and second language studies and director of MIT’s&nbsp;<a href=\"https://languages.mit.edu/\" target=\"_blank\">Global Languages</a> program.&nbsp;</p><p dir=\"ltr\">“The basis of health care delivery is the knowledge of health and disease,” Celi says. “We’re seeing poor outcomes despite massive investments because our knowledge system is broken.”</p><p><strong>A chance collaboration</strong></p><p dir=\"ltr\">Urlaub and Celi met during a MITHIC launch event. Conversations during the event reception revealed a shared interest in exploring improvements in medical communication and practice with AI.</p><p dir=\"ltr\">“We’re trying to incorporate data science into health-care delivery,” Celi says. “We’ve been recruiting social scientists [at IMES] to help advance our work, because the science we create isn’t neutral.”</p><p dir=\"ltr\">Language is a non-neutral mediator in health care delivery, the team believes, and can be a boon or barrier to effective treatment. “Later, after we met, I joined one of his working groups whose focus was metaphors for pain: the language we use to describe it and its measurement,” Urlaub continues. “One of the questions we considered was how effective communication can occur between doctors and patients.”</p><p dir=\"ltr\">Technology, they argue, impacts casual communication, and its impact depends on both users and creators. As AI and large language models (LLMs) gain power and prominence, their use is broadening to include fields like health care and wellness.&nbsp;</p><p dir=\"ltr\">Rodrigo Gameiro, a physician and researcher with MIT’s Laboratory for Computational Physiology, is another program participant. He notes that work at the laboratory centers responsible AI development and implementation. Designing systems that leverage AI effectively, particularly when considering challenges related to communicating across linguistic and cultural divides that can occur in health care, demands a nuanced approach.&nbsp;</p><p dir=\"ltr\">“When we build AI systems that interact with human language, we’re not just teaching machines how to process words; we’re teaching them to navigate the complex web of meaning embedded in language,” Gameiro says.</p><p dir=\"ltr\">Language’s complexities can impact treatment and patient care. “Pain can only be communicated through metaphor,” Urlaub continues, “but metaphors don’t always match, linguistically and culturally.” Smiley faces and one-to-10 scales — pain measurement tools English-speaking medical professionals may use to assess their patients — may not travel well across racial, ethnic, cultural, and language boundaries.</p><p><strong>“Science has to have a heart”&nbsp;</strong></p><p dir=\"ltr\">LLMs can potentially help scientists improve health care, although there are some systemic and pedagogical challenges to consider. Science can focus on outcomes to the exclusion of the people it’s meant to help, Celi argues. “Science has to have a heart,” he says. “Measuring students’ effectiveness by counting the number of papers they publish or patents they produce misses the point.”</p><p dir=\"ltr\">The point, Urlaub says, is to investigate carefully while simultaneously acknowledging what we don’t know, citing what philosophers call Epistemic Humility. Knowledge, the investigators argue, is provisional, and always incomplete. Deeply held beliefs may require revision in light of new evidence.&nbsp;</p><p dir=\"ltr\">“No one’s mental view of the world is complete,” Celi says. “You need to create an environment in which people are comfortable acknowledging their biases.”</p><p dir=\"ltr\">“How do we share concerns between language educators and others interested in AI?” Urlaub asks. “How do we identify and investigate the relationship between medical professionals and language educators interested in AI’s potential to aid in the elimination of gaps in communication between doctors and patients?”&nbsp;</p><p dir=\"ltr\">Language, in Gameiro’s estimation, is more than just a tool for communication. “It reflects culture, identity, and power dynamics,” he says. In situations where a patient might not be comfortable describing pain or discomfort because of the physician’s position as an authority, or because their culture demands yielding to those perceived as authority figures, misunderstandings can be dangerous.&nbsp;</p><p><strong>Changing the conversation</strong></p><p dir=\"ltr\">AI’s facility with language can help medical professionals navigate these areas more carefully, providing digital frameworks offering valuable cultural and linguistic contexts in which patient and practitioner can rely on data-driven, research-supported tools to improve dialogue. Institutions need to reconsider how they educate medical professionals and invite the communities they serve into the conversation, the team says.&nbsp;</p><p dir=\"ltr\">‘We need to ask ourselves what we truly want,” Celi says. “Why are we measuring what we’re measuring?” The biases we bring with us to these interactions — doctors, patients, their families, and their communities — remain barriers to improved care, Urlaub and Gameiro say.</p><p dir=\"ltr\">“We want to connect people who think differently, and make AI work for everyone,” Gameiro continues. “Technology without purpose is just exclusion at scale.”</p><p dir=\"ltr\">“Collaborations like these can allow for deep processing and better ideas,” Urlaub says.</p><p dir=\"ltr\">Creating spaces where ideas about AI and health care can potentially become actions is a key element of the project. The Language/AI Incubator hosted its first colloquium at MIT in May, which was led by Mena Ramos, a physician and the co-founder and CEO of the&nbsp;<a href=\"https://globalultrasoundinstitute.com/\" target=\"_blank\">Global Ultrasound Institute</a>.&nbsp;</p><p dir=\"ltr\">The colloquium also featured presentations from Celi, as well as Alfred Spector, a visiting scholar in MIT’s&nbsp;<a href=\"https://www.eecs.mit.edu/\" target=\"_blank\">Department of Electrical Engineering and Computer Science</a>, and Douglas Jones, a senior staff member in the MIT Lincoln Laboratory’s Human Language Technology Group. A second Language/AI Incubator colloquium is planned for August.</p><p dir=\"ltr\">Greater integration between the social and hard sciences can potentially increase the likelihood of developing viable solutions and reducing biases. Allowing for shifts in the ways patients and doctors view the relationship, while offering each shared ownership of the interaction, can help improve outcomes. Facilitating these conversations with AI may speed the integration of these perspectives.&nbsp;</p><p dir=\"ltr\">“Community advocates have a voice and should be included in these conversations,” Celi says. “AI and statistical modeling can’t collect all the data needed to treat all the people who need it.”</p><p dir=\"ltr\">Community needs and improved educational opportunities and practices should be coupled with cross-disciplinary approaches to knowledge acquisition and transfer. The ways people see things are limited by their perceptions and other factors. “Whose language are we modeling?” Gameiro asks about building LLMs. “Which varieties of speech are being included or excluded?” Since meaning and intent can shift across those contexts, it’s important to remember these when designing AI tools.&nbsp;</p><p><strong>“AI is our chance to rewrite the rules”</strong></p><p dir=\"ltr\">While there’s lots of potential in the collaboration, there are serious challenges to overcome, including establishing and scaling the technological means to improve patient-provider communication with AI, extending opportunities for collaboration to marginalized and underserved communities, and reconsidering and revamping patient care.&nbsp;</p><p dir=\"ltr\">But the team isn’t daunted.</p><p dir=\"ltr\">Celi believes there are opportunities to address the widening gap between people and practitioners while addressing gaps in health care. “Our intent is to reattach the string that’s been cut between society and science,” he says. “We can empower scientists and the public to investigate the world together while also acknowledging the limitations engendered in overcoming their biases.”</p><p dir=\"ltr\">Gameiro is a passionate advocate for AI’s ability to change everything we know about medicine. “I’m a medical doctor, and I don’t think I’m being hyperbolic when I say I believe AI is our chance to rewrite the rules of what medicine can do and who we can reach,” he says.</p><p dir=\"ltr\">“Education changes humans from objects to subjects,” Urlaub argues, describing the difference between disinterested observers and active and engaged participants in the new care model he hopes to build. “We need to better understand technology’s impact on the lines between these states of being.”</p><p dir=\"ltr\">Celi, Gameiro, and Urlaub each advocate for MITHIC-like spaces across health care, places where innovation and collaboration are allowed to occur without the kinds of arbitrary benchmarks institutions have previously used to mark success.</p><p dir=\"ltr\">“AI will transform all these sectors,” Urlaub believes. “MITHIC is a generous framework that allows us to embrace uncertainty with flexibility.”</p><p dir=\"ltr\">“We want to employ our power to build community among disparate audiences while admitting we don’t have all the answers,” Celi says. “If we fail, it’s because we failed to dream big enough about how a reimagined world could look.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/mit-language-ai-incubator.jpg?itok=cjqvFlrc",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image: iStock"
        }
      ],
      "credit": "Image: iStock",
      "tags": [
        {
          "term": "Languages",
          "scheme": "https://news.mit.edu/topic/languages",
          "label": null
        },
        {
          "term": "Communications",
          "scheme": "https://news.mit.edu/topic/communications-0",
          "label": null
        },
        {
          "term": "Health care",
          "scheme": "https://news.mit.edu/topic/health-care",
          "label": null
        },
        {
          "term": "Technology and society",
          "scheme": "https://news.mit.edu/topic/technology-society",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Institute for Medical Engineering and Science (IMES)",
          "scheme": "https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0",
          "label": null
        },
        {
          "term": "Lincoln Laboratory",
          "scheme": "https://news.mit.edu/topic/lincoln-laboratory-0",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "School of Humanities Arts and Social Sciences",
          "scheme": "https://news.mit.edu/topic/school-humanities-arts-and-social-sciences",
          "label": null
        }
      ]
    },
    {
      "title": "AI shapes autonomous underwater “gliders”",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "AI shapes autonomous underwater “gliders”"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/ai-shapes-autonomous-underwater-gliders-0709"
        }
      ],
      "link": "https://news.mit.edu/2025/ai-shapes-autonomous-underwater-gliders-0709",
      "summary": "An AI pipeline developed by CSAIL researchers enables unique hydrodynamic designs for bodyboard-sized vehicles that glide underwater and could help scientists gather marine data.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT researchers used a new machine-learning method to produce two real-world underwater gliders: a two-winged machine resembling an airplane (lower right), and a unique, four-winged object (lower left)."
      },
      "published": "Wed, 09 Jul 2025 16:35:00 -0400",
      "published_parsed": [
        2025,
        7,
        9,
        20,
        35,
        0,
        2,
        190,
        0
      ],
      "id": "https://news.mit.edu/2025/ai-shapes-autonomous-underwater-gliders-0709",
      "guidislink": false,
      "authors": [
        {
          "name": "Alex Shipps | MIT CSAIL"
        }
      ],
      "author": "Alex Shipps | MIT CSAIL",
      "author_detail": {
        "name": "Alex Shipps | MIT CSAIL"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\" id=\"docs-internal-guid-cf34fa1c-7fff-d3f4-d4e3-35ce42aa6255\">Marine scientists have long marveled at how animals like fish and seals swim so efficiently despite having different shapes. Their bodies are optimized for efficient, hydrodynamic aquatic navigation so they can exert minimal energy when traveling long distances.<br /><br />Autonomous vehicles can drift through the ocean in a similar way, collecting data about vast underwater environments. However, the shapes of these gliding machines are less diverse than what we find in marine life — go-to designs often resemble tubes or torpedoes, since they’re fairly hydrodynamic as well. Plus, testing new builds requires lots of real-world trial-and-error.<br /><br />Researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and the University of Wisconsin at Madison propose that AI could help us explore uncharted glider designs more conveniently. Their method uses machine learning to test different 3D designs in a physics simulator, then molds them into more hydrodynamic shapes. The resulting model can be fabricated via a 3D printer using significantly less energy than hand-made ones.<br /><br />The MIT scientists say that this design pipeline could create new, more efficient machines that help oceanographers measure water temperature and salt levels, gather more detailed insights about currents, and monitor the impacts of climate change. The team demonstrated this potential by producing two gliders roughly the size of a boogie board: a two-winged machine resembling an airplane, and a unique, four-winged object resembling a flat fish with four fins.</p><p dir=\"ltr\">Peter Yichen Chen, MIT CSAIL postdoc and co-lead researcher on the project, notes that these designs are just a few of the novel shapes his team’s approach can generate. “We’ve developed a semi-automated process that can help us test unconventional designs that would be very taxing for humans to design,” he says. “This level of shape diversity hasn’t been explored previously, so most of these designs haven’t been tested in the real world.”</p><p dir=\"ltr\">But how did AI come up with these ideas in the first place? First, the researchers found 3D models of over 20 conventional sea exploration shapes, such as submarines, whales, manta rays, and sharks. Then, they enclosed these models in “deformation cages” that map out different articulation points that the researchers pulled around to create new shapes.</p><p dir=\"ltr\">The CSAIL-led team built a dataset of conventional and deformed shapes before simulating how they would perform at different “angles-of-attack” — the direction a vessel will tilt as it glides through the water. For example, a swimmer may want to dive at a -30 degree angle to retrieve an item from a pool.</p><p dir=\"ltr\">These diverse shapes and angles of attack were then used as inputs for a neural network that essentially anticipates how efficiently a glider shape will perform at particular angles and optimizes it as needed.<br /><br /><strong>Giving gliding robots a lift</strong></p><p dir=\"ltr\">The team’s neural network simulates how a particular glider would react to underwater physics, aiming to capture how it moves forward and the force that drags against it. The goal: find the best lift-to-drag ratio, representing how much the glider is being held up compared to how much it’s being held back. The higher the ratio, the more efficiently the vehicle travels; the lower it is, the more the glider will slow down during its voyage.</p><p dir=\"ltr\">Lift-to-drag ratios are key for flying planes: At takeoff, you want to maximize lift to ensure it can glide well against wind currents, and when landing, you need sufficient force to drag it to a full stop.</p><p dir=\"ltr\">Niklas Hagemann, an MIT graduate student in architecture and CSAIL affiliate, notes that this ratio is just as useful if you want a similar gliding motion in the ocean.<br /><br />“Our pipeline modifies glider shapes to find the best lift-to-drag ratio, optimizing its performance underwater,” says Hagemann, who is also a co-lead author on a&nbsp;<a href=\"https://arxiv.org/abs/2505.00222\">paper</a> that was presented at the International Conference on Robotics and Automation in June. “You can then export the top-performing designs so they can be 3D-printed.”</p><p dir=\"ltr\"><strong>Going for a quick glide</strong><br /><br />While their AI pipeline seemed realistic, the researchers needed to ensure its predictions about glider performance were accurate by experimenting in more lifelike environments.</p><p dir=\"ltr\">They first fabricated their two-wing design as a scaled-down vehicle resembling a paper airplane. This glider was taken to MIT’s Wright Brothers Wind Tunnel, an indoor space with fans that simulate wind flow. Placed at different angles, the glider’s predicted lift-to-drag ratio was only about 5 percent higher on average than the ones recorded in the wind experiments — a small difference between simulation and reality.<br /><br />A digital evaluation involving a visual, more complex physics simulator also supported the notion that the AI pipeline made fairly accurate predictions about how the gliders would move. It visualized how these machines would descend in 3D.<br /><br />To truly evaluate these gliders in the real world, though, the team needed to see how their devices would fare underwater. They printed two designs that performed the best at specific points-of-attack for this test: a jet-like device at 9 degrees and the four-wing vehicle at 30 degrees.</p><p dir=\"ltr\">Both shapes were fabricated in a 3D printer as hollow shells with small holes that flood when fully submerged. This lightweight design makes the vehicle easier to handle outside of the water and requires less material to be fabricated. The researchers placed a tube-like device inside these shell coverings, which housed a range of hardware, including a pump to change the glider’s buoyancy, a mass shifter (a device that controls the machine’s angle-of-attack), and electronic components.<br /><br />Each design outperformed a handmade torpedo-shaped glider by moving more efficiently across a pool. With higher lift-to-drag ratios than their counterpart, both AI-driven machines exerted less energy, similar to the effortless ways marine animals navigate the oceans.<br /><br />As much as the project is an encouraging step forward for glider design, the researchers are looking to narrow the gap between simulation and real-world performance. They are also hoping to develop machines that can react to sudden changes in currents, making the gliders more adaptable to seas and oceans.<br /><br />Chen adds that the team is looking to explore new types of shapes, particularly thinner glider designs. They intend to make their framework faster, perhaps bolstering it with new features that enable more customization, maneuverability, or even the creation of miniature vehicles.<br /><br />Chen and Hagemann co-led research on this project with OpenAI researcher Pingchuan Ma SM ’23, PhD ’25. They authored the paper with Wei Wang, a University of Wisconsin at Madison assistant professor and recent CSAIL postdoc; John Romanishin ’12, SM ’18, PhD ’23; and two MIT professors and CSAIL members: lab director Daniela Rus and senior author Wojciech Matusik. Their work was supported, in part, by a Defense Advanced Research Projects Agency (DARPA) grant and the MIT-GIST Program.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/mit-auv-Gliders.png?itok=HN0AnVPX",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image courtesy of the researchers."
        }
      ],
      "credit": "Image courtesy of the researchers.",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Robotics",
          "scheme": "https://news.mit.edu/topic/robotics",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Design",
          "scheme": "https://news.mit.edu/topic/design",
          "label": null
        },
        {
          "term": "Autonomous Underwater Vehicles (AUV)",
          "scheme": "https://news.mit.edu/topic/autonomous-underwater-vehicles-auv",
          "label": null
        },
        {
          "term": "Invention",
          "scheme": "https://news.mit.edu/topic/invention",
          "label": null
        },
        {
          "term": "3-D printing",
          "scheme": "https://news.mit.edu/topic/3-d-printing",
          "label": null
        },
        {
          "term": "Marine biology",
          "scheme": "https://news.mit.edu/topic/marine-biology",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "Defense Advanced Research Projects Agency (DARPA)",
          "scheme": "https://news.mit.edu/topic/darpa",
          "label": null
        }
      ]
    },
    {
      "title": "Study could lead to LLMs that are better at complex reasoning",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Study could lead to LLMs that are better at complex reasoning"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/study-could-lead-llms-better-complex-reasoning-0708"
        }
      ],
      "link": "https://news.mit.edu/2025/study-could-lead-llms-better-complex-reasoning-0708",
      "summary": "Researchers developed a way to make large language models more adaptable to challenging tasks like strategic planning or process optimization.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT researchers have shown how strategically applying a method known as test-time training with task-specific examples can boost the accuracy of an LLM more than sixfold."
      },
      "published": "Tue, 08 Jul 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        8,
        4,
        0,
        0,
        1,
        189,
        0
      ],
      "id": "https://news.mit.edu/2025/study-could-lead-llms-better-complex-reasoning-0708",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>For all their impressive capabilities, large language models (LLMs) often fall short when given challenging new tasks that require complex reasoning skills.</p><p>While an accounting firm’s LLM might excel at summarizing financial reports, that same model could fail unexpectedly if tasked with predicting market trends or identifying fraudulent transactions.</p><p>To make LLMs more adaptable, MIT researchers investigated how a certain training technique can be strategically deployed to boost a model’s performance on unfamiliar, difficult problems.</p><p>They show that test-time training, a method that involves temporarily updating some of a model’s inner workings during deployment, can lead to a sixfold improvement in accuracy. The researchers developed a framework for implementing a test-time training strategy that uses examples of the new task to maximize these gains.</p><p>Their work could improve a model’s flexibility, enabling an off-the-shelf LLM to adapt to complex tasks that require planning or abstraction. This could lead to LLMs that would be more accurate in many applications that require logical deduction, from medical diagnostics to supply chain management.</p><p>“Genuine learning — what we did here with test-time training — is something these models can’t do on their own after they are shipped. They can’t gain new skills or get better at a task. But we have shown that if you push the model a little bit to do actual learning, you see that huge improvements in performance can happen,” says Ekin Akyürek PhD ’25, lead author of the study.</p><p>Akyürek is joined on the <a href=\"https://arxiv.org/pdf/2411.07279\" target=\"_blank\">paper</a> by graduate students Mehul Damani, Linlu Qiu, Han Guo, and Jyothish Pari; undergraduate Adam Zweiger; and senior authors Yoon Kim, an assistant professor of Electrical Engineering and Computer Science (EECS) and a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL); and Jacob Andreas, an associate professor in EECS and a member of CSAIL. The research will be presented at the International Conference on Machine Learning.</p><p><strong>Tackling hard domains</strong></p><p>LLM users often try to improve the performance of their model on a new task using a technique called in-context learning. They feed the model a few examples of the new task as text prompts which guide the model’s outputs.</p><p>But in-context learning doesn’t always work for problems that require logic and reasoning.</p><p>The MIT researchers investigated how test-time training can be used in conjunction with in-context learning to boost performance on these challenging tasks. Test-time training involves updating some model parameters — the internal variables it uses to make predictions — using a small amount of new data specific to the task at hand.</p><p>The researchers explored how test-time training interacts with in-context learning. They studied design choices that maximize the performance improvements one can coax out of a general-purpose LLM.</p><p>“We find that test-time training is a much stronger form of learning.&nbsp;While simply providing examples can modestly boost accuracy, actually updating the model with those examples can lead to significantly better performance, particularly&nbsp;in challenging domains,” Damani says.</p><p>In-context learning requires a small set of task examples, including problems and their solutions. The researchers use these examples to create a task-specific dataset needed for test-time training.</p><p>To expand the size of this dataset, they create new inputs by slightly changing the problems and solutions in the examples, such as by horizontally flipping some input data. They find that training the model on the outputs of this new dataset leads to the best performance.</p><p>In addition, the researchers only update a small number of model parameters using a technique called low-rank adaption, which improves the efficiency of the test-time training process.</p><p>“This is important because our method needs to be efficient if it is going to be deployed in the real world. We find that you can get huge improvements in accuracy with a very small amount of parameter training,” Akyürek says.</p><p><strong>Developing new skills</strong></p><p>Streamlining the process is key, since test-time training is employed on a per-instance basis, meaning a user would need to do this for each individual task. The updates to the model are only temporary, and the model reverts to its original form after making a prediction.</p><p>A model that usually takes less than a minute to answer a query might take five or 10 minutes to provide an answer with test-time training, Akyürek adds.</p><p>“We wouldn’t want to do this for all user queries, but it is useful if you have a very hard task that you want to the model to solve well. There also might be tasks that are too challenging for an LLM to solve without this method,” he says.</p><p>The researchers tested their approach on two benchmark datasets of extremely complex problems, such as IQ puzzles. It boosted accuracy as much as sixfold over techniques that use only in-context learning.</p><p>Tasks that involved structured patterns or those which used completely unfamiliar types of data showed the largest performance improvements.</p><p>“For simpler tasks, in-context learning might be OK. But updating the parameters themselves might develop a new skill in the model,” Damani says.</p><p>In the future, the researchers want to use these insights toward the development of models that continually learn.</p><p>The long-term goal is an LLM that, given a query, can automatically determine if it needs to use test-time training to update parameters or if it can solve the task using in-context learning, and then implement the best test-time training strategy without the need for human intervention.</p><p>This work is supported, in part, by the MIT-IBM Watson AI Lab and the National Science Foundation.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT-fewshot-01-press.jpg?itok=WPSxbpOJ",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: Jose-Luis Olivares, MIT; iStock"
        }
      ],
      "credit": "Credit: Jose-Luis Olivares, MIT; iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "MIT-IBM Watson AI Lab",
          "scheme": "https://news.mit.edu/topic/mit-ibm-watson-ai-lab",
          "label": null
        },
        {
          "term": "National Science Foundation (NSF)",
          "scheme": "https://news.mit.edu/topic/nsf",
          "label": null
        }
      ]
    },
    {
      "title": "New postdoctoral fellowship program to accelerate innovation in health care",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "New postdoctoral fellowship program to accelerate innovation in health care"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/new-postdoctoral-fellowship-program-accelerate-innovation-health-care-0707"
        }
      ],
      "link": "https://news.mit.edu/2025/new-postdoctoral-fellowship-program-accelerate-innovation-health-care-0707",
      "summary": "Launched with a gift from the Biswas Family Foundation, the Biswas Postdoctoral Fellowship Program will support postdocs in health and life sciences.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "The Biswas Postdoctoral Fellowship Program is supported by a gift from the Biswas Family Foundation, co-founded by Hope Biswas (left) and MIT alumnus Sanjit Biswas SM ’05."
      },
      "published": "Mon, 07 Jul 2025 10:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        7,
        14,
        0,
        0,
        0,
        188,
        0
      ],
      "id": "https://news.mit.edu/2025/new-postdoctoral-fellowship-program-accelerate-innovation-health-care-0707",
      "guidislink": false,
      "authors": [
        {
          "name": "Michaela Jarvis | Office of Innovation and Strategy"
        }
      ],
      "author": "Michaela Jarvis | Office of Innovation and Strategy",
      "author_detail": {
        "name": "Michaela Jarvis | Office of Innovation and Strategy"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>The <a href=\"https://heals.mit.edu/\">MIT Health and Life Sciences Collaborative (MIT HEALS) </a>is launching the Biswas Postdoctoral Fellowship Program to advance the work of outstanding early-career researchers in health and life sciences. Supported by a gift from the Biswas Family Foundation, the program aims to help apply cutting-edge research to improve health care and the lives of millions.</p><p>The program will support exceptional postdocs dedicated to innovation in human health care through a full range of pathways, such as leveraging AI in health-related research, developing low-cost diagnostics, and the convergence of life sciences with such areas as economics, business, policy, or the humanities. With initial funding of $12 million, five four-year fellowships will be awarded for each of the next four years, starting in early 2026.</p><p>“An essential goal of MIT HEALS is to find new ways and opportunities to deliver health care solutions at scale, and the Biswas Family Foundation shares our commitment to scalable innovation and broad impact. MIT is also in the talent business, and the foundation’s gift allows us to bring exceptional scholars to campus to explore some of the most pressing issues in human health and build meaningful connections across academia and industry. We look forward to welcoming the first cohort of Biswas Fellows to MIT,” says MIT president Sally Kornbluth.</p><p>“We are deeply honored to launch this world-class postdoctoral fellows program,” adds Anantha P. Chandrakasan, MIT’s chief innovation and strategy officer and head of MIT HEALS. “We fully expect to attract top candidates from around the globe to lead innovative cross-cutting projects in AI and health, cancer therapies, diagnostics, and beyond. These fellows will be selected through a rigorous process overseen by a distinguished committee, and will have the opportunity to collaborate with our faculty on the most promising and impactful ideas.”</p><p>Angela Koehler, faculty lead of MIT HEALS, professor in MIT’s Department of Biological Engineering, and associate director of the Koch Institute for Integrative Cancer Research, emphasized that the objectives of MIT HEALS align well with a stated goal of the Biswas Family Foundation: to leverage “scientific and technological advancements to revolutionize health care and make a lasting impact on global public health.”</p><p>“Health care is a team sport,” Koehler says. “MIT HEALS seeks to create connections involving investigators with diverse expertise across the Institute to tackle the most transformative problems impacting human health. Members of the MIT community are well poised to participate in teams and make an impact.”</p><p>MIT HEALS also seeks to maximize its effectiveness by expanding collaboration with medical schools and hospitals, starting with defining important problems that can be approached through research, and continuing all the way to clinical studies, Koehler says.</p><p>The Biswas Family Foundation has already demonstrated a similar strategy.</p><p>“The Biswas family has a history of enabling connections and partnerships between institutions that each bring a piece to the puzzle,” Koehler says. “This could be a dataset, an algorithm, an agent, a technology platform, or patients.”</p><p>Hope Biswas, co-founder of the Biswas Family Foundation with her husband, MIT alumnus Sanjit Biswas SM ’05, also highlighted the synergies between the foundation and MIT.</p><p>“The Biswas Family Foundation is proud to support the MIT HEALS initiative, which reimagines how scientific discovery can translate into real-world health impact. Its focus on promoting interdisciplinary collaboration to find new solutions to challenges in health care aligns closely with our mission to advance science and technology to improve health outcomes at scale,” Biswas says.</p><p>“As part of this commitment,” Biswas adds, “we are especially proud to support outstanding postdoctoral scholars focused on high-impact cross-disciplinary work in fields such as computational biology, nanoscale therapeutics, women’s health, and fundamental, curiosity-driven life sciences research. We are excited to contribute to an effort that brings together cutting-edge science and a deep commitment to translating knowledge into action.”</p><p>AI and machine-learning systems present a new universe of opportunities to investigate disease, biological mechanisms, therapeutics, and health care delivery using huge datasets.</p><p>“AI and computational systems biology can improve the accuracy of diagnostic approaches, enable the development of precision medicines, improve choices related to individualized treatment strategy, and improve operational efficiency within health care systems,” says Koehler. “Sanjit and Hope’s support of broad initiatives in AI and computational systems biology will help MIT researchers explore a variety of paths to impact human health on a large scale.”</p><p>Frontiers in health-related research are increasingly found where diverse fields converge, and Koehler provides the example of how advances in high-throughput experimentation to develop large datasets “may couple well with the development of new computation or AI tools.” She adds that the four-year funding term provided by the postdoctoral fellowship is “long enough to enable fellows to think big and take on projects at interfaces, emerging as bilingual researchers at the end of the program.”</p><p>Chandrakasan sees potential in the program for the Biswas Fellows to make revolutionary progress in health research.</p><p>“I’m incredibly grateful to the Biswas Family Foundation for their generous support in enabling transformative research at MIT,” Chandrakasan says.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/Sanjit-and-Hope-Biswas.jpg?itok=XApYiAPf",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo courtesy of the Biswas family."
        }
      ],
      "credit": "Photo courtesy of the Biswas family.",
      "tags": [
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "Biological engineering",
          "scheme": "https://news.mit.edu/topic/biological-engineering",
          "label": null
        },
        {
          "term": "Koch Institute",
          "scheme": "https://news.mit.edu/topic/koch-institute-0",
          "label": null
        },
        {
          "term": "Health sciences and technology",
          "scheme": "https://news.mit.edu/topic/health",
          "label": null
        },
        {
          "term": "Health care",
          "scheme": "https://news.mit.edu/topic/health-care",
          "label": null
        },
        {
          "term": "Health",
          "scheme": "https://news.mit.edu/topic/health2",
          "label": null
        },
        {
          "term": "Awards, honors and fellowships",
          "scheme": "https://news.mit.edu/topic/awards",
          "label": null
        },
        {
          "term": "Graduate, postdoctoral",
          "scheme": "https://news.mit.edu/topic/graduate",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Alumni/ae",
          "scheme": "https://news.mit.edu/topic/alumni",
          "label": null
        },
        {
          "term": "Collaboration",
          "scheme": "https://news.mit.edu/topic/collaboration",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Funding",
          "scheme": "https://news.mit.edu/topic/funding",
          "label": null
        }
      ]
    },
    {
      "title": "Exploring data and its influence on political behavior",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Exploring data and its influence on political behavior"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/exploring-data-and-its-influence-political-behavior-0707"
        }
      ],
      "link": "https://news.mit.edu/2025/exploring-data-and-its-influence-political-behavior-0707",
      "summary": "In MIT's course 17.831 (Data and Politics), students are introduced to the power of analysis, visualization, and research-supported insight into political outcomes.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "“You have to understand the people at the other end of the data,” argues associate professor of political science Daniel Hidalgo. Class 17.831 (Data and Politics) helps students make sense of political campaigns and their outcomes."
      },
      "published": "Mon, 07 Jul 2025 10:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        7,
        14,
        0,
        0,
        0,
        188,
        0
      ],
      "id": "https://news.mit.edu/2025/exploring-data-and-its-influence-political-behavior-0707",
      "guidislink": false,
      "authors": [
        {
          "name": "Benjamin Daniel | School of Humanities, Arts, and Social Sciences"
        }
      ],
      "author": "Benjamin Daniel | School of Humanities, Arts, and Social Sciences",
      "author_detail": {
        "name": "Benjamin Daniel | School of Humanities, Arts, and Social Sciences"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Data and politics are becoming increasingly intertwined. Today’s political campaigns and voter mobilization efforts are now entirely data-driven. Voters, pollsters, and elected officials are relying on data to make choices that have local, regional, and national impacts.</p><p>A <a href=\"https://polisci.mit.edu/\" target=\"_blank\">Department of Political Science</a> course offers students tools to help make sense of these choices and their outcomes.</p><p>In class 17.831 (Data and Politics), students are introduced to principles and practices necessary to understand electoral and other types of political behavior. Taught by associate professor of political science <a href=\"https://polisci.mit.edu/people/f-daniel-hidalgo\" target=\"_blank\">Daniel Hidalgo</a>, students use real-world datasets to explore topics like election polling and prediction, voter turnout, voter targeting, and shifts in public opinion over time.</p><p>The course wants students to describe why and how the use of data and statistical methods has changed electoral politics, understand the basic principles of social science statistics, and analyze data using modern statistical computing tools. The course capstone is an original project that involves the collection, analysis, and interpretation of original survey data used in modern campaigns.</p><p>“I wanted to create an applied, practice-based course that would appeal to undergraduates and provide a foundation for parsing, understanding, and reporting on large datasets in politics,” says Hidalgo, who redesigned the course for the spring 2025 semester.</p><p>Hidalgo, who also works in the <a href=\"https://pmlab.mit.edu/\" target=\"_blank\">Political Methodology Lab</a> at MIT, investigates the political economy of elections, campaigns, and representation in developing democracies, especially in Latin America, as well as quantitative methods in the social sciences.</p><p><strong>Politics and modernity</strong></p><p>The influence of, and access to, artificial intelligence and large language models makes a course like Data and Politics even more important, Hidalgo says. “You have to understand the people at the other end of the data,” he argues.</p><p>The course also centers the human element in politics, exploring conflict, bias, their structures, and impacts while also working to improve information literacy and coherent storytelling.</p><p>“Data analysis and collection will never be perfect,” Hidalgo says. “But analyzing and understanding who holds which ideas, and why, and using the information to tell a coherent story is valuable in politics and elsewhere.”</p><p>The “always on” nature of news and related content, coupled with the variety of communications channels available to voters, has increased the complexity of the data collection process in polling and campaigns. “In the past, people would answer the phone when you called their homes,” Hidalgo notes, describing analog methods previously used to collect voter data. Now, political scientists, data analysts, and others must contend with the availability of streaming content, mobile devices, and other channels comprising a vast, fractured media ecosystem.</p><p>The course opens a window into what happens behind the scenes of local and national political campaigns, which appealed to second-year political science major Jackson Hamilton. “I took this class hoping to expand my ability to use coding for political science applications, and in order to better understand how political models and predictions work,” he says.</p><p>“We tailor-made our own sets of questions and experimental designs that we thought would be interesting,” Hamilton adds. “I found that political issues that get a lot of media coverage are not necessarily the same issues which divide lawmakers, at least locally.”</p><p><strong>Transparency and accountability in politics and other areas</strong></p><p>Teaching students to use tools like polling and data analysis effectively can improve their ability to identify and combat disinformation and misinformation. “As a political scientist, I’m substantively engaged,” Hidalgo says, “and I’d like to help others be engaged, too.”</p><p>“There’s lots of data available, and this course provides a foundation and the resources necessary to understand and visualize it,” Hidalgo continues. “The ability to design, implement, and understand surveys has value inside and outside the classroom.”</p><p>In politics, Hidalgo believes equipping students to navigate these spaces effectively can potentially improve and increase civic engagement. Data, he says, can help defend ideas. “There’s so much information, it’s important to develop the skills and abilities necessary to understand and visualize it,” he says. “This has value for everyone.”</p><p>Second-year physics major Sean Wilson, who also took the class this spring, notes the value of data visualization and analysis both as a potential physicist and a voter. “Data analysis in both politics and in physics is essential work given that voting tendencies, public opinion, and government leadership change so often in the United States,” he says, “and that modeling can be used to support physical hypotheses and improve our understanding of how things work.”</p><p>For Wilson, the course can help anyone interested in understanding large groups’ behaviors. “Political scientists are constantly working to better understand how and why certain events occur in U.S. politics, and data analysis is an effective tool for doing so,” he says. “Members of a representative democracy can make better decisions with this kind of information.”</p><p>Hamilton, meanwhile, learned more about the behind-the-scenes machinery at work in electoral politics. “I had the opportunity to create a couple of budget trade-off questions, to get a sense of what people actually thought the government should spend money on when they had to make choices,” he says.</p><p>“Computer science and data science aren’t just useful for STEM applications; data science approaches can also be extremely useful in many social sciences,” Hamilton argues.</p><p>“[Hidalgo helped me realize] that I needed to understand and use data science approaches to gain a deeper understanding of my areas of interest,” Hamilton says. “He focuses on how different approaches in coding can be applied to different types of problems in political science.”&nbsp;</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/mit-Data-Politics-class.jpg?itok=elxuASsV",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo: Hanley Valentin"
        }
      ],
      "credit": "Photo: Hanley Valentin",
      "tags": [
        {
          "term": "School of Humanities Arts and Social Sciences",
          "scheme": "https://news.mit.edu/topic/school-humanities-arts-and-social-sciences",
          "label": null
        },
        {
          "term": "Political science",
          "scheme": "https://news.mit.edu/topic/political-science",
          "label": null
        },
        {
          "term": "Social sciences",
          "scheme": "https://news.mit.edu/topic/social-sciences",
          "label": null
        },
        {
          "term": "Classes and programs",
          "scheme": "https://news.mit.edu/topic/classes-and-programs",
          "label": null
        },
        {
          "term": "Politics",
          "scheme": "https://news.mit.edu/topic/politics",
          "label": null
        },
        {
          "term": "Democracy",
          "scheme": "https://news.mit.edu/topic/democracy",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Statistics",
          "scheme": "https://news.mit.edu/topic/statistics",
          "label": null
        },
        {
          "term": "Faculty",
          "scheme": "https://news.mit.edu/topic/faculty",
          "label": null
        },
        {
          "term": "Students",
          "scheme": "https://news.mit.edu/topic/students",
          "label": null
        }
      ]
    },
    {
      "title": "Robotic probe quickly measures key properties of new materials",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Robotic probe quickly measures key properties of new materials"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/robotic-probe-quickly-measures-key-properties-new-materials-0704"
        }
      ],
      "link": "https://news.mit.edu/2025/robotic-probe-quickly-measures-key-properties-new-materials-0704",
      "summary": "Developed to analyze new semiconductors, the system could streamline the development of more powerful solar panels.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Scientists are striving to discover new semiconductor materials that could boost the efficiency of solar cells and other electronics. The pace of innovation is bottlenecked by the speed at which researchers can manually measure important material properties, but a fully autonomous robotic system developed by MIT researchers could speed things up."
      },
      "published": "Fri, 04 Jul 2025 14:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        4,
        18,
        0,
        0,
        4,
        185,
        0
      ],
      "id": "https://news.mit.edu/2025/robotic-probe-quickly-measures-key-properties-new-materials-0704",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Scientists are striving to discover new semiconductor materials that could boost the efficiency of solar cells and other electronics. But the pace of innovation is bottlenecked by the speed at which researchers can manually measure important material properties.</p><p>A fully autonomous robotic system developed by MIT researchers could speed things up.</p><p>Their system utilizes a robotic probe to measure an important electrical property known as photoconductance, which is how electrically responsive a material is to the presence of light.</p><p>The researchers inject materials-science-domain knowledge from human experts into the machine-learning model that guides the robot’s decision making. This enables the robot to identify the best places to contact a material with the probe to gain the most information about its photoconductance, while a specialized planning procedure finds the fastest way to move between contact points.</p><p>During a 24-hour test, the fully autonomous robotic probe took more than 125 unique measurements per hour, with more precision and reliability than other artificial intelligence-based methods.</p><p>By dramatically increasing the speed at which scientists can characterize important properties of new semiconductor materials, this method could spur the development of solar panels that produce more electricity.</p><p>“I find this paper to be incredibly exciting because it provides a pathway for autonomous, contact-based characterization methods. Not every important property of a material can be measured in a contactless way. If you need to make contact with your sample, you want it to be fast and you want to maximize the amount of information that you gain,” says Tonio Buonassisi, professor of mechanical engineering and senior author of a <a href=\"https://doi.org/10.1126/sciadv.adw7071\" target=\"_blank\">paper</a> on the autonomous system.</p><p>His co-authors include lead author Alexander (Aleks) Siemenn, a graduate student; postdocs Basita Das and Kangyu Ji; and graduate student Fang Sheng. The work appears today in <em>Science Advances</em>.</p><p><strong>Making contact</strong></p><p>Since 2018, researchers in Buonassisi’s laboratory have been working toward a fully autonomous materials discovery laboratory. They’ve recently focused on discovering new perovskites, which are a class of semiconductor materials used in photovoltaics like solar panels.</p><p>In prior work, they developed techniques to rapidly synthesize and print unique combinations of perovskite material. They also designed&nbsp;<a href=\"https://news.mit.edu/2024/new-computer-vision-method-helps-speed-screening-electronic-materials-0611\" target=\"_blank\">imaging-based methods</a> to determine some important material properties.</p><p>But photoconductance is most accurately characterized by placing a probe onto the material, shining a light, and measuring the electrical response.</p><p>“To allow our experimental laboratory to operate as quickly and accurately as possible, we had to come up with a solution that would produce the best measurements while minimizing the time it takes to run the whole procedure,” says Siemenn.</p><p>Doing so required the integration of machine learning, robotics, and material science into one autonomous system.</p><p>To begin, the robotic system uses its onboard camera to take an image of a slide with perovskite material printed on it.</p><p>Then it uses computer vision to cut that image into segments, which are fed into a neural network model that has been specially designed to incorporate domain expertise from chemists and materials scientists.</p><p>“These robots can improve the repeatability and precision of our operations, but it is important to still have a human in the loop. If we don’t have a good way to implement the rich knowledge from these chemical experts into our robots, we are not going to be able to discover new materials,” Siemenn adds.</p><p>The model uses this domain knowledge to determine the optimal points for the probe to contact based on the shape of the sample and its material composition. These contact points are fed into a path planner that finds the most efficient way for the probe to reach all points.</p><p>The adaptability of this machine-learning approach is especially important because the printed samples have unique shapes, from circular drops to jellybean-like structures.</p><p>“It is almost like measuring snowflakes — it is difficult to get two that are identical,” Buonassisi says.</p><p>Once the path planner finds the shortest path, it sends signals to the robot’s motors, which manipulate the probe and take measurements at each contact point in rapid succession.</p><p>Key to the speed of this approach is the self-supervised nature of the neural network model. The model determines optimal contact points directly on a sample image — without the need for labeled training data.</p><p>The researchers also accelerated the system by enhancing the path planning procedure. They found that adding a small amount of noise, or randomness, to the algorithm helped it find the shortest path.</p><p>“As we progress in this age of autonomous labs, you really do need all three of these expertise — hardware building, software, and an understanding of materials science — coming together into the same team to be able to innovate quickly. And that is part of the secret sauce here,” Buonassisi says.</p><p><strong>Rich data, rapid results</strong></p><p>Once they had built the system from the ground up, the researchers tested each component. Their results showed that the neural network model found better contact points with less computation time than seven other AI-based methods. In addition, the path planning algorithm consistently found shorter path plans than other methods.</p><p>When they put all the pieces together to conduct a 24-hour fully autonomous experiment, the robotic system conducted more than 3,000 unique photoconductance measurements at a rate exceeding 125 per hour.</p><p>In addition, the level of detail provided by this precise measurement approach enabled the researchers to identify hotspots with higher photoconductance as well as areas of material degradation.</p><p>“Being able to gather such rich data that can be captured at such fast rates, without the need for human guidance, starts to open up doors to be able to discover and develop new high-performance semiconductors, especially for sustainability applications like solar panels,” Siemenn says.</p><p>The researchers want to continue building on this robotic system as they strive to create a fully autonomous lab for materials discovery.</p><p>This work is supported, in part, by First Solar, Eni through the MIT Energy Initiative, MathWorks, the University of Toronto’s Acceleration Consortium, the U.S. Department of Energy, and the U.S. National Science Foundation.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202507/MIT-Semiconductor-Properties-01.jpg?itok=Fwzfj0MI",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: iStock"
        }
      ],
      "credit": "Credit: iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Computer vision",
          "scheme": "https://news.mit.edu/topic/computer-vision",
          "label": null
        },
        {
          "term": "Materials science and engineering",
          "scheme": "https://news.mit.edu/topic/materialsscienceandengineering",
          "label": null
        },
        {
          "term": "Robotics",
          "scheme": "https://news.mit.edu/topic/robotics",
          "label": null
        },
        {
          "term": "Mechanical engineering",
          "scheme": "https://news.mit.edu/topic/mechanical-engineering",
          "label": null
        },
        {
          "term": "Solar",
          "scheme": "https://news.mit.edu/topic/solar",
          "label": null
        },
        {
          "term": "Sustainability",
          "scheme": "https://news.mit.edu/topic/sustainability",
          "label": null
        },
        {
          "term": "Renewable energy",
          "scheme": "https://news.mit.edu/topic/renewable-energy",
          "label": null
        },
        {
          "term": "Research Laboratory of Electronics",
          "scheme": "https://news.mit.edu/topic/research-laboratory-electronics-1",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "National Science Foundation (NSF)",
          "scheme": "https://news.mit.edu/topic/nsf",
          "label": null
        },
        {
          "term": "Department of Energy (DoE)",
          "scheme": "https://news.mit.edu/topic/doe",
          "label": null
        }
      ]
    },
    {
      "title": "Confronting the AI/energy conundrum",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Confronting the AI/energy conundrum"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/confronting-ai-energy-conundrum-0702"
        }
      ],
      "link": "https://news.mit.edu/2025/confronting-ai-energy-conundrum-0702",
      "summary": "The MIT Energy Initiative’s annual research symposium explores artificial intelligence as both a problem and a solution for the clean energy transition.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "At the 2025 MIT Energy Initiative Spring Symposium, Evelyn Wang (at lectern), the MIT vice president for energy and climate, joined MITEI Director William H. Green to discuss how collaborations across campus can help solve the data center challenge."
      },
      "published": "Wed, 02 Jul 2025 15:00:00 -0400",
      "published_parsed": [
        2025,
        7,
        2,
        19,
        0,
        0,
        2,
        183,
        0
      ],
      "id": "https://news.mit.edu/2025/confronting-ai-energy-conundrum-0702",
      "guidislink": false,
      "authors": [
        {
          "name": "Leda Zimmerman | MIT Energy Initiative"
        }
      ],
      "author": "Leda Zimmerman | MIT Energy Initiative",
      "author_detail": {
        "name": "Leda Zimmerman | MIT Energy Initiative"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>The explosive growth of AI-powered computing centers is creating an unprecedented surge in electricity demand that threatens to overwhelm power grids and derail climate goals. At the same time, artificial intelligence technologies could revolutionize energy systems, accelerating the transition to clean power.</p><p>“We’re at a cusp of potentially gigantic change throughout the economy,” said <a href=\"https://energy.mit.edu/profile/william-green/\">William H. Green</a>, director of the MIT Energy Initiative (MITEI) and Hoyt C. Hottel Professor in the MIT Department of Chemical Engineering, at MITEI’s Spring Symposium, “AI and energy: Peril and promise,” held on May 13. The event brought together experts from industry, academia, and government to explore solutions to what Green described as both “local problems with electric supply and meeting our clean energy targets” while seeking to “reap the benefits of AI without some of the harms.” The challenge of data center energy demand and potential benefits of AI to the energy transition is a research priority for MITEI.</p><p><strong>AI’s startling energy demands</strong></p><p>From the start, the symposium highlighted sobering statistics about AI’s appetite for electricity. After decades of flat electricity demand in the United States, computing centers now consume approximately 4 percent of the nation's electricity. Although there is great uncertainty, some projections suggest this demand could rise to 12-15 percent by 2030, largely driven by artificial intelligence applications.</p><p>Vijay Gadepally, senior scientist at MIT’s Lincoln Laboratory, emphasized the scale of AI’s consumption. “The power required for sustaining some of these large models is doubling almost every three months,” he noted. “A single ChatGPT conversation uses as much electricity as charging your phone, and generating an image consumes about a bottle of water for cooling.”</p><p>Facilities requiring 50 to 100 megawatts of power are emerging rapidly across the United States and globally, driven both by casual and institutional research needs relying on large language programs such as ChatGPT and Gemini. Gadepally cited congressional testimony by Sam Altman, CEO of OpenAI, highlighting how fundamental this relationship has become: “The cost of intelligence, the cost of AI, will converge to the cost of energy.”</p><p>“The energy demands of AI are a significant challenge, but we also have an opportunity to harness these vast computational capabilities to contribute to climate change solutions,” said <a href=\"https://energy.mit.edu/profile/evelyn-wang/\">Evelyn Wang</a>, MIT vice president for energy and climate and the former director at the Advanced Research Projects Agency-Energy (ARPA-E) at the U.S. Department of Energy.</p><p>Wang also noted that innovations developed for AI and data centers — such as efficiency, cooling technologies, and clean-power solutions — could have broad applications beyond computing facilities themselves.</p><p><strong>Strategies for clean energy solutions</strong></p><p>The symposium explored multiple pathways to address the AI-energy challenge. Some panelists presented models suggesting that while artificial intelligence may increase emissions in the short term, its optimization capabilities could enable substantial emissions reductions after 2030 through more efficient power systems and accelerated clean technology development.</p><p>Research shows regional variations in the cost of powering computing centers with clean electricity, according to Emre Gençer, co-founder and CEO of Sesame Sustainability and former MITEI principal research scientist. Gençer’s analysis revealed that the central United States offers considerably lower costs due to complementary solar and wind resources. However, achieving zero-emission power would require massive battery deployments — five to 10 times more than moderate carbon scenarios — driving costs two to three times higher.</p><p>“If we want to do zero emissions with reliable power, we need technologies other than renewables and batteries, which will be too expensive,” Gençer said. He pointed to “long-duration storage technologies, small modular reactors, geothermal, or hybrid approaches” as necessary complements.</p><p>Because of data center energy demand, there is renewed interest in nuclear power, noted Kathryn Biegel, manager of R&amp;D and corporate strategy at Constellation Energy, adding that her company is restarting the reactor at the former Three Mile Island site, now called the “Crane Clean Energy Center,” to meet this demand. “The data center space has become a major, major priority for Constellation,” she said, emphasizing how their needs for both reliability and carbon-free electricity are reshaping the power industry.</p><p><strong>Can AI accelerate the energy transition?</strong></p><p>Artificial intelligence could dramatically improve power systems, according to <a href=\"https://energy.mit.edu/profile/priya-donti/\">Priya Donti</a>, assistant professor and the Silverman Family Career Development Professor in MIT's Department of Electrical Engineering and Computer Science and the Laboratory for Information and Decision Systems. She showcased how AI can accelerate power grid optimization by embedding physics-based constraints into neural networks, potentially solving complex power flow problems at “10 times, or even greater, speed compared to your traditional models.”</p><p>AI is already reducing carbon emissions, according to examples shared by Antonia Gawel, global director of sustainability and partnerships at Google. Google Maps’ fuel-efficient routing feature has “helped to prevent more than 2.9 million metric tons of GHG [greenhouse gas] emissions reductions since launch, which is the equivalent of taking 650,000 fuel-based cars off the road for a year,\" she said. Another Google research project uses artificial intelligence to help pilots avoid creating contrails, which represent about 1 percent of global warming impact.</p><p>AI’s potential to speed materials discovery for power applications was highlighted by <a href=\"https://energy.mit.edu/profile/rafael-gomez-bombarelli/\">Rafael Gómez-Bombarelli</a>, the Paul M. Cook Career Development Associate Professor in the MIT Department of Materials Science and Engineering. “AI-supervised models can be trained to go from structure to property,” he noted, enabling the development of materials crucial for both computing and efficiency.</p><p><strong>Securing growth with sustainability</strong></p><p>Throughout the symposium, participants grappled with balancing rapid AI deployment against environmental impacts. While AI training receives most attention, Dustin Demetriou, senior technical staff member in sustainability and data center innovation at IBM, quoted a World Economic Forum article that suggested that “80 percent of the environmental footprint is estimated to be due to inferencing.” Demetriou emphasized the need for efficiency across all artificial intelligence applications.</p><p>Jevons’ paradox, where “efficiency gains tend to increase overall resource consumption rather than decrease it” is another factor to consider, cautioned Emma Strubell, the Raj Reddy Assistant Professor in the Language Technologies Institute in the School of Computer Science at Carnegie Mellon University. Strubell advocated for viewing computing center electricity as a limited resource requiring thoughtful allocation across different applications.</p><p>Several presenters discussed novel approaches for integrating renewable sources with existing grid infrastructure, including potential hybrid solutions that combine clean installations with existing natural gas plants that have valuable grid connections already in place. These approaches could provide substantial clean capacity across the United States at reasonable costs while minimizing reliability impacts.</p><p><strong>Navigating the AI-energy paradox</strong></p><p>The symposium highlighted MIT’s central role in developing solutions to the AI-electricity challenge.</p><p>Green spoke of a new MITEI program on computing centers, power, and computation that will operate alongside the comprehensive spread of MIT Climate Project research. “We’re going to try to tackle a very complicated problem all the way from the power sources through the actual algorithms that deliver value to the customers — in a way that’s going to be acceptable to all the stakeholders and really meet all the needs,” Green said.</p><p>Participants in the symposium were polled about priorities for MIT’s research by <a href=\"https://energy.mit.edu/profile/randall-field/\">Randall Field</a>, MITEI director of research. The real-time results ranked “data center and grid integration issues” as the top priority, followed by “AI for accelerated discovery of advanced materials for energy.”</p><p>In addition, attendees revealed that most view AI's potential regarding power as a “promise,” rather than a “peril,” although a considerable portion remain uncertain about the ultimate impact. When asked about priorities in power supply for computing facilities, half of the respondents selected carbon intensity as their top concern, with reliability and cost following.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MITEI-evelyn-wang.JPG?itok=8_x4d0nl",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo: Jake Belcher"
        }
      ],
      "credit": "Photo: Jake Belcher",
      "tags": [
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "Chemical engineering",
          "scheme": "https://news.mit.edu/topic/chemical-engineering",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "DMSE",
          "scheme": "https://news.mit.edu/topic/dmse",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "Lincoln Laboratory",
          "scheme": "https://news.mit.edu/topic/lincoln-laboratory-0",
          "label": null
        },
        {
          "term": "MIT Energy Initiative",
          "scheme": "https://news.mit.edu/topic/mit-energy-initiative",
          "label": null
        },
        {
          "term": "Energy",
          "scheme": "https://news.mit.edu/topic/energy",
          "label": null
        },
        {
          "term": "Renewable energy",
          "scheme": "https://news.mit.edu/topic/renewable-energy",
          "label": null
        },
        {
          "term": "Alternative energy",
          "scheme": "https://news.mit.edu/topic/alternative-energy",
          "label": null
        },
        {
          "term": "Energy efficiency",
          "scheme": "https://news.mit.edu/topic/energy-efficiency",
          "label": null
        },
        {
          "term": "Emissions",
          "scheme": "https://news.mit.edu/topic/emissions",
          "label": null
        },
        {
          "term": "Sustainability",
          "scheme": "https://news.mit.edu/topic/sustainability",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Special events and guest speakers",
          "scheme": "https://news.mit.edu/topic/special-events",
          "label": null
        },
        {
          "term": "Faculty",
          "scheme": "https://news.mit.edu/topic/faculty",
          "label": null
        },
        {
          "term": "Staff",
          "scheme": "https://news.mit.edu/topic/staff",
          "label": null
        }
      ]
    },
    {
      "title": "Accelerating scientific discovery with AI",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Accelerating scientific discovery with AI"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630"
        }
      ],
      "link": "https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630",
      "summary": "FutureHouse, co-founded by Sam Rodriques PhD ’19, has developed AI agents to automate key steps on the path toward scientific progress.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "FutureHouse seeks to accelerate scientific research with an AI platform designed to automate many of the most critical steps on the path toward scientific progress."
      },
      "published": "Mon, 30 Jun 2025 10:30:00 -0400",
      "published_parsed": [
        2025,
        6,
        30,
        14,
        30,
        0,
        0,
        181,
        0
      ],
      "id": "https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630",
      "guidislink": false,
      "authors": [
        {
          "name": "Zach Winn | MIT News"
        }
      ],
      "author": "Zach Winn | MIT News",
      "author_detail": {
        "name": "Zach Winn | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Several researchers have taken a broad view of scientific progress over the last 50 years and come to the same troubling conclusion: Scientific productivity is declining. It’s taking more time, more funding, and larger teams to make discoveries that once came faster and cheaper. Although a variety of explanations have been offered for the slowdown, one is that, as research becomes more complex and specialized, scientists must spend more time reviewing publications, designing sophisticated experiments, and analyzing data.</p><p>Now, the philanthropically funded research lab FutureHouse is seeking to accelerate scientific research with an AI platform designed to automate many of the critical steps on the path toward scientific progress. The platform is made up of a series of AI agents specialized for tasks including information retrieval, information synthesis, chemical synthesis design, and data analysis.</p><p>FutureHouse founders Sam Rodriques PhD ’19 and Andrew White believe that by giving every scientist access to their AI agents, they can break through the biggest bottlenecks in science and help solve some of humanity’s most pressing problems.</p><p>“Natural language is the real language of science,” Rodriques says. “Other people are building foundation models for biology, where machine learning models speak the language of DNA or proteins, and that’s powerful. But discoveries aren’t represented in DNA or proteins. The only way we know how to represent discoveries, hypothesize, and reason is with natural language.”</p><p><strong>Finding big problems</strong></p><p>For his PhD research at MIT, Rodriques sought to understand the inner workings of the brain in the lab of Professor Ed Boyden.</p><p>“The entire idea behind FutureHouse was inspired by this impression I got during my PhD at MIT that even if we had all the information we needed to know about how the brain works, we wouldn’t know it because nobody has time to read all the literature,” Rodriques explains. “Even if they could read it all, they wouldn’t be able to assemble it into a comprehensive theory. That was a foundational piece of the FutureHouse puzzle.”</p><p>Rodriques wrote about the need for&nbsp;<a href=\"https://news.mit.edu/2025/former-mit-researchers-advance-new-model-innovation-0606\" target=\"_blank\">new kinds of large research collaborations</a> as the last chapter of his PhD thesis in 2019, and though he spent some time running a lab at the Francis Crick Institute in London after graduation, he found himself gravitating toward broad problems in science that no single lab could take on.</p><p>“I was interested in how to automate or scale up science and what kinds of new organizational structures or technologies would unlock higher scientific productivity,” Rodriques says.</p><p>When Chat-GPT 3.5 was released in November 2022, Rodriques saw a path toward more powerful models that could generate scientific insights on their own. Around that time, he also met Andrew White, a computational chemist at the University of Rochester who had been granted early access to Chat-GPT 4. White had built the first large language agent for science, and the researchers joined forces to start FutureHouse.</p><p>The founders started out wanting to create distinct AI tools for tasks like literature searches, data analysis, and hypothesis generation. They began with data collection, eventually releasing PaperQA in September 2024, which Rodriques calls the best AI agent in the world for retrieving and summarizing information in scientific literature. Around the same time, they released Has Anyone, a tool that lets scientists determine if anyone has conducted specific experiments or explored specific hypotheses.</p><p>“We were just sitting around asking, ‘What are the kinds of questions that we as scientists ask all the time?’” Rodriques recalls.</p><p>When FutureHouse officially launched its platform on May 1 of this year, it rebranded some of its tools. Paper QA is now Crow, and Has Anyone is now called Owl. Falcon is an agent capable of compiling and reviewing more sources than Crow. Another new agent, Phoenix, can use specialized tools to help researchers plan chemistry experiments. And Finch is an agent designed to automate data driven discovery in biology.</p><p>On May 20, the company demonstrated a multi-agent scientific discovery workflow to automate key steps of the scientific process and identify a new therapeutic candidate for dry age-related macular degeneration (dAMD), a leading cause of irreversible blindness worldwide. In June, FutureHouse released ether0, a 24B open-weights reasoning model for chemistry.</p><p>“You really have to think of these agents as part of a larger system,” Rodriques says. “Soon, the literature search agents will be integrated with the data analysis agent, the hypothesis generation agent, an experiment planning agent, and they will all be engineered to work together seamlessly.”</p><p><strong>Agents for everyone</strong></p><p>Today anyone can access FutureHouse’s agents at platform.futurehouse.org. The company’s platform launch generated excitement in the industry, and stories have started to come in about scientists using the agents to accelerate research.</p><p>One of FutureHouse’s scientists used the agents to identify a gene that could be associated with polycystic ovary syndrome and come up with a new treatment hypothesis for the disease. Another researcher at the Lawrence Berkeley National Laboratory used Crow to create an AI assistant capable of searching the PubMed research database for information related to Alzheimer’s disease.</p><p>Scientists at another research institution have used the agents to conduct systematic reviews of genes relevant to Parkinson’s disease, finding FutureHouse’s agents performed better than general agents.</p><p>Rodriques says scientists who think of the agents less like Google Scholar and more like a smart assistant scientist get the most out of the platform.</p><p>“People who are looking for speculation tend to get more mileage out of Chat-GPT o3 deep research, while people who are looking for really faithful literature reviews tend to get more out of our agents,” Rodriques explains.</p><p>Rodriques also thinks FutureHouse will soon get to a point where its agents can use the raw data from research papers to test the reproducibility of its results and verify conclusions.</p><p>In the longer run, to keep scientific progress marching forward, Rodriques says FutureHouse is working on embedding its agents with tacit knowledge to be able to perform more sophisticated analyses while also giving the agents the ability to use computational tools to explore hypotheses.</p><p>“There have been so many advances around foundation models for science and around language models for proteins and DNA, that we now need to give our agents access to those models and all of the other tools people commonly use to do science,” Rodriques says. “Building the infrastructure to allow agents to use more specialized tools for science is going to be critical.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT-Future-House-01-press.jpg?itok=TIK4Yrb0",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: Christine Daniloff, MIT; iStock"
        }
      ],
      "credit": "Credit: Christine Daniloff, MIT; iStock",
      "tags": [
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Startups",
          "scheme": "https://news.mit.edu/topic/startups",
          "label": null
        },
        {
          "term": "Innovation and Entrepreneurship (I&E)",
          "scheme": "https://news.mit.edu/topic/innovation",
          "label": null
        },
        {
          "term": "Brain and cognitive sciences",
          "scheme": "https://news.mit.edu/topic/brain-cognitive",
          "label": null
        },
        {
          "term": "Neuroscience",
          "scheme": "https://news.mit.edu/topic/neuroscience",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        },
        {
          "term": "Alumni/ae",
          "scheme": "https://news.mit.edu/topic/alumni",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Public health",
          "scheme": "https://news.mit.edu/topic/public-health",
          "label": null
        }
      ]
    },
    {
      "title": "MIT and Mass General Brigham launch joint seed program to accelerate innovations in health",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT and Mass General Brigham launch joint seed program to accelerate innovations in health"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627"
        }
      ],
      "link": "https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627",
      "summary": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Vincent Roche, president and CEO of Analog Devices (left); Sally Kornbluth, president of MIT (center); and Anne Klibanski, president and CEO of Mass General Brigham, held a signing ceremony officially launching the MIT-MGB Seed Program. The program will fund collaborative projects, led by MIT and Mass General Brigham researchers, that advance research in human health, with the goal of developing next-generation therapies, diagnostics, and digital tools that can improve lives at scale."
      },
      "published": "Fri, 27 Jun 2025 13:00:00 -0400",
      "published_parsed": [
        2025,
        6,
        27,
        17,
        0,
        0,
        4,
        178,
        0
      ],
      "id": "https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627",
      "guidislink": false,
      "authors": [
        {
          "name": "Mary Beth Gallagher | Office of Innovation and Strategy"
        }
      ],
      "author": "Mary Beth Gallagher | Office of Innovation and Strategy",
      "author_detail": {
        "name": "Mary Beth Gallagher | Office of Innovation and Strategy"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Leveraging the strengths of two world-class research institutions, MIT and Mass General Brigham (MGB) recently celebrated the launch of the MIT-MGB Seed Program. The new initiative, which is supported by Analog Devices Inc. (ADI), will fund joint research projects led by researchers at MIT and Mass General Brigham. These collaborative projects will advance research in human health, with the goal of developing next-generation therapies, diagnostics, and digital tools that can improve lives at scale.&nbsp;</p><p>The program represents a unique opportunity to dramatically accelerate innovations that address some of the most urgent challenges in human health. By supporting interdisciplinary teams from MIT and Mass General Brigham, including both researchers and clinicians, the seed program will foster groundbreaking work that brings together expertise in artificial intelligence, machine learning, and measurement and sensing technologies with pioneering clinical research and patient care.</p><p>“The power of this program&nbsp;is that it&nbsp;combines MIT’s strength in science, engineering, and innovation with Mass General Brigham’s world-class scientific and clinical research. With the support and incentive to work together, researchers and clinicians&nbsp;will have the freedom&nbsp;to tackle compelling&nbsp;problems&nbsp;and find novel ways to&nbsp;overcome them to&nbsp;achieve transformative changes in patient care,” says Sally Kornbluth, president of MIT.</p><p>“The MIT-MGB Seed Program will enable cross-disciplinary collaboration to advance transformative research and breakthrough science. By combining the collective strengths and expertise of our great institutions, we can transform medical care and drive innovation and discovery with speed,” says Anne Klibanski, president and CEO of Mass General Brigham.</p><p>The initiative is funded by a gift from ADI. Over the next three years, the ADI Fund for Health and Life Sciences will support approximately six joint projects annually, with funding split between the two institutions.&nbsp;</p><p>“The converging domains of biology, medicine, and computing promise a new era of health-care efficacy, efficiency, and access. ADI has enjoyed a long and fruitful history of collaboration with MIT and Mass General Brigham, and we are excited by this new initiative’s potential to transform the future of patient care,” adds Vincent Roche, CEO and chair of the board of directors at ADI.</p><p>In addition to funding, teams selected for the program will have access to entrepreneurial workshops, including some hosted by The Engine — an MIT-built venture firm focused on tough tech. These sessions will connect researchers with company founders, investors, and industry leaders, helping them chart a path from breakthrough discoveries in the lab to real-world impact.</p><p>The program will launch an open call for proposals to researchers at MIT and Mass General Brigham. The first cohort of funded projects is expected to launch in fall 2025. Awardees will be selected by a joint review committee composed of MIT and Mass General Brigham experts.</p><p>According to MIT’s faculty lead for the MIT-MGB Seed Program, Alex K. Shalek, building collaborative research teams with leaders from both institutions could help fill critical gaps that often impede innovation in health and life sciences. Shalek also serves as director&nbsp;of the Institute for Medical Engineering &amp; Science (IMES), the J. W. Kieckhefer Professor in IMES and Chemistry, and an extramural member of the&nbsp;Koch Institute for Integrative Cancer Research.</p><p>&nbsp;“Clinicians often see where current interventions fall short, but may lack the scientific tools or engineering expertise needed to develop new ones. Conversely, MIT researchers may not fully grasp these clinical challenges or have access to the right patient data and samples,” explains Shalek, who is also a member of the Ragon Institute of Mass General Brigham, MIT, and Harvard. “By supporting bilateral collaborations and building a community across disciplines, this program is poised to drive critical advances in diagnostics, therapeutics, and AI-driven health applications.”</p><p>Emery Brown, a practicing anesthesiologist at Massachusetts General Hospital, will serve alongside Shalek as Mass General Brigham’s faculty lead for the program.</p><p>“The MIT-MGB Seed Program creates a perfect storm. The program will provide an opportunity for MIT faculty to bring novel science and engineering to attack and solve important clinical problems,” adds Brown, who is also the Edward Hood Taplin Professor of Medical Engineering and Computational Neuroscience at MIT. “The pursuit of solutions to important and challenging clinical problems by Mass General Brigham physicians and scientists will no doubt spur MIT scientists and engineers to develop new technologies, or find novel applications of existing technologies.”</p><p>The MIT-MGB Seed Program is a flagship initiative in the <a href=\"https://heals.mit.edu/\">MIT Health and Life Sciences Collaborative (MIT HEALS)</a>. It reflects MIT HEALS’ core mission to establish MIT as a central hub for health and life sciences innovation and translation, and to leverage connections with other world-class research institutions in the Boston area.</p><p>“This program exemplifies the power of interdisciplinary research,” says Anantha Chandrakasan, MIT’s chief innovation and strategy officer, dean of engineering, and head of MIT HEALS. “It creates a critical bridge between clinical practice and technological innovation — two areas that must be deeply connected to advance real-world solutions.”</p><p>The program’s launch was celebrated at a special event at MIT’s Samberg Conference Center on March 31.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/mit-mgb-seed-program.jpg?itok=duAg7v8E",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo: Gretchen Ertl"
        }
      ],
      "credit": "Photo: Gretchen Ertl",
      "tags": [
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        },
        {
          "term": "Biological engineering",
          "scheme": "https://news.mit.edu/topic/biological-engineering",
          "label": null
        },
        {
          "term": "Institute for Medical Engineering and Science (IMES)",
          "scheme": "https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0",
          "label": null
        },
        {
          "term": "Koch Institute",
          "scheme": "https://news.mit.edu/topic/koch-institute-0",
          "label": null
        },
        {
          "term": "The Engine",
          "scheme": "https://news.mit.edu/topic/engine",
          "label": null
        },
        {
          "term": "Health sciences and technology",
          "scheme": "https://news.mit.edu/topic/health",
          "label": null
        },
        {
          "term": "Health care",
          "scheme": "https://news.mit.edu/topic/health-care",
          "label": null
        },
        {
          "term": "Medicine",
          "scheme": "https://news.mit.edu/topic/medicine",
          "label": null
        },
        {
          "term": "Funding",
          "scheme": "https://news.mit.edu/topic/funding",
          "label": null
        },
        {
          "term": "Collaboration",
          "scheme": "https://news.mit.edu/topic/collaboration",
          "label": null
        },
        {
          "term": "Innovation and Entrepreneurship (I&E)",
          "scheme": "https://news.mit.edu/topic/innovation",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Cambridge, Boston and region",
          "scheme": "https://news.mit.edu/topic/cambridge",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        }
      ]
    },
    {
      "title": "Using generative AI to help robots jump higher and land safely",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Using generative AI to help robots jump higher and land safely"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627"
        }
      ],
      "link": "https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627",
      "summary": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Byungchul Kim (left) and Tsun-Hsuan \"Johnson\" Wang applied generative AI to improve robots designed by humans."
      },
      "published": "Fri, 27 Jun 2025 13:00:00 -0400",
      "published_parsed": [
        2025,
        6,
        27,
        17,
        0,
        0,
        4,
        178,
        0
      ],
      "id": "https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627",
      "guidislink": false,
      "authors": [
        {
          "name": "Alex Shipps | MIT CSAIL"
        }
      ],
      "author": "Alex Shipps | MIT CSAIL",
      "author_detail": {
        "name": "Alex Shipps | MIT CSAIL"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p dir=\"ltr\" id=\"docs-internal-guid-6e565cc0-7fff-cbe0-c9eb-bc35383dc425\">Diffusion models like OpenAI’s DALL-E are becoming increasingly useful in helping brainstorm new designs. Humans can prompt these systems to generate an image, create a video, or refine a blueprint, and come back with ideas they hadn’t considered before.<br /><br />But did you know that generative artificial intelligence (GenAI) models are also making headway in creating working robots?&nbsp;<a href=\"https://www.youtube.com/watch?v=LSzasdvD3Ss\">Recent</a> diffusion-based approaches have generated structures and the systems that control them from scratch. With or without a user’s input, these models can make new designs and then evaluate them in simulation before they’re fabricated.<br /><br />A new approach from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) applies this generative know-how toward improving humans’ robotic designs. Users can draft a 3D model of a robot and specify which parts they’d like to see a diffusion model modify, providing its dimensions beforehand. GenAI then brainstorms the optimal shape for these areas and tests its ideas in simulation. When the system finds the right design, you can save and then fabricate a working, real-world robot with a 3D printer, without requiring additional tweaks.<br /><br />The researchers used this approach to create a robot that leaps up an average of roughly 2 feet, or 41 percent higher than a similar machine they created on their own. The machines are nearly identical in appearance: They’re both made of a type of plastic called polylactic acid, and while they initially appear flat, they spring up into a diamond shape when a motor pulls on the cord attached to them. So what exactly did AI do differently?<br /><br />A closer look reveals that the AI-generated linkages are curved, and resemble thick drumsticks (the musical instrument drummers use), whereas the standard robot’s connecting parts are straight and rectangular.</p><p dir=\"ltr\"><strong>Better and better blobs</strong></p><p dir=\"ltr\">The researchers began to refine their jumping robot by sampling 500 potential designs using an initial embedding vector — a numerical representation that captures high-level features to guide the designs generated by the AI model. From these, they selected the top 12 options based on performance in simulation and used them to optimize the embedding vector.</p><p dir=\"ltr\">This process was repeated five times, progressively guiding the AI model to generate better designs. The resulting design resembled a blob, so the researchers prompted their system to scale the draft to fit their 3D model. They then fabricated the shape, finding that it indeed improved the robot’s jumping abilities.</p><p dir=\"ltr\">The advantage of using diffusion models for this task, according to co-lead author and CSAIL postdoc Byungchul Kim, is that they can find unconventional solutions to refine robots.</p><p dir=\"ltr\">“We wanted to make our machine jump higher, so we figured we could just make the links connecting its parts as thin as possible to make them light,” says Kim. “However, such a thin structure can easily break if we just use 3D printed material. Our diffusion model came up with a better idea by suggesting a unique shape that allowed the robot to store more energy before it jumped, without making the links too thin. This creativity helped us learn about the machine’s underlying physics.”</p><p dir=\"ltr\">The team then tasked their system with drafting an optimized foot to ensure it landed safely. They repeated the optimization process, eventually choosing the best-performing design to attach to the bottom of their machine. Kim and his colleagues found that their AI-designed machine fell far less often than its baseline, to the tune of an 84 percent improvement.</p><p dir=\"ltr\">The diffusion model’s ability to upgrade a robot’s jumping and landing skills suggests it could be useful in enhancing how other machines are designed. For example, a company working on manufacturing or household robots could use a similar approach to improve their prototypes, saving engineers time normally reserved for iterating on those changes.</p><p dir=\"ltr\"><strong>The balance behind the bounce</strong></p><p dir=\"ltr\">To create a robot that could jump high and land stably, the researchers recognized that they needed to strike a balance between both goals. They represented both jumping height and landing success rate as numerical data, and then trained their system to find a sweet spot between both embedding vectors that could help build an optimal 3D structure.</p><p dir=\"ltr\">The researchers note that while this AI-assisted robot outperformed its human-designed counterpart, it could soon reach even greater new heights. This iteration involved using materials that were compatible with a 3D printer, but future versions would jump even higher with lighter materials.<br /><br />Co-lead author and MIT PhD student and CSAIL affiliate Tsun-Hsuan “Johnson” Wang says the project is a jumping-off point for new robotics designs that generative AI could help with.</p><p dir=\"ltr\">“We want to branch out to more flexible goals,” says Wang. “Imagine using natural language to guide a diffusion model to draft a robot that can pick up a mug, or operate an electric drill.”<br /><br />Kim says that a diffusion model could also help to generate articulation and ideate on how parts connect, potentially improving how high the robot would jump. The team is also exploring the possibility of adding more motors to control which direction the machine jumps and perhaps improve its landing stability.</p><p>The researchers’ work was supported, in part, by the National Science Foundation’s Emerging Frontiers in Research and Innovation program, the Singapore-MIT Alliance for Research and Technology’s Mens, Manus and Machina program, and the Gwangju Institute of Science and Technology (GIST)-CSAIL Collaboration. They presented their work at the 2025 International Conference on Robotics and Automation.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT-Jumping_Robot%20%285%29.png?itok=uV6zSNBB",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Image courtesy of MIT CSAIL"
        }
      ],
      "credit": "Image courtesy of MIT CSAIL",
      "tags": [
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Robotics",
          "scheme": "https://news.mit.edu/topic/robotics",
          "label": null
        },
        {
          "term": "Design",
          "scheme": "https://news.mit.edu/topic/design",
          "label": null
        },
        {
          "term": "3-D printing",
          "scheme": "https://news.mit.edu/topic/3-d-printing",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        }
      ]
    },
    {
      "title": "Merging AI and underwater photography to reveal hidden ocean worlds",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Merging AI and underwater photography to reveal hidden ocean worlds"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/lobstger-merging-ai-underwater-photography-to-reveal-hidden-ocean-worlds-0625"
        }
      ],
      "link": "https://news.mit.edu/2025/lobstger-merging-ai-underwater-photography-to-reveal-hidden-ocean-worlds-0625",
      "summary": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Can you spot the real photo? One of these blue shark images was captured 30 nautical miles off the coast of Cape Cod; the other was generated by LOBSTgER’s diffusion models after 30,000 training epochs (an epoch refers to one complete pass of an entire training dataset through a learning algorithm). Answer at the end of this article."
      },
      "published": "Wed, 25 Jun 2025 09:55:00 -0400",
      "published_parsed": [
        2025,
        6,
        25,
        13,
        55,
        0,
        2,
        176,
        0
      ],
      "id": "https://news.mit.edu/2025/lobstger-merging-ai-underwater-photography-to-reveal-hidden-ocean-worlds-0625",
      "guidislink": false,
      "authors": [
        {
          "name": "MIT Sea Grant"
        }
      ],
      "author": "MIT Sea Grant",
      "author_detail": {
        "name": "MIT Sea Grant"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>In the Northeastern United States, the Gulf of Maine represents one of the most biologically diverse marine ecosystems on the planet — home to whales, sharks, jellyfish, herring, plankton, and hundreds of other species. But even as this ecosystem supports rich biodiversity, it is undergoing rapid environmental change. The Gulf of Maine is warming faster than 99 percent of the world’s oceans, with consequences that are still unfolding.</p><p>A new research initiative developing at MIT Sea Grant, called LOBSTgER — short for Learning Oceanic Bioecological Systems Through Generative Representations — brings together artificial intelligence and underwater photography to document the ocean life left vulnerable to these changes and share them with the public in new visual ways. Co-led by underwater photographer and visiting artist at MIT Sea Grant Keith Ellenbogen and MIT mechanical engineering PhD student Andreas Mentzelopoulos, the project explores how generative AI can expand scientific storytelling by building on field-based photographic data.<br /><br />Just as the 19th-century camera transformed our ability to document and reveal the natural world — capturing life with unprecedented detail and bringing distant or hidden environments into view — generative AI marks a new frontier in visual storytelling. Like early photography, AI opens a creative and conceptual space, challenging how we define authenticity and how we communicate scientific and artistic perspectives.&nbsp;</p><p>In the LOBSTgER project, generative models are trained exclusively on a curated library of Ellenbogen’s original underwater photographs — each image crafted with artistic intent, technical precision, accurate species identification, and clear geographic context. By building a high-quality dataset grounded in real-world observations, the project ensures that the resulting imagery maintains both visual integrity and ecological relevance. In addition, LOBSTgER’s models are built using custom code developed by Mentzelopoulos to protect the process and outputs from any potential biases from external data or models. LOBSTgER’s generative AI builds upon real photography, expanding the researchers’ visual vocabulary to deepen the public’s connection to the natural world.</p><p>At its heart, LOBSTgER operates at the intersection of art, science, and technology. The project draws from the visual language of photography, the observational rigor of marine science, and the computational power of generative AI. By uniting these disciplines, the team is not only developing new ways to visualize ocean life — they are also reimagining how environmental stories can be told. This integrative approach makes LOBSTgER both a research tool and a creative experiment — one that reflects MIT’s long-standing tradition of interdisciplinary innovation.</p><p>Underwater photography in New England’s coastal waters is notoriously difficult. Limited visibility, swirling sediment, bubbles, and the unpredictable movement of marine life all pose constant challenges. For the past several years, Ellenbogen has navigated these challenges and is building a comprehensive record of the region’s biodiversity through the project, Space to Sea: Visualizing New England’s Ocean Wilderness.&nbsp;This large dataset of underwater images provides the foundation for training LOBSTgER’s generative AI models. The images span diverse angles, lighting conditions, and animal behaviors, resulting in a visual archive that is both artistically striking and biologically accurate.</p><p>LOBSTgER’s&nbsp;custom diffusion models are trained to replicate not only the biodiversity Ellenbogen documents, but also the artistic style he uses to capture it. By learning from thousands of real underwater images, the models internalize fine-grained details such as natural lighting gradients, species-specific coloration, and even the atmospheric texture created by suspended particles and refracted sunlight. The result is imagery that not only appears visually accurate, but also feels immersive and moving.</p><p>The models can both generate new, synthetic, but scientifically accurate images unconditionally (i.e., requiring no user input/guidance), and enhance real photographs conditionally (i.e., image-to-image generation). By integrating AI into the photographic workflow, Ellenbogen will be able to use these tools to recover detail in turbid water, adjust lighting to emphasize key subjects, or even simulate scenes that would be nearly impossible to capture in the field. The team also believes this approach may benefit other underwater photographers and image editors facing similar challenges. This hybrid method is designed to accelerate the curation process and enable storytellers to construct a more complete and coherent visual narrative of life beneath the surface.</p><p>In one key series, Ellenbogen captured high-resolution images of lion’s mane jellyfish, blue sharks, American lobsters, and ocean sunfish (<em>Mola mola</em>) while free diving in coastal waters. “Getting a high-quality dataset is not easy,” Ellenbogen says. “It requires multiple dives, missed opportunities, and unpredictable conditions. But these challenges are part of what makes underwater documentation both difficult and rewarding.”</p><p>Mentzelopoulos has developed original code to train a family of latent diffusion models for LOBSTgER grounded on Ellenbogen’s images. Developing such models requires a high level of technical expertise, and training models from scratch is a complex process demanding hundreds of hours of computation and meticulous hyperparameter tuning.</p><p>The project reflects a parallel process: field documentation through photography and model development through iterative training. Ellenbogen works in the field, capturing rare and fleeting encounters with marine animals; Mentzelopoulos works in the lab, translating those moments into machine-learning contexts that can extend and reinterpret the visual language of the ocean.</p><p>“The goal isn’t to replace photography,” Mentzelopoulos says. “It’s to build on and complement it — making the invisible visible, and helping people see environmental complexity in a way that resonates both emotionally and intellectually. Our models aim to capture not just biological realism, but the emotional charge that can drive real-world engagement and action.”</p><p>LOBSTgER points to a hybrid future that merges direct observation with technological interpretation. The team’s long-term goal is to develop a comprehensive model that can visualize a wide range of species found in the Gulf of Maine and, eventually, apply similar methods to marine ecosystems around the world.</p><p>The researchers suggest that photography and generative AI form a continuum, rather than a conflict. Photography captures what is — the texture, light, and animal behavior during actual encounters — while AI extends that vision beyond what is seen, toward what could be understood, inferred, or imagined based on scientific data and artistic vision. Together, they offer a powerful framework for communicating science through image-making.</p><p>In a region where ecosystems are changing rapidly, the act of visualizing becomes more than just documentation. It becomes a tool for awareness, engagement, and, ultimately, conservation. LOBSTgER is still in its infancy, and the team looks forward to sharing more discoveries, images, and insights as the project evolves.</p><p><em>Answer from the lead image: The left image was generated using using LOBSTgER’s unconditional models and the right image is real.</em></p><p>For more information, contact <a href=\"mailto:keithe@mit.edu\">Keith Ellenbogen</a> and <a href=\"mailto:ament@mit.edu\">Andreas Mentzelopoulos</a>.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/mit-LOBSTgER.jpg?itok=taPGS8Nq",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "AI-generated image: Keith Ellenbogen, Andreas Mentzelopoulos, and LOBSTgER. Photo: Keith Ellenbogen"
        }
      ],
      "credit": "AI-generated image: Keith Ellenbogen, Andreas Mentzelopoulos, and LOBSTgER. Photo: Keith Ellenbogen",
      "tags": [
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "Mechanical engineering",
          "scheme": "https://news.mit.edu/topic/mechanical-engineering",
          "label": null
        },
        {
          "term": "MIT Sea Grant",
          "scheme": "https://news.mit.edu/topic/mit-sea-grant",
          "label": null
        },
        {
          "term": "Oceanography and ocean engineering",
          "scheme": "https://news.mit.edu/topic/oceans",
          "label": null
        },
        {
          "term": "Marine biology",
          "scheme": "https://news.mit.edu/topic/marine-biology",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Photography",
          "scheme": "https://news.mit.edu/topic/photography",
          "label": null
        },
        {
          "term": "Environment",
          "scheme": "https://news.mit.edu/topic/environment",
          "label": null
        }
      ]
    },
    {
      "title": "LLMs factor in unrelated information when recommending medical treatments",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "LLMs factor in unrelated information when recommending medical treatments"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/llms-factor-unrelated-information-when-recommending-medical-treatments-0623"
        }
      ],
      "link": "https://news.mit.edu/2025/llms-factor-unrelated-information-when-recommending-medical-treatments-0623",
      "summary": "Researchers find nonclinical information in patient messages — like typos, extra white space, and colorful language — reduces the accuracy of an AI model.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "An MIT study finds non-clinical information in patient messages, like typos, extra whitespace, or colorful language, can reduce the accuracy of a large language model deployed to make treatment recommendations."
      },
      "published": "Mon, 23 Jun 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        6,
        23,
        4,
        0,
        0,
        0,
        174,
        0
      ],
      "id": "https://news.mit.edu/2025/llms-factor-unrelated-information-when-recommending-medical-treatments-0623",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>A large language model (LLM) deployed to make treatment recommendations can be tripped up by nonclinical information in patient messages, like typos, extra white space, missing gender markers, or the use of uncertain, dramatic, and informal language, according to a study by MIT researchers.</p><p>They found that making stylistic or grammatical changes to messages increases the likelihood an LLM will recommend that a patient self-manage their reported health condition rather than come in for an appointment, even when that patient should seek medical care.</p><p>Their analysis also revealed that these nonclinical variations in text, which mimic how people really communicate, are more likely to change a model’s treatment recommendations for female patients, resulting in a higher percentage of women who were erroneously advised not to seek medical care, according to human doctors.</p><p>This work “is strong evidence that models must be audited before use in health care — which is a setting where they are already in use,” says Marzyeh Ghassemi, an associate professor in the MIT Department of Electrical Engineering and Computer Science (EECS), a member of the Institute of Medical Engineering Sciences and the Laboratory for Information and Decision Systems, and senior author of the study.</p><p>These findings indicate that LLMs take nonclinical information into account for clinical decision-making in previously unknown ways. It brings to light the need for more rigorous studies of LLMs before they are deployed for high-stakes applications like making treatment recommendations, the researchers say.</p><p>“These models are often trained and tested on medical exam questions but then used in tasks that are pretty far from that, like evaluating the severity of a clinical case. There is still so much about LLMs that we don’t know,” adds Abinitha Gourabathina, an EECS graduate student and lead author of the study.</p><p>They are joined on the <a href=\"https://dl.acm.org/doi/10.1145/3715275.3732121\" target=\"_blank\">paper</a>, which will be presented at the ACM Conference on Fairness, Accountability, and Transparency, by graduate student Eileen Pan and postdoc Walter Gerych.</p><p><strong>Mixed messages</strong></p><div><p>Large language models like OpenAI’s GPT-4 are being used to&nbsp;<a href=\"https://www.fiercehealthcare.com/ai-and-machine-learning/himss24-how-epic-building-out-ai-ambient-technology-clinicians\" target=\"_blank\">draft clinical notes and triage patient messages</a> in health care facilities around the globe, in an effort to streamline some tasks to help overburdened clinicians.</p><p>A growing body of work has explored the clinical reasoning capabilities of LLMs, especially from a fairness point of view, but few studies have evaluated how nonclinical information affects a model’s judgment.</p><p>Interested in how gender impacts LLM reasoning, Gourabathina ran experiments where she swapped the gender cues in patient notes. She was surprised that formatting errors in the prompts, like extra white space, caused meaningful changes in the LLM responses.</p><p>To explore this problem, the researchers designed a study in which they altered the model’s input data by swapping or removing gender markers, adding colorful or uncertain language, or inserting extra space and typos into patient messages.</p><p>Each perturbation was designed to mimic text that might be written by someone in a vulnerable patient population, based on psychosocial research into how people communicate with clinicians.</p><p>For instance, extra spaces and typos simulate the writing of patients with limited English proficiency or those with less technological aptitude, and the addition of uncertain language represents patients with health anxiety.</p><p>“The medical datasets these models are trained on are usually cleaned and structured, and not a very realistic reflection of the patient population. We wanted to see how these very realistic changes in text could impact downstream use cases,” Gourabathina says.</p><p>They used an LLM to create perturbed copies of thousands of patient notes while ensuring the text changes were minimal and preserved all clinical data, such as medication and previous diagnosis. Then they evaluated four LLMs, including the large, commercial model GPT-4 and a smaller LLM built specifically for medical settings.</p><p>They prompted each LLM with three questions based on the patient note: Should the patient manage at home, should the patient come in for a clinic visit, and should a medical resource be allocated to the patient, like a lab test.</p><p>The researchers compared the LLM recommendations to real clinical responses.</p><p><strong>Inconsistent recommendations</strong></p><p>They saw inconsistencies in treatment recommendations and significant disagreement among the LLMs when they were fed perturbed data. Across the board, the LLMs exhibited a 7 to 9 percent increase in self-management suggestions for all nine types of altered patient messages.</p><p>This means LLMs were more likely to recommend that patients not seek medical care when messages contained typos or gender-neutral pronouns, for instance. The use of colorful language, like slang or dramatic expressions, had the biggest impact.</p><p>They also found that models made about 7 percent more errors for female patients and were more likely to recommend that female patients self-manage at home, even when the researchers removed all gender cues from the clinical context.</p><p>Many of the worst results, like patients told to self-manage when they have a serious medical condition, likely wouldn’t be captured by tests that focus on the models’ overall clinical accuracy.</p><p>“In research, we tend to look at aggregated statistics, but there are a lot of things that are lost in translation. We need to look at the direction in which these errors are occurring — not recommending visitation when you should is much more harmful than doing the opposite,” Gourabathina says.</p><p>The inconsistencies caused by nonclinical language become even more pronounced in conversational settings where an LLM interacts with a patient, which is a common use case for patient-facing chatbots.</p><p>But in <a href=\"https://arxiv.org/pdf/2506.17163\" target=\"_blank\">follow-up work</a>, the researchers found that these same changes in patient messages don’t affect the accuracy of human clinicians.</p><p>“In our follow up work under review, we further find that large language models are fragile to changes that human clinicians are not,” Ghassemi says. “This is perhaps unsurprising — LLMs were not designed to prioritize patient medical care. LLMs are flexible and performant enough on average that we might think this is a good use case. But we don’t want to optimize a health care system that only works well for patients in specific groups.”</p><p>The researchers want to expand on this work by designing natural language perturbations that capture other vulnerable populations and better mimic real messages. They also want to explore how LLMs infer gender from clinical text.</p></div>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT_Medium-Message-01-press.jpg?itok=EtW2RMdY",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: MIT News"
        }
      ],
      "credit": "Credit: MIT News",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Human-computer interaction",
          "scheme": "https://news.mit.edu/topic/human-computer-interaction",
          "label": null
        },
        {
          "term": "Technology and society",
          "scheme": "https://news.mit.edu/topic/technology-society",
          "label": null
        },
        {
          "term": "Health",
          "scheme": "https://news.mit.edu/topic/health2",
          "label": null
        },
        {
          "term": "Health care",
          "scheme": "https://news.mit.edu/topic/health-care",
          "label": null
        },
        {
          "term": "Medicine",
          "scheme": "https://news.mit.edu/topic/medicine",
          "label": null
        },
        {
          "term": "Diagnostics",
          "scheme": "https://news.mit.edu/topic/diagnostics",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "Institute for Medical Engineering and Science (IMES)",
          "scheme": "https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        }
      ]
    },
    {
      "title": "Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620"
        }
      ],
      "link": "https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620",
      "summary": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Anantha P. Chandrakasan, chief innovation and strategy officer and dean of the School of Engineering who is head of the MIT Generative AI Impact Consortium (MGAIC), kicks off an afternoon of presentations."
      },
      "published": "Fri, 20 Jun 2025 16:45:00 -0400",
      "published_parsed": [
        2025,
        6,
        20,
        20,
        45,
        0,
        4,
        171,
        0
      ],
      "id": "https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620",
      "guidislink": false,
      "authors": [
        {
          "name": "Amanda Diehl | MIT Schwarzman College of Computing"
        }
      ],
      "author": "Amanda Diehl | MIT Schwarzman College of Computing",
      "author_detail": {
        "name": "Amanda Diehl | MIT Schwarzman College of Computing"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p><a href=\"https://news.mit.edu/2025/introducing-mit-generative-ai-impact-consortium-0203\">Launched in February of this year</a>, the <a href=\"http://genai.mit.edu/\">MIT Generative AI Impact Consortium </a>(MGAIC), a presidential initiative led by MIT’s Office of Innovation and Strategy and administered by the MIT Stephen A. Schwarzman College of Computing, issued a call for proposals, inviting researchers from across MIT to submit ideas for innovative projects studying high-impact uses of generative AI models.</p><p>The call received 180 submissions from nearly 250 faculty members, spanning all of MIT’s five schools and the college. The overwhelming response across the Institute exemplifies the growing interest in AI and follows in the wake of <a href=\"https://news.mit.edu/2023/mit-generative-ai-week-fosters-dialogue-across-disciplines-1211\">MIT’s Generative AI Week</a> and <a href=\"https://mitpress.mit.edu/preprints-of-generative-ai-impact-papers-publish-through-mit-presss-mit-open-publishing-services-mitops/\">call for impact papers</a>. <a href=\"https://computing-dev.mit.edu/mit-generative-ai-impact-consortium-seed-grants/\">Fifty-five proposals were selected</a> for MGAIC’s inaugural seed grants, with several more selected to be funded by the consortium’s founding company members.</p><p>Over 30 funding recipients presented their proposals to the greater MIT community at a kickoff event on May 13. Anantha P. Chandrakasan, chief innovation and strategy officer and dean of the School of Engineering who is head of the consortium, welcomed the attendees and thanked the consortium’s founding industry members.</p><p>“The amazing response to our call for proposals is an incredible testament to the energy and creativity that MGAIC has sparked at MIT. We are especially grateful to our founding members, whose support and vision helped bring this endeavor to life,” adds Chandrakasan. “One of the things that has been most remarkable about MGAIC is that this is a truly cross-Institute initiative. Deans from all five schools and the college collaborated in shaping and implementing it.”</p><p>Vivek F. Farias, the Patrick J. McGovern (1959) Professor at the MIT Sloan School of Management and co-faculty director of the consortium with Tim Kraska, associate professor of electrical engineering and computer science in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL), emceed the afternoon of five-minute lightning presentations.</p><p>Presentation highlights include:</p><p>“AI-Driven Tutors and Open Datasets for Early Literacy Education,” presented by Ola Ozernov-Palchik, a research scientist at the McGovern Institute for Brain Research, proposed a refinement for AI-tutors for pK-7 students to potentially decrease literacy disparities.</p><p>“Developing jam_bots: Real-Time Collaborative Agents for Live Human-AI Musical Improvisation,” presented by Anna Huang, assistant professor of music and assistant professor of electrical engineering and computer science, and Joe Paradiso, the Alexander W. Dreyfoos (1954) Professor in Media Arts and Sciences at the MIT Media Lab, aims to enhance human-AI musical collaboration in real-time for live concert improvisation.</p><p>“GENIUS: GENerative Intelligence for Urban Sustainability,” presented by Norhan Bayomi, a postdoc at the MIT Environmental Solutions Initiative and a research assistant in the Urban Metabolism Group, which aims to address the critical gap of a standardized approach in evaluating and benchmarking cities’ climate policies.</p><p>Georgia Perakis, the John C Head III Dean (Interim) of the MIT Sloan School of Management and professor of operations management, operations research, and statistics, who serves as co-chair of the GenAI Dean’s oversight group with Dan Huttenlocher, dean of the MIT Schwarzman College of Computing, ended the event with closing remarks that emphasized “the readiness and eagerness of our community to lead in this space.”</p><p>“This is only the beginning,” she continued. “We are at the front edge of a historic moment — one where MIT has the opportunity, and the responsibility, to shape the future of generative AI with purpose, with excellence, and with care.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/mit-Anantha.jpg?itok=6ENWNAbm",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo: Jiin Kang"
        }
      ],
      "credit": "Photo: Jiin Kang",
      "tags": [
        {
          "term": "Special events and guest speakers",
          "scheme": "https://news.mit.edu/topic/special-events",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Technology and society",
          "scheme": "https://news.mit.edu/topic/technology-society",
          "label": null
        },
        {
          "term": "Faculty",
          "scheme": "https://news.mit.edu/topic/faculty",
          "label": null
        },
        {
          "term": "Music and theater arts",
          "scheme": "https://news.mit.edu/topic/music-and-theater-arts",
          "label": null
        },
        {
          "term": "Human-computer interaction",
          "scheme": "https://news.mit.edu/topic/human-computer-interaction",
          "label": null
        },
        {
          "term": "Robotics",
          "scheme": "https://news.mit.edu/topic/robotics",
          "label": null
        },
        {
          "term": "Industry",
          "scheme": "https://news.mit.edu/topic/industry",
          "label": null
        },
        {
          "term": "Collaboration",
          "scheme": "https://news.mit.edu/topic/collaboration",
          "label": null
        },
        {
          "term": "Funding",
          "scheme": "https://news.mit.edu/topic/funding",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "McGovern Institute",
          "scheme": "https://news.mit.edu/topic/mcgovern-institute-0",
          "label": null
        },
        {
          "term": "School of Science",
          "scheme": "https://news.mit.edu/topic/school-science",
          "label": null
        },
        {
          "term": "MIT Sloan School of Management",
          "scheme": "https://news.mit.edu/topic/mit-sloan-school-management",
          "label": null
        },
        {
          "term": "Media Lab",
          "scheme": "https://news.mit.edu/topic/media-lab-0",
          "label": null
        },
        {
          "term": "School of Architecture and Planning",
          "scheme": "https://news.mit.edu/topic/school-architecture-and-planning",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "School of Humanities Arts and Social Sciences",
          "scheme": "https://news.mit.edu/topic/school-humanities-arts-and-social-sciences",
          "label": null
        }
      ]
    },
    {
      "title": "Combining technology, education, and human connection to improve online learning",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Combining technology, education, and human connection to improve online learning"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/caitlin-morris-combines-tech-education-human-connection-improve-online-learning-0617"
        }
      ],
      "link": "https://news.mit.edu/2025/caitlin-morris-combines-tech-education-human-connection-improve-online-learning-0617",
      "summary": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the “social magic” that influences curiosity and motivation.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT Morningside Academy for Design (MAD) Fellow Caitlin Morris is an architect, artist, researcher, and educator who has studied psychology and used online learning tools to teach herself coding and other skills."
      },
      "published": "Tue, 17 Jun 2025 16:25:00 -0400",
      "published_parsed": [
        2025,
        6,
        17,
        20,
        25,
        0,
        1,
        168,
        0
      ],
      "id": "https://news.mit.edu/2025/caitlin-morris-combines-tech-education-human-connection-improve-online-learning-0617",
      "guidislink": false,
      "authors": [
        {
          "name": "Denise Brehm | MIT Morningside Academy for Design"
        }
      ],
      "author": "Denise Brehm | MIT Morningside Academy for Design",
      "author_detail": {
        "name": "Denise Brehm | MIT Morningside Academy for Design"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p><a href=\"https://design.mit.edu/\">MIT Morningside Academy for Design</a> (MAD) Fellow&nbsp;<a href=\"https://www.caitlinmorris.net/index.html\">Caitlin Morris</a> is an architect, artist,&nbsp;researcher, and educator who has studied psychology and used online learning tools to teach herself coding and other skills. She’s a soft-spoken observer, with a keen interest in how people use space and respond to their environments.&nbsp;Combining her observational skills with active community engagement, she works at the intersection of technology, education, and human connection to improve digital learning platforms.</p><p>Morris grew up in rural upstate New York in a family of makers. She learned to sew, cook, and build things with wood at a young age. One of her earlier memories is of a small handsaw she made — with the help of her father, a professional carpenter. It had wooden handles on both sides to make sawing easier for her.</p><p>Later, when she needed to learn something, she’d turn to project-based communities, rather than books. She taught herself to code late at night, taking advantage of community-oriented platforms where people answer questions and post sketches, allowing her to see the code behind the objects people made.</p><p>“For me, that was this huge, wake-up moment of feeling like there was a path to expression that was not a traditional computer-science classroom,” she says. “I think that’s partly why I feel so passionate about what I’m doing now. That was the big transformation: having that community available in this really personal, project-based way.”</p><p>Subsequently, Morris has become involved in community-based learning in diverse ways: She’s a co-organizer of the MIT Media Lab’s Festival of Learning; she leads creative coding community meetups; and she’s been active in the open-source software community development.</p><p>“My years of organizing learning and making communities — both in person and online — have shown me firsthand how powerful social interaction can be for motivation and curiosity,” Morris said. “My research is really about identifying which elements of that social magic are most essential, so we can design digital environments that better support those dynamics.”</p><p>Even in her artwork, Morris sometimes works with a collective. She’s contributed to the creation of about 10 large art installations that combine movement, sound, imagery, lighting, and other technologies to immerse the visitor in an experience evoking some aspect of nature, such as flowing water, birds in flight, or crowd kinetics. These marvelous installations are commanding and calming at the same time, possibly because they focus the mind, eye, and sometimes the ear.</p><p>She did much of this work with New York-based Hypersonic, a company of artists and technologists specializing in large kinetic installations in public spaces. Before that, she earned a BS in psychology and a BS in architectural building sciences from Rensselaer Polytechnic Institute, then an MFA in design and technology from the Parsons School of Design at The New School.</p><p>During, in between, after, and sometimes concurrently, she taught design, coding, and other technologies at the high school, undergraduate, and graduate-student levels.</p><p>“I think what kind of got me hooked on teaching was that the way I learned as a child was not the same as in the classroom,” Morris explains. “And I later saw this in many of my students. I got the feeling that the normal way of learning things was not working for them. And they thought it was their fault. They just didn’t really feel welcome within the traditional education model.”</p><p>Morris says that when she worked with those students, tossing aside tradition and instead saying — “You know, we’re just going to do this animation. Or we’re going to make this design or this website or these graphics, and we’re going to approach it in this totally different way” — she saw people “kind of unlock and be like, ‘Oh my gosh. I never thought I could do that.’</p><p>“For me, that was the hook, that’s the magic of it. Because I was coming from that experience of having to figure out those unlock mechanisms for myself, it was really exciting to be able to share them with other people, those unlock moments.”</p><p>For her doctoral work with the MIT Media Lab’s Fluid Interfaces Group, she’s focusing on the personal space and emotional gaps associated with learning, particularly online and AI-assisted learning. This research builds on her experience increasing human connection in both physical and virtual learning environments.</p><p>“I’m developing a framework that combines AI-driven behavioral analysis with human expert assessment to study social learning dynamics,” she says. “My research investigates how social interaction patterns influence curiosity development and intrinsic motivation in learning, with particular focus on understanding how these dynamics differ between real peers and AI-supported environments.”</p><p>The first step in her research is determining which elements of social interaction are not replaceable by an AI-based digital tutor. Following that assessment, her goal is to build a prototype platform for experiential learning.</p><p>“I’m creating tools that can simultaneously track observable behaviors — like physical actions, language cues, and interaction patterns — while capturing learners’ subjective experiences through reflection and interviews,” Morris explains. “This approach helps connect what people do with how they feel about their learning experience.</p><p>“I aim to make two primary contributions: first, analysis tools for studying social learning dynamics; and second, prototype tools that demonstrate practical approaches for supporting social curiosity in digital learning environments. These contributions could help bridge the gap between the efficiency of digital platforms and the rich social interaction that occurs in effective in-person learning.”</p><p>Her goals make Morris a perfect fit for the MIT MAD Fellowship. One statement in MAD’s mission is: “Breaking away from traditional education, we foster creativity, critical thinking, making, and collaboration, exploring a range of dynamic approaches to prepare students for complex, real-world challenges.”</p><p>Morris wants to help community organizations deal with the rapid AI-powered changes in education, once she finishes her doctorate in 2026. “What should we do with this ‘physical space versus virtual space’ divide?” she asks. That is the space currently captivating Morris’s thoughts.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/mit-Caitlin-Morris.jpg?itok=aWiNBgih",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo: Adélaïde Zollinger"
        }
      ],
      "credit": "Photo: Adélaïde Zollinger",
      "tags": [
        {
          "term": "Profile",
          "scheme": "https://news.mit.edu/topic/profile",
          "label": null
        },
        {
          "term": "Students",
          "scheme": "https://news.mit.edu/topic/students",
          "label": null
        },
        {
          "term": "Graduate, postdoctoral",
          "scheme": "https://news.mit.edu/topic/graduate",
          "label": null
        },
        {
          "term": "Education, teaching, academics",
          "scheme": "https://news.mit.edu/topic/education",
          "label": null
        },
        {
          "term": "Design",
          "scheme": "https://news.mit.edu/topic/design",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Software",
          "scheme": "https://news.mit.edu/topic/software",
          "label": null
        },
        {
          "term": "Programming",
          "scheme": "https://news.mit.edu/topic/programming",
          "label": null
        },
        {
          "term": "Human-computer interaction",
          "scheme": "https://news.mit.edu/topic/human-computer-interaction",
          "label": null
        },
        {
          "term": "Online learning",
          "scheme": "https://news.mit.edu/topic/onlinelearning",
          "label": null
        },
        {
          "term": "Maker movement",
          "scheme": "https://news.mit.edu/topic/maker-movement",
          "label": null
        },
        {
          "term": "Arts",
          "scheme": "https://news.mit.edu/topic/arts",
          "label": null
        },
        {
          "term": "Media Lab",
          "scheme": "https://news.mit.edu/topic/media-lab-0",
          "label": null
        },
        {
          "term": "School of Architecture and Planning",
          "scheme": "https://news.mit.edu/topic/school-architecture-and-planning",
          "label": null
        },
        {
          "term": "MIT Morningside Academy for Design",
          "scheme": "https://news.mit.edu/topic/mit-morningside-academy-design",
          "label": null
        }
      ]
    },
    {
      "title": "Unpacking the bias of large language models",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Unpacking the bias of large language models"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/unpacking-large-language-model-bias-0617"
        }
      ],
      "link": "https://news.mit.edu/2025/unpacking-large-language-model-bias-0617",
      "summary": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT researchers discovered the underlying cause of position bias, a phenomenon that causes large language models to overemphasize the beginning or end of a document or conversation, while neglecting the middle."
      },
      "published": "Tue, 17 Jun 2025 16:00:00 -0400",
      "published_parsed": [
        2025,
        6,
        17,
        20,
        0,
        0,
        1,
        168,
        0
      ],
      "id": "https://news.mit.edu/2025/unpacking-large-language-model-bias-0617",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Research has shown that large language models (LLMs) tend to overemphasize information at the beginning and end of a document or conversation, while neglecting the middle.</p><p>This “position bias” means that, if a lawyer is using an LLM-powered virtual assistant to retrieve a certain phrase in a 30-page affidavit, the LLM is more likely to find the right text if it is on the initial or final pages.</p><p>MIT researchers have discovered the mechanism behind this phenomenon.</p><p>They created a theoretical framework to study how information flows through the machine-learning architecture that forms the backbone of LLMs. They found that certain design choices which control how the model processes input data can cause position bias.</p><p>Their experiments revealed that model architectures, particularly those affecting how information is spread across input words within the model, can give rise to or intensify position bias, and that training data also contribute to the problem.</p><p>In addition to pinpointing the origins of position bias, their framework can be used to diagnose and correct it in future model designs.</p><p>This could lead to more reliable chatbots that stay on topic during long conversations, medical AI systems that reason more fairly when handling a trove of patient data, and code assistants that pay closer attention to all parts of a program.</p><p>“These models are black boxes, so as an LLM user, you probably don’t know that position bias can cause your model to be inconsistent. You just feed it your documents in whatever order you want and expect it to work. But by understanding the underlying mechanism of these black-box models better, we can improve them by addressing these limitations,” says Xinyi Wu, a graduate student in the MIT Institute for Data, Systems, and Society (IDSS) and the Laboratory for Information and Decision Systems (LIDS), and first author of a <a href=\"https://arxiv.org/pdf/2502.01951\" target=\"_blank\">paper</a> on this research.</p><p>Her co-authors include Yifei Wang, an MIT postdoc; and senior authors Stefanie Jegelka, an associate professor of electrical engineering and computer science (EECS) and a member of IDSS and the Computer Science and Artificial Intelligence Laboratory (CSAIL); and Ali Jadbabaie, professor and head of the Department of Civil and Environmental Engineering, a core faculty member of IDSS, and a principal investigator in LIDS. The research will be presented at the International Conference on Machine Learning.</p><p><strong>Analyzing attention</strong></p><p>LLMs like Claude, Llama, and GPT-4 are powered by a type of neural network architecture known as a transformer. Transformers are designed to process sequential data, encoding a sentence into chunks called tokens and then learning the relationships between tokens to predict what words comes next.</p><p>These models have gotten very good at this because of the attention mechanism, which uses interconnected layers of data processing nodes to make sense of context by allowing tokens to selectively focus on, or attend to, related tokens.</p><p>But if every token can attend to every other token in a 30-page document, that quickly becomes computationally intractable. So, when engineers build transformer models, they often employ attention masking techniques which limit the words a token can attend to.</p><p>For instance, a causal mask only allows words to attend to those that came before it.</p><p>Engineers also use positional encodings to help the model understand the location of each word in a sentence, improving performance.</p><p>The MIT researchers built a graph-based theoretical framework to explore how these modeling choices, attention masks and positional encodings, could affect position bias.</p><p>“Everything is coupled and tangled within the attention mechanism, so it is very hard to study. Graphs are a flexible language to describe the dependent relationship among words within the attention mechanism and trace them across multiple layers,” Wu says.</p><p>Their theoretical analysis suggested that causal masking gives the model an inherent bias toward the beginning of an input, even when that bias doesn’t exist in the data.</p><p>If the earlier words are relatively unimportant for a sentence’s meaning, causal masking can cause the transformer to pay more attention to its beginning anyway.</p><p>“While it is often true that earlier words and later words in a sentence are more important, if an LLM is used on a task that is not natural language generation, like ranking or information retrieval, these biases can be extremely harmful,” Wu says.</p><p>As a model grows, with additional layers of attention mechanism, this bias is amplified because earlier parts of the input are used more frequently in the model’s reasoning process.</p><p>They also found that using positional encodings to link words more strongly to nearby words can mitigate position bias. The technique refocuses the model’s attention in the right place, but its effect can be diluted in models with more attention layers.</p><p>And these design choices are only one cause of position bias — some can come from training data the model uses to learn how to prioritize words in a sequence.</p><p>“If you know your data are biased in a certain way, then you should also finetune your model on top of adjusting your modeling choices,” Wu says.</p><p><strong>Lost in the middle</strong></p><p>After they’d established a theoretical framework, the researchers performed experiments in which they systematically varied the position of the correct answer in text sequences for an information retrieval task.</p><p>The experiments showed a “lost-in-the-middle” phenomenon, where retrieval accuracy followed a U-shaped pattern. Models performed best if the right answer was located at the beginning of the sequence. Performance declined the closer it got to the middle before rebounding a bit if the correct answer was near the end.</p><p>Ultimately, their work suggests that using a different masking technique, removing extra layers from the attention mechanism, or strategically employing positional encodings could reduce position bias and improve a model’s accuracy.</p><p>“By doing a combination of theory and experiments, we were able to look at the consequences of model design choices that weren’t clear at the time. If you want to use a model in high-stakes applications, you must know when it will work, when it won’t, and why,” Jadbabaie says.</p><p>In the future, the researchers want to further explore the effects of positional encodings and study how position bias could be strategically exploited in certain applications.</p><p>“These researchers offer a rare theoretical lens into the attention mechanism at the heart of the transformer model. They provide a compelling analysis that clarifies longstanding quirks in transformer behavior, showing that attention mechanisms, especially with causal masks, inherently bias models toward the beginning of sequences. The paper achieves the best of both worlds — mathematical clarity paired with insights that reach into the guts of real-world systems,” says Amin Saberi, professor and director of the Stanford University Center for Computational Market Design, who was not involved with this work.</p><p>This research is supported, in part, by the U.S. Office of Naval Research, the National Science Foundation, and an Alexander von Humboldt Professorship.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT-transform-bias-01-press.jpg?itok=qeAFK3E3",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: MIT News; iStock"
        }
      ],
      "credit": "Credit: MIT News; iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Human-computer interaction",
          "scheme": "https://news.mit.edu/topic/human-computer-interaction",
          "label": null
        },
        {
          "term": "IDSS",
          "scheme": "https://news.mit.edu/topic/idss",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Civil and environmental engineering",
          "scheme": "https://news.mit.edu/topic/civil-engineering",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "National Science Foundation (NSF)",
          "scheme": "https://news.mit.edu/topic/nsf",
          "label": null
        }
      ]
    },
    {
      "title": "Celebrating an academic-industry collaboration to advance vehicle technology",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Celebrating an academic-industry collaboration to advance vehicle technology"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/celebrating-academic-industry-collaboration-advance-vehicle-technology-0616"
        }
      ],
      "link": "https://news.mit.edu/2025/celebrating-academic-industry-collaboration-advance-vehicle-technology-0616",
      "summary": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Bryan Reimer, founder and co-director of the AVT Consortium, gives the opening remarks."
      },
      "published": "Mon, 16 Jun 2025 14:45:00 -0400",
      "published_parsed": [
        2025,
        6,
        16,
        18,
        45,
        0,
        0,
        167,
        0
      ],
      "id": "https://news.mit.edu/2025/celebrating-academic-industry-collaboration-advance-vehicle-technology-0616",
      "guidislink": false,
      "authors": [
        {
          "name": "Mackenzie Berry | MIT AgeLab | MIT Center for Transportation and Logistics"
        }
      ],
      "author": "Mackenzie Berry | MIT AgeLab | MIT Center for Transportation and Logistics",
      "author_detail": {
        "name": "Mackenzie Berry | MIT AgeLab | MIT Center for Transportation and Logistics"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>On May 6, MIT AgeLab’s Advanced Vehicle Technology (AVT) Consortium, part of the MIT Center for Transportation and Logistics, celebrated 10 years of its global academic-industry collaboration. AVT was founded with the aim of developing new data that contribute to automotive manufacturers, suppliers, and insurers’ real-world understanding of how drivers use and respond to increasingly sophisticated vehicle technologies, such as assistive and automated driving, while accelerating the applied insight needed to advance design and development. The celebration event brought together stakeholders from across the industry for a set of keynote addresses and panel discussions on critical topics significant to the industry and its future, including artificial intelligence, automotive technology, collision repair, consumer behavior, sustainability, vehicle safety policy, and global competitiveness.</p><p>Bryan Reimer, founder and co-director of the AVT Consortium, opened the event by remarking that over the decade AVT has collected hundreds of terabytes of data, presented and discussed research with its over 25 member organizations, supported members’ strategic and policy initiatives, published select outcomes, and built AVT into a global influencer with tremendous impact in the automotive industry. He noted that current opportunities and challenges for the industry include distracted driving, a lack of consumer trust and concerns around transparency in assistive and automated driving features, and high consumer expectations for vehicle technology, safety, and affordability. How will industry respond? Major players in attendance weighed in.</p><p>In a powerful exchange on vehicle safety regulation, John Bozzella, president and CEO of the Alliance for Automotive Innovation, and Mark Rosekind, former chief safety innovation officer of Zoox, former administrator of the National Highway Traffic Safety Administration, and former member of the National Transportation Safety Board, challenged industry and government to adopt a more strategic, data-driven, and collaborative approach to safety. They asserted that regulation must evolve alongside innovation, not lag behind it by decades. Appealing to the automakers in attendance, Bozzella cited the success of voluntary commitments on automatic emergency braking as a model for future progress. “That’s a way to do something important and impactful ahead of regulation.” They advocated for shared data platforms, anonymous reporting, and a common regulatory vision that sets safety baselines while allowing room for experimentation. The 40,000 annual road fatalities demand urgency — what’s needed is a move away from tactical fixes and toward a systemic safety strategy. “Safety delayed is safety denied,” Rosekind stated. “Tell me how you’re going to improve safety. Let’s be explicit.”</p><p>Drawing inspiration from aviation’s exemplary safety record, Kathy Abbott, chief scientific and technical advisor for the Federal Aviation Administration, pointed to a culture of rigorous regulation, continuous improvement, and cross-sectoral data sharing. Aviation’s model, built on highly trained personnel and strict predictability standards, contrasts sharply with the fragmented approach in the automotive industry. The keynote emphasized that a foundation of safety culture — one that recognizes that technological ability alone isn’t justification for deployment — must guide the auto industry forward. Just as aviation doesn’t equate absence of failure with success, vehicle safety must be measured holistically and proactively.</p><p>With assistive and automated driving top of mind in the industry, Pete Bigelow of <em>Automotive News</em> offered a pragmatic diagnosis. With companies like Ford and Volkswagen stepping back from full autonomy projects like Argo AI, the industry is now focused on Level 2 and 3 technologies, which refer to assisted and automated driving, respectively. Tesla, GM, and Mercedes are experimenting with subscription models for driver assistance systems, yet consumer confusion remains high. JD Power reports that many drivers do not grasp the differences between L2 and L2+, or whether these technologies offer safety or convenience features. Safety benefits have yet to manifest in reduced traffic deaths, which have risen by 20 percent since 2020. The recurring challenge: L3 systems demand that human drivers take over during technical difficulties, despite driver disengagement being their primary benefit, potentially worsening outcomes. Bigelow cited a quote from Bryan Reimer as one of the best he’s received in his career: “Level 3 systems are an engineer’s dream and a plaintiff attorney’s next yacht,” highlighting the legal and design complexity of systems that demand handoffs between machine and human.</p><p>In terms of the impact of AI on the automotive industry, Mauricio Muñoz, senior research engineer at AI Sweden, underscored that despite AI’s transformative potential, the automotive industry cannot rely on general AI megatrends to solve domain-specific challenges. While landmark achievements like AlphaFold demonstrate AI’s prowess, automotive applications require domain expertise, data sovereignty, and targeted collaboration. Energy constraints, data firewalls, and the high costs of AI infrastructure all pose limitations, making it critical that companies fund purpose-driven research that can reduce costs and improve implementation fidelity. Muñoz warned that while excitement abounds — with some predicting artificial superintelligence by 2028 — real progress demands organizational alignment and a deep understanding of the automotive context, not just computational power.</p><p>Turning the focus to consumers, a collision repair panel drawing Richard Billyeald from Thatcham Research, Hami Ebrahimi from Caliber Collision, and Mike Nelson from Nelson Law explored the unintended consequences of vehicle technology advances: spiraling repair costs, labor shortages, and a lack of repairability standards. Panelists warned that even minor repairs for advanced vehicles now require costly and complex sensor recalibrations — compounded by inconsistent manufacturer guidance and no clear consumer alerts when systems are out of calibration. The panel called for greater standardization, consumer education, and repair-friendly design. As insurance premiums climb and more people forgo insurance claims, the lack of coordination between automakers, regulators, and service providers threatens consumer safety and undermines trust. The group warned that until Level 2 systems function reliably and affordably, moving toward Level 3 autonomy is premature and risky.</p><p>While the repair panel emphasized today’s urgent challenges, other speakers looked to the future. Honda’s Ryan Harty, for example, highlighted the company’s aggressive push toward sustainability and safety. Honda aims for zero environmental impact and zero traffic fatalities, with plans to be 100 percent electric by 2040 and to lead in energy storage and clean power integration. The company has developed tools to coach young drivers and is investing in charging infrastructure, grid-aware battery usage, and green hydrogen storage. “What consumers buy in the market dictates what the manufacturers make,” Harty noted, underscoring the importance of aligning product strategy with user demand and environmental responsibility. He stressed that manufacturers can only decarbonize as fast as the industry allows, and emphasized the need to shift from cost-based to life-cycle-based product strategies.</p><p>Finally, a panel involving Laura Chace of ITS America, Jon Demerly of Qualcomm, Brad Stertz of Audi/VW Group, and Anant Thaker of Aptiv covered the near-, mid-, and long-term future of vehicle technology. Panelists emphasized that consumer expectations, infrastructure investment, and regulatory modernization must evolve together. Despite record bicycle fatality rates and persistent distracted driving, features like school bus detection and stop sign alerts remain underutilized due to skepticism and cost. Panelists stressed that we must design systems for proactive safety rather than reactive response. The slow integration of digital infrastructure — sensors, edge computing, data analytics — stems not only from technical hurdles, but procurement and policy challenges as well.&nbsp;</p><p>Reimer concluded the event by urging industry leaders to re-center the consumer in all conversations — from affordability to maintenance and repair. With the rising costs of ownership, growing gaps in trust in technology, and misalignment between innovation and consumer value, the future of mobility depends on rebuilding trust and reshaping industry economics. He called for global collaboration, greater standardization, and transparent innovation that consumers can understand and afford. He highlighted that global competitiveness and public safety both hang in the balance. As Reimer noted, “success will come through partnerships” — between industry, academia, and government — that work toward shared investment, cultural change, and a collective willingness to prioritize the public good.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202505/MIT-AVT-conference.jpg?itok=nA4-EB4I",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Photo: Kelly Davidson Studio"
        }
      ],
      "credit": "Photo: Kelly Davidson Studio",
      "tags": [
        {
          "term": "Special events and guest speakers",
          "scheme": "https://news.mit.edu/topic/special-events",
          "label": null
        },
        {
          "term": "Automobiles",
          "scheme": "https://news.mit.edu/topic/automobiles",
          "label": null
        },
        {
          "term": "Transportation",
          "scheme": "https://news.mit.edu/topic/transportation",
          "label": null
        },
        {
          "term": "AgeLab",
          "scheme": "https://news.mit.edu/topic/agelab",
          "label": null
        },
        {
          "term": "Industry",
          "scheme": "https://news.mit.edu/topic/industry",
          "label": null
        },
        {
          "term": "Collaboration",
          "scheme": "https://news.mit.edu/topic/collaboration",
          "label": null
        },
        {
          "term": "Design",
          "scheme": "https://news.mit.edu/topic/design",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Safety",
          "scheme": "https://news.mit.edu/topic/safety",
          "label": null
        },
        {
          "term": "Sustainability",
          "scheme": "https://news.mit.edu/topic/sustainability",
          "label": null
        },
        {
          "term": "Technology and policy",
          "scheme": "https://news.mit.edu/topic/technology-and-policy",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Autonomous vehicles",
          "scheme": "https://news.mit.edu/topic/autonomous-vehicles",
          "label": null
        },
        {
          "term": "Electric vehicles",
          "scheme": "https://news.mit.edu/topic/electric-vehicles",
          "label": null
        },
        {
          "term": "Center for Transportation and Logistics",
          "scheme": "https://news.mit.edu/topic/center-transportation-and-logistics-0",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        }
      ]
    },
    {
      "title": "Photonic processor could streamline 6G wireless signal processing",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Photonic processor could streamline 6G wireless signal processing"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/photonic-processor-could-streamline-6g-wireless-signal-processing-0611"
        }
      ],
      "link": "https://news.mit.edu/2025/photonic-processor-could-streamline-6g-wireless-signal-processing-0611",
      "summary": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "This image shows an artist’s interpretation of new optical processor for an edge device, developed by MIT researchers, that performs machine learning computations at the speed of light, classifying wireless signals in a matter of nanoseconds."
      },
      "published": "Wed, 11 Jun 2025 14:00:00 -0400",
      "published_parsed": [
        2025,
        6,
        11,
        18,
        0,
        0,
        2,
        162,
        0
      ],
      "id": "https://news.mit.edu/2025/photonic-processor-could-streamline-6g-wireless-signal-processing-0611",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>As more connected devices demand an increasing amount of bandwidth for tasks like teleworking and cloud computing, it will become extremely challenging to manage the finite amount of wireless spectrum available for all users to share.</p><p>Engineers are employing artificial intelligence to dynamically manage the available wireless spectrum, with an eye toward reducing latency and boosting performance. But most AI methods for classifying and processing wireless signals are power-hungry and can’t operate in real-time.</p><p>Now, MIT researchers have developed a novel AI hardware accelerator that is specifically designed for wireless signal processing. Their optical processor performs machine-learning computations at the speed of light, classifying wireless signals in a matter of nanoseconds.</p><p>The photonic chip is about 100 times faster than the best digital alternative, while converging to about 95 percent accuracy in signal classification. The new hardware accelerator is also scalable and flexible, so it could be used for a variety of high-performance computing applications. At the same time, it is smaller, lighter, cheaper, and more energy-efficient than digital AI hardware accelerators.</p><p>The device could be especially useful in future 6G wireless applications, such as cognitive radios that optimize data rates by adapting wireless modulation formats to the changing wireless environment.</p><p>By enabling an edge device to perform deep-learning computations in real-time, this new hardware accelerator could provide dramatic speedups in many applications beyond signal processing. For instance, it could help autonomous vehicles make split-second reactions to environmental changes or enable smart pacemakers to continuously monitor the health of a patient’s heart.</p><p>“There are many applications that would be enabled by edge devices that are capable of analyzing wireless signals. What we’ve presented in our paper could open up many possibilities for real-time and reliable AI inference. This work is the beginning of something that could be quite impactful,” says Dirk Englund, a professor in the MIT Department of Electrical Engineering and Computer Science, principal investigator in the Quantum Photonics and Artificial Intelligence Group and the Research Laboratory of Electronics (RLE), and senior author of the <a href=\"https://www.science.org/doi/10.1126/sciadv.adt3558\" target=\"_blank\">paper</a>.</p><p>He is joined on the paper by lead author Ronald Davis III PhD ’24; Zaijun Chen, a former MIT postdoc who is now an assistant professor at the University of Southern California; and Ryan Hamerly, a visiting scientist at RLE and senior scientist at NTT Research. The research appears today in <em>Science Advances</em>.</p><p><strong>Light-speed processing&nbsp;&nbsp;</strong></p><p>State-of-the-art digital AI accelerators for wireless signal processing convert the signal into an image and run it through a deep-learning model to classify it. While this approach is highly accurate, the computationally intensive nature of deep neural networks makes it infeasible for many time-sensitive applications.</p><p>Optical systems can accelerate deep neural networks by encoding and processing data using light, which is also less energy intensive than digital computing. But researchers have struggled to maximize the performance of general-purpose optical neural networks when used for signal processing, while ensuring the optical device is scalable.</p><p>By developing an optical neural network architecture specifically for signal processing, which they call a multiplicative analog frequency transform optical neural network (MAFT-ONN), the researchers tackled that problem head-on.</p><p>The MAFT-ONN addresses the problem of scalability by encoding all signal data and performing all machine-learning operations within what is known as the frequency domain — before the wireless signals are digitized.</p><p>The researchers designed their optical neural network to perform all linear and nonlinear operations in-line. Both types of operations are required for deep learning.</p><p>Thanks to this innovative design, they only need one MAFT-ONN device per layer for the entire optical neural network, as opposed to other methods that require one device for each individual computational unit, or “neuron.”</p><p>“We can fit 10,000 neurons onto a single device and compute the necessary multiplications in a single shot,” Davis says.&nbsp; &nbsp;</p><p>The researchers accomplish this using a technique called photoelectric multiplication, which dramatically boosts efficiency. It also allows them to create an optical neural network that can be readily scaled up with additional layers without requiring extra overhead.</p><p><strong>Results in nanoseconds</strong></p><p>MAFT-ONN takes a wireless signal as input, processes the signal data, and passes the information along for later operations the edge device performs. For instance, by classifying a signal’s modulation, MAFT-ONN would enable a device to automatically infer the type of signal to extract the data it carries.</p><p>One of the biggest challenges the researchers faced when designing MAFT-ONN was determining how to map the machine-learning computations to the optical hardware.</p><p>“We couldn’t just take a normal machine-learning framework off the shelf and use it. We had to customize it to fit the hardware and figure out how to exploit the physics so it would perform the computations we wanted it to,” Davis says.</p><p>When they tested their architecture on signal classification in simulations, the optical neural network achieved 85 percent accuracy in a single shot, which can quickly converge to more than 99 percent accuracy using multiple measurements.&nbsp; MAFT-ONN only required about 120 nanoseconds to perform entire process.</p><p>“The longer you measure, the higher accuracy you will get. Because MAFT-ONN computes inferences in nanoseconds, you don’t lose much speed to gain more accuracy,” Davis adds.</p><p>While state-of-the-art digital radio frequency devices can perform machine-learning inference in a microseconds, optics can do it in nanoseconds or even picoseconds.</p><p>Moving forward, the researchers want to employ what are known as multiplexing schemes so they could perform more computations and scale up the MAFT-ONN. They also want to extend their work into more complex deep learning architectures that could run transformer models or LLMs.</p><p>This work was funded, in part, by the U.S. Army Research Laboratory, the U.S. Air Force, MIT Lincoln Laboratory, Nippon Telegraph and Telephone, and the National Science Foundation.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT-Photonic-Process-01-press.jpg?itok=k9Og_vpo",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: Sampson Wilcox, Research Laboratory of Electronics"
        }
      ],
      "credit": "Credit: Sampson Wilcox, Research Laboratory of Electronics",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Electronics",
          "scheme": "https://news.mit.edu/topic/electronics",
          "label": null
        },
        {
          "term": "Research Laboratory of Electronics",
          "scheme": "https://news.mit.edu/topic/research-laboratory-electronics-1",
          "label": null
        },
        {
          "term": "Photonics",
          "scheme": "https://news.mit.edu/topic/photonics",
          "label": null
        },
        {
          "term": "Optics",
          "scheme": "https://news.mit.edu/topic/optics",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Wireless",
          "scheme": "https://news.mit.edu/topic/wireless",
          "label": null
        },
        {
          "term": "Internet of things",
          "scheme": "https://news.mit.edu/topic/internet-things",
          "label": null
        },
        {
          "term": "Mobile devices",
          "scheme": "https://news.mit.edu/topic/mobile-devices",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "Lincoln Laboratory",
          "scheme": "https://news.mit.edu/topic/lincoln-laboratory-0",
          "label": null
        },
        {
          "term": "National Science Foundation (NSF)",
          "scheme": "https://news.mit.edu/topic/nsf",
          "label": null
        }
      ]
    },
    {
      "title": "Have a damaged painting? Restore it in just hours with an AI-generated “mask”",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Have a damaged painting? Restore it in just hours with an AI-generated “mask”"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/restoring-damaged-paintings-using-ai-generated-mask-0611"
        }
      ],
      "link": "https://news.mit.edu/2025/restoring-damaged-paintings-using-ai-generated-mask-0611",
      "summary": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Scans of the painting during various stages in its restoration. At left is the damaged piece, with the middle panel showing a map of the different kinds of damage present; green lines show full splits in the underlying panel support, thin red lines depict major paint craquelure, blue areas correspond to large paint losses, while pink regions show smaller defects like scratches. At right is the restored painting with the applied laminate mask."
      },
      "published": "Wed, 11 Jun 2025 11:00:00 -0400",
      "published_parsed": [
        2025,
        6,
        11,
        15,
        0,
        0,
        2,
        162,
        0
      ],
      "id": "https://news.mit.edu/2025/restoring-damaged-paintings-using-ai-generated-mask-0611",
      "guidislink": false,
      "authors": [
        {
          "name": "Jennifer Chu | MIT News"
        }
      ],
      "author": "Jennifer Chu | MIT News",
      "author_detail": {
        "name": "Jennifer Chu | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Art restoration takes steady hands and a discerning eye. For centuries, conservators have restored paintings by identifying areas needing repair, then mixing an exact shade to fill in one area at a time. Often, a painting can have thousands of tiny regions requiring individual attention. Restoring a single painting can take anywhere from a few weeks to over a decade.</p><p>In recent years, digital restoration tools have opened a route to creating virtual representations of original, restored works. These tools apply techniques of computer vision, image recognition, and color matching, to generate a “digitally restored” version of a painting relatively quickly.</p><p>Still, there has been no way to translate digital restorations directly onto an original work, until now. In a <a href=\"https://www.nature.com/articles/s41586-025-09045-4\" target=\"_blank\">paper</a> appearing today in the journal <em>Nature</em>, Alex Kachkine, a mechanical engineering graduate student at MIT, presents a new method he’s developed to physically apply a digital restoration directly onto an original painting.</p><p>The restoration is printed on a very thin polymer film, in the form of a mask that can be aligned and adhered to an original painting. It can also be easily removed. Kachkine says that a digital file of the mask can be stored and referred to by future conservators, to see exactly what changes were made to restore the original painting.</p><p>“Because there’s a digital record of what mask was used, in 100 years, the next time someone is working with this, they’ll have an extremely clear understanding of what was done to the painting,” Kachkine says. “And that’s never really been possible in conservation before.”</p><p>As a demonstration, he applied the method to a highly damaged 15th century oil painting. The method automatically identified 5,612 separate regions in need of repair, and filled in these regions using 57,314 different colors. The entire process, from start to finish, took 3.5 hours, which he estimates is about 66 times faster than traditional restoration methods.</p><p>Kachkine acknowledges that, as with any restoration project, there are ethical issues to consider, in terms of whether a restored version is an appropriate representation of an artist’s original style and intent. Any application of his new method, he says, should be done in consultation with conservators with knowledge of a painting’s history and origins.</p><p>“There is a lot of damaged art in storage that might never be seen,” Kachkine says. “Hopefully with this new method, there’s a chance we’ll see more art, which I would be delighted by.”</p><p><strong>Digital connections</strong></p><p>The new restoration process started as a side project. In 2021, as Kachkine made his way to MIT to start his PhD program in mechanical engineering, he drove up the East Coast and made a point to visit as many art galleries as he could along the way.</p><p>“I’ve been into art for a very long time now, since I was a kid,” says Kachkine, who restores paintings as a hobby, using traditional hand-painting techniques. As he toured galleries, he came to realize that the art on the walls is only a fraction of the works that galleries hold. Much of the art that galleries acquire is stored away because the works are aged or damaged, and take time to properly restore.</p><p>“Restoring a painting is fun, and it’s great to sit down and infill things and have a nice evening,” Kachkine says. “But that’s a very slow process.”</p><p>As he has learned, digital tools can significantly speed up the restoration process. Researchers have developed artificial intelligence algorithms that quickly comb through huge amounts of data. The algorithms learn connections within this visual data, which they apply to generate a digitally restored version of a particular painting, in a way that closely resembles the style of an artist or time period. However, such digital restorations are usually displayed virtually or printed as stand-alone works and cannot be directly applied to retouch original art.</p><p>“All this made me think: If we could just restore a painting digitally, and effect the results physically, that would resolve a lot of pain points and drawbacks of a conventional manual process,” Kachkine says.</p><p><strong>“Align and restore”</strong></p><p>For the new study, Kachkine developed a method to physically apply a digital restoration onto an original painting, using a 15th-century painting that he acquired when he first came to MIT. His new method involves first using traditional techniques to clean a painting and remove any past restoration efforts.</p><p>“This painting is almost 600 years old and has gone through conservation many times,” he says. “In this case there was a fair amount of overpainting, all of which has to be cleaned off to see what’s actually there to begin with.”</p><p>He scanned the cleaned painting, including the many regions where paint had faded or cracked. He then used existing artificial intelligence algorithms to analyze the scan and&nbsp;create a virtual version of what the painting likely looked like in its original state.</p><p>Then, Kachkine developed software that creates a map of regions on the original painting that require infilling, along with the exact colors needed to match the digitally restored version. This map is then translated into a physical, two-layer mask that is printed onto thin polymer-based films. The first layer is printed in color, while the second layer is printed in the exact same pattern, but in white.</p><p>“In order to fully reproduce color, you need both white and color ink to get the full spectrum,” Kachkine explains. “If those two layers are misaligned, that’s very easy to see. So I also developed a few computational tools, based on what we know of human color perception, to determine how small of a region we can practically align and restore.”</p><p>Kachkine used high-fidelity commercial inkjets to print the mask’s two layers, which he carefully aligned and overlaid by hand onto the original painting and adhered with a thin spray of conventional varnish. The printed films are made from materials that can be easily dissolved with conservation-grade solutions, in case conservators need to reveal the original, damaged work. The digital file of the mask can also be saved as a detailed record of what was restored.</p><p>For the painting that Kachkine used, the method was able to fill in thousands of losses in just a few hours. “A few years ago, I was restoring this baroque Italian painting with probably the same order magnitude of losses, and it took me nine months of part-time work,” he recalls. “The more losses there are, the better this method is.”</p><p>He estimates that the new method can be orders of magnitude faster than traditional, hand-painted approaches. If the method is adopted widely, he emphasizes that conservators should be involved at every step in the process, to ensure that the final work is in keeping with an artist’s style and intent.</p><p>“It will take a lot of deliberation about the ethical challenges involved at every stage in this process to see how can this be applied in a way that’s most consistent with conservation principles,” he says. “We’re setting up a framework for developing further methods. As others work on this, we’ll end up with methods that are more precise.”</p><p>This work was supported, in part, by the John O. and Katherine A. Lutz Memorial Fund. The research was&nbsp;carried out, in part, through the use of equipment and facilities at MIT.Nano, with additional support from the MIT Microsystems Technology Laboratories, the MIT Department of Mechanical Engineering, and the MIT Libraries.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT-Restoring-Paintings-01-press.jpg?itok=PuiJGVXh",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: Courtesy of the researchers"
        }
      ],
      "credit": "Credit: Courtesy of the researchers",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Arts",
          "scheme": "https://news.mit.edu/topic/arts",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "automation",
          "scheme": "https://news.mit.edu/topic/automation",
          "label": null
        },
        {
          "term": "Computer vision",
          "scheme": "https://news.mit.edu/topic/computer-vision",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Mechanical engineering",
          "scheme": "https://news.mit.edu/topic/mechanical-engineering",
          "label": null
        },
        {
          "term": "Visual arts",
          "scheme": "https://news.mit.edu/topic/visual-arts",
          "label": null
        },
        {
          "term": "MIT Libraries",
          "scheme": "https://news.mit.edu/topic/libraries",
          "label": null
        },
        {
          "term": "MIT.nano",
          "scheme": "https://news.mit.edu/topic/mitnano",
          "label": null
        },
        {
          "term": "Microsystems Technology Laboratories",
          "scheme": "https://news.mit.edu/topic/microsystems-technology-laboratories-0",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        }
      ]
    },
    {
      "title": "How we really judge AI",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "How we really judge AI"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/how-we-really-judge-ai-0610"
        }
      ],
      "link": "https://news.mit.edu/2025/how-we-really-judge-ai-0610",
      "summary": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "A new study finds that people are neither entirely enthusiastic nor totally averse to AI. Rather than falling into camps of techno-optimists and Luddites, people are discerning about the practical upshot of using AI, case by case."
      },
      "published": "Tue, 10 Jun 2025 11:30:00 -0400",
      "published_parsed": [
        2025,
        6,
        10,
        15,
        30,
        0,
        1,
        161,
        0
      ],
      "id": "https://news.mit.edu/2025/how-we-really-judge-ai-0610",
      "guidislink": false,
      "authors": [
        {
          "name": "Peter Dizikes | MIT News"
        }
      ],
      "author": "Peter Dizikes | MIT News",
      "author_detail": {
        "name": "Peter Dizikes | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Suppose you were shown that an artificial intelligence tool offers accurate predictions about some stocks you own. How would you feel about using it? Now, suppose you are applying for a job at a company where the HR department uses an AI system to screen resumes. Would you be comfortable with that?</p><p>A new study finds that people are neither entirely enthusiastic nor totally averse to AI. Rather than falling into camps of techno-optimists and Luddites, people are discerning about the practical upshot of using AI, case by case.</p><p>“We propose that AI appreciation occurs when AI is perceived as being more capable than humans and personalization is perceived as being unnecessary in a given decision context,” says MIT Professor Jackson Lu, co-author of a newly published paper detailing the study’s results. “AI aversion occurs when either of these conditions is not met, and AI appreciation occurs only when both conditions are satisfied.”</p><p>The paper, “<a href=\"https://psycnet.apa.org/doiLanding?doi=10.1037%2Fbul0000477\" target=\"_blank\">AI Aversion or Appreciation? A Capability–Personalization Framework and a Meta-Analytic Review</a>,” appears in <em>Psychological Bulletin</em>. The paper has eight co-authors, including Lu, who is the Career Development Associate Professor of Work and Organization Studies at the MIT Sloan School of Management.</p><p><strong>New framework adds insight</strong></p><p>People’s reactions to AI have long been subject to extensive debate, often producing seemingly disparate findings. An influential 2015 paper on “algorithm aversion” found that people are less forgiving of AI-generated errors than of human errors, whereas a widely noted 2019 paper on “algorithm appreciation” found that people preferred advice from AI, compared to advice from humans.</p><p>To reconcile these mixed findings, Lu and his co-authors conducted a meta-analysis of 163 prior studies that compared people’s preferences for AI versus humans. The researchers tested whether the data supported their proposed “Capability–Personalization Framework” — the idea that in a given context, both the perceived capability of AI and the perceived necessity for personalization shape our preferences for either AI or humans.</p><p>Across the 163 studies, the research team analyzed over 82,000 reactions to 93 distinct “decision contexts” — for instance, whether or not participants would feel comfortable with AI being used in cancer diagnoses. The analysis confirmed that the Capability–Personalization Framework indeed helps account for people’s preferences.</p><p>“The meta-analysis supported our theoretical framework,” Lu says. “Both dimensions are important:&nbsp;Individuals evaluate whether or not AI is more capable than people at a given task, and whether the task calls for personalization. People will prefer AI only if they think the AI is more capable than humans and the task is nonpersonal.”</p><p>He adds: “The key idea here is that high perceived capability alone does not guarantee AI appreciation. Personalization matters too.”</p><p>For example, people tend to favor AI when it comes to detecting fraud or sorting large datasets — areas where AI’s abilities exceed those of humans in speed and scale, and personalization is not required. But they are more resistant to AI in contexts like therapy, job interviews, or medical diagnoses, where they feel a human is better able to recognize their unique circumstances.</p><p>“People have a fundamental desire to see themselves as unique and distinct from other people,” Lu says. “AI is often viewed as impersonal and operating in a rote manner. Even if the AI is trained on a wealth of data, people feel AI can’t grasp their personal situations. They want a human recruiter, a human doctor who can see them as distinct from other people.”</p><p><strong>Context also matters: From tangibility to unemployment</strong></p><p>The study also uncovered other factors that influence individuals’ preferences for AI. For instance, AI appreciation is more pronounced for tangible robots than for intangible algorithms.</p><p>Economic context also matters. In countries with lower unemployment, AI appreciation is more pronounced.</p><p>“It makes intuitive sense,” Lu says. “If you worry about being replaced by AI, you’re less likely to embrace it.”&nbsp;&nbsp;</p><p>Lu is continuing to examine people’s complex and evolving attitudes toward AI. While he does not view the current meta-analysis as the last word on the matter, he hopes the Capability–Personalization Framework offers a valuable lens for understanding how people evaluate AI across different contexts.</p><p>“We’re not claiming&nbsp;perceived capability and personalization are the only two dimensions that matter, but according to our meta-analysis, these two dimensions&nbsp;capture much of what shapes people’s preferences for AI versus humans across a wide range of&nbsp;studies,” Lu concludes.</p><p>In addition to Lu, the paper’s co-authors are Xin Qin, Chen Chen, Hansen Zhou, Xiaowei Dong, and Limei Cao of Sun Yat-sen University; Xiang Zhou of Shenzhen University; and Dongyuan Wu of Fudan University.</p><p>The research was supported, in part, by grants to Qin and Wu from the National Natural Science Foundation of China.&nbsp;</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT-AI-Aversion-Appreciation-01.jpg?itok=vlwejm54",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: Christine Daniloff, MIT; iStock"
        }
      ],
      "credit": "Credit: Christine Daniloff, MIT; iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Behavior",
          "scheme": "https://news.mit.edu/topic/behavior",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Technology and society",
          "scheme": "https://news.mit.edu/topic/technology-society",
          "label": null
        },
        {
          "term": "MIT Sloan School of Management",
          "scheme": "https://news.mit.edu/topic/mit-sloan-school-management",
          "label": null
        }
      ]
    },
    {
      "title": "AI-enabled control system helps autonomous drones stay on target in uncertain environments",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "AI-enabled control system helps autonomous drones stay on target in uncertain environments"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/ai-enabled-control-system-helps-autonomous-drones-uncertain-environments-0609"
        }
      ],
      "link": "https://news.mit.edu/2025/ai-enabled-control-system-helps-autonomous-drones-uncertain-environments-0609",
      "summary": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "MIT researchers developed a new adaptive control system that could help autonomous drones stay on target in uncertain environments."
      },
      "published": "Mon, 09 Jun 2025 16:40:00 -0400",
      "published_parsed": [
        2025,
        6,
        9,
        20,
        40,
        0,
        0,
        160,
        0
      ],
      "id": "https://news.mit.edu/2025/ai-enabled-control-system-helps-autonomous-drones-uncertain-environments-0609",
      "guidislink": false,
      "authors": [
        {
          "name": "Adam Zewe | MIT News"
        }
      ],
      "author": "Adam Zewe | MIT News",
      "author_detail": {
        "name": "Adam Zewe | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>An autonomous drone carrying water to help extinguish a wildfire in the Sierra Nevada might encounter swirling Santa Ana winds that threaten to push it off course. Rapidly adapting to these unknown disturbances inflight presents an enormous challenge for the drone’s&nbsp;flight control system.</p><p>To help such a drone stay on target, MIT researchers developed a new, machine learning-based adaptive control&nbsp;algorithm that could minimize its deviation from its intended trajectory in the face of unpredictable forces like gusty winds.</p><p>Unlike standard approaches, the new technique does not require the person programming the autonomous drone to know anything in advance about the structure of these uncertain disturbances. Instead, the control system’s artificial intelligence model learns all it needs to know from&nbsp;a small amount of&nbsp;observational data collected from 15 minutes of flight time.</p><p>Importantly, the technique automatically determines which optimization algorithm it should use to adapt to the disturbances, which improves tracking performance. It chooses the algorithm that best suits the geometry of specific disturbances this drone is facing.</p><p>The researchers train their control system to do both things simultaneously using a technique called meta-learning, which teaches the system how to adapt to different types of disturbances.</p><p>Taken together, these ingredients enable their adaptive control system to achieve 50 percent less trajectory tracking error than baseline methods in simulations and perform better with new wind speeds it didn’t see during training.</p><p>In the future, this adaptive control system could help autonomous drones more efficiently deliver heavy parcels despite strong winds or monitor fire-prone areas of a national park.</p><p>“The concurrent learning of these components is what gives our method its strength. By leveraging meta-learning, our controller can automatically make choices that will be best for quick adaptation,” says Navid Azizan, who is the Esther and Harold E. Edgerton Assistant Professor in the MIT Department of Mechanical Engineering and the Institute for Data, Systems, and Society (IDSS), a principal investigator of the Laboratory for Information and Decision Systems (LIDS), and the senior author of a <a href=\"https://arxiv.org/pdf/2407.20165\" target=\"_blank\">paper</a> on this control system.</p><p>Azizan is joined on the paper by lead author Sunbochen Tang, a graduate student in the Department of Aeronautics and Astronautics, and Haoyuan Sun, a graduate student in the Department of Electrical Engineering and Computer Science. The research was recently presented at the Learning for Dynamics and Control Conference.</p><p><strong>Finding the right algorithm</strong></p><p>Typically, a control system incorporates a function that models the drone and its environment, and includes some existing information on the structure of potential disturbances. But in a real world filled with uncertain conditions, it is often impossible to hand-design this structure in advance.</p><p>Many control systems use an adaptation method based on a popular optimization algorithm, known as gradient descent, to estimate the unknown parts of the problem and determine how to keep the drone as close as possible to its target trajectory during flight. However, gradient descent is only one algorithm in a larger family of algorithms available to choose, known as mirror descent.</p><p>“Mirror descent is a general family of algorithms, and for any given problem, one of these algorithms can be more suitable than others. The name of the game is how to choose the particular algorithm that is right for your problem. In our method, we automate this choice,” Azizan says.</p><p>In their control system, the researchers replaced the function that contains some structure of potential disturbances with a neural network model that learns to approximate them from data. In this way, they don’t need to have an a priori structure of the wind speeds this drone could encounter in advance.</p><p>Their method also uses an algorithm to automatically select the right mirror-descent function while learning the neural network model from data, rather than assuming a user has the ideal function picked out already. The researchers give this algorithm a range of functions to pick from, and it finds the one that best fits the problem at hand.</p><p>“Choosing a good distance-generating function to construct the right mirror-descent adaptation matters a lot in getting the right algorithm to reduce the tracking error,” Tang adds.</p><p><strong>Learning to adapt</strong></p><p>While the wind speeds the drone may encounter could change every time it takes flight, the controller’s neural network and mirror function should stay the same so they don’t need to be recomputed each time.</p><p>To make their controller more flexible, the researchers use meta-learning, teaching it to adapt by showing it a range of wind speed families during training.</p><p>“Our method can cope with different objectives because, using meta-learning, we can learn a shared representation through different scenarios efficiently from data,” Tang explains.</p><p>In the end, the user feeds the control system a target trajectory and it continuously recalculates, in real-time, how the drone should produce thrust to keep it as close as possible to that trajectory while accommodating the uncertain disturbance it encounters.</p><p>In both simulations and real-world experiments, the researchers showed that their method led to significantly less trajectory tracking error than baseline approaches with every wind speed they tested.</p><p>“Even if the wind disturbances are much stronger than we had seen during training, our technique shows that it can still handle them successfully,” Azizan adds.</p><p>In addition, the margin by which their method outperformed the baselines grew as the wind speeds intensified, showing that it can adapt to challenging environments.</p><p>The team is now performing hardware experiments to test their control system on real drones with varying wind conditions and other disturbances.</p><p>They also want to extend their method so it can handle disturbances from multiple sources at once. For instance, changing wind speeds could cause the weight of a parcel the drone is carrying to shift in flight, especially when the drone is carrying sloshing payloads.</p><p>They also want to explore continual learning, so the drone could adapt to new disturbances without the need to also be retrained on the data it has seen so far.</p><p>“Navid and his collaborators have developed breakthrough work that combines meta-learning with conventional adaptive control to learn nonlinear features and the suitable adaptation law from data. Key to their approach is the use of mirror descent techniques that exploit the underlying geometry of the problem and do so automatically. Their work can contribute significantly to the design of autonomous systems that need to operate in complex and uncertain environments,” says Babak Hassibi, the Mose and Lillian S. Bohn Professor of Electrical Engineering and Computing and Mathematical Sciences at Caltech, who was not involved with this work.</p><p>This research was supported, in part, by MathWorks, the MIT-IBM Watson AI Lab, the MIT-Amazon Science Hub, and the MIT-Google Program for Computing Innovation.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT_MetaLearning-01.jpg?itok=W4xrH8QL",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: iStock"
        }
      ],
      "credit": "Credit: iStock",
      "tags": [
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Robotics",
          "scheme": "https://news.mit.edu/topic/robotics",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Drones",
          "scheme": "https://news.mit.edu/topic/drones",
          "label": null
        },
        {
          "term": "Autonomous vehicles",
          "scheme": "https://news.mit.edu/topic/autonomous-vehicles",
          "label": null
        },
        {
          "term": "Mechanical engineering",
          "scheme": "https://news.mit.edu/topic/mechanical-engineering",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "Aeronautical and astronautical engineering",
          "scheme": "https://news.mit.edu/topic/aeronautics",
          "label": null
        },
        {
          "term": "Laboratory for Information and Decision Systems (LIDS)",
          "scheme": "https://news.mit.edu/topic/lids",
          "label": null
        },
        {
          "term": "IDSS",
          "scheme": "https://news.mit.edu/topic/idss",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        },
        {
          "term": "MIT-IBM Watson AI Lab",
          "scheme": "https://news.mit.edu/topic/mit-ibm-watson-ai-lab",
          "label": null
        }
      ]
    },
    {
      "title": "Helping machines understand visual content with AI",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Helping machines understand visual content with AI"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609"
        }
      ],
      "link": "https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609",
      "summary": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Coactive, founded by Cody Coleman '15, MEng '17 and William Gaviria Rojas ’13, has built an AI-powered platform to unlock new insights from content of all types, including video."
      },
      "published": "Mon, 09 Jun 2025 15:45:00 -0400",
      "published_parsed": [
        2025,
        6,
        9,
        19,
        45,
        0,
        0,
        160,
        0
      ],
      "id": "https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609",
      "guidislink": false,
      "authors": [
        {
          "name": "Zach Winn | MIT News"
        }
      ],
      "author": "Zach Winn | MIT News",
      "author_detail": {
        "name": "Zach Winn | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Data should drive every decision a modern business makes. But most businesses have a massive blind spot: They don’t know what’s happening in their visual data.</p><p>Coactive is working to change that. The company, founded by Cody Coleman ’13, MEng ’15 and William Gaviria Rojas<strong>&nbsp;</strong>’13, has created an artificial intelligence-powered platform that can make sense of data like images, audio, and video to unlock new insights.</p><p>Coactive’s platform can instantly search, organize, and analyze unstructured visual content to help businesses make faster, better decisions.</p><p>“In the first big data revolution, businesses got better at getting value out of their structured data,” Coleman says, referring to data from tables and spreadsheets. “But now, approximately 80 to 90 percent of the data in the world is unstructured. In the next chapter of big data, companies will have to process data like images, video, and audio at scale, and AI is a key piece of unlocking that capability.”</p><p>Coactive is already working with several large media and retail companies to help them understand their visual content without relying on manual sorting and tagging. That’s helping them get the right content to users faster, remove explicit content from their platforms, and uncover how specific content influences user behavior.</p><p>More broadly, the founders believe Coactive serves as an example of how AI can empower humans to work more efficiently and solve new problems.</p><p>“The word coactive means to work together concurrently, and that’s our grand vision: helping humans and machines work together,” Coleman says. “We believe that vision is more important now than ever because AI can either pull us apart or bring us together. We want Coactive to be an agent that pulls us together and gives human beings a new set of superpowers.”</p><p><strong>Giving computers vision</strong></p><p>Coleman met Gaviria Rojas in the summer before their first yearthrough the MIT Interphase Edge program. Both would go on to major in electrical engineering and computer science and work on bringing <a href=\"https://ocw.mit.edu/\" target=\"_blank\">MIT OpenCourseWare</a> content to Mexican universities, among other projects.</p><p>“That was a great example of entrepreneurship,” Coleman recalls of the OpenCourseWare project. “It was really empowering to be responsible for the business and the software development. It led me to start my own small web-development businesses afterward, and to take [the MIT course] Founder’s Journey.”</p><p>Coleman first explored the power of AI at MIT while working as a graduate researcher with the Office of Digital Learning (now MIT Open Learning), where he used machine learning to study how humans learn on MITx, which hosts massive, open online courses created by MIT faculty and instructors.</p><p>“It was really amazing to me that you could democratize this transformational journey that I went through at MIT with digital learning — and that you could apply AI and machine learning to create adaptive systems that not only help us understand how humans learn, but also deliver more personalized learning experiences to people around the world,” Coleman says of MITx. “That was also the first time I got to explore video content and apply AI to it.”</p><p>After MIT, Coleman went to Stanford University for his PhD, where he worked on lowering barriers to using AI. The research led him to work with companies like Pinterest and Meta on AI and machine-learning applications.</p><p>“That’s where I was able to see around the corner into the future of what people wanted to do with AI and their content,” Coleman recalls. “I was seeing how leading companies were using AI to drive business value, and that’s where the initial spark for Coactive came from. I thought, ‘What if we create an enterprise-grade operating system for content and multimodal AI to make that easy?’”</p><p>Meanwhile, Gaviria Rojas<strong>&nbsp;</strong>moved to the Bay Area in 2020 and started working as<strong>&nbsp;</strong>a data scientist at eBay. As part of the move, he needed help transporting his couch, and Coleman was the lucky friend he called.</p><p>“On the car ride, we realized we both saw an explosion happening around data and AI,” Gaviria Rojas says. “At MIT, we got a front row seat to the big data revolution, and we saw people inventing technologies to unlock value from that data at scale. Cody and I realized we had another powder keg about to explode with enterprises collecting tremendous amount of data, but this time it was multimodal data like images, video, audio, and text. There was a missing technology to unlock it at scale. That was AI.”</p><p>The platform the founders went on to build — what Coleman describes as an “AI operating system” — is model agnostic, meaning the company can swap out the AI systems under the hood as models continue to improve. Coactive’s platform includes prebuilt applications that business customers can use to do things like search through their content, generate metadata, and conduct analytics to extract insights.</p><p>“Before AI, computers would see the world through bytes, whereas humans would see the world through vision,” Coleman says. “Now with AI, machines can finally see the world like we do, and that’s going to cause the digital and physical worlds to blur.”</p><p><strong>Improving the human-computer interface</strong></p><p>Reuters’ database of images supplies the world’s journalists with millions of photos. Before Coactive, the company relied on reporters manually entering tags with each photo so that the right images would show up when journalists searched for certain subjects.</p><p>“It was incredible slow and expensive to go through all of these raw assets, so people just didn’t add tags,” Coleman says. “That meant when you searched for things, there were limited results even if relevant photos were in the database.”</p><p>Now, when journalists on Reuters’ website select ‘Enable AI Search,’ Coactive can pull up relevant content based on its AI system’s understanding of the details in each image and video.</p><p>“It’s vastly improving the quality of results for reporters, which enables them to tell better, more accurate stories than ever before,” Coleman says.</p><p>Reuters is not alone in struggling to manage all of its content. Digital asset management is a huge component of many media and retail companies, who today often rely on manually entered metadata for sorting and searching through that content.</p><p>Another Coactive customer is Fandom, which is one of the world’s largest platforms for information around TV shows, videogames, and movies with more than 300 million monthly active users. Fandom is using Coactive to understand visual data in their online communities and help remove excessive gore and sexualized content.</p><p>“It used to take 24 to 48 hours for Fandom to review each new piece of content,” Coleman says. “Now with Coactive, they’ve codified their community guidelines and can generate finer-grain information in an average of about 500 milliseconds.”</p><p>With every use case, the founders see Coactive as enabling a new paradigm in the ways humans work with machines.</p><p>“Throughout the history of human-computer interaction, we’ve had to bend over a keyboard and mouse to input information in a way that machines could understand,” Coleman says. “Now, for the first time, we can just speak naturally, we can share images and video with AI, and it can understand that content. That’s a fundamental change in the way we think about human-computer interactions. The core vision of Coactive is because of that change, we need a new operating system and a new way of working with content and AI.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT-Coactive-AI-01-press.jpg?itok=YBc2evUx",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: Courtesy of Coactive AI; MIT News"
        }
      ],
      "credit": "Credit: Courtesy of Coactive AI; MIT News",
      "tags": [
        {
          "term": "Startups",
          "scheme": "https://news.mit.edu/topic/startups",
          "label": null
        },
        {
          "term": "Innovation and Entrepreneurship (I&E)",
          "scheme": "https://news.mit.edu/topic/innovation",
          "label": null
        },
        {
          "term": "Alumni/ae",
          "scheme": "https://news.mit.edu/topic/alumni",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Computer vision",
          "scheme": "https://news.mit.edu/topic/computer-vision",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "OpenCourseWare",
          "scheme": "https://news.mit.edu/topic/opencourseware",
          "label": null
        }
      ]
    },
    {
      "title": "Teaching AI models what they don’t know",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Teaching AI models what they don’t know"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/themis-ai-teaches-ai-models-what-they-dont-know-0603"
        }
      ],
      "link": "https://news.mit.edu/2025/themis-ai-teaches-ai-models-what-they-dont-know-0603",
      "summary": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "“We want to enable AI in the highest-stakes applications of every industry,” says Themis AI co-founder Alexander Amini ’17, SM ’18, PhD ’22."
      },
      "published": "Tue, 03 Jun 2025 00:00:00 -0400",
      "published_parsed": [
        2025,
        6,
        3,
        4,
        0,
        0,
        1,
        154,
        0
      ],
      "id": "https://news.mit.edu/2025/themis-ai-teaches-ai-models-what-they-dont-know-0603",
      "guidislink": false,
      "authors": [
        {
          "name": "Zach Winn | MIT News"
        }
      ],
      "author": "Zach Winn | MIT News",
      "author_detail": {
        "name": "Zach Winn | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p>Artificial intelligence systems like ChatGPT provide plausible-sounding answers to any question you might ask. But they don’t always reveal the gaps in their knowledge or areas where they’re uncertain. That problem can have huge consequences as AI systems are increasingly used to do things like develop drugs, synthesize information, and drive autonomous cars.</p><p>Now, the MIT spinout Themis AI is helping quantify model uncertainty and correct outputs before they cause bigger problems. The company’s Capsa platform can work with any machine-learning model to detect and correct unreliable outputs in seconds. It works by modifying AI models to enable them to detect patterns in their data processing that indicate ambiguity, incompleteness, or bias.</p><p>“The idea is to take a model, wrap it in Capsa, identify the uncertainties and failure modes of the model, and then enhance the model,” says Themis AI co-founder and MIT Professor Daniela Rus, who is also the director of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). “We’re excited about offering a solution that can improve models and offer guarantees that the model is working correctly.”</p><p>Rus founded Themis AI in 2021 with Alexander Amini ’17, SM ’18, PhD ’22 and Elaheh Ahmadi ’20, MEng ’21, two former research affiliates in her lab. Since then, they’ve helped telecom companies with network planning and automation, helped oil and gas companies use AI to understand seismic imagery, and published papers on developing more reliable and trustworthy chatbots.</p><p>“We want to enable AI in the highest-stakes applications of every industry,” Amini says. “We’ve all seen examples of AI hallucinating or making mistakes. As AI is deployed more broadly, those mistakes could lead to devastating consequences. Themis makes it possible that any AI can forecast and predict its own failures, before they happen.”</p><p><a name=\"_msocom_1\"></a></p><div><div><div id=\"_com_1\"><p><strong>Helping models know what they don’t know</strong></p></div></div></div><p>Rus’ lab has been researching model uncertainty for years. In 2018, she received funding from Toyota to study the reliability of a machine learning-based autonomous driving solution.</p><p>“That is a safety-critical context where understanding model reliability is very important,” Rus says.</p><p>In separate <a href=\"https://dl.acm.org/doi/abs/10.1145/3306618.3314243\" target=\"_blank\">work</a>, Rus, Amini, and their collaborators built an algorithm that could detect racial and gender bias in facial recognition systems and automatically reweight the model’s training data, showing it eliminated bias. The algorithm worked by identifying the unrepresentative parts of the underlying training data and generating new, similar data samples to rebalance it.</p><p>In 2021, the eventual co-founders showed a <a href=\"https://pubs.acs.org/doi/full/10.1021/acscentsci.1c00546\" target=\"_blank\">similar approach</a> could be used to help pharmaceutical companies use AI models to predict the properties of drug candidates. They founded Themis AI later that year.</p><p>“Guiding drug discovery could potentially save a lot of money,” Rus says. “That was the use case that made us realize how powerful this tool could be.”</p><p>Today Themis AI is working with enterprises in a variety of industries, and many of those companies are building large language models. By using Capsa, these models are able to quantify their own uncertainty for each output.</p><p>“Many companies are interested in using LLMs that are based on their data, but they’re concerned about reliability,” observes Stewart Jamieson SM ’20, PhD ’24, Themis AI's head of technology. “We help LLMs self-report their confidence and uncertainty, which enables more reliable question answering and flagging unreliable outputs.”</p><p>Themis AI is also in discussions with semiconductor companies building AI solutions on their chips that can work outside of cloud environments.</p><p>“Normally these smaller models that work on phones or embedded systems aren’t very accurate compared to what you could run on a server, but we can get the best of both worlds: low latency, efficient edge computing without sacrificing quality,” Jamieson explains. “We see a future where edge devices do most of the work, but whenever they’re unsure of their output, they can forward those tasks to a central server.”</p><p>Pharmaceutical companies can also use Capsa to improve AI models being used to identify drug candidates and predict their performance in clinical trials.</p><p>“The predictions and outputs of these models are very complex and hard to interpret — experts spend a lot of time and effort trying to make sense of them,” Amini remarks. “Capsa can give insights right out of the gate to understand if the predictions are backed by evidence in the training set or are just speculation without a lot of grounding. That can accelerate the identification of the strongest predictions, and we think that has a huge potential for societal good.”</p><p><strong>Research for impact</strong></p><p>Themis AI’s team believes the company is well-positioned to improve the cutting edge of constantly evolving AI technology. For instance, the company is exploring Capsa’s ability to improve accuracy in an AI technique known as chain-of-thought reasoning, in which LLMs explain the steps they take to get to an answer.</p><p>“We’ve seen signs Capsa could help guide those reasoning processes to identify the highest-confidence chains of reasoning,” Jamieson says. “We think that has huge implications in terms of improving the LLM experience, reducing latencies, and reducing computation requirements. It’s an extremely high-impact opportunity for us.”</p><p>For Rus, who has co-founded several companies since coming to MIT, Themis AI is an opportunity to ensure her MIT research has impact.</p><p>“My students and I have become increasingly passionate about going the extra step to make our work relevant for the world,\" Rus says. “AI has tremendous potential to transform industries, but AI also raises concerns. What excites me is the opportunity to help develop technical solutions that address these challenges and also build trust and understanding between people and the technologies that are becoming part of their daily lives.”</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT-ThemisAI-01-Press.jpg?itok=ez4Dk4qN",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: MIT News; iStock"
        }
      ],
      "credit": "Credit: MIT News; iStock",
      "tags": [
        {
          "term": "Startups",
          "scheme": "https://news.mit.edu/topic/startups",
          "label": null
        },
        {
          "term": "Innovation and Entrepreneurship (I&E)",
          "scheme": "https://news.mit.edu/topic/innovation",
          "label": null
        },
        {
          "term": "Computer science and technology",
          "scheme": "https://news.mit.edu/topic/computers",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Algorithms",
          "scheme": "https://news.mit.edu/topic/algorithms",
          "label": null
        },
        {
          "term": "Machine learning",
          "scheme": "https://news.mit.edu/topic/machine-learning",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Neuroscience",
          "scheme": "https://news.mit.edu/topic/neuroscience",
          "label": null
        },
        {
          "term": "Faculty",
          "scheme": "https://news.mit.edu/topic/faculty",
          "label": null
        },
        {
          "term": "Alumni/ae",
          "scheme": "https://news.mit.edu/topic/alumni",
          "label": null
        },
        {
          "term": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
          "scheme": "https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        },
        {
          "term": "Electrical engineering and computer science (EECS)",
          "scheme": "https://news.mit.edu/topic/electrical-engineering-computer-science-eecs",
          "label": null
        },
        {
          "term": "MIT Schwarzman College of Computing",
          "scheme": "https://news.mit.edu/topic/mit-schwarzman-college-computing",
          "label": null
        }
      ]
    },
    {
      "title": "3 Questions: How to help students recognize potential bias in their AI datasets",
      "title_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "3 Questions: How to help students recognize potential bias in their AI datasets"
      },
      "links": [
        {
          "rel": "alternate",
          "type": "text/html",
          "href": "https://news.mit.edu/2025/3-questions-recognizing-potential-bias-in-ai-datasets-0602"
        }
      ],
      "link": "https://news.mit.edu/2025/3-questions-recognizing-potential-bias-in-ai-datasets-0602",
      "summary": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
      "summary_detail": {
        "type": "text/plain",
        "language": "en",
        "base": "https://news.mit.edu",
        "value": "Courses on developing AI models for health care need to focus more on teaching how to identify and address bias."
      },
      "published": "Mon, 02 Jun 2025 10:30:00 -0400",
      "published_parsed": [
        2025,
        6,
        2,
        14,
        30,
        0,
        0,
        153,
        0
      ],
      "id": "https://news.mit.edu/2025/3-questions-recognizing-potential-bias-in-ai-datasets-0602",
      "guidislink": false,
      "authors": [
        {
          "name": "Anne Trafton | MIT News"
        }
      ],
      "author": "Anne Trafton | MIT News",
      "author_detail": {
        "name": "Anne Trafton | MIT News"
      },
      "content": [
        {
          "type": "text/html",
          "language": "en",
          "base": "https://news.mit.edu",
          "value": "<p><em>Every year, thousands of students take courses that teach them how to deploy artificial intelligence models that can help doctors diagnose disease and determine appropriate treatments. However, many of these courses omit a key element: training students to detect flaws in the training data used to develop the models.</em></p><p><em>Leo Anthony Celi, a senior research scientist at MIT’s Institute for Medical Engineering and Science, a physician at Beth Israel Deaconess Medical Center, and an associate professor at Harvard Medical School, has documented these shortcomings in a </em><a href=\"https://dl.acm.org/doi/10.1145/3737650\" target=\"_blank\"><em>new paper</em></a><em> and hopes to persuade course developers to teach students to more thoroughly evaluate their data before incorporating it into their models. Many previous studies have found that models trained mostly on clinical data from white males don’t work well when applied to people from other groups. Here, Celi describes the impact of such bias and how educators might address it in their teachings about AI models.</em></p><p><strong>Q:</strong> How does bias get into these datasets, and how can these shortcomings be addressed?</p><p><strong>A:</strong> Any problems in the data will be baked into any modeling of the data. In the past we have described instruments and devices that don’t work well across individuals. As one example, we found that&nbsp;<a href=\"https://news.mit.edu/2022/pulse-oximeters-dont-work-as-well-patients-of-color-0802\" target=\"_blank\">pulse oximeters</a> overestimate oxygen levels for people of color, because there weren’t enough people of color enrolled in the clinical trials of the devices. We remind our students that medical devices and equipment are optimized on healthy young males. They were never optimized for an 80-year-old woman with heart failure, and yet we use them for those purposes. And the FDA does not require that a device work well on this diverse of a population that we will be using it on. All they need is proof that it works on healthy subjects.</p><p>Additionally, the electronic health record system is in no shape to be used as the building blocks of AI. Those records were not designed to be a learning system, and for that reason, you have to be really careful about using electronic health records. The electronic health record system is to be replaced, but that’s not going to happen anytime soon, so we need to be smarter. We need to be more creative about using the data that we have now, no matter how bad they are, in building algorithms.</p><p>One promising avenue that we are exploring is the development of a&nbsp;<a href=\"https://arxiv.org/abs/2501.02648\" target=\"_blank\">transformer model</a> of numeric electronic health record data, including but not limited to laboratory test results. Modeling the underlying relationship between the laboratory tests, the vital signs and the treatments can mitigate the effect of missing data as a result of social determinants of health and provider implicit biases.</p><p><strong>Q:</strong> Why is it important for courses in AI to cover the sources of potential bias? What did you find when you analyzed such courses’ content?</p><p><strong>A:</strong>&nbsp;Our course at MIT started in 2016, and at some point we realized that we were encouraging people to race to build models that are overfitted to some statistical measure of model performance, when in fact the data that we’re using is rife with problems that people are not aware of. At that time, we were wondering: How common is this problem?</p><p>Our suspicion was that if you looked at the courses where the syllabus is available online, or the online courses, that none of them even bothers to tell the students that they should be paranoid about the data. And true enough, when we looked at the different online courses, it’s all about building the model. How do you build the model? How do you visualize the data? We found that of 11 courses we reviewed, only five included sections on bias in datasets, and only two contained any significant discussion of bias.</p><p>That said, we cannot discount the value of these courses. I’ve heard lots of stories where people self-study based on these online courses, but at the same time, given how influential they are, how impactful they are, we need to really double down on requiring them to teach the right skillsets, as more and more people are drawn to this AI multiverse. It’s important for people to really equip themselves with the agency to be able to work with AI. We’re hoping that this paper will shine a spotlight on this huge gap in the way we teach AI now to our students.</p><p><strong>Q:</strong> What kind of content should course developers be incorporating?</p><p><strong>A:</strong> One, giving them a checklist of questions in the beginning. Where did this data came from? Who were the observers? Who were the doctors and nurses who collected the data? And then learn a little bit about the landscape of those institutions. If it’s an ICU database, they need to ask who makes it to the ICU, and who doesn’t make it to the ICU, because that already introduces a sampling selection bias. If all the minority patients don’t even get admitted to the ICU because they cannot reach the ICU in time, then the models are not going to work for them. Truly, to me, 50 percent of the course content should really be understanding the data, if not more, because the modeling itself is easy once you understand the data.</p><p>Since 2014, the MIT Critical Data consortium has been organizing datathons (data “hackathons”) around the world. At these gatherings, doctors, nurses, other health care workers, and data scientists get together to comb through databases and try to examine health and disease in the local context. Textbooks and journal papers present diseases based on observations and trials involving a narrow demographic typically from countries with resources for research.&nbsp;</p><p>Our main objective now, what we want to teach them, is critical thinking skills. And the main ingredient for critical thinking is bringing together people with different backgrounds.</p><p>You cannot teach critical thinking in a room full of CEOs or in a room full of doctors. The environment is just not there. When we have datathons, we don’t even have to teach them how do you do critical thinking. As soon as you bring the right mix of people — and it’s not just coming from different backgrounds but from different generations — you don’t even have to tell them how to think critically. It just happens. The environment is right for that kind of thinking. So, we now tell our participants and our students, please, please do not start building any model unless you truly understand how the data came about, which patients made it into the database, what devices were used to measure, and are those devices consistently accurate across individuals?</p><p>When we have events around the world, we encourage them to look for data sets that are local, so that they are relevant. There’s resistance because they know that they will discover how bad their data sets are. We say that that’s fine. This is how you fix that. If you don’t know how bad they are, you’re going to continue collecting them in a very bad manner and they’re useless. You have to acknowledge that you’re not going to get it right the first time, and that’s perfectly fine. MIMIC (the Medical Information Marked for Intensive Care database built at Beth Israel Deaconess Medical Center) took a decade before we had a decent schema, and we only have a decent schema because people were telling us how bad MIMIC was.</p><p>We may not have the answers to all of these questions, but we can evoke something in people that helps them realize that there are so many problems in the data.&nbsp;I’m always thrilled to look at the blog posts from people who attended a datathon, who say that their world has changed. Now they’re more excited about the field because they realize the immense potential, but also the immense risk of harm if they don’t do this correctly.</p>"
        }
      ],
      "media_content": [
        {
          "url": "https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202506/MIT_AI-Health-Data-01.jpg?itok=1NaqOcQ2",
          "medium": "image",
          "type": "image/jpeg",
          "width": "390",
          "height": "260"
        }
      ],
      "media_credit": [
        {
          "content": "Credit: iStock"
        }
      ],
      "credit": "Credit: iStock",
      "tags": [
        {
          "term": "Interview",
          "scheme": "https://news.mit.edu/topic/interview",
          "label": null
        },
        {
          "term": "Staff",
          "scheme": "https://news.mit.edu/topic/staff",
          "label": null
        },
        {
          "term": "Research",
          "scheme": "https://news.mit.edu/topic/research",
          "label": null
        },
        {
          "term": "Artificial intelligence",
          "scheme": "https://news.mit.edu/topic/artificial-intelligence2",
          "label": null
        },
        {
          "term": "Medicine",
          "scheme": "https://news.mit.edu/topic/medicine",
          "label": null
        },
        {
          "term": "Health care",
          "scheme": "https://news.mit.edu/topic/health-care",
          "label": null
        },
        {
          "term": "Data",
          "scheme": "https://news.mit.edu/topic/data",
          "label": null
        },
        {
          "term": "Institute for Medical Engineering and Science (IMES)",
          "scheme": "https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0",
          "label": null
        },
        {
          "term": "School of Engineering",
          "scheme": "https://news.mit.edu/topic/school-engineering",
          "label": null
        }
      ]
    }
  ]
}